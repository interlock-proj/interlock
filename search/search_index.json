{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Interlock","text":"<p>CQRS and Event Sourcing made easy in Python.</p>"},{"location":"#what-is-interlock","title":"What is Interlock?","text":"<p>Interlock is a Python framework for building applications using Command Query Responsibility Segregation (CQRS) and Event Sourcing patterns. It provides:</p> <ul> <li>Aggregates: Domain objects that encapsulate business logic and emit events</li> <li>Commands: Explicit intent-driven messages that trigger state changes</li> <li>Queries: Typed messages that request data from read models</li> <li>Events: Immutable records of what happened in your system</li> <li>Projections: Build read models from events and serve queries</li> <li>Middleware: Cross-cutting concerns like logging, caching, and authorization</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install interlock\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from pydantic import BaseModel\nfrom uuid import UUID, uuid4\n\nfrom interlock.application import ApplicationBuilder, Projection\nfrom interlock.domain import Aggregate, Command, Query\nfrom interlock.routing import handles_command, applies_event, handles_event, handles_query\n\n\n# 1. Define commands (intent to change) and queries (request data)\nclass DepositMoney(Command[None]):\n    amount: int\n\nclass GetBalance(Query[int]):\n    pass\n\n\n# 2. Define event data (what happened)\nclass MoneyDeposited(BaseModel):\n    amount: int\n\n\n# 3. Define an aggregate (write side - business logic)\nclass BankAccount(Aggregate):\n    balance: int = 0\n\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        if command.amount &lt;= 0:\n            raise ValueError(\"Amount must be positive\")\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @applies_event\n    def apply_deposit(self, event: MoneyDeposited) -&gt; None:\n        self.balance += event.amount\n\n\n# 4. Define a projection (read side - query handling)\nclass BalanceProjection(Projection):\n    def __init__(self):\n        super().__init__()\n        self.balances: dict[UUID, int] = {}\n\n    @handles_event\n    async def on_deposit(self, event: MoneyDeposited, aggregate_id: UUID) -&gt; None:\n        self.balances[aggregate_id] = self.balances.get(aggregate_id, 0) + event.amount\n\n    @handles_query\n    async def get_balance(self, query: GetBalance, aggregate_id: UUID) -&gt; int:\n        return self.balances.get(aggregate_id, 0)\n\n\n# 5. Build and run the application\nasync def main():\n    app = (\n        ApplicationBuilder()\n        .register_aggregate(BankAccount)\n        .register_projection(BalanceProjection)\n        .build()\n    )\n\n    async with app:\n        account_id = uuid4()\n\n        # Write: dispatch commands\n        await app.dispatch(DepositMoney(aggregate_id=account_id, amount=100))\n\n        # Read: dispatch queries\n        balance = await app.query(GetBalance(account_id=account_id))\n        print(f\"Balance: ${balance}\")  # Balance: $100\n\n\n# Run with: asyncio.run(main())\n</code></pre> <ul> <li> <p> Quick to set up</p> <p>Install with pip and get started in minutes with intuitive APIs</p> <p> Getting started</p> </li> <li> <p> Learn step by step</p> <p>Follow our FastAPI-style tutorial to build your first event-sourced app</p> <p> Tutorial</p> </li> <li> <p> Understand the concepts</p> <p>Deep dive into CQRS, Event Sourcing, and domain-driven design</p> <p> Concepts</p> </li> <li> <p> API Reference</p> <p>Auto-generated documentation for all modules and classes</p> <p> Reference</p> </li> </ul>"},{"location":"concepts/","title":"Concepts","text":"<p>This section provides in-depth explanations of the patterns and principles behind Interlock.</p>"},{"location":"concepts/#core-patterns","title":"Core Patterns","text":"<ul> <li> <p> Event Sourcing</p> <p>Store state as a sequence of events rather than current values. Enables complete audit trails, temporal queries, and rebuilding state from history.</p> <p> Learn about Event Sourcing</p> </li> <li> <p> CQRS</p> <p>Separate read and write models to optimize each for its purpose. Scale reads and writes independently.</p> <p> Learn about CQRS</p> </li> </ul> <p>Separate but Complementary</p> <p>Event Sourcing and CQRS are independent patterns that work exceptionally well together. Interlock combines both to give you a cohesive programming model\u2014aggregates use Event Sourcing for the write side, while Event Processors build read models for the query side.</p>"},{"location":"concepts/#building-blocks","title":"Building Blocks","text":"<ul> <li> <p> Aggregates</p> <p>Domain objects that maintain consistency boundaries and emit events</p> <p> Learn about Aggregates</p> </li> <li> <p> Commands</p> <p>Messages that express intent to change state</p> <p> Learn about Commands</p> </li> <li> <p> Queries</p> <p>Messages that request data without changing state</p> <p> Learn about Queries</p> </li> <li> <p> Events</p> <p>Immutable records of things that happened</p> <p> Learn about Events</p> </li> <li> <p> Event Processors</p> <p>Components that react to events for side effects and integrations</p> <p> Learn about Event Processors</p> </li> <li> <p> Projections</p> <p>Read models that handle events and serve typed queries</p> <p> Learn about Projections</p> </li> </ul>"},{"location":"concepts/#how-they-fit-together","title":"How They Fit Together","text":"<pre><code>flowchart LR\n    subgraph \"Write Side\"\n        CMD[Commands] --&gt; AGG[Aggregates]\n        AGG --&gt; EVT[Events]\n    end\n\n    EVT --&gt; STORE[(Event Store)]\n    STORE --&gt; PROJ[Projections]\n\n    subgraph \"Read Side\"\n        QRY[Queries] --&gt; PROJ\n        PROJ --&gt; RES[Responses]\n    end</code></pre> <ol> <li>Commands express user intent (\"deposit $100\")</li> <li>Aggregates validate business rules and emit events</li> <li>Events are persisted to the event store</li> <li>Projections consume events to build read models</li> <li>Queries request data from projections, which return typed responses</li> </ol>"},{"location":"concepts/#why-these-patterns","title":"Why These Patterns?","text":"Benefit How Interlock Delivers It Complete audit trail Every change is recorded as an event Temporal queries Query your system at any point in time Scalability Read and write sides scale independently Flexibility Build multiple read models from the same events Debugging Replay events to understand how state evolved Resilience Rebuild state from events after failures"},{"location":"concepts/aggregates/","title":"Aggregates","text":"<p>An aggregate is a cluster of domain objects treated as a single unit for data changes. Originating from Domain-Driven Design, aggregates are the core building blocks for modeling business domains in event-sourced systems.</p>"},{"location":"concepts/aggregates/#the-problem-consistency-in-complex-domains","title":"The Problem: Consistency in Complex Domains","text":"<p>Real-world domains have complex relationships. Consider a shopping cart:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             Shopping Cart               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  - items: [Item, Item, Item]            \u2502\n\u2502  - customer: Customer                   \u2502\n\u2502  - shipping_address: Address            \u2502\n\u2502  - applied_coupon: Coupon               \u2502\n\u2502  - calculated_total: Money              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>When adding an item, multiple things must happen atomically:</p> <ol> <li>Validate the item is in stock</li> <li>Add item to the list</li> <li>Recalculate the total</li> <li>Check if the coupon still applies</li> <li>Update the shipping cost</li> </ol> <p>If any step fails or executes partially, the cart is left in an inconsistent state. How do we ensure all-or-nothing changes?</p>"},{"location":"concepts/aggregates/#the-solution-consistency-boundaries","title":"The Solution: Consistency Boundaries","text":"<p>An aggregate defines a consistency boundary\u2014a scope within which all invariants must hold after every operation. The aggregate root is the single entry point for all modifications.</p> <pre><code>flowchart TB\n    subgraph Aggregate[\"ShoppingCart Aggregate\"]\n        ROOT[ShoppingCart&lt;br/&gt;Aggregate Root]\n        ITEMS[CartItems]\n        TOTAL[CalculatedTotal]\n        COUPON[AppliedCoupon]\n        ROOT --&gt; ITEMS\n        ROOT --&gt; TOTAL\n        ROOT --&gt; COUPON\n    end\n\n    CLIENT[Client Code] --&gt;|Commands| ROOT\n    ROOT --&gt;|Events| OUT[Event Store]\n\n    style ROOT fill:#e8f5e9\n    style Aggregate fill:#f5f5f5</code></pre> <p>Key principles:</p> <ul> <li>Single entry point: All changes go through the aggregate root</li> <li>Internal consistency: Invariants are checked on every change</li> <li>Transactional boundary: One aggregate per transaction</li> <li>Reference by ID: Aggregates reference others by ID, not direct object reference</li> </ul>"},{"location":"concepts/aggregates/#anatomy-of-an-aggregate","title":"Anatomy of an Aggregate","text":"<p>In Interlock, aggregates extend the <code>Aggregate</code> base class:</p> <pre><code>from interlock.domain import Aggregate, Command, Event\nfrom interlock.routing import handles_command, applies_event\nfrom pydantic import BaseModel\nfrom uuid import UUID, uuid4\n\n# Commands - express intent\nclass DepositMoney(Command):\n    amount: int\n\nclass WithdrawMoney(Command):\n    amount: int\n\n# Event data - what happened\nclass MoneyDeposited(BaseModel):\n    amount: int\n\nclass MoneyWithdrawn(BaseModel):\n    amount: int\n\n# The aggregate\nclass BankAccount(Aggregate):\n    owner_name: str = \"\"\n    balance: int = 0\n    is_closed: bool = False\n\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        if self.is_closed:\n            raise ValueError(\"Cannot deposit to closed account\")\n        if command.amount &lt;= 0:\n            raise ValueError(\"Amount must be positive\")\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @handles_command\n    async def withdraw(self, command: WithdrawMoney) -&gt; None:\n        if self.is_closed:\n            raise ValueError(\"Cannot withdraw from closed account\")\n        if command.amount &gt; self.balance:\n            raise ValueError(\"Insufficient funds\")\n        self.emit(MoneyWithdrawn(amount=command.amount))\n\n    @applies_event\n    def apply_deposit(self, event: MoneyDeposited) -&gt; None:\n        self.balance += event.amount\n\n    @applies_event\n    def apply_withdrawal(self, event: MoneyWithdrawn) -&gt; None:\n        self.balance -= event.amount\n</code></pre>"},{"location":"concepts/aggregates/#built-in-properties","title":"Built-in Properties","text":"<p>Every aggregate automatically includes:</p> Property Type Description <code>id</code> <code>UUID</code> Unique identifier (auto-generated) <code>version</code> <code>int</code> Incremented with each event (for concurrency control) <code>uncommitted_events</code> <code>list</code> Events emitted but not yet persisted"},{"location":"concepts/aggregates/#command-handlers","title":"Command Handlers","text":"<p>Command handlers validate business rules and emit events. They're marked with <code>@handles_command</code> and identified by their type annotation:</p> <pre><code>@handles_command\nasync def deposit(self, command: DepositMoney) -&gt; None:\n    # 1. Validate invariants\n    if self.is_closed:\n        raise ValueError(\"Cannot deposit to closed account\")\n    if command.amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n\n    # 2. Emit event (don't mutate state directly!)\n    self.emit(MoneyDeposited(amount=command.amount))\n</code></pre> <p>Don't Mutate State in Handlers</p> <p>Command handlers should never directly modify state. They validate and emit events. The <code>@applies_event</code> methods handle state changes\u2014this ensures state can be reconstructed from events.</p>"},{"location":"concepts/aggregates/#handler-discovery","title":"Handler Discovery","text":"<p>Interlock discovers handlers through:</p> <ol> <li>The <code>@handles_command</code> decorator</li> <li>The type annotation on the command parameter</li> </ol> <p>The method name doesn't matter\u2014only the type annotation:</p> <pre><code># Both work identically\n@handles_command\nasync def deposit(self, command: DepositMoney) -&gt; None: ...\n\n@handles_command\nasync def handle_deposit_money(self, command: DepositMoney) -&gt; None: ...\n</code></pre>"},{"location":"concepts/aggregates/#event-appliers","title":"Event Appliers","text":"<p>Event appliers update the aggregate's state. They must be pure\u2014no side effects, no I/O, no exceptions:</p> <pre><code>@applies_event\ndef apply_deposit(self, event: MoneyDeposited) -&gt; None:\n    self.balance += event.amount\n\n@applies_event\ndef apply_withdrawal(self, event: MoneyWithdrawn) -&gt; None:\n    self.balance -= event.amount\n</code></pre> <p>Event appliers are called in two scenarios:</p> <ol> <li>During command handling: After <code>emit()</code>, the event is immediately applied</li> <li>During reconstruction: When loading an aggregate from the event store</li> </ol> <p>Keep Appliers Simple</p> <p>Event appliers should be simple state assignments. Complex logic belongs in command handlers where you can validate and reject invalid operations.</p>"},{"location":"concepts/aggregates/#aggregate-lifecycle","title":"Aggregate Lifecycle","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant App as Application\n    participant Store as Event Store\n    participant Agg as Aggregate\n\n    Client-&gt;&gt;App: dispatch(DepositMoney)\n    App-&gt;&gt;Store: Load events for aggregate_id\n    Store--&gt;&gt;App: [Event1, Event2, ...]\n    App-&gt;&gt;Agg: Create + replay events\n    Note over Agg: State reconstructed\n    App-&gt;&gt;Agg: handle(command)\n    Agg-&gt;&gt;Agg: Validate\n    Agg-&gt;&gt;Agg: emit(MoneyDeposited)\n    Agg-&gt;&gt;Agg: apply(MoneyDeposited)\n    App-&gt;&gt;Store: Append new events\n    App--&gt;&gt;Client: Success</code></pre>"},{"location":"concepts/aggregates/#design-guidelines","title":"Design Guidelines","text":""},{"location":"concepts/aggregates/#keep-aggregates-small","title":"Keep Aggregates Small","text":"<p>Large aggregates increase contention and make it harder to maintain consistency. Split them when:</p> <ul> <li>Parts change at different rates</li> <li>Different users modify different parts</li> <li>You're experiencing concurrency conflicts</li> </ul> <pre><code># Too large - users and orders change independently\nclass Customer(Aggregate):\n    name: str\n    email: str\n    orders: list[Order]  # Could be thousands!\n    preferences: Preferences\n    payment_methods: list[PaymentMethod]\n\n# Better - separate aggregates\nclass CustomerProfile(Aggregate):\n    name: str\n    email: str\n    preferences: Preferences\n\nclass Order(Aggregate):\n    customer_id: UUID  # Reference by ID\n    items: list[OrderItem]\n    status: OrderStatus\n</code></pre>"},{"location":"concepts/aggregates/#one-aggregate-per-transaction","title":"One Aggregate Per Transaction","text":"<p>Modify only one aggregate per command. Cross-aggregate operations use Sagas:</p> <pre><code># Wrong - modifying multiple aggregates\nasync def transfer(self, command: TransferMoney) -&gt; None:\n    source_account.withdraw(command.amount)  # \u274c\n    target_account.deposit(command.amount)   # \u274c\n\n# Right - emit an event, let a saga coordinate\nasync def initiate_transfer(self, command: InitiateTransfer) -&gt; None:\n    self.emit(TransferInitiated(\n        to_account=command.to_account,\n        amount=command.amount\n    ))\n</code></pre>"},{"location":"concepts/aggregates/#reference-by-id","title":"Reference by ID","text":"<p>Aggregates should never hold direct references to other aggregates:</p> <pre><code># Wrong - direct reference creates implicit coupling\nclass Order(Aggregate):\n    customer: Customer  # \u274c\n\n# Right - reference by ID\nclass Order(Aggregate):\n    customer_id: UUID  # \u2713\n</code></pre>"},{"location":"concepts/aggregates/#protect-invariants","title":"Protect Invariants","text":"<p>The aggregate is the guardian of its invariants. Reject invalid operations:</p> <pre><code>@handles_command\nasync def withdraw(self, command: WithdrawMoney) -&gt; None:\n    # Invariant: balance must never go negative\n    if command.amount &gt; self.balance:\n        raise InsufficientFundsError(\n            f\"Cannot withdraw {command.amount}, balance is {self.balance}\"\n        )\n    self.emit(MoneyWithdrawn(amount=command.amount))\n</code></pre>"},{"location":"concepts/aggregates/#optimistic-concurrency","title":"Optimistic Concurrency","text":"<p>Interlock uses the aggregate's <code>version</code> field for optimistic concurrency control:</p> <ol> <li>Load aggregate (version = 5)</li> <li>Handle command, emit events</li> <li>Try to save with expected version = 5</li> <li>If actual version \u2260 5, raise <code>ConcurrencyError</code></li> </ol> <pre><code>sequenceDiagram\n    participant P1 as Process 1\n    participant P2 as Process 2\n    participant Store as Event Store\n\n    P1-&gt;&gt;Store: Load account (v=5)\n    P2-&gt;&gt;Store: Load account (v=5)\n    P1-&gt;&gt;P1: Withdraw $100\n    P2-&gt;&gt;P2: Withdraw $50\n    P1-&gt;&gt;Store: Save events (expect v=5)\n    Store--&gt;&gt;P1: Success (v=6)\n    P2-&gt;&gt;Store: Save events (expect v=5)\n    Store--xP2: ConcurrencyError (v=6 \u2260 5)</code></pre> <p>This prevents lost updates when multiple processes modify the same aggregate.</p>"},{"location":"concepts/aggregates/#handling-concurrencyerror-manually","title":"Handling ConcurrencyError Manually","text":"<p>You can catch and handle concurrency errors explicitly:</p> <pre><code>from interlock.domain import ConcurrencyError\n\ntry:\n    await app.dispatch(WithdrawMoney(aggregate_id=account_id, amount=100))\nexcept ConcurrencyError:\n    # Another process modified the aggregate\n    # Options: retry, fail, notify user, etc.\n    pass\n</code></pre>"},{"location":"concepts/aggregates/#concurrencyretrymiddleware","title":"ConcurrencyRetryMiddleware","text":"<p>For automatic retry on conflicts, use <code>ConcurrencyRetryMiddleware</code>:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.commands import ConcurrencyRetryMiddleware\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_middleware(\n        lambda: ConcurrencyRetryMiddleware(\n            max_attempts=3,    # Total attempts (1 initial + 2 retries)\n            retry_delay=0.1    # Seconds between retries\n        )\n    )\n    .build()\n)\n</code></pre> <p>When a <code>ConcurrencyError</code> occurs, the middleware:</p> <ol> <li>Catches the error</li> <li>Waits for <code>retry_delay</code> seconds</li> <li>Re-dispatches the command (which reloads the aggregate with fresh state)</li> <li>Repeats up to <code>max_attempts</code> times</li> <li>Raises <code>ConcurrencyError</code> if all attempts fail</li> </ol> <pre><code>flowchart TB\n    CMD[Command] --&gt; TRY{Try Processing}\n    TRY --&gt;|Success| DONE[Done \u2713]\n    TRY --&gt;|ConcurrencyError| CHECK{Attempts&lt;br/&gt;Remaining?}\n    CHECK --&gt;|Yes| WAIT[Wait retry_delay]\n    WAIT --&gt; TRY\n    CHECK --&gt;|No| FAIL[Raise ConcurrencyError]</code></pre> <p>When to Use Automatic Retry</p> <p>Automatic retry works well when:</p> <ul> <li>Conflicts are rare and transient</li> <li>Commands are idempotent or the aggregate validates state</li> <li>A brief delay is acceptable</li> </ul> <p>Avoid automatic retry when:</p> <ul> <li>Conflicts indicate a design problem (aggregate too large)</li> <li>Commands have external side effects before emitting events</li> <li>You need user confirmation before retry</li> </ul>"},{"location":"concepts/aggregates/#retry-and-idempotency-together","title":"Retry and Idempotency Together","text":"<p>For robust command handling, combine retry with idempotency:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    # Order matters: idempotency check happens before retry\n    .register_middleware(IdempotencyMiddleware)\n    .register_middleware(\n        lambda: ConcurrencyRetryMiddleware(max_attempts=3, retry_delay=0.1)\n    )\n    .build()\n)\n</code></pre> <p>This ensures:</p> <ol> <li>Duplicate commands are rejected (idempotency)</li> <li>Transient conflicts are retried (concurrency)</li> <li>Persistent conflicts surface as errors</li> </ol>"},{"location":"concepts/aggregates/#testing-aggregates","title":"Testing Aggregates","text":"<p>Use <code>AggregateScenario</code> for behavior-driven testing:</p> <pre><code>from interlock.testing import AggregateScenario\n\nasync def test_cannot_overdraw():\n    async with AggregateScenario(BankAccount) as scenario:\n        await scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .when(WithdrawMoney(aggregate_id=scenario.aggregate_id, amount=150)) \\\n            .should_raise(ValueError, \"Insufficient funds\")\n\nasync def test_successful_withdrawal():\n    async with AggregateScenario(BankAccount) as scenario:\n        await scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .when(WithdrawMoney(aggregate_id=scenario.aggregate_id, amount=50)) \\\n            .should_emit(MoneyWithdrawn(amount=50)) \\\n            .should_have_state(lambda a: a.balance == 50)\n</code></pre>"},{"location":"concepts/aggregates/#further-reading","title":"Further Reading","text":"<ul> <li>Tutorial: Your First Aggregate \u2014 Hands-on introduction</li> <li>Commands \u2014 Messages that express intent</li> <li>Events \u2014 Immutable records of state changes</li> <li>Event Sourcing \u2014 How aggregates persist state</li> <li>Sagas \u2014 Coordinating multiple aggregates</li> </ul>"},{"location":"concepts/commands/","title":"Commands","text":"<p>A command is a message that expresses an intent to perform an action. Commands are the entry point for all state changes in a CQRS system\u2014they represent what a user or system wants to happen.</p>"},{"location":"concepts/commands/#commands-vs-direct-mutation","title":"Commands vs Direct Mutation","text":"<p>In traditional applications, we often mutate state directly:</p> <pre><code># Direct mutation - hard to track, audit, or intercept\naccount.balance += 100\naccount.save()\n</code></pre> <p>With commands, we express intent:</p> <pre><code># Command - declarative, interceptable, auditable\nawait app.dispatch(DepositMoney(\n    aggregate_id=account_id,\n    amount=100\n))\n</code></pre> <p>This indirection enables:</p> <ul> <li>Validation before changes occur</li> <li>Authorization checks via middleware</li> <li>Audit trails of all attempted operations</li> <li>Retry logic for failed operations</li> <li>Async processing and queuing</li> </ul>"},{"location":"concepts/commands/#defining-commands","title":"Defining Commands","text":"<p>Commands in Interlock extend the <code>Command</code> base class. Commands are generic over  their response type:</p> <pre><code>from interlock.domain import Command\nfrom uuid import UUID, uuid4\n\nclass CreateAccount(Command[UUID]):\n    \"\"\"Create a new bank account, returning its ID.\"\"\"\n    owner: str\n\nclass DepositMoney(Command[None]):\n    \"\"\"Deposit money into a bank account.\"\"\"\n    amount: int\n\nclass WithdrawMoney(Command[None]):\n    \"\"\"Withdraw money from a bank account.\"\"\"\n    amount: int\n\nclass TransferMoney(Command[None]):\n    \"\"\"Transfer money between accounts.\"\"\"\n    to_account_id: UUID\n    amount: int\n</code></pre> <p>The type parameter (<code>[UUID]</code>, <code>[None]</code>) indicates what the command handler returns.  Use <code>Command[None]</code> for commands that don't return a value.</p>"},{"location":"concepts/commands/#required-fields","title":"Required Fields","text":"<p>Every command automatically includes these fields:</p> Field Type Description <code>aggregate_id</code> <code>UUID</code> Target aggregate for this command <code>command_id</code> <code>UUID</code> Unique identifier (auto-generated) <code>correlation_id</code> <code>UUID \\| None</code> Links related operations <code>causation_id</code> <code>UUID \\| None</code> What triggered this command <p>The <code>aggregate_id</code> is required when creating a command\u2014it identifies which aggregate should handle it:</p> <pre><code># aggregate_id is required\ncommand = DepositMoney(\n    aggregate_id=uuid4(),  # Which account to deposit to\n    amount=100\n)\n\n# command_id is auto-generated\nprint(command.command_id)  # 01HXYZ...\n</code></pre>"},{"location":"concepts/commands/#naming-conventions","title":"Naming Conventions","text":"<p>Commands should be named in the imperative mood\u2014they're instructions:</p> \u2713 Good (Imperative) \u2717 Bad <code>CreateAccount</code> <code>AccountCreation</code> <code>DepositMoney</code> <code>MoneyDeposited</code> <code>CancelOrder</code> <code>OrderCancellation</code> <code>SendInvitation</code> <code>InvitationSent</code> <p>The imperative form makes intent clear: this is something we want to do, not something that happened (that's an event).</p>"},{"location":"concepts/commands/#commands-vs-events","title":"Commands vs Events","text":"<p>Commands and events are both messages, but serve different purposes:</p> Aspect Commands Events Tense Imperative (do this) Past tense (this happened) Intent Request a change Record a fact Outcome May succeed or fail Already happened Handlers Exactly one Zero or many Mutability Can be rejected/modified Immutable forever <pre><code># Command - a request that might fail\nclass WithdrawMoney(Command):\n    amount: int\n\n# Event - a fact that happened\nclass MoneyWithdrawn(BaseModel):\n    amount: int\n</code></pre>"},{"location":"concepts/commands/#dispatching-commands","title":"Dispatching Commands","text":"<p>Send commands through the application:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .build()\n)\n\nasync with app:\n    # Dispatch a command (returns the command's declared response type)\n    account_id = await app.dispatch(CreateAccount(\n        aggregate_id=uuid4(),  # Pre-generated ID\n        owner=\"Alice\"\n    ))\n\n    # Command[None] returns None\n    await app.dispatch(DepositMoney(\n        aggregate_id=account_id,\n        amount=100\n    ))\n</code></pre>"},{"location":"concepts/commands/#what-happens-during-dispatch","title":"What Happens During Dispatch","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant App as Application\n    participant MW as Middleware\n    participant Agg as Aggregate\n    participant Store as Event Store\n\n    Client-&gt;&gt;App: dispatch(DepositMoney)\n    App-&gt;&gt;MW: Pass through middleware chain\n    MW-&gt;&gt;MW: Validate, authorize, log...\n    MW-&gt;&gt;App: Continue\n    App-&gt;&gt;Store: Load aggregate events\n    Store--&gt;&gt;App: Events\n    App-&gt;&gt;Agg: Reconstruct from events\n    App-&gt;&gt;Agg: handle(command)\n    Agg-&gt;&gt;Agg: Validate &amp; emit events\n    App-&gt;&gt;Store: Persist new events\n    App--&gt;&gt;Client: Success</code></pre>"},{"location":"concepts/commands/#validation","title":"Validation","text":"<p>Commands can fail validation at multiple levels:</p>"},{"location":"concepts/commands/#1-schema-validation-pydantic","title":"1. Schema Validation (Pydantic)","text":"<p>Type and constraint validation happens automatically:</p> <pre><code>class DepositMoney(Command):\n    amount: int = Field(gt=0)  # Must be positive\n\n# This raises ValidationError before dispatch\nDepositMoney(aggregate_id=uuid4(), amount=-100)\n</code></pre>"},{"location":"concepts/commands/#2-middleware-validation","title":"2. Middleware Validation","text":"<p>Cross-cutting validation in middleware:</p> <pre><code>from interlock.application.middleware import Middleware, Handler\n\nclass FraudDetectionMiddleware(Middleware):\n    @intercepts\n    async def check_large_deposits(\n        self, \n        command: DepositMoney, \n        next: Handler\n    ):\n        if command.amount &gt; 10000:\n            await self.fraud_service.flag_for_review(command)\n        return await next(command)\n</code></pre>"},{"location":"concepts/commands/#3-domain-validation","title":"3. Domain Validation","text":"<p>Business rules enforced by the aggregate:</p> <pre><code>@handles_command\nasync def withdraw(self, command: WithdrawMoney) -&gt; None:\n    if command.amount &gt; self.balance:\n        raise InsufficientFundsError()\n    self.emit(MoneyWithdrawn(amount=command.amount))\n</code></pre>"},{"location":"concepts/commands/#command-routing","title":"Command Routing","text":"<p>Interlock routes commands to aggregates through a two-step process:</p> <ol> <li>Find the aggregate type: Based on which aggregate has a handler for this command type</li> <li>Load the aggregate instance: Using the <code>aggregate_id</code> from the command</li> </ol> <pre><code>class BankAccount(Aggregate):\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        # This handler tells Interlock that DepositMoney\n        # should be routed to BankAccount\n        ...\n</code></pre>"},{"location":"concepts/commands/#multiple-aggregates","title":"Multiple Aggregates","text":"<p>Different commands route to different aggregates:</p> <pre><code>class BankAccount(Aggregate):\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None: ...\n\nclass CreditCard(Aggregate):\n    @handles_command\n    async def charge(self, command: ChargeCreditCard) -&gt; None: ...\n\n# Commands route to the correct aggregate\nawait app.dispatch(DepositMoney(...))      # \u2192 BankAccount\nawait app.dispatch(ChargeCreditCard(...))  # \u2192 CreditCard\n</code></pre>"},{"location":"concepts/commands/#correlation-and-causation","title":"Correlation and Causation","text":"<p>Commands support distributed tracing through correlation and causation IDs:</p> <pre><code># Initial command from user action\ninitial_command = CreateOrder(\n    aggregate_id=order_id,\n    items=[...],\n    correlation_id=uuid4()  # Start of the trace\n)\n\n# Later, a saga dispatches a related command\nawait command_bus.dispatch(ChargePayment(\n    aggregate_id=payment_id,\n    amount=order.total,\n    correlation_id=initial_command.correlation_id,  # Same trace\n    causation_id=initial_command.command_id  # What caused this\n))\n</code></pre> <p>This enables:</p> <ul> <li>Tracing: Follow a logical operation across services</li> <li>Debugging: Understand causal chains when things go wrong</li> <li>Auditing: See exactly what triggered what</li> </ul>"},{"location":"concepts/commands/#idempotency","title":"Idempotency","text":"<p>In distributed systems, commands can be delivered more than once due to:</p> <ul> <li>Network retries</li> <li>Message queue redelivery</li> <li>Client-side retry logic</li> <li>Load balancer failovers</li> </ul> <p>Without idempotency protection, a <code>DepositMoney</code> command retried twice could double the deposit. Interlock provides built-in idempotency support through middleware and pluggable storage backends.</p>"},{"location":"concepts/commands/#idempotency-keys","title":"Idempotency Keys","text":"<p>Add an <code>idempotency_key</code> field or property to any command to enable idempotency tracking:</p> <pre><code>from interlock.domain import Command\n\n# Option 1: Field-based key (client provides explicitly)\nclass DepositMoney(Command):\n    \"\"\"A deposit that can only be processed once.\"\"\"\n    amount: int\n    idempotency_key: str  # Required for idempotency\n\n# Create with an explicit idempotency key\ncommand = DepositMoney(\n    aggregate_id=account_id,\n    amount=100,\n    idempotency_key=\"deposit-abc-123\"  # Client-provided key\n)\n</code></pre> <pre><code># Option 2: Property-based key (computed from command data)\nclass TransferMoney(Command):\n    \"\"\"A transfer that derives its idempotency key from its parameters.\"\"\"\n    from_account: UUID\n    to_account: UUID\n    amount: int\n\n    @property\n    def idempotency_key(self) -&gt; str:\n        # Same transfer attempt always produces the same key\n        return f\"{self.from_account}-{self.to_account}-{self.amount}\"\n</code></pre> <p>The <code>idempotency_key</code> can be a field (explicit) or a property (computed). Common strategies:</p> Strategy Example Use When Request ID <code>\"req-a1b2c3\"</code> Each API request has a unique ID Transaction reference <code>\"txn-20240115-001\"</code> External systems provide references Computed from data <code>f\"{user}-{amount}-{date}\"</code> Dedupe based on operation content UUID from client <code>str(uuid4())</code> Client generates before submission"},{"location":"concepts/commands/#idempotencymiddleware","title":"IdempotencyMiddleware","text":"<p>The <code>IdempotencyMiddleware</code> intercepts commands that have an <code>idempotency_key</code> and checks if they've been processed:</p> <pre><code>flowchart LR\n    CMD[Command] --&gt; CHK{Has&lt;br/&gt;idempotency_key?}\n    CHK --&gt;|No| PROC[Process Command]\n    CHK --&gt;|Yes| MW{Check&lt;br/&gt;Storage}\n    MW --&gt;|New key| PROC\n    MW --&gt;|Seen key| SKIP[Skip Silently]\n    PROC --&gt; STORE[Store Key]</code></pre> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.commands import (\n    IdempotencyMiddleware,\n    IdempotencyStorageBackend,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(\n        IdempotencyStorageBackend,\n        IdempotencyStorageBackend.in_memory  # Or a persistent backend\n    )\n    .register_middleware(IdempotencyMiddleware)\n    .build()\n)\n</code></pre> <p>When a command with a previously-seen <code>idempotency_key</code> arrives, the middleware:</p> <ol> <li>Detects the duplicate</li> <li>Logs a warning</li> <li>Returns successfully (without processing)</li> </ol> <p>Commands without an <code>idempotency_key</code> attribute pass through unchanged.</p>"},{"location":"concepts/commands/#storage-backends","title":"Storage Backends","text":"<p>The <code>IdempotencyStorageBackend</code> interface is pluggable. Interlock provides:</p> <ul> <li><code>IdempotencyStorageBackend.in_memory()</code> \u2014 For testing and development</li> <li><code>IdempotencyStorageBackend.null()</code> \u2014 Disables idempotency (always processes)</li> </ul> <p>For production, you'll want a persistent backend. See the Database Integrations guide for available implementations.</p>"},{"location":"concepts/commands/#failure-handling","title":"Failure Handling","text":"<p>The middleware stores the key after successful processing:</p> <pre><code># Pseudocode of middleware behavior\nasync def ensure_idempotency(self, command, next):\n    # Commands without idempotency_key pass through\n    if not hasattr(command, 'idempotency_key'):\n        await next(command)\n        return\n\n    if await backend.has_idempotency_key(command.idempotency_key):\n        return  # Skip duplicate\n\n    await next(command)  # Process (may raise)\n\n    # Only stored if processing succeeded\n    await backend.store_idempotency_key(command.idempotency_key)\n</code></pre> <p>This means:</p> <ul> <li>\u2713 If processing fails, the key is NOT stored \u2192 retry is allowed</li> <li>\u2713 If processing succeeds, the key IS stored \u2192 retries are blocked</li> <li>\u26a0\ufe0f If storage fails after processing, you may get a duplicate on retry</li> </ul>"},{"location":"concepts/commands/#commands-without-idempotency","title":"Commands Without Idempotency","text":"<p>Commands without an <code>idempotency_key</code> bypass idempotency checking entirely:</p> <pre><code># No idempotency_key - each dispatch is processed\nclass DepositMoney(Command):\n    amount: int\n\nawait app.dispatch(DepositMoney(aggregate_id=id, amount=100))\nawait app.dispatch(DepositMoney(aggregate_id=id, amount=100))\n# Both deposits are processed - balance increases by 200\n</code></pre> <p>Add <code>idempotency_key</code> to your commands when:</p> <ul> <li>Commands arrive via unreliable transports (webhooks, queues)</li> <li>Clients may retry on timeout</li> <li>The operation should only happen once per logical request</li> </ul>"},{"location":"concepts/commands/#best-practices","title":"Best Practices","text":""},{"location":"concepts/commands/#be-specific","title":"Be Specific","text":"<p>Prefer specific commands over generic ones:</p> <pre><code># Too generic - loses intent\nclass UpdateAccount(Command):\n    changes: dict\n\n# Specific - clear intent\nclass ChangeAccountEmail(Command):\n    new_email: str\n\nclass CloseAccount(Command):\n    reason: str\n</code></pre>"},{"location":"concepts/commands/#include-necessary-context","title":"Include Necessary Context","text":"<p>Commands should carry all information needed to process them:</p> <pre><code># Missing context - handler needs to look up user\nclass ApproveOrder(Command):\n    pass  # Who approved it? When?\n\n# Complete context\nclass ApproveOrder(Command):\n    approved_by: UUID\n    approval_notes: str | None = None\n</code></pre>"},{"location":"concepts/commands/#dont-include-derived-data","title":"Don't Include Derived Data","text":"<p>Let the domain compute derived values:</p> <pre><code># Wrong - client computed the new balance\nclass DepositMoney(Command):\n    amount: int\n    new_balance: int  # \u274c Don't trust client calculations\n\n# Right - aggregate computes the new balance\nclass DepositMoney(Command):\n    amount: int  # \u2713 Just the deposit amount\n</code></pre>"},{"location":"concepts/commands/#further-reading","title":"Further Reading","text":"<ul> <li>Tutorial: Commands &amp; Handlers \u2014 Hands-on guide</li> <li>Aggregates \u2014 Where commands are handled</li> <li>Events \u2014 What commands produce</li> <li>Custom Middleware \u2014 Intercepting commands</li> </ul>"},{"location":"concepts/cqrs/","title":"CQRS","text":"<p>Command Query Responsibility Segregation (CQRS) is a pattern that uses different models for reading and writing information. First described by Greg Young and popularized in the Domain-Driven Design community, CQRS can be valuable for complex domains\u2014but it adds significant complexity that isn't warranted for most systems.</p> <p>Further Reading</p> <p>For an in-depth treatment of CQRS, see Martin Fowler's article on CQRS.</p>"},{"location":"concepts/cqrs/#beyond-crud","title":"Beyond CRUD","text":"<p>The mainstream approach for interacting with an information system is to treat it as a CRUD datastore\u2014Create, Read, Update, Delete. We have a mental model of records that we manipulate directly:</p> <pre><code># Traditional CRUD approach\nclass AccountRepository:\n    def create(self, account: Account) -&gt; None: ...\n    def read(self, id: str) -&gt; Account: ...\n    def update(self, account: Account) -&gt; None: ...\n    def delete(self, id: str) -&gt; None: ...\n</code></pre> <p>This works well for simple applications. But as systems grow sophisticated, tensions emerge:</p> <ul> <li>Multiple representations: Users see data through various presentations\u2014dashboards, reports, detail views\u2014each requiring different shapes of data</li> <li>Complex updates: Validation rules, derived data, and business logic make writes far more nuanced than simple record updates</li> <li>Different optimization needs: Reads often benefit from denormalization and caching, while writes need consistency guarantees</li> </ul> <p>The traditional approach forces a single conceptual model to serve both purposes. This model becomes a compromise that does neither well.</p>"},{"location":"concepts/cqrs/#the-core-idea","title":"The Core Idea","text":"<p>CQRS splits the conceptual model into separate models for commands (updates) and queries (reads):</p> <pre><code>flowchart TB\n    subgraph \"Write Side\"\n        CMD[Commands] --&gt; AGG[Aggregates]\n        AGG --&gt; EVT[Events]\n    end\n\n    EVT --&gt; SYNC[Synchronization]\n\n    subgraph \"Read Side\"\n        SYNC --&gt; PROJ[Projections]\n        PROJ --&gt; QUERY[Queries]\n    end\n\n    style CMD fill:#e8f5e9\n    style QUERY fill:#e3f2fd</code></pre>"},{"location":"concepts/cqrs/#write-side-command-model","title":"Write Side (Command Model)","text":"<p>The command model handles all state changes:</p> <ul> <li>Commands express intent: <code>DepositMoney</code>, <code>TransferFunds</code>, <code>CloseAccount</code></li> <li>Aggregates enforce business rules and emit events</li> <li>Events record what happened</li> </ul> <p>This side is optimized for consistency and business logic.</p>"},{"location":"concepts/cqrs/#read-side-query-model","title":"Read Side (Query Model)","text":"<p>The query model serves reads:</p> <ul> <li>Projections build read-optimized views from events</li> <li>Queries return data shaped for specific use cases</li> <li>Multiple projections can serve different needs</li> </ul> <p>This side is optimized for query performance and flexibility.</p>"},{"location":"concepts/cqrs/#variations","title":"Variations","text":"<p>CQRS allows considerable variation in implementation:</p>"},{"location":"concepts/cqrs/#shared-database","title":"Shared Database","text":"<p>The simplest form\u2014both models read from the same database, but use different object models:</p> <pre><code>flowchart LR\n    CMD[Command Model] --&gt; DB[(Database)]\n    DB --&gt; QRY[Query Model]</code></pre> <p>The command model writes; the query model reads with optimized queries or views.</p>"},{"location":"concepts/cqrs/#separate-databases","title":"Separate Databases","text":"<p>For higher performance or scale, the models can use separate databases:</p> <pre><code>flowchart LR\n    CMD[Command Model] --&gt; WDB[(Write DB)]\n    WDB --&gt; |Events| SYNC[Sync]\n    SYNC --&gt; RDB[(Read DB)]\n    RDB --&gt; QRY[Query Model]</code></pre> <p>This enables:</p> <ul> <li>Independent scaling of read and write workloads</li> <li>Read replicas optimized for specific query patterns</li> <li>Geographic distribution</li> </ul> <p>The trade-off is eventual consistency\u2014the read model lags slightly behind the write model.</p>"},{"location":"concepts/cqrs/#natural-companions","title":"Natural Companions","text":"<p>CQRS fits naturally with several architectural patterns:</p>"},{"location":"concepts/cqrs/#event-sourcing","title":"Event Sourcing","text":"<p>CQRS and Event Sourcing are separate but complementary patterns:</p> Pattern Core Idea CQRS Separate models for reads and writes Event Sourcing Store state as a sequence of events <p>You can use either pattern independently\u2014CQRS without Event Sourcing, or Event Sourcing without CQRS. However, they work exceptionally well together:</p> <ul> <li>Event Sourcing provides the events that update read models</li> <li>Events flow naturally from write side to read side</li> <li>The event log becomes the synchronization mechanism</li> <li>Rebuilding projections is as simple as replaying events</li> </ul> <p>Interlock's Approach</p> <p>Interlock combines both patterns to help you build robust applications. The write side uses Event Sourcing (aggregates emit events, state is reconstructed from event history), while the read side uses Event Processors to build projections\u2014a natural CQRS architecture. This gives you the benefits of both patterns with a cohesive programming model.</p>"},{"location":"concepts/cqrs/#task-based-uis","title":"Task-Based UIs","text":"<p>Moving away from CRUD encourages task-based interfaces:</p> <pre><code># CRUD-style (generic)\naccount.balance = account.balance + 100\naccount.save()\n\n# Task-based (intent-revealing)\nawait app.dispatch(DepositMoney(\n    aggregate_id=account_id,\n    amount=100,\n    source=\"ATM-1234\"\n))\n</code></pre> <p>Task-based UIs capture user intent, enabling richer business logic and better audit trails.</p>"},{"location":"concepts/cqrs/#eventual-consistency","title":"Eventual Consistency","text":"<p>With separate models, you must decide how consistent they need to be:</p> <ul> <li>Strong consistency: Slower, but reads always reflect latest writes</li> <li>Eventual consistency: Faster, but reads may be slightly stale</li> </ul> <p>Most CQRS systems embrace eventual consistency on the read side, since many use cases tolerate minor staleness.</p>"},{"location":"concepts/cqrs/#when-to-use-cqrs","title":"When to Use CQRS","text":"<p>Use With Caution</p> <p>CQRS is a significant mental leap for all concerned. Most systems fit a CRUD mental model and should be built that way. CQRS adds complexity that can reduce productivity and increase risk if misapplied.</p>"},{"location":"concepts/cqrs/#good-fit","title":"Good Fit","text":"<p>CQRS provides benefits when:</p> Scenario Why CQRS Helps Complex domain logic Write model focuses purely on business rules High read/write disparity Scale reads and writes independently Multiple read representations Build projections optimized for each view Collaborative domains Handle concurrent modifications gracefully Audit requirements Event-based updates provide complete history"},{"location":"concepts/cqrs/#poor-fit","title":"Poor Fit","text":"<p>Avoid CQRS when:</p> <ul> <li>Simple CRUD suffices: Most line-of-business applications</li> <li>Team unfamiliarity: The pattern requires experience to apply well</li> <li>Tight timelines: Learning curve can impact delivery</li> <li>Read/write similarity: When the same model works for both</li> </ul>"},{"location":"concepts/cqrs/#bounded-contexts","title":"Bounded Contexts","text":"<p>CQRS should apply to specific portions of a system, not the whole thing. In Domain-Driven Design terms, each Bounded Context makes its own modeling decisions:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Application                       \u2502\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Accounting    \u2502    \u2502      Reporting          \u2502 \u2502\n\u2502  \u2502     (CQRS)      \u2502    \u2502       (CRUD)            \u2502 \u2502\n\u2502  \u2502                 \u2502    \u2502                         \u2502 \u2502\n\u2502  \u2502 Complex domain  \u2502    \u2502 Simple queries,         \u2502 \u2502\n\u2502  \u2502 Audit needs     \u2502    \u2502 no business logic       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Notifications  \u2502    \u2502    User Management      \u2502 \u2502\n\u2502  \u2502     (Events)    \u2502    \u2502        (CRUD)           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/cqrs/#cqrs-in-interlock","title":"CQRS in Interlock","text":"<p>Interlock provides the building blocks for CQRS applications:</p>"},{"location":"concepts/cqrs/#write-side","title":"Write Side","text":"<pre><code>from interlock.domain import Aggregate, Command, Event\nfrom interlock.routing import handles_command, applies_event\n\nclass DepositMoney(Command):\n    amount: int\n\nclass MoneyDeposited(Event):\n    amount: int\n\nclass BankAccount(Aggregate):\n    balance: int = 0\n\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        if command.amount &lt;= 0:\n            raise ValueError(\"Amount must be positive\")\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @applies_event\n    def apply_deposit(self, event: MoneyDeposited) -&gt; None:\n        self.balance += event.amount\n</code></pre>"},{"location":"concepts/cqrs/#read-side","title":"Read Side","text":"<pre><code>from abc import ABC, abstractmethod\nfrom interlock.application import Projection\nfrom interlock.domain import Query\nfrom interlock.routing import handles_event, handles_query\n\n# Define repository interface (allows swapping storage backends)\nclass BalanceRepository(ABC):\n    @abstractmethod\n    async def get(self, account_id: UUID) -&gt; int: ...\n\n    @abstractmethod\n    async def save(self, account_id: UUID, balance: int) -&gt; None: ...\n\n# Query with typed response\nclass GetAccountBalance(Query[int]):\n    account_id: UUID\n\n# Projection with injected repository\nclass AccountBalanceProjection(Projection):\n    def __init__(self, repository: BalanceRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_deposit(self, event: MoneyDeposited) -&gt; None:\n        current = await self.repository.get(event.aggregate_id)\n        await self.repository.save(\n            event.aggregate_id, \n            current + event.amount\n        )\n\n    @handles_query\n    async def get_balance(self, query: GetAccountBalance) -&gt; int:\n        return await self.repository.get(query.account_id)\n</code></pre>"},{"location":"concepts/cqrs/#flexibility","title":"Flexibility","text":"<p>Interlock is opinionated about the write side (commands, aggregates, events) but  flexible about the read side:</p> <ul> <li>Use <code>Projection</code> for read models with typed queries</li> <li>Use <code>EventProcessor</code> for side effects (notifications, integrations)</li> <li>Inject any database or storage via dependency injection</li> <li>Mix synchronous and eventually-consistent reads</li> </ul>"},{"location":"concepts/cqrs/#summary","title":"Summary","text":"<p>CQRS separates your application into command and query models, enabling each to be optimized for its purpose. It's a powerful pattern for complex domains with demanding requirements\u2014but most systems don't need it.</p> <p>Key takeaways:</p> <ul> <li>CQRS splits conceptual models, not just data access</li> <li>Use it for specific bounded contexts, not entire applications  </li> <li>Pairs naturally with Event Sourcing and eventual consistency</li> <li>Adds complexity\u2014ensure the benefits justify the cost</li> </ul> <p>Start with a simpler architecture. Introduce CQRS when you encounter the specific problems it solves.</p>"},{"location":"concepts/event-processors/","title":"Event Processors","text":"<p>Event processors subscribe to events and execute logic in response. They're the \"read side\" of CQRS\u2014building optimized views, triggering notifications, and coordinating workflows.</p>"},{"location":"concepts/event-processors/#why-event-processors","title":"Why Event Processors?","text":"<p>In an event-sourced system, aggregates emit events when state changes. But those events have value beyond just rebuilding aggregate state:</p> <pre><code>flowchart LR\n    AGG[Aggregates] --&gt;|emit| EVT[Events]\n    EVT --&gt; EP1[Account Balance&lt;br/&gt;Projection]\n    EVT --&gt; EP2[Transaction&lt;br/&gt;History]\n    EVT --&gt; EP3[Email&lt;br/&gt;Notifications]\n    EVT --&gt; EP4[Fraud&lt;br/&gt;Detection]\n    EVT --&gt; EP5[Analytics&lt;br/&gt;Pipeline]</code></pre> <p>Event processors consume these events to:</p> <ul> <li>Build read models: Denormalized views optimized for queries</li> <li>Send notifications: Emails, SMS, push notifications</li> <li>Integrate systems: Call external APIs and services</li> <li>Coordinate workflows: Multi-step business processes (sagas)</li> <li>Update analytics: Metrics, dashboards, data warehouses</li> </ul>"},{"location":"concepts/event-processors/#defining-event-processors","title":"Defining Event Processors","text":"<p>Event processors extend the <code>EventProcessor</code> base class and use <code>@handles_event</code> to subscribe to events:</p> <pre><code>from interlock.application.events import EventProcessor\nfrom interlock.domain import Event\nfrom interlock.routing import handles_event\n\nclass AccountBalanceProjection(EventProcessor):\n    \"\"\"Maintains a read-optimized view of account balances.\"\"\"\n\n    def __init__(self, repository: BalanceRepository):\n        self.repository = repository\n\n    @handles_event\n    async def on_account_opened(self, event: Event[AccountOpened]) -&gt; None:\n        # Use Event[T] to access aggregate_id from the wrapper\n        await self.repository.create(\n            account_id=event.aggregate_id,\n            owner=event.data.owner_name,\n            balance=event.data.initial_deposit\n        )\n\n    @handles_event\n    async def on_money_deposited(self, event: Event[MoneyDeposited]) -&gt; None:\n        await self.repository.increment(\n            event.aggregate_id, \n            event.data.amount\n        )\n\n    @handles_event\n    async def on_money_withdrawn(self, event: Event[MoneyWithdrawn]) -&gt; None:\n        await self.repository.decrement(\n            event.aggregate_id, \n            event.data.amount\n        )\n</code></pre>"},{"location":"concepts/event-processors/#handler-discovery","title":"Handler Discovery","text":"<p>Like aggregates, handlers are discovered through:</p> <ol> <li>The <code>@handles_event</code> decorator</li> <li>The type annotation on the event parameter</li> </ol> <pre><code># Both work identically\n@handles_event\nasync def on_deposit(self, event: MoneyDeposited) -&gt; None: ...\n\n@handles_event\nasync def handle_money_deposited(self, event: MoneyDeposited) -&gt; None: ...\n</code></pre>"},{"location":"concepts/event-processors/#accessing-event-metadata","title":"Accessing Event Metadata","text":"<p>By default, handlers receive just the event payload. To access event metadata (like <code>aggregate_id</code>, <code>timestamp</code>, <code>correlation_id</code>), use the <code>Event[T]</code> annotation:</p> <pre><code>from interlock.domain import Event\n\nclass AccountBalanceProjection(EventProcessor):\n    # Payload-only: simple, clean, but no metadata access\n    @handles_event\n    async def on_deposit_simple(self, event: MoneyDeposited) -&gt; None:\n        # Must include aggregate_id in payload if needed\n        await self.repository.increment(event.account_id, event.amount)\n\n    # Event wrapper: full access to metadata\n    @handles_event\n    async def on_withdrawal_with_metadata(self, event: Event[MoneyWithdrawn]) -&gt; None:\n        # Access any metadata from the wrapper\n        await self.repository.record_withdrawal(\n            aggregate_id=event.aggregate_id,      # From wrapper\n            amount=event.data.amount,             # Payload is in event.data\n            timestamp=event.timestamp,            # Metadata\n            sequence=event.sequence_number        # Metadata\n        )\n</code></pre> <p>Use <code>Event[T]</code> when you need:</p> <ul> <li><code>aggregate_id</code> without duplicating it in every event payload</li> <li><code>timestamp</code> for time-based logic</li> <li><code>sequence_number</code> for ordering or idempotency</li> <li><code>correlation_id</code>/<code>causation_id</code> for tracing</li> </ul> <p>Use the plain type (<code>T</code>) when:</p> <ul> <li>You only need the event data itself</li> <li>You've included necessary IDs in the event payload</li> <li>You want simpler handler signatures</li> </ul>"},{"location":"concepts/event-processors/#common-use-cases","title":"Common Use Cases","text":""},{"location":"concepts/event-processors/#projections-read-models","title":"Projections (Read Models)","text":"<p>Build views optimized for specific queries:</p> <pre><code>class CustomerDashboardProjection(EventProcessor):\n    \"\"\"Builds a denormalized view for the customer dashboard.\"\"\"\n\n    @handles_event\n    async def on_order_placed(self, event: OrderPlaced) -&gt; None:\n        await self.db.upsert(\n            \"customer_dashboard\",\n            customer_id=event.customer_id,\n            update={\n                \"$inc\": {\"total_orders\": 1, \"total_spent\": event.amount},\n                \"$set\": {\"last_order_date\": event.timestamp}\n            }\n        )\n</code></pre>"},{"location":"concepts/event-processors/#notifications","title":"Notifications","text":"<p>Trigger communications based on events:</p> <pre><code>class OrderNotificationProcessor(EventProcessor):\n    def __init__(self, email_service: EmailService):\n        self.email_service = email_service\n\n    @handles_event\n    async def on_order_shipped(self, event: OrderShipped) -&gt; None:\n        await self.email_service.send(\n            to=event.customer_email,\n            template=\"order_shipped\",\n            data={\"tracking_number\": event.tracking_number}\n        )\n</code></pre>"},{"location":"concepts/event-processors/#integration","title":"Integration","text":"<p>Sync with external systems:</p> <pre><code>class SearchIndexProcessor(EventProcessor):\n    def __init__(self, search_client: SearchClient):\n        self.search_client = search_client\n\n    @handles_event\n    async def on_product_created(self, event: ProductCreated) -&gt; None:\n        await self.search_client.index({\n            \"id\": event.product_id,\n            \"name\": event.name,\n            \"description\": event.description,\n            \"category\": event.category\n        })\n\n    @handles_event\n    async def on_product_deleted(self, event: ProductDeleted) -&gt; None:\n        await self.search_client.delete(event.product_id)\n</code></pre>"},{"location":"concepts/event-processors/#analytics","title":"Analytics","text":"<p>Feed data pipelines:</p> <pre><code>class TransactionMetricsProcessor(EventProcessor):\n    def __init__(self, metrics: MetricsClient):\n        self.metrics = metrics\n\n    @handles_event\n    async def on_money_deposited(self, event: MoneyDeposited) -&gt; None:\n        self.metrics.increment(\"deposits.count\")\n        self.metrics.histogram(\"deposits.amount\", event.amount)\n\n    @handles_event\n    async def on_money_withdrawn(self, event: MoneyWithdrawn) -&gt; None:\n        self.metrics.increment(\"withdrawals.count\")\n        self.metrics.histogram(\"withdrawals.amount\", event.amount)\n</code></pre>"},{"location":"concepts/event-processors/#registering-processors","title":"Registering Processors","text":"<p>Register processors with the application:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(BalanceRepository, InMemoryBalanceRepository)\n    .register_event_processor(AccountBalanceProjection)\n    .register_event_processor(TransactionMetricsProcessor)\n    .build()\n)\n</code></pre> <p>Or use convention-based discovery:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .convention_based(\"my_app\")  # Discovers processors in my_app/\n    .build()\n)\n</code></pre>"},{"location":"concepts/event-processors/#running-processors","title":"Running Processors","text":"<p>Interlock supports two delivery strategies that determine when and how processors execute:</p>"},{"location":"concepts/event-processors/#synchronous-delivery-default","title":"Synchronous Delivery (Default)","text":"<p>With synchronous delivery, processors execute immediately during command handling:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant App as Application\n    participant Agg as Aggregate\n    participant Proc as Processor\n\n    Client-&gt;&gt;App: dispatch(DepositMoney)\n    App-&gt;&gt;Agg: handle(command)\n    Agg-&gt;&gt;Agg: emit(MoneyDeposited)\n    App-&gt;&gt;Proc: handle(MoneyDeposited)\n    Proc-&gt;&gt;Proc: Update read model\n    App--&gt;&gt;Client: Success \u2713\n    Note over Client,App: All processors complete before return</code></pre> <p>Characteristics:</p> <ul> <li>Immediate consistency: Read models update before command returns</li> <li>Simple deployment: Single process, no message broker needed</li> <li>Coupled failures: Processor errors fail the command</li> <li>Higher latency: Command waits for all processors</li> </ul> <p>This is the default because it's simplest for getting started. No additional configuration needed.</p>"},{"location":"concepts/event-processors/#asynchronous-delivery","title":"Asynchronous Delivery","text":"<p>With asynchronous delivery, processors run separately from command handling:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.events import AsynchronousDelivery, EventDelivery\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(EventDelivery, AsynchronousDelivery)\n    .register_aggregate(BankAccount)\n    .register_event_processor(AccountBalanceProjection)\n    .build()\n)\n</code></pre> <p>Then run processors explicitly:</p> <pre><code>async with app:\n    # Start processors in background tasks\n    await app.run_event_processors(\n        AccountBalanceProjection,\n        TransactionMetricsProcessor,\n    )\n</code></pre> <p>Characteristics:</p> <ul> <li>Eventual consistency: Read models update after command returns</li> <li>Scalable: Processors can run in separate containers</li> <li>Decoupled failures: Processor errors don't affect commands</li> <li>Lower latency: Command returns immediately after persistence</li> </ul>"},{"location":"concepts/event-processors/#event-transports","title":"Event Transports","text":"<p>Asynchronous delivery requires an <code>EventTransport</code> to move events from producers to consumers. Interlock provides:</p> <ul> <li><code>InMemoryEventTransport</code> \u2014 For testing and single-process async (default)</li> <li>Kafka, Redis, etc. \u2014 For distributed production deployments</li> </ul> <p>The transport determines how events flow between the command side and processor side:</p> <pre><code>flowchart LR\n    CMD[Command Handler] --&gt;|publish| TRANSPORT[(Event Transport)]\n    TRANSPORT --&gt;|subscribe| PROC1[Processor 1]\n    TRANSPORT --&gt;|subscribe| PROC2[Processor 2]</code></pre> <p>For production systems, you'll typically use a durable message broker. See the Database Integrations guide for available transport implementations.</p>"},{"location":"concepts/event-processors/#choosing-a-strategy","title":"Choosing a Strategy","text":"Consideration Synchronous Asynchronous Consistency Immediate Eventual Deployment Single process Can distribute Command latency Higher (includes processors) Lower (just persistence) Failure isolation Coupled Isolated Complexity Simple Requires infrastructure <p>Recommendations:</p> <ul> <li>Development/prototyping: Start with synchronous (default)</li> <li>Production monolith: Synchronous often sufficient</li> <li>Microservices: Asynchronous with external transport (Kafka, etc.)</li> <li>High throughput: Asynchronous to minimize command latency</li> </ul>"},{"location":"concepts/event-processors/#eventual-consistency","title":"Eventual Consistency","text":"<p>With asynchronous delivery, processors run independently from command handling:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant App as Application\n    participant Agg as Aggregate\n    participant Store as Event Store\n    participant Proc as Processor\n\n    Client-&gt;&gt;App: dispatch(DepositMoney)\n    App-&gt;&gt;Agg: handle(command)\n    Agg-&gt;&gt;Agg: emit(MoneyDeposited)\n    App-&gt;&gt;Store: Persist event\n    App--&gt;&gt;Client: Success \u2713\n    Note over Client,App: Client returns immediately\n    Store--&gt;&gt;Proc: Event delivered\n    Proc-&gt;&gt;Proc: Update read model\n    Note over Proc: Slight delay</code></pre> <p>The read model may lag slightly behind writes. Design your UI to handle this:</p> <ul> <li>Show optimistic updates</li> <li>Display \"processing\" states</li> <li>Refresh after short delays</li> </ul>"},{"location":"concepts/event-processors/#idempotency","title":"Idempotency","text":"<p>Events may be delivered more than once. Make handlers idempotent:</p> <pre><code>@handles_event\nasync def on_order_placed(self, event: OrderPlaced) -&gt; None:\n    # Idempotent - upsert instead of insert\n    await self.db.upsert(\n        \"orders\",\n        {\"order_id\": event.order_id},  # Unique key\n        {\"$set\": {\"status\": \"placed\", \"items\": event.items}}\n    )\n</code></pre> <p>Interlock provides <code>IdempotencyStorageBackend</code> for tracking processed events.</p>"},{"location":"concepts/event-processors/#error-handling","title":"Error Handling","text":"<p>When a processor fails:</p> <ol> <li>The event is not acknowledged</li> <li>Delivery is retried (based on configuration)</li> <li>After max retries, the event goes to a dead-letter queue</li> </ol> <pre><code>class ResilientProcessor(EventProcessor):\n    @handles_event\n    async def on_order_placed(self, event: OrderPlaced) -&gt; None:\n        try:\n            await self.external_api.notify(event)\n        except TemporaryError:\n            # Raising an exception triggers retry\n            raise\n        except PermanentError:\n            # Log and continue - don't block the stream\n            logger.error(f\"Failed to process {event}\", exc_info=True)\n</code></pre>"},{"location":"concepts/event-processors/#testing-processors","title":"Testing Processors","text":"<p>Use <code>ProcessorScenario</code> for behavior-driven testing:</p> <pre><code>import pytest\nfrom interlock.application import ApplicationBuilder\n\n@pytest.fixture\ndef app():\n    repository = InMemoryBalanceRepository()\n    return (\n        ApplicationBuilder()\n        .register_dependency(BalanceRepository, lambda: repository)\n        .register_event_processor(AccountBalanceProjection)\n        .build()\n    )\n\nasync def test_tracks_balance_after_deposit(app):\n    account_id = uuid4()\n\n    async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        await scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .should_have_state(\n                lambda p: p.repository.get_balance(account_id) == 100\n            )\n</code></pre>"},{"location":"concepts/event-processors/#processor-vs-saga","title":"Processor vs Saga","text":"<p>Both process events, but serve different purposes:</p> Aspect Event Processor Saga State Stateless or projection-only Maintains workflow state Purpose Read models, side effects Multi-step coordination Commands Rarely dispatches commands Orchestrates via commands Idempotency Handle yourself Built-in step tracking <p>Use processors for:</p> <ul> <li>Building read models</li> <li>One-shot side effects (notifications)</li> <li>Analytics and metrics</li> </ul> <p>Use Sagas for:</p> <ul> <li>Multi-aggregate transactions</li> <li>Long-running workflows</li> <li>Compensation on failure</li> </ul>"},{"location":"concepts/event-processors/#best-practices","title":"Best Practices","text":""},{"location":"concepts/event-processors/#single-responsibility","title":"Single Responsibility","text":"<p>One processor, one purpose:</p> <pre><code># Good - focused processors\nclass AccountBalanceProjection(EventProcessor): ...\nclass TransactionHistoryProjection(EventProcessor): ...\nclass NotificationProcessor(EventProcessor): ...\n\n# Avoid - kitchen sink processor\nclass EverythingProcessor(EventProcessor):\n    # Builds projections AND sends emails AND updates metrics...\n</code></pre>"},{"location":"concepts/event-processors/#handle-all-relevant-events","title":"Handle All Relevant Events","text":"<p>Don't miss events that affect your projection:</p> <pre><code>class BalanceProjection(EventProcessor):\n    @handles_event\n    async def on_opened(self, event: AccountOpened) -&gt; None: ...\n\n    @handles_event\n    async def on_deposited(self, event: MoneyDeposited) -&gt; None: ...\n\n    @handles_event\n    async def on_withdrawn(self, event: MoneyWithdrawn) -&gt; None: ...\n\n    @handles_event\n    async def on_closed(self, event: AccountClosed) -&gt; None: ...\n    # Don't forget account closure!\n</code></pre>"},{"location":"concepts/event-processors/#design-for-replay","title":"Design for Replay","text":"<p>Processors may need to rebuild from scratch:</p> <ul> <li>Make handlers idempotent</li> <li>Don't rely on external state ordering</li> <li>Consider tombstone/delete events</li> </ul>"},{"location":"concepts/event-processors/#further-reading","title":"Further Reading","text":"<ul> <li>Tutorial: Event Processors \u2014 Hands-on guide</li> <li>CQRS \u2014 The pattern processors implement</li> <li>Sagas Guide \u2014 Stateful event coordination</li> <li>Writing Tests \u2014 Testing strategies</li> </ul>"},{"location":"concepts/event-sourcing/","title":"Event Sourcing","text":"<p>Event Sourcing ensures that all changes to application state are captured as  a sequence of events. Rather than storing just the current state, you store the  complete history of how that state came to be.</p> <p>Martin Fowler</p> <p>\"The fundamental idea of Event Sourcing is that of ensuring every change to  the state of an application is captured in an event object, and that these  event objects are themselves stored in the sequence they were applied for  the same lifetime as the application state itself.\"</p> <p>\u2014 Event Sourcing</p>"},{"location":"concepts/event-sourcing/#the-core-idea","title":"The Core Idea","text":"<p>We can always query an application to find its current state. But sometimes we  need more than that\u2014we need to know how we got there.</p> <p>Consider a bank account. With traditional storage, we might see:</p> <pre><code>Account: ACC-001\nBalance: $750\n</code></pre> <p>But how did we arrive at $750? Was it a $1000 deposit followed by a $250  withdrawal? Or $500 deposited twice with a $250 fee? The current state doesn't  tell us.</p> <p>With Event Sourcing, we store the sequence of events:</p> <pre><code>1. AccountOpened(id=\"ACC-001\", owner=\"Alice\")\n2. MoneyDeposited(amount=1000)\n3. MoneyWithdrawn(amount=250)\n</code></pre> <p>The current balance is derived by replaying these events: <code>0 + 1000 - 250 = 750</code>.</p>"},{"location":"concepts/event-sourcing/#how-it-works","title":"How It Works","text":"<p>When something changes in your domain, instead of directly mutating state, you:</p> <ol> <li>Create an event describing what happened</li> <li>Store the event in an append-only log</li> <li>Apply the event to update the in-memory state</li> </ol> <pre><code>sequenceDiagram\n    participant Client\n    participant Aggregate\n    participant EventStore\n\n    Client-&gt;&gt;Aggregate: WithdrawMoney($100)\n    Aggregate-&gt;&gt;Aggregate: Validate withdrawal\n    Aggregate-&gt;&gt;EventStore: Append MoneyWithdrawn($100)\n    EventStore--&gt;&gt;Aggregate: Event stored\n    Aggregate-&gt;&gt;Aggregate: Apply event to state\n    Aggregate--&gt;&gt;Client: Success</code></pre> <p>To load an aggregate, you replay its events from the store:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant EventStore\n    participant Aggregate\n\n    Client-&gt;&gt;EventStore: Load events for ACC-001\n    EventStore--&gt;&gt;Aggregate: AccountOpened\n    Aggregate-&gt;&gt;Aggregate: Apply \u2192 balance=0\n    EventStore--&gt;&gt;Aggregate: MoneyDeposited(1000)\n    Aggregate-&gt;&gt;Aggregate: Apply \u2192 balance=1000\n    EventStore--&gt;&gt;Aggregate: MoneyWithdrawn(250)\n    Aggregate-&gt;&gt;Aggregate: Apply \u2192 balance=750\n    Aggregate--&gt;&gt;Client: Aggregate ready (balance=750)</code></pre>"},{"location":"concepts/event-sourcing/#what-this-enables","title":"What This Enables","text":"<p>Storing events rather than state unlocks powerful capabilities:</p>"},{"location":"concepts/event-sourcing/#complete-rebuild","title":"Complete Rebuild","text":"<p>You can discard the current application state entirely and rebuild it by  replaying all events. This is invaluable for:</p> <ul> <li>Fixing bugs in state calculation</li> <li>Migrating to new data structures</li> <li>Testing state reconstruction logic</li> </ul>"},{"location":"concepts/event-sourcing/#temporal-queries","title":"Temporal Queries","text":"<p>You can determine the application state at any point in time by replaying  events up to that moment:</p> <pre><code># What was the balance on January 15th?\nevents = event_store.load(account_id, up_to=datetime(2024, 1, 15))\nstate = replay(events)\nprint(state.balance)  # Balance as of Jan 15\n</code></pre>"},{"location":"concepts/event-sourcing/#event-replay-for-corrections","title":"Event Replay for Corrections","text":"<p>If you discover a past event was incorrect, you can:</p> <ol> <li>Reverse the effects of that event and all subsequent events</li> <li>Apply the corrected event</li> <li>Replay subsequent events</li> </ol> <p>This handles scenarios like: - Retroactive corrections (\"this deposit was actually $500, not $50\") - Events received out of order (common in distributed systems)</p>"},{"location":"concepts/event-sourcing/#audit-trail","title":"Audit Trail","text":"<p>Every change is recorded with full context\u2014who, what, when. This is essential  for regulated industries (finance, healthcare) where you must prove what  happened and when.</p>"},{"location":"concepts/event-sourcing/#multiple-projections","title":"Multiple Projections","text":"<p>The same event stream can feed multiple read models optimized for different  queries. A <code>MoneyDeposited</code> event might update:</p> <ul> <li>An account balance projection</li> <li>A daily transaction summary</li> <li>A fraud detection system</li> <li>A customer notification service</li> </ul>"},{"location":"concepts/event-sourcing/#the-event-store","title":"The Event Store","text":"<p>The event store is an append-only log of events, typically organized by  aggregate ID:</p> <pre><code>Aggregate: ACC-001\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Seq \u2502 Timestamp            \u2502 Event                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0   \u2502 2024-01-01 10:00:00  \u2502 AccountOpened(owner=Alice)  \u2502\n\u2502 1   \u2502 2024-01-05 14:30:00  \u2502 MoneyDeposited(amount=1000) \u2502\n\u2502 2   \u2502 2024-01-10 09:15:00  \u2502 MoneyWithdrawn(amount=250)  \u2502\n\u2502 3   \u2502 2024-01-12 16:45:00  \u2502 MoneyDeposited(amount=500)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key properties:</p> <ul> <li>Append-only: Events are never modified or deleted</li> <li>Ordered: Events have a sequence number within their stream</li> <li>Immutable: Once stored, events never change</li> </ul>"},{"location":"concepts/event-sourcing/#performance-snapshots","title":"Performance: Snapshots","text":"<p>Replaying thousands of events on every load is slow. Snapshots solve this  by periodically saving the current state:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Events: [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10]... \u2502\n\u2502                              \u2191                          \u2502\n\u2502                         Snapshot at seq 5               \u2502\n\u2502                         (balance=$1250)                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nTo load: Load snapshot \u2192 Replay events 6, 7, 8, 9, 10...\n</code></pre> <p>Snapshots are purely an optimization\u2014you can always rebuild from events if  needed.</p>"},{"location":"concepts/event-sourcing/#challenges","title":"Challenges","text":"<p>Event Sourcing isn't free. Consider these challenges:</p>"},{"location":"concepts/event-sourcing/#event-schema-evolution","title":"Event Schema Evolution","text":"<p>Events are immutable, but your domain model evolves. When you need to change  an event's structure, you need upcasting to transform old events to new  schemas.</p> <p>See: Event Upcasting Guide</p>"},{"location":"concepts/event-sourcing/#eventual-consistency","title":"Eventual Consistency","text":"<p>Read models (projections) are updated asynchronously from the event stream.  There's a window where a query might return stale data. Your UI and API design  must account for this.</p>"},{"location":"concepts/event-sourcing/#learning-curve","title":"Learning Curve","text":"<p>Event Sourcing requires a different mental model. Developers must think in  terms of \"what happened\" rather than \"what is the current state.\"</p>"},{"location":"concepts/event-sourcing/#storage-growth","title":"Storage Growth","text":"<p>Events accumulate forever (that's the point). You need strategies for:</p> <ul> <li>Archiving old events</li> <li>Efficient storage formats</li> <li>Snapshot frequency tuning</li> </ul>"},{"location":"concepts/event-sourcing/#event-sourcing-in-interlock","title":"Event Sourcing in Interlock","text":"<p>Interlock provides the infrastructure for Event Sourcing:</p> Component Purpose <code>Aggregate</code> Base class with <code>emit()</code> for recording events <code>@applies_event</code> Decorator for event handler methods <code>EventStore</code> Abstract interface for event persistence <code>AggregateSnapshotStorageBackend</code> Snapshot storage for performance Event Upcasting Schema evolution support <p>Example aggregate using Event Sourcing:</p> <pre><code>from interlock.domain import Aggregate\nfrom interlock.routing import handles_command, applies_event\n\nclass BankAccount(Aggregate):\n    balance: int = 0\n\n    @handles_command\n    def handle_deposit(self, command: DepositMoney) -&gt; None:\n        # Don't mutate directly\u2014emit an event\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @applies_event\n    def apply_deposited(self, event: MoneyDeposited) -&gt; None:\n        # Event handler updates state\n        self.balance += event.amount\n</code></pre>"},{"location":"concepts/event-sourcing/#event-sourcing-and-cqrs","title":"Event Sourcing and CQRS","text":"<p>Event Sourcing and CQRS are separate but complementary patterns:</p> Pattern Core Idea Event Sourcing Store state as a sequence of events CQRS Separate models for reads and writes <p>You can use either pattern independently. However, they work exceptionally well together\u2014Event Sourcing naturally produces the events that CQRS read models consume.</p> <p>Interlock's Approach</p> <p>Interlock combines both patterns to help you build robust applications. Aggregates use Event Sourcing (emitting events, reconstructing state from history), while Event Processors build optimized read models\u2014a natural CQRS architecture. This gives you the benefits of both patterns with a cohesive programming model.</p>"},{"location":"concepts/event-sourcing/#further-reading","title":"Further Reading","text":"<ul> <li>Martin Fowler: Event Sourcing \u2014    In-depth exploration of the pattern</li> <li>Tutorial: Events &amp; Sourcing \u2014    Hands-on introduction</li> <li>Event Upcasting Guide \u2014    Handling schema evolution</li> <li>CQRS \u2014    Command Query Responsibility Segregation</li> </ul>"},{"location":"concepts/events/","title":"Events","text":"<p>An event is an immutable record of something that happened in the system. Events are the cornerstone of Event Sourcing\u2014they're the source of truth for all aggregate state.</p>"},{"location":"concepts/events/#events-as-facts","title":"Events as Facts","text":"<p>Unlike commands (which express intent), events are facts. They record what already happened:</p> <pre><code># Command: \"I want to deposit $100\" (might fail)\nDepositMoney(aggregate_id=account_id, amount=100)\n\n# Event: \"$100 was deposited\" (already happened)\nMoneyDeposited(amount=100)\n</code></pre> <p>Events are:</p> <ul> <li>Immutable: Once recorded, they never change</li> <li>Ordered: They have a sequence within their aggregate</li> <li>Timestamped: They record when they occurred</li> <li>The source of truth: State is derived from events</li> </ul>"},{"location":"concepts/events/#defining-events","title":"Defining Events","text":"<p>Event data in Interlock is defined as Pydantic models:</p> <pre><code>from pydantic import BaseModel\n\nclass AccountOpened(BaseModel):\n    \"\"\"A new account was opened.\"\"\"\n    owner_name: str\n    initial_deposit: int = 0\n\nclass MoneyDeposited(BaseModel):\n    \"\"\"Money was deposited into an account.\"\"\"\n    amount: int\n\nclass MoneyWithdrawn(BaseModel):\n    \"\"\"Money was withdrawn from an account.\"\"\"\n    amount: int\n\nclass AccountClosed(BaseModel):\n    \"\"\"An account was closed.\"\"\"\n    reason: str\n    final_balance: int\n</code></pre>"},{"location":"concepts/events/#the-event-wrapper","title":"The Event Wrapper","text":"<p>When events are stored and transported, Interlock wraps them in an <code>Event</code> envelope that adds metadata:</p> <pre><code>from interlock.domain import Event\n\n# The full event structure\nevent = Event(\n    id=uuid4(),                    # Unique event ID\n    aggregate_id=account_id,      # Which aggregate emitted this\n    data=MoneyDeposited(amount=100),  # Your event data\n    sequence_number=5,            # Position in aggregate's stream\n    timestamp=datetime.now(UTC),  # When it occurred\n    correlation_id=...,           # Trace ID\n    causation_id=...              # What caused this\n)\n\n# Access the data\nprint(event.data.amount)  # 100\n</code></pre>"},{"location":"concepts/events/#event-metadata","title":"Event Metadata","text":"<p>Every event automatically includes:</p> Field Type Description <code>id</code> <code>UUID</code> Unique identifier for this event <code>aggregate_id</code> <code>UUID</code> The aggregate that produced this event <code>sequence_number</code> <code>int</code> Position in the aggregate's event stream <code>timestamp</code> <code>datetime</code> When the event occurred (UTC) <code>correlation_id</code> <code>UUID \\| None</code> Links related events across a workflow <code>causation_id</code> <code>UUID \\| None</code> The command that caused this event"},{"location":"concepts/events/#accessing-event-metadata-in-processors","title":"Accessing Event Metadata in Processors","text":"<p>Event processors can receive either just the event payload or the full <code>Event</code> wrapper, depending on their type annotation:</p> <pre><code>class AccountBalanceProjection(EventProcessor):\n    # Option 1: Receive just the payload\n    @handles_event\n    async def on_deposit_payload(self, event: MoneyDeposited) -&gt; None:\n        # 'event' is the MoneyDeposited payload only\n        # Use this when you don't need aggregate_id or metadata\n        await self.log_deposit(event.amount)\n\n    # Option 2: Receive the full Event wrapper (recommended)\n    @handles_event\n    async def on_withdrawal_with_metadata(self, event: Event[MoneyWithdrawn]) -&gt; None:\n        # 'event' is the full Event wrapper with all metadata\n        await self.repo.decrement(\n            event.aggregate_id,      # Access from wrapper\n            event.data.amount,       # Payload is in event.data\n            event.timestamp          # Other metadata available too\n        )\n</code></pre> <p>Use the <code>Event[T]</code> annotation when you need:</p> <ul> <li>The <code>aggregate_id</code> without duplicating it in the payload</li> <li>Event metadata like <code>timestamp</code>, <code>sequence_number</code>, <code>correlation_id</code></li> <li>The full tracing context</li> </ul> <p>Use the plain type annotation (<code>T</code>) when:</p> <ul> <li>You only need the event data itself</li> <li>You want simpler code and don't need metadata</li> <li>You've already included necessary IDs in the payload</li> </ul>"},{"location":"concepts/events/#naming-conventions","title":"Naming Conventions","text":"<p>Events should be named in the past tense\u2014they describe what happened:</p> \u2713 Good (Past Tense) \u2717 Bad <code>AccountCreated</code> <code>CreateAccount</code> <code>MoneyDeposited</code> <code>DepositMoney</code> <code>OrderShipped</code> <code>ShipOrder</code> <code>PaymentFailed</code> <code>FailPayment</code>"},{"location":"concepts/events/#emitting-events","title":"Emitting Events","text":"<p>Aggregates emit events through the <code>emit()</code> method:</p> <pre><code>class BankAccount(Aggregate):\n    balance: int = 0\n\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        if command.amount &lt;= 0:\n            raise ValueError(\"Amount must be positive\")\n\n        # Emit the event - this records what happened\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @applies_event\n    def apply_deposit(self, event: MoneyDeposited) -&gt; None:\n        # Apply the event to update state\n        self.balance += event.amount\n</code></pre> <p>When <code>emit()</code> is called:</p> <ol> <li>The event is wrapped with metadata</li> <li>The event is added to <code>uncommitted_events</code></li> <li>The event is immediately applied to the aggregate</li> <li>Later, uncommitted events are persisted to the event store</li> </ol>"},{"location":"concepts/events/#event-immutability","title":"Event Immutability","text":"<p>Events Are Forever</p> <p>Once an event is stored, it must never be modified or deleted. This is a fundamental principle of event sourcing.</p> <p>Events represent historical facts. Changing them would be like rewriting history\u2014it breaks the integrity of your system.</p>"},{"location":"concepts/events/#handling-mistakes","title":"Handling Mistakes","text":"<p>If an event was recorded incorrectly, emit a compensating event:</p> <pre><code># Original (incorrect) event\nMoneyDeposited(amount=50)  # Should have been $500\n\n# DON'T do this\nevent.amount = 500  # \u274c Never modify events\n\n# DO emit a correction\nself.emit(DepositCorrected(\n    original_event_id=event.id,\n    original_amount=50,\n    corrected_amount=500\n))\n</code></pre> <p>This approach:</p> <ul> <li>Preserves the complete history</li> <li>Makes corrections auditable</li> <li>Allows replaying events correctly</li> </ul>"},{"location":"concepts/events/#event-ordering","title":"Event Ordering","text":"<p>Events within an aggregate are strictly ordered by <code>sequence_number</code>:</p> <pre><code>Aggregate: ACC-001\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Seq \u2502 Timestamp            \u2502 Event                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 2024-01-01 10:00:00  \u2502 AccountOpened(owner=\"Alice\")\u2502\n\u2502 2   \u2502 2024-01-05 14:30:00  \u2502 MoneyDeposited(amount=1000) \u2502\n\u2502 3   \u2502 2024-01-10 09:15:00  \u2502 MoneyWithdrawn(amount=250)  \u2502\n\u2502 4   \u2502 2024-01-12 16:45:00  \u2502 MoneyDeposited(amount=500)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Properties:</p> <ul> <li>Sequence numbers start at 1</li> <li>Each new event increments the sequence</li> <li>No gaps\u2014sequences are contiguous</li> <li>Used for optimistic concurrency control</li> </ul>"},{"location":"concepts/events/#event-schema-evolution","title":"Event Schema Evolution","text":"<p>Your domain model evolves, but events are immutable. When you need to change an event's structure, you have two options:</p>"},{"location":"concepts/events/#1-backward-compatible-changes","title":"1. Backward-Compatible Changes","text":"<p>Pydantic handles simple additions with defaults:</p> <pre><code># Original\nclass MoneyDeposited(BaseModel):\n    amount: int\n\n# Extended - old events work automatically\nclass MoneyDeposited(BaseModel):\n    amount: int\n    source: str = \"unknown\"  # Default for old events\n</code></pre>"},{"location":"concepts/events/#2-event-upcasting","title":"2. Event Upcasting","text":"<p>For more complex changes, use upcasters to transform old events:</p> <pre><code>from interlock.application.events import EventUpcaster\n\nclass MoneyDepositedV1(BaseModel):\n    amount: int\n\nclass MoneyDepositedV2(BaseModel):\n    amount: int\n    currency: str\n\nclass UpcastMoneyDeposited(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        return MoneyDepositedV2(\n            amount=data.amount,\n            currency=\"USD\"  # Assume old events were USD\n        )\n</code></pre> <p>See the Event Upcasting Guide for details.</p>"},{"location":"concepts/events/#consuming-events","title":"Consuming Events","text":"<p>Events flow to multiple consumers:</p>"},{"location":"concepts/events/#event-appliers-in-aggregates","title":"Event Appliers (in Aggregates)","text":"<p>Update aggregate state:</p> <pre><code>@applies_event\ndef apply_deposit(self, event: MoneyDeposited) -&gt; None:\n    self.balance += event.amount\n</code></pre>"},{"location":"concepts/events/#event-processors","title":"Event Processors","text":"<p>Build read models and trigger side effects:</p> <pre><code>class MoneyDeposited(BaseModel):\n    amount: int\n\nclass AccountBalanceProjection(EventProcessor):\n    @handles_event\n    async def on_deposit(self, event: Event[MoneyDeposited]) -&gt; None:\n        await self.repository.increment_balance(\n            event.aggregate_id,  # Access from wrapper\n            event.data.amount\n        )\n</code></pre>"},{"location":"concepts/events/#sagas","title":"Sagas","text":"<p>Coordinate multi-aggregate workflows:</p> <pre><code>class MoneyTransferSaga(Saga[TransferState]):\n    @saga_step\n    async def on_money_withdrawn(\n        self, \n        event: MoneyWithdrawn, \n        state: TransferState\n    ) -&gt; TransferState:\n        # Source account debited, now credit the target\n        await self.command_bus.dispatch(DepositMoney(\n            aggregate_id=state.to_account,\n            amount=state.amount\n        ))\n        return state\n</code></pre>"},{"location":"concepts/events/#event-design-guidelines","title":"Event Design Guidelines","text":""},{"location":"concepts/events/#include-sufficient-context","title":"Include Sufficient Context","text":"<p>Events should be self-describing:</p> <pre><code># Too sparse - lacks context\nclass OrderPlaced(BaseModel):\n    order_id: str\n\n# Self-describing\nclass OrderPlaced(BaseModel):\n    customer_id: str\n    items: list[OrderItem]\n    total_amount: int\n    shipping_address: Address\n    placed_at: datetime\n</code></pre>"},{"location":"concepts/events/#dont-include-derived-data","title":"Don't Include Derived Data","text":"<p>Let consumers compute derived values:</p> <pre><code># Wrong - includes derived state\nclass MoneyDeposited(BaseModel):\n    amount: int\n    new_balance: int  # \u274c Derived, might be wrong on replay\n\n# Right - just the facts\nclass MoneyDeposited(BaseModel):\n    amount: int  # \u2713 Consumers can compute balance\n</code></pre>"},{"location":"concepts/events/#consider-event-granularity","title":"Consider Event Granularity","text":"<p>Balance between too many small events and too few large ones:</p> <pre><code># Too granular - chatty\nclass OrderItemAdded(BaseModel): ...\nclass OrderItemRemoved(BaseModel): ...\nclass OrderShippingUpdated(BaseModel): ...\nclass OrderDiscountApplied(BaseModel): ...\n\n# Too coarse - loses information\nclass OrderUpdated(BaseModel):\n    changes: dict  # What changed?\n\n# Good balance\nclass OrderPlaced(BaseModel): ...\nclass OrderItemsModified(BaseModel): ...\nclass OrderShipped(BaseModel): ...\nclass OrderCancelled(BaseModel): ...\n</code></pre>"},{"location":"concepts/events/#correlation-and-causation","title":"Correlation and Causation","text":"<p>Events include tracing metadata:</p> <pre><code># Events from the same logical operation share correlation_id\nevent1 = Event(\n    data=TransferInitiated(...),\n    correlation_id=\"01HXYZ...\",  # Trace ID\n    causation_id=\"01HABC...\"     # The command that started this\n)\n\nevent2 = Event(\n    data=MoneyWithdrawn(...),\n    correlation_id=\"01HXYZ...\",  # Same trace\n    causation_id=\"01HDEF...\"     # The previous event\n)\n</code></pre> <p>This enables:</p> <ul> <li>Distributed tracing: Follow operations across services</li> <li>Causal ordering: Understand event relationships</li> <li>Debugging: See the chain of events</li> </ul>"},{"location":"concepts/events/#further-reading","title":"Further Reading","text":"<ul> <li>Tutorial: Events &amp; Sourcing \u2014 Hands-on guide</li> <li>Event Sourcing \u2014 The pattern that events enable</li> <li>Event Processors \u2014 Reacting to events</li> <li>Event Upcasting Guide \u2014 Schema evolution</li> </ul>"},{"location":"concepts/projections/","title":"Projections","text":"<p>A projection is a read model that combines event handling with query serving.  Projections are the read side of CQRS\u2014they build optimized views from events and  serve typed queries against those views.</p>"},{"location":"concepts/projections/#projections-vs-event-processors","title":"Projections vs Event Processors","text":"<p>While both <code>EventProcessor</code> and <code>Projection</code> handle events, they serve different  purposes:</p> Aspect EventProcessor Projection Purpose React to events Build and query read models Event handling \u2713 \u2713 Query handling \u2717 \u2713 Use case Side effects, notifications Read models, lookups <p>A projection is an event processor (it extends <code>EventProcessor</code>), but adds  the ability to handle queries.</p>"},{"location":"concepts/projections/#projections-vs-aggregates","title":"Projections vs Aggregates","text":"<p>Projections are the read-side counterpart to aggregates:</p> Aspect Aggregates Projections Handles Commands Queries Purpose Enforce invariants, emit events Build views, serve reads State Event-sourced, authoritative Derived, eventually consistent Updates Receives commands Receives events <pre><code>graph LR\n    C[Command] --&gt; A[Aggregate]\n    A --&gt; E[Events]\n    E --&gt; P[Projection]\n    Q[Query] --&gt; P\n    P --&gt; R[Response]</code></pre>"},{"location":"concepts/projections/#defining-projections","title":"Defining Projections","text":"<p>Projections extend <code>Projection</code> and use two decorators:</p> <ul> <li><code>@handles_event</code> \u2014 Methods that process events to update state</li> <li><code>@handles_query</code> \u2014 Methods that serve queries against the state</li> </ul> <pre><code>from interlock.application import Projection\nfrom interlock.domain import Query\nfrom interlock.routing import handles_event, handles_query\nfrom pydantic import BaseModel\nfrom uuid import UUID, uuid4\n\n# Response type\nclass UserProfile(BaseModel):\n    id: UUID\n    name: str\n    email: str\n\n# Query types (see Queries documentation for details)\nclass GetUserById(Query[UserProfile]):\n    user_id: UUID\n\nclass GetUserByEmail(Query[UUID | None]):\n    email: str\n\nclass CountUsers(Query[int]):\n    pass\n\n# Projection that builds a user directory\nclass UserDirectoryProjection(Projection):\n    def __init__(self):\n        super().__init__()\n        self.users: dict[UUID, UserProfile] = {}\n        self.email_index: dict[str, UUID] = {}\n\n    # Event handlers update state\n    @handles_event\n    async def on_user_created(self, event: UserCreated) -&gt; None:\n        profile = UserProfile(\n            id=event.user_id,\n            name=event.name,\n            email=event.email\n        )\n        self.users[event.user_id] = profile\n        self.email_index[event.email] = event.user_id\n\n    @handles_event\n    async def on_email_changed(self, event: EmailChanged) -&gt; None:\n        user = self.users.get(event.user_id)\n        if user:\n            del self.email_index[user.email]\n            user.email = event.new_email\n            self.email_index[event.new_email] = event.user_id\n\n    # Query handlers serve reads\n    @handles_query\n    async def get_by_id(self, query: GetUserById) -&gt; UserProfile:\n        return self.users[query.user_id]\n\n    @handles_query\n    async def get_by_email(self, query: GetUserByEmail) -&gt; UUID | None:\n        return self.email_index.get(query.email)\n\n    @handles_query\n    async def count(self, query: CountUsers) -&gt; int:\n        return len(self.users)\n</code></pre>"},{"location":"concepts/projections/#registering-projections","title":"Registering Projections","text":"<p>Register projections with the application builder:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_projection(UserDirectoryProjection)\n    .register_projection(OrderHistoryProjection)\n    .build()\n)\n</code></pre> <p>Each query type can only be handled by one projection\u2014the framework uses the  query type to route to the correct projection.</p>"},{"location":"concepts/projections/#dispatching-queries","title":"Dispatching Queries","text":"<p>See Queries for complete details. The short version:</p> <pre><code>async with app:\n    # Queries are dispatched through app.query()\n    user = await app.query(GetUserById(user_id=user_id))\n    print(user.name)\n\n    # Queries pass through middleware\n    count = await app.query(CountUsers())\n    print(f\"Total users: {count}\")\n</code></pre>"},{"location":"concepts/projections/#middleware-with-projections","title":"Middleware with Projections","text":"<p>Middleware can intercept queries just like commands. Use the <code>Query</code> base type  to intercept all queries:</p> <pre><code>from interlock.application.middleware import Middleware, Handler\nfrom interlock.domain import Query\nfrom interlock.routing import intercepts\n\nclass QueryLoggingMiddleware(Middleware):\n    @intercepts\n    async def log_query(self, query: Query, next: Handler):\n        print(f\"Query: {type(query).__name__}\")\n        result = await next(query)\n        print(f\"Result: {result}\")\n        return result\n\nclass CachingMiddleware(Middleware):\n    def __init__(self):\n        self.cache = {}\n\n    @intercepts\n    async def cache_queries(self, query: Query, next: Handler):\n        key = f\"{type(query).__name__}:{query.model_dump_json()}\"\n\n        if key in self.cache:\n            return self.cache[key]\n\n        result = await next(query)\n        self.cache[key] = result\n        return result\n</code></pre> <p>The same middleware instance handles both commands and queries\u2014use type  annotations to control which messages are intercepted.</p>"},{"location":"concepts/projections/#persistence","title":"Persistence","text":"<p>Projections are responsible for their own state persistence. The simple examples  above use in-memory state, which is fine for testing but not production.</p>"},{"location":"concepts/projections/#repository-pattern-recommended","title":"Repository Pattern (Recommended)","text":"<p>The recommended approach is to define an abstract repository interface and  inject it into the projection. This decouples the projection from the storage  mechanism, allowing you to:</p> <ul> <li>Swap storage backends without changing projection code</li> <li>Use in-memory storage for fast unit tests</li> <li>Use different databases in different environments</li> </ul>"},{"location":"concepts/projections/#step-1-define-the-repository-interface","title":"Step 1: Define the Repository Interface","text":"<p>Create an abstract base class that defines the operations your projection needs:</p> <pre><code>from abc import ABC, abstractmethod\nfrom uuid import UUID, uuid4\n\nclass UserDirectoryRepository(ABC):\n    \"\"\"Abstract interface for user directory storage.\"\"\"\n\n    @abstractmethod\n    async def save_user(self, user: UserProfile) -&gt; None:\n        \"\"\"Save or update a user profile.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_user(self, user_id: UUID) -&gt; UserProfile | None:\n        \"\"\"Get a user by ID, or None if not found.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_user_by_email(self, email: str) -&gt; UUID | None:\n        \"\"\"Look up user ID by email, or None if not found.\"\"\"\n        ...\n\n    @abstractmethod\n    async def update_email(self, user_id: UUID, new_email: str) -&gt; None:\n        \"\"\"Update a user's email address.\"\"\"\n        ...\n\n    @abstractmethod\n    async def count_users(self) -&gt; int:\n        \"\"\"Return total number of users.\"\"\"\n        ...\n</code></pre>"},{"location":"concepts/projections/#step-2-implement-the-interface","title":"Step 2: Implement the Interface","text":"<p>Provide implementations for different environments:</p> <pre><code># In-memory implementation for testing\nclass InMemoryUserDirectoryRepository(UserDirectoryRepository):\n    def __init__(self):\n        self.users: dict[UUID, UserProfile] = {}\n        self.email_index: dict[str, UUID] = {}\n\n    async def save_user(self, user: UserProfile) -&gt; None:\n        self.users[user.id] = user\n        self.email_index[user.email] = user.id\n\n    async def get_user(self, user_id: UUID) -&gt; UserProfile | None:\n        return self.users.get(user_id)\n\n    async def get_user_by_email(self, email: str) -&gt; UUID | None:\n        return self.email_index.get(email)\n\n    async def update_email(self, user_id: UUID, new_email: str) -&gt; None:\n        user = self.users.get(user_id)\n        if user:\n            del self.email_index[user.email]\n            user.email = new_email\n            self.email_index[new_email] = user_id\n\n    async def count_users(self) -&gt; int:\n        return len(self.users)\n\n\n# PostgreSQL implementation for production\nclass PostgresUserDirectoryRepository(UserDirectoryRepository):\n    def __init__(self, connection_pool: asyncpg.Pool):\n        self.pool = connection_pool\n\n    async def save_user(self, user: UserProfile) -&gt; None:\n        async with self.pool.acquire() as conn:\n            await conn.execute(\n                \"\"\"\n                INSERT INTO user_directory (id, name, email)\n                VALUES ($1, $2, $3)\n                ON CONFLICT (id) DO UPDATE SET name = $2, email = $3\n                \"\"\",\n                str(user.id), user.name, user.email\n            )\n\n    async def get_user(self, user_id: UUID) -&gt; UserProfile | None:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT id, name, email FROM user_directory WHERE id = $1\",\n                str(user_id)\n            )\n            if row:\n                return UserProfile(\n                    id=UUID(row[\"id\"]),\n                    name=row[\"name\"],\n                    email=row[\"email\"]\n                )\n            return None\n\n    # ... other methods\n</code></pre>"},{"location":"concepts/projections/#step-3-inject-the-interface","title":"Step 3: Inject the Interface","text":"<p>The projection depends on the abstract interface, not a concrete implementation:</p> <pre><code>class UserDirectoryProjection(Projection):\n    def __init__(self, repository: UserDirectoryRepository):  # (1)!\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_user_created(self, event: UserCreated) -&gt; None:\n        await self.repository.save_user(UserProfile(\n            id=event.user_id,\n            name=event.name,\n            email=event.email\n        ))\n\n    @handles_event\n    async def on_email_changed(self, event: EmailChanged) -&gt; None:\n        await self.repository.update_email(event.user_id, event.new_email)\n\n    @handles_query\n    async def get_by_id(self, query: GetUserById) -&gt; UserProfile:\n        user = await self.repository.get_user(query.user_id)\n        if not user:\n            raise KeyError(f\"User not found: {query.user_id}\")\n        return user\n\n    @handles_query\n    async def get_by_email(self, query: GetUserByEmail) -&gt; UUID | None:\n        return await self.repository.get_user_by_email(query.email)\n\n    @handles_query\n    async def count(self, query: CountUsers) -&gt; int:\n        return await self.repository.count_users()\n</code></pre> <ol> <li>Inject the abstract interface, not a concrete implementation</li> </ol>"},{"location":"concepts/projections/#step-4-register-the-implementation","title":"Step 4: Register the Implementation","text":"<p>Choose which implementation to use when building the application:</p> <pre><code># Production configuration\napp = (\n    ApplicationBuilder()\n    .register_dependency(asyncpg.Pool, create_connection_pool)\n    .register_dependency(\n        UserDirectoryRepository,  # Interface\n        PostgresUserDirectoryRepository  # Implementation\n    )\n    .register_projection(UserDirectoryProjection)\n    .build()\n)\n\n# Test configuration\ntest_app = (\n    ApplicationBuilder()\n    .register_dependency(\n        UserDirectoryRepository,\n        InMemoryUserDirectoryRepository\n    )\n    .register_projection(UserDirectoryProjection)\n    .build()\n)\n</code></pre>"},{"location":"concepts/projections/#benefits-of-this-approach","title":"Benefits of This Approach","text":"Benefit Description Testability Unit tests use fast in-memory storage Flexibility Swap databases without changing projection code Clarity Repository interface documents storage requirements Single Responsibility Projection handles events/queries; repository handles storage"},{"location":"concepts/projections/#id-lookups","title":"ID Lookups","text":"<p>A common use case for projections is dereferencing natural identifiers to  aggregate IDs. For example, looking up an account by email to find its  aggregate ID before dispatching commands.</p> <p>Following the repository pattern:</p> <pre><code>from abc import ABC, abstractmethod\n\n# Repository interface for account lookups\nclass AccountLookupRepository(ABC):\n    @abstractmethod\n    async def save_mapping(self, email: str, account_id: UUID) -&gt; None:\n        ...\n\n    @abstractmethod\n    async def get_account_id(self, email: str) -&gt; UUID | None:\n        ...\n\n\n# In-memory implementation\nclass InMemoryAccountLookupRepository(AccountLookupRepository):\n    def __init__(self):\n        self.email_to_id: dict[str, UUID] = {}\n\n    async def save_mapping(self, email: str, account_id: UUID) -&gt; None:\n        self.email_to_id[email] = account_id\n\n    async def get_account_id(self, email: str) -&gt; UUID | None:\n        return self.email_to_id.get(email)\n\n\n# Query definition\nclass GetAccountIdByEmail(Query[UUID | None]):\n    email: str\n\n\n# Projection with injected repository\nclass AccountLookupProjection(Projection):\n    def __init__(self, repository: AccountLookupRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_account_created(self, event: AccountCreated) -&gt; None:\n        await self.repository.save_mapping(event.email, event.account_id)\n\n    @handles_query\n    async def lookup(self, query: GetAccountIdByEmail) -&gt; UUID | None:\n        return await self.repository.get_account_id(query.email)\n</code></pre> <p>Usage:</p> <pre><code># Find aggregate ID by natural key\naccount_id = await app.query(GetAccountIdByEmail(email=\"alice@example.com\"))\n\nif account_id:\n    # Now dispatch commands to the aggregate\n    await app.dispatch(DepositMoney(aggregate_id=account_id, amount=100))\nelse:\n    raise ValueError(\"Account not found\")\n</code></pre> <p>This pattern is especially useful when:</p> <ul> <li>External systems reference entities by natural keys (email, username, SKU)</li> <li>APIs need to accept human-readable identifiers</li> <li>You need to check existence before dispatching commands</li> </ul>"},{"location":"concepts/projections/#testing-projections","title":"Testing Projections","text":"<p>When using the repository pattern, inject an in-memory implementation for fast,  isolated unit tests.</p>"},{"location":"concepts/projections/#direct-testing-with-projectionscenario","title":"Direct Testing with ProjectionScenario","text":"<p>Use <code>ProjectionScenario</code> for Given-When-Then testing:</p> <pre><code>from interlock.testing import ProjectionScenario\n\n@pytest.fixture\ndef projection():\n    \"\"\"Create projection with in-memory repository.\"\"\"\n    repository = InMemoryUserDirectoryRepository()\n    return UserDirectoryProjection(repository)\n\n@pytest.mark.asyncio\nasync def test_user_lookup(projection):\n    user_id = uuid4()\n\n    async with ProjectionScenario(projection) as scenario:\n        # Given: User was created\n        scenario.given(\n            UserCreated(user_id=user_id, name=\"Alice\", email=\"alice@test.com\")\n        )\n\n        # When: Query by email\n        result = await scenario.when(\n            GetUserByEmail(email=\"alice@test.com\")\n        )\n\n        # Then: Returns the user ID\n        assert result == user_id\n\n@pytest.mark.asyncio\nasync def test_user_count(projection):\n    async with ProjectionScenario(projection) as scenario:\n        scenario.given(\n            UserCreated(user_id=uuid4(), name=\"Alice\", email=\"a@test.com\"),\n            UserCreated(user_id=uuid4(), name=\"Bob\", email=\"b@test.com\"),\n        )\n\n        count = await scenario.when(CountUsers())\n\n        assert count == 2\n</code></pre>"},{"location":"concepts/projections/#testing-with-full-di","title":"Testing with Full DI","text":"<p>Use <code>app.projection_scenario()</code> to test with the full dependency injection  container. This is useful for integration tests:</p> <pre><code>@pytest.fixture\ndef test_app():\n    \"\"\"Build app with in-memory repositories.\"\"\"\n    return (\n        ApplicationBuilder()\n        .register_dependency(\n            UserDirectoryRepository,\n            InMemoryUserDirectoryRepository\n        )\n        .register_projection(UserDirectoryProjection)\n        .build()\n    )\n\n@pytest.mark.asyncio\nasync def test_with_di(test_app):\n    async with test_app.projection_scenario(UserDirectoryProjection) as scenario:\n        scenario.given(UserCreated(user_id=uuid4(), name=\"Alice\", email=\"a@test.com\"))\n        result = await scenario.when(GetUserByEmail(email=\"a@test.com\"))\n        assert result is not None\n</code></pre>"},{"location":"concepts/projections/#summary","title":"Summary","text":"Concept Description <code>Projection</code> Base class combining event handling + query serving <code>@handles_event</code> Decorator for event handler methods <code>@handles_query</code> Decorator for query handler methods <code>app.query()</code> Dispatch a query through middleware to projection <code>ProjectionScenario</code> Testing utility for projections"},{"location":"concepts/projections/#further-reading","title":"Further Reading","text":"<ul> <li>Queries \u2014 The messages projections handle</li> <li>CQRS \u2014 The pattern projections implement</li> <li>Event Processors \u2014 Related concept for event handling</li> <li>Custom Middleware \u2014 Intercepting queries</li> </ul>"},{"location":"concepts/queries/","title":"Queries","text":"<p>A query is a message that requests data without changing state. Queries are the read-side counterpart to commands\u2014they represent what a user or system wants to know.</p>"},{"location":"concepts/queries/#queries-vs-commands","title":"Queries vs Commands","text":"<p>While commands and queries are both messages, they serve opposite purposes:</p> Aspect Commands Queries Purpose Change state Read state Side effects Yes (events emitted) No Handler Aggregate Projection Return value Optional result Required result Idempotency May need explicit handling Naturally idempotent <pre><code># Command - requests a change\nclass DepositMoney(Command[None]):\n    amount: int\n\n# Query - requests data\nclass GetAccountBalance(Query[int]):\n    account_id: UUID\n</code></pre>"},{"location":"concepts/queries/#defining-queries","title":"Defining Queries","text":"<p>Queries extend <code>Query[TResponse]</code> where <code>TResponse</code> is the expected return type:</p> <pre><code>from interlock.domain import Query\nfrom pydantic import BaseModel\nfrom uuid import UUID, uuid4\n\nclass UserProfile(BaseModel):\n    id: UUID\n    name: str\n    email: str\n\n# Query that returns a UserProfile\nclass GetUserById(Query[UserProfile]):\n    user_id: UUID\n\n# Query that returns an optional UUID (for lookups)\nclass GetUserByEmail(Query[UUID | None]):\n    email: str\n\n# Query that returns an int\nclass GetAccountBalance(Query[int]):\n    account_id: UUID\n\n# Query that returns a list\nclass ListRecentOrders(Query[list[Order]]):\n    user_id: UUID\n    limit: int = 10\n</code></pre> <p>The type parameter provides:</p> <ul> <li>Type safety \u2014 IDE and type checkers verify response types</li> <li>Documentation \u2014 Clear contract for what queries return</li> <li>Autocomplete \u2014 IDE support on query results</li> </ul>"},{"location":"concepts/queries/#query-fields","title":"Query Fields","text":"<p>Every query automatically includes these fields:</p> Field Type Description <code>query_id</code> <code>UUID</code> Unique identifier (auto-generated) <code>correlation_id</code> <code>UUID \\| None</code> Links related operations <code>causation_id</code> <code>UUID \\| None</code> What triggered this query <pre><code>query = GetUserById(user_id=some_id)\nprint(query.query_id)  # Auto-generated UUID\n</code></pre> <p>Unlike commands, queries don't have an <code>aggregate_id</code>\u2014they're routed to  projections based on which projection has a handler for the query type.</p>"},{"location":"concepts/queries/#naming-conventions","title":"Naming Conventions","text":"<p>Queries should be named to describe what data they return:</p> \u2713 Good \u2717 Bad <code>GetUserById</code> <code>UserQuery</code> <code>GetAccountBalance</code> <code>BalanceRequest</code> <code>ListRecentOrders</code> <code>OrdersQuery</code> <code>FindUserByEmail</code> <code>EmailLookup</code> <code>CountActiveUsers</code> <code>UserCount</code> <p>Common prefixes:</p> <ul> <li><code>Get...</code> \u2014 Retrieve a single item by ID</li> <li><code>Find...</code> \u2014 Search/lookup by criteria</li> <li><code>List...</code> \u2014 Return a collection</li> <li><code>Count...</code> \u2014 Return an aggregate count</li> <li><code>Check...</code> \u2014 Return a boolean</li> </ul>"},{"location":"concepts/queries/#dispatching-queries","title":"Dispatching Queries","text":"<p>Send queries through the application's <code>query()</code> method:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_projection(UserProjection)\n    .build()\n)\n\nasync with app:\n    # Get user by ID (returns UserProfile)\n    user = await app.query(GetUserById(user_id=user_id))\n    print(user.name)\n\n    # Find user by email (returns UUID | None)\n    found_id = await app.query(GetUserByEmail(email=\"alice@example.com\"))\n    if found_id:\n        print(f\"Found user: {found_id}\")\n\n    # Count all users (returns int)\n    count = await app.query(CountUsers())\n    print(f\"Total users: {count}\")\n</code></pre>"},{"location":"concepts/queries/#what-happens-during-dispatch","title":"What Happens During Dispatch","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant App as Application\n    participant MW as Middleware\n    participant Proj as Projection\n    participant Repo as Repository\n\n    Client-&gt;&gt;App: query(GetUserById)\n    App-&gt;&gt;MW: Pass through middleware chain\n    MW-&gt;&gt;MW: Log, cache, authorize...\n    MW-&gt;&gt;App: Continue\n    App-&gt;&gt;Proj: Route to projection\n    Proj-&gt;&gt;Repo: Fetch from storage\n    Repo--&gt;&gt;Proj: Data\n    Proj--&gt;&gt;App: UserProfile\n    App--&gt;&gt;Client: UserProfile</code></pre>"},{"location":"concepts/queries/#query-routing","title":"Query Routing","text":"<p>Queries are routed to projections through a two-step process:</p> <ol> <li>Find the projection type: Based on which projection has a <code>@handles_query</code> handler for this query type</li> <li>Get the projection instance: From the projection registry</li> <li>Execute the handler: Returns the typed response</li> </ol> <pre><code>class UserProjection(Projection):\n    @handles_query\n    async def get_user(self, query: GetUserById) -&gt; UserProfile:\n        # This handler tells Interlock that GetUserById\n        # should be routed to UserProjection\n        ...\n</code></pre>"},{"location":"concepts/queries/#multiple-projections","title":"Multiple Projections","text":"<p>Different queries route to different projections:</p> <pre><code>class UserProjection(Projection):\n    @handles_query\n    async def get_user(self, query: GetUserById) -&gt; UserProfile: ...\n\nclass OrderProjection(Projection):\n    @handles_query\n    async def list_orders(self, query: ListRecentOrders) -&gt; list[Order]: ...\n\n# Queries route to the correct projection\nuser = await app.query(GetUserById(...))      # \u2192 UserProjection\norders = await app.query(ListRecentOrders(...))  # \u2192 OrderProjection\n</code></pre>"},{"location":"concepts/queries/#correlation-and-causation","title":"Correlation and Causation","text":"<p>Like commands, queries support distributed tracing:</p> <pre><code># Query triggered by a command handler or saga\nbalance = await app.query(GetAccountBalance(\n    account_id=account_id,\n    correlation_id=context.correlation_id,  # Same trace\n    causation_id=context.command_id  # What caused this query\n))\n</code></pre> <p>This enables:</p> <ul> <li>Tracing: Follow read operations in distributed traces</li> <li>Debugging: Understand what triggered expensive queries</li> <li>Auditing: Track who queried what data</li> </ul>"},{"location":"concepts/queries/#validation","title":"Validation","text":"<p>Queries support Pydantic validation:</p> <pre><code>from pydantic import Field\n\nclass ListRecentOrders(Query[list[Order]]):\n    user_id: UUID\n    limit: int = Field(default=10, ge=1, le=100)  # 1-100 range\n    offset: int = Field(default=0, ge=0)\n\n# This raises ValidationError\nListRecentOrders(user_id=uuid4(), limit=500)  # limit &gt; 100\n</code></pre>"},{"location":"concepts/queries/#common-patterns","title":"Common Patterns","text":""},{"location":"concepts/queries/#lookup-queries","title":"Lookup Queries","text":"<p>Dereference natural identifiers to aggregate IDs:</p> <pre><code>class GetAccountIdByEmail(Query[UUID | None]):\n    \"\"\"Find account aggregate ID by email address.\"\"\"\n    email: str\n\n# Usage: find aggregate ID, then dispatch command\naccount_id = await app.query(GetAccountIdByEmail(email=\"alice@example.com\"))\nif account_id:\n    await app.dispatch(DepositMoney(aggregate_id=account_id, amount=100))\n</code></pre>"},{"location":"concepts/queries/#existence-checks","title":"Existence Checks","text":"<pre><code>class CheckEmailExists(Query[bool]):\n    email: str\n\nexists = await app.query(CheckEmailExists(email=\"alice@example.com\"))\nif exists:\n    raise EmailAlreadyTakenError()\n</code></pre>"},{"location":"concepts/queries/#paginated-queries","title":"Paginated Queries","text":"<pre><code>class Page(BaseModel, Generic[T]):\n    items: list[T]\n    total: int\n    has_more: bool\n\nclass ListUsers(Query[Page[UserSummary]]):\n    limit: int = 20\n    cursor: str | None = None\n\npage = await app.query(ListUsers(limit=20))\nprint(f\"Showing {len(page.items)} of {page.total} users\")\n</code></pre>"},{"location":"concepts/queries/#best-practices","title":"Best Practices","text":""},{"location":"concepts/queries/#keep-queries-focused","title":"Keep Queries Focused","text":"<p>Each query should return data for a specific use case:</p> <pre><code># Too broad - returns everything\nclass GetUser(Query[User]):\n    user_id: UUID\n\n# Focused - returns what the profile page needs\nclass GetUserProfile(Query[UserProfile]):\n    user_id: UUID\n\n# Focused - returns what the admin dashboard needs  \nclass GetUserAdminView(Query[UserAdminDetails]):\n    user_id: UUID\n</code></pre>"},{"location":"concepts/queries/#include-necessary-parameters","title":"Include Necessary Parameters","text":"<p>Queries should carry all information needed to fetch the data:</p> <pre><code># Missing context\nclass ListOrders(Query[list[Order]]):\n    pass  # Whose orders? How many?\n\n# Complete context\nclass ListOrders(Query[list[Order]]):\n    user_id: UUID\n    status: OrderStatus | None = None\n    limit: int = 20\n</code></pre>"},{"location":"concepts/queries/#return-rich-types","title":"Return Rich Types","text":"<p>Return structured types, not dictionaries:</p> <pre><code># Avoid - loses type safety\nclass GetUser(Query[dict]):\n    user_id: UUID\n\n# Better - strongly typed\nclass GetUser(Query[UserProfile]):\n    user_id: UUID\n</code></pre>"},{"location":"concepts/queries/#further-reading","title":"Further Reading","text":"<ul> <li>Projections \u2014 Where queries are handled</li> <li>Commands \u2014 The write-side counterpart</li> <li>CQRS \u2014 The pattern queries implement</li> <li>Custom Middleware \u2014 Intercepting queries</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to Interlock! This guide will help you get up and running quickly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Basic familiarity with Python and async programming</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"pipuvpoetry <pre><code>pip install interlock\n</code></pre> <pre><code>uv add interlock\n</code></pre> <pre><code>poetry add interlock\n</code></pre>"},{"location":"getting-started/#verify-installation","title":"Verify Installation","text":"<pre><code>import interlock\nprint(interlock.__version__)\n</code></pre>"},{"location":"getting-started/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Quick Start</p> <p>Build a minimal working example in 5 minutes</p> <p> Quick Start</p> </li> <li> <p> Tutorial</p> <p>Learn Interlock step-by-step with a complete project</p> <p> Tutorial</p> </li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Build your first event-sourced application in 5 minutes.</p> <p>Prerequisites</p> <p>Make sure you have installed Interlock before continuing.</p>"},{"location":"getting-started/quickstart/#step-1-define-your-domain","title":"Step 1: Define Your Domain","text":"<pre><code>from pydantic import BaseModel\nfrom uuid import UUID, uuid4\n\nfrom interlock.domain import Aggregate, Command, Query\nfrom interlock.routing import handles_command, applies_event\n\n# Define commands (write operations)\nclass OpenAccount(Command[None]):\n    owner_name: str\n\nclass DepositMoney(Command[None]):\n    amount: int\n\n# Define queries (read operations)\nclass GetBalance(Query[int]):\n    account_id: UUID\n\n# Define event data\nclass AccountOpened(BaseModel):\n    owner_name: str\n\nclass MoneyDeposited(BaseModel):\n    amount: int\n\n# Define an aggregate\nclass BankAccount(Aggregate):\n    owner_name: str = \"\"\n    balance: int = 0\n\n    @handles_command\n    async def open(self, command: OpenAccount) -&gt; None:\n        self.emit(AccountOpened(owner_name=command.owner_name))\n\n    @handles_command\n    async def deposit(self, command: DepositMoney) -&gt; None:\n        if command.amount &lt;= 0:\n            raise ValueError(\"Amount must be positive\")\n        self.emit(MoneyDeposited(amount=command.amount))\n\n    @applies_event\n    def apply_opened(self, event: AccountOpened) -&gt; None:\n        self.owner_name = event.owner_name\n\n    @applies_event\n    def apply_deposit(self, event: MoneyDeposited) -&gt; None:\n        self.balance += event.amount\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-define-a-projection","title":"Step 2: Define a Projection","text":"<p>Projections build read models from events and serve queries:</p> <pre><code>from interlock.application import Projection\nfrom interlock.routing import handles_event, handles_query\n\nclass BalanceProjection(Projection):\n    def __init__(self):\n        super().__init__()\n        self.balances: dict[UUID, int] = {}\n\n    @handles_event\n    async def on_deposit(self, event: MoneyDeposited, aggregate_id: UUID) -&gt; None:\n        current = self.balances.get(aggregate_id, 0)\n        self.balances[aggregate_id] = current + event.amount\n\n    @handles_query\n    async def get_balance(self, query: GetBalance) -&gt; int:\n        return self.balances.get(query.account_id, 0)\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-create-an-application","title":"Step 3: Create an Application","text":"<pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_projection(BalanceProjection)\n    .build()\n)\n</code></pre>"},{"location":"getting-started/quickstart/#step-4-send-commands-and-queries","title":"Step 4: Send Commands and Queries","text":"<pre><code>async def main():\n    async with app:\n        # Create a new account\n        account_id = uuid4()\n        await app.dispatch(OpenAccount(\n            aggregate_id=account_id,\n            owner_name=\"Alice\"\n        ))\n\n        # Deposit money\n        await app.dispatch(DepositMoney(\n            aggregate_id=account_id,\n            amount=100\n        ))\n\n        # Query the balance\n        balance = await app.query(GetBalance(account_id=account_id))\n        print(f\"Balance: ${balance}\")  # Balance: $100\n\n# Run it\nimport asyncio\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#what-just-happened","title":"What Just Happened?","text":""},{"location":"getting-started/quickstart/#write-side-commands","title":"Write Side (Commands)","text":"<ol> <li>Command dispatched: <code>DepositMoney</code> was sent to the application</li> <li>Aggregate loaded: The <code>BankAccount</code> aggregate was created (or loaded from events)</li> <li>Handler executed: <code>@handles_command</code> method validated and emitted an event</li> <li>Event applied: <code>@applies_event</code> method updated the aggregate's state</li> <li>Event persisted: The event was stored (in-memory by default)</li> </ol>"},{"location":"getting-started/quickstart/#read-side-queries","title":"Read Side (Queries)","text":"<ol> <li>Query dispatched: <code>GetBalance</code> was sent to the application</li> <li>Projection found: The framework routed the query to <code>BalanceProjection</code></li> <li>Handler executed: <code>@handles_query</code> method returned the balance</li> <li>Result returned: The typed response was returned to the caller</li> </ol> <pre><code>flowchart LR\n    subgraph \"Write Side\"\n        CMD[DepositMoney] --&gt; AGG[BankAccount]\n        AGG --&gt; EVT[MoneyDeposited]\n    end\n\n    EVT --&gt; STORE[(Event Store)]\n    STORE --&gt; PROJ[BalanceProjection]\n\n    subgraph \"Read Side\"\n        QRY[GetBalance] --&gt; PROJ\n        PROJ --&gt; RES[$100]\n    end</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li> Follow the full tutorial</li> <li> Learn about concepts</li> <li> Explore the API reference</li> </ul>"},{"location":"guides/","title":"Guides","text":"<p>Task-oriented how-to guides for specific features and use cases.</p>"},{"location":"guides/#available-guides","title":"Available Guides","text":"<ul> <li> <p> Application Lifecycle</p> <p>Manage startup and shutdown of your application's dependencies</p> <p> Application Lifecycle</p> </li> <li> <p> Dependency Injection</p> <p>Wire up your components with constructor injection</p> <p> Dependency Injection</p> </li> <li> <p> Aggregate Optimization</p> <p>Speed up aggregate loading with snapshots and caching</p> <p> Aggregate Optimization</p> </li> <li> <p> Processor Catchup</p> <p>Keep event processors synchronized with the event stream</p> <p> Processor Catchup</p> </li> <li> <p> Event Upcasting</p> <p>Evolve your event schemas without breaking existing data</p> <p> Event Upcasting</p> </li> <li> <p> Sagas</p> <p>Orchestrate long-running, multi-step business processes</p> <p> Sagas</p> </li> <li> <p> Writing Tests</p> <p>Test your aggregates and processors effectively</p> <p> Writing Tests</p> </li> <li> <p> Custom Middleware</p> <p>Build middleware for cross-cutting concerns</p> <p> Custom Middleware</p> </li> <li> <p> Database Integrations</p> <p>Connect Interlock to MongoDB, PostgreSQL, and more</p> <p> Database Integrations</p> </li> </ul>"},{"location":"guides/aggregate-optimization/","title":"Aggregate Optimization","text":"<p>As your aggregates accumulate events, loading them by replaying every event becomes expensive. Interlock provides snapshots and caching to optimize aggregate loading performance.</p>"},{"location":"guides/aggregate-optimization/#the-problem","title":"The Problem","text":"<p>Every time an aggregate is loaded, Interlock replays all its events to rebuild the current state:</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Store as Event Store\n    participant Agg as BankAccount\n\n    App-&gt;&gt;Store: Load aggregate \"acc-123\"\n    Store-&gt;&gt;Agg: Create fresh BankAccount()\n    Note over Agg: balance = 0\n    Store-&gt;&gt;Agg: Replay event 1\n    Store-&gt;&gt;Agg: Replay event 2\n    Store-&gt;&gt;Agg: ...\n    Store-&gt;&gt;Agg: Replay event 10,000\n    Note over Agg: balance = final\n    Store-&gt;&gt;App: Return hydrated aggregate</code></pre> <p>For aggregates with thousands of events, this replay can be slow. Two optimization strategies help:</p> Strategy What it does Best for Snapshots Periodically save aggregate state Long-lived aggregates with many events Caching Keep recently-used aggregates in memory Frequently accessed aggregates"},{"location":"guides/aggregate-optimization/#snapshots","title":"Snapshots","text":"<p>A snapshot saves the aggregate's full state at a point in time. When loading, Interlock loads the snapshot and only replays events that occurred after it:</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Snap as Snapshot Store\n    participant Store as Event Store\n    participant Agg as BankAccount\n\n    App-&gt;&gt;Snap: Load snapshot for \"acc-123\"\n    Snap-&gt;&gt;Agg: Restore state (version 9,500)\n    Note over Agg: balance = $45,230\n    App-&gt;&gt;Store: Load events after version 9,500\n    Store-&gt;&gt;Agg: Replay event 9,501\n    Store-&gt;&gt;Agg: ...\n    Store-&gt;&gt;Agg: Replay event 10,000\n    Note over Agg: balance = final\n    Store-&gt;&gt;App: Return hydrated aggregate</code></pre> <p>Instead of replaying 10,000 events, we only replay 500.</p>"},{"location":"guides/aggregate-optimization/#snapshot-strategies","title":"Snapshot Strategies","text":"<p>A snapshot strategy decides when to create snapshots. Configure it per-aggregate:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.aggregates import SnapshotAfterN, SnapshotAfterTime\nfrom datetime import timedelta\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(\n        BankAccount,\n        snapshot_strategy=SnapshotAfterN(100),  # Snapshot every 100 events\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/aggregate-optimization/#available-strategies","title":"Available Strategies","text":"Strategy Description When to use <code>NeverSnapshot</code> Never create snapshots (default) Small aggregates, few events <code>SnapshotAfterN(n)</code> Snapshot every N events Most common choice <code>SnapshotAfterTime(delta)</code> Snapshot after time elapsed since last snapshot Time-based policies <p><code>SnapshotAfterN(n)</code> - Create a snapshot when <code>aggregate.version % n == 0</code>:</p> <pre><code>from interlock.application.aggregates import SnapshotAfterN\n\n# Snapshot at versions 100, 200, 300, ...\nsnapshot_strategy=SnapshotAfterN(100)\n</code></pre> <p><code>SnapshotAfterTime(timedelta)</code> - Create a snapshot if the last snapshot is older than the threshold:</p> <pre><code>from interlock.application.aggregates import SnapshotAfterTime\nfrom datetime import timedelta\n\n# Snapshot if last snapshot was &gt; 1 hour ago\nsnapshot_strategy=SnapshotAfterTime(timedelta(hours=1))\n</code></pre>"},{"location":"guides/aggregate-optimization/#snapshot-storage-backends","title":"Snapshot Storage Backends","text":"<p>A snapshot backend handles persisting and loading snapshots. Configure it per-aggregate:</p> <pre><code>from interlock.application.aggregates import InMemoryAggregateSnapshotStorageBackend\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(\n        BankAccount,\n        snapshot_strategy=SnapshotAfterN(100),\n        snapshot_backend=InMemoryAggregateSnapshotStorageBackend,\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/aggregate-optimization/#available-backends","title":"Available Backends","text":"Backend Description When to use <code>NullAggregateSnapshotStorageBackend</code> No-op, doesn't store (default) Snapshots disabled <code>InMemoryAggregateSnapshotStorageBackend</code> Stores in memory Testing, development <p>For production, you'll typically implement a custom backend backed by your database. See the Database Integrations guide for planned implementations.</p>"},{"location":"guides/aggregate-optimization/#custom-snapshot-backend","title":"Custom Snapshot Backend","text":"<p>Implement <code>AggregateSnapshotStorageBackend</code> for your storage:</p> <pre><code>from interlock.application.aggregates import AggregateSnapshotStorageBackend\nfrom interlock.domain import Aggregate\nfrom uuid import UUID, uuid4\nfrom typing import TypeVar\n\nT = TypeVar(\"T\", bound=Aggregate)\n\nclass PostgresSnapshotBackend(AggregateSnapshotStorageBackend):\n    def __init__(self, connection_pool, aggregate_type: type[Aggregate]):\n        self.pool = connection_pool\n        self.aggregate_type = aggregate_type\n\n    async def save_snapshot(self, aggregate: Aggregate) -&gt; None:\n        async with self.pool.acquire() as conn:\n            await conn.execute(\n                \"\"\"\n                INSERT INTO snapshots (aggregate_id, aggregate_type, version, data)\n                VALUES ($1, $2, $3, $4)\n                ON CONFLICT (aggregate_id) DO UPDATE\n                SET version = $3, data = $4\n                \"\"\",\n                str(aggregate.id),\n                type(aggregate).__name__,\n                aggregate.version,\n                aggregate.model_dump_json()\n            )\n\n    async def load_snapshot(\n        self, \n        aggregate_id: UUID,\n        intended_version: int | None = None\n    ) -&gt; Aggregate | None:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT data, version FROM snapshots WHERE aggregate_id = $1\",\n                str(aggregate_id)\n            )\n            if row and (intended_version is None or row['version'] &lt;= intended_version):\n                return self.aggregate_type.model_validate_json(row['data'])\n            return None\n</code></pre>"},{"location":"guides/aggregate-optimization/#caching","title":"Caching","text":"<p>Caching keeps recently-loaded aggregates in memory to avoid reloading them entirely.</p>"},{"location":"guides/aggregate-optimization/#cache-strategies","title":"Cache Strategies","text":"<p>A cache strategy decides which aggregates to cache:</p> <pre><code>from interlock.application.aggregates import AlwaysCache\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(\n        BankAccount,\n        cache_strategy=AlwaysCache,\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/aggregate-optimization/#available-strategies_1","title":"Available Strategies","text":"Strategy Description When to use <code>NeverCache</code> Never cache aggregates (default) Memory-constrained, low reuse <code>AlwaysCache</code> Cache all loaded aggregates High reuse, sufficient memory"},{"location":"guides/aggregate-optimization/#cache-backends","title":"Cache Backends","text":"<p>A cache backend handles storing and retrieving cached aggregates:</p> <pre><code>from interlock.application.aggregates import AlwaysCache\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(\n        BankAccount,\n        cache_strategy=AlwaysCache,\n        cache_backend=RedisAggregateCacheBackend,  # Custom implementation\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/aggregate-optimization/#available-backends_1","title":"Available Backends","text":"Backend Description When to use <code>NullAggregateCacheBackend</code> No-op, doesn't cache (default) Caching disabled <p>For production caching (Redis, Memcached), implement a custom backend.</p>"},{"location":"guides/aggregate-optimization/#custom-cache-backend","title":"Custom Cache Backend","text":"<p>Implement <code>AggregateCacheBackend</code> for your cache:</p> <pre><code>from interlock.application.aggregates import AggregateCacheBackend\nfrom interlock.domain import Aggregate\nfrom uuid import UUID, uuid4\n\nclass RedisAggregateCacheBackend(AggregateCacheBackend):\n    def __init__(self, redis_client):\n        self.redis = redis_client\n        self.ttl = 3600  # 1 hour\n\n    async def get_aggregate(self, aggregate_id: UUID) -&gt; Aggregate | None:\n        data = await self.redis.get(f\"agg:{aggregate_id}\")\n        if data:\n            return Aggregate.model_validate_json(data)\n        return None\n\n    async def set_aggregate(self, aggregate: Aggregate) -&gt; None:\n        await self.redis.setex(\n            f\"agg:{aggregate.id}\",\n            self.ttl,\n            aggregate.model_dump_json()\n        )\n\n    async def remove_aggregate(self, aggregate_id: UUID) -&gt; None:\n        await self.redis.delete(f\"agg:{aggregate_id}\")\n</code></pre>"},{"location":"guides/aggregate-optimization/#combining-strategies","title":"Combining Strategies","text":"<p>For optimal performance, combine snapshots and caching:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.aggregates import (\n    SnapshotAfterN,\n    AlwaysCache,\n    InMemoryAggregateSnapshotStorageBackend,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(\n        BankAccount,\n        snapshot_strategy=SnapshotAfterN(100),\n        snapshot_backend=InMemoryAggregateSnapshotStorageBackend,\n        cache_strategy=AlwaysCache,\n        cache_backend=RedisAggregateCacheBackend,\n    )\n    .build()\n)\n</code></pre> <p>The loading flow becomes:</p> <pre><code>flowchart TD\n    START[Load Aggregate] --&gt; CACHE{In Cache?}\n    CACHE --&gt;|Yes| RETURN[Return Cached]\n    CACHE --&gt;|No| SNAP{Has Snapshot?}\n    SNAP --&gt;|Yes| LOAD_SNAP[Load Snapshot]\n    SNAP --&gt;|No| FRESH[Create Fresh]\n    LOAD_SNAP --&gt; REPLAY[Replay Recent Events]\n    FRESH --&gt; REPLAY_ALL[Replay All Events]\n    REPLAY --&gt; CACHE_IT[Store in Cache]\n    REPLAY_ALL --&gt; CACHE_IT\n    CACHE_IT --&gt; RETURN</code></pre>"},{"location":"guides/aggregate-optimization/#best-practices","title":"Best Practices","text":""},{"location":"guides/aggregate-optimization/#when-to-use-snapshots","title":"When to Use Snapshots","text":"Scenario Recommendation &lt; 100 events per aggregate Probably not needed 100-1000 events Consider <code>SnapshotAfterN(100)</code> &gt; 1000 events Definitely use snapshots Aggregates with expensive event application Lower snapshot threshold"},{"location":"guides/aggregate-optimization/#when-to-use-caching","title":"When to Use Caching","text":"Scenario Recommendation Single-use aggregates Don't cache (<code>NeverCache</code>) Frequently accessed aggregates Use <code>AlwaysCache</code> + Redis Memory-constrained environments Be selective or skip caching Multi-instance deployments Use distributed cache (Redis)"},{"location":"guides/aggregate-optimization/#snapshot-vs-cache","title":"Snapshot vs Cache","text":"Aspect Snapshot Cache Persistence Durable (survives restart) Ephemeral (lost on restart) Scope All events before snapshot Current loaded state Storage Database Memory or distributed cache Purpose Reduce replay time Avoid any loading"},{"location":"guides/aggregate-optimization/#further-reading","title":"Further Reading","text":"<ul> <li>Aggregates Concept \u2014 Understanding aggregates</li> <li>Event Sourcing \u2014 Why events are replayed</li> <li>Database Integrations \u2014 Production storage backends</li> </ul>"},{"location":"guides/application-lifecycle/","title":"Application Lifecycle","text":"<p>Interlock provides hooks for managing the lifecycle of your application's dependencies\u2014starting database connections, initializing external services, and cleaning up resources gracefully.</p>"},{"location":"guides/application-lifecycle/#the-haslifecycle-protocol","title":"The HasLifecycle Protocol","text":"<p>Any dependency can participate in the application lifecycle by implementing the <code>HasLifecycle</code> protocol:</p> <pre><code>from interlock.application import HasLifecycle\n\nclass DatabaseConnection(HasLifecycle):\n    def __init__(self, connection_string: str):\n        self.connection_string = connection_string\n        self.connection = None\n\n    async def on_startup(self) -&gt; None:\n        \"\"\"Called when the application starts.\"\"\"\n        self.connection = await connect(self.connection_string)\n        print(\"Database connected\")\n\n    async def on_shutdown(self) -&gt; None:\n        \"\"\"Called when the application shuts down.\"\"\"\n        await self.connection.close()\n        print(\"Database disconnected\")\n</code></pre> <p>The protocol defines two methods:</p> Method When Called Purpose <code>on_startup()</code> Application startup Initialize resources, open connections <code>on_shutdown()</code> Application shutdown Clean up resources, close connections"},{"location":"guides/application-lifecycle/#using-the-context-manager","title":"Using the Context Manager","text":"<p>The simplest way to manage lifecycle is with the async context manager:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(DatabaseConnection, lambda: DatabaseConnection(\"postgres://...\"))\n    .register_aggregate(BankAccount)\n    .build()\n)\n\nasync def main():\n    async with app:\n        # on_startup() called for all HasLifecycle dependencies\n        await app.dispatch(DepositMoney(aggregate_id=account_id, amount=100))\n        # ... your application logic ...\n    # on_shutdown() called for all HasLifecycle dependencies\n</code></pre> <p>This ensures:</p> <ul> <li>All <code>on_startup()</code> methods complete before your code runs</li> <li>All <code>on_shutdown()</code> methods run even if exceptions occur</li> <li>Resources are properly cleaned up</li> </ul>"},{"location":"guides/application-lifecycle/#manual-lifecycle-control","title":"Manual Lifecycle Control","text":"<p>For more control, call startup and shutdown explicitly:</p> <pre><code>app = ApplicationBuilder().build()\n\n# Start the application\nawait app.startup()\n\ntry:\n    # Run your application\n    await run_server(app)\nfinally:\n    # Always shutdown, even on error\n    await app.shutdown()\n</code></pre>"},{"location":"guides/application-lifecycle/#startup-and-shutdown-order","title":"Startup and Shutdown Order","text":"<p>Dependencies start in registration order and shut down in reverse order:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_dependency(DatabaseConnection)   # Starts 1st, shuts down 3rd\n    .register_dependency(CacheService)         # Starts 2nd, shuts down 2nd\n    .register_dependency(SearchIndex)          # Starts 3rd, shuts down 1st\n    .build()\n)\n</code></pre> <pre><code>sequenceDiagram\n    participant App as Application\n    participant DB as DatabaseConnection\n    participant Cache as CacheService\n    participant Search as SearchIndex\n\n    Note over App: Startup (registration order)\n    App-&gt;&gt;DB: on_startup()\n    DB--&gt;&gt;App: Ready\n    App-&gt;&gt;Cache: on_startup()\n    Cache--&gt;&gt;App: Ready\n    App-&gt;&gt;Search: on_startup()\n    Search--&gt;&gt;App: Ready\n\n    Note over App: Application running...\n\n    Note over App: Shutdown (reverse order)\n    App-&gt;&gt;Search: on_shutdown()\n    Search--&gt;&gt;App: Done\n    App-&gt;&gt;Cache: on_shutdown()\n    Cache--&gt;&gt;App: Done\n    App-&gt;&gt;DB: on_shutdown()\n    DB--&gt;&gt;App: Done</code></pre> <p>This ordering is important when dependencies have relationships. For example:</p> <ul> <li>A cache that depends on a database should start after the database</li> <li>The cache should shut down before the database closes</li> </ul>"},{"location":"guides/application-lifecycle/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/application-lifecycle/#database-connections","title":"Database Connections","text":"<pre><code>class PostgresConnection(HasLifecycle):\n    def __init__(self, config: DatabaseConfig):\n        self.config = config\n        self.pool = None\n\n    async def on_startup(self) -&gt; None:\n        self.pool = await asyncpg.create_pool(\n            host=self.config.host,\n            port=self.config.port,\n            database=self.config.database,\n            user=self.config.user,\n            password=self.config.password,\n        )\n\n    async def on_shutdown(self) -&gt; None:\n        await self.pool.close()\n\n    async def execute(self, query: str, *args):\n        async with self.pool.acquire() as conn:\n            return await conn.execute(query, *args)\n</code></pre>"},{"location":"guides/application-lifecycle/#message-broker-connections","title":"Message Broker Connections","text":"<pre><code>class KafkaProducer(HasLifecycle):\n    def __init__(self, config: KafkaConfig):\n        self.config = config\n        self.producer = None\n\n    async def on_startup(self) -&gt; None:\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers=self.config.brokers\n        )\n        await self.producer.start()\n\n    async def on_shutdown(self) -&gt; None:\n        await self.producer.stop()\n\n    async def send(self, topic: str, message: bytes) -&gt; None:\n        await self.producer.send_and_wait(topic, message)\n</code></pre>"},{"location":"guides/application-lifecycle/#external-service-clients","title":"External Service Clients","text":"<pre><code>class PaymentGateway(HasLifecycle):\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.session = None\n\n    async def on_startup(self) -&gt; None:\n        self.session = aiohttp.ClientSession(\n            headers={\"Authorization\": f\"Bearer {self.api_key}\"}\n        )\n\n    async def on_shutdown(self) -&gt; None:\n        await self.session.close()\n\n    async def charge(self, amount: int, customer_id: str) -&gt; str:\n        async with self.session.post(\"/charge\", json={...}) as resp:\n            return (await resp.json())[\"transaction_id\"]\n</code></pre>"},{"location":"guides/application-lifecycle/#health-check-services","title":"Health Check Services","text":"<pre><code>class HealthCheckService(HasLifecycle):\n    def __init__(self, dependencies: list[HasLifecycle]):\n        self.dependencies = dependencies\n        self.healthy = False\n\n    async def on_startup(self) -&gt; None:\n        # All dependencies are started by this point\n        self.healthy = True\n\n    async def on_shutdown(self) -&gt; None:\n        self.healthy = False\n\n    def is_healthy(self) -&gt; bool:\n        return self.healthy\n</code></pre>"},{"location":"guides/application-lifecycle/#integration-with-event-stores-and-transports","title":"Integration with Event Stores and Transports","text":"<p>Interlock's built-in backends (event stores, transports, etc.) can also implement <code>HasLifecycle</code>. When using database integrations, the connection lifecycle is managed automatically:</p> <pre><code>from interlock.integrations.mongodb import MongoEventStore\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(EventStore, MongoEventStore)\n    .build()\n)\n\nasync with app:\n    # MongoDB connection opened automatically\n    await app.dispatch(...)\n# MongoDB connection closed automatically\n</code></pre>"},{"location":"guides/application-lifecycle/#error-handling","title":"Error Handling","text":"<p>If <code>on_startup()</code> fails for any dependency, the application raises the exception immediately. Dependencies that successfully started are not automatically shut down\u2014you should handle this in your error handling:</p> <pre><code>try:\n    async with app:\n        await run_application()\nexcept StartupError as e:\n    logger.error(f\"Startup failed: {e}\")\n    # Consider manual cleanup if needed\n</code></pre> <p>If <code>on_shutdown()</code> fails, the exception is logged but shutdown continues for remaining dependencies. This ensures all resources attempt cleanup even if one fails.</p>"},{"location":"guides/application-lifecycle/#best-practices","title":"Best Practices","text":""},{"location":"guides/application-lifecycle/#1-keep-lifecycle-methods-fast","title":"1. Keep Lifecycle Methods Fast","text":"<p>Startup and shutdown should be quick. Defer heavy initialization if possible:</p> <pre><code>async def on_startup(self) -&gt; None:\n    # Good: Just open connection\n    self.connection = await connect()\n\n    # Avoid: Heavy data loading\n    # self.cache = await load_entire_database()\n</code></pre>"},{"location":"guides/application-lifecycle/#2-handle-partial-startup","title":"2. Handle Partial Startup","text":"<p>Design components to handle cases where not all dependencies started:</p> <pre><code>async def on_shutdown(self) -&gt; None:\n    if self.connection is not None:\n        await self.connection.close()\n</code></pre>"},{"location":"guides/application-lifecycle/#3-log-lifecycle-events","title":"3. Log Lifecycle Events","text":"<p>Add logging to track startup/shutdown progress:</p> <pre><code>async def on_startup(self) -&gt; None:\n    logger.info(\"Starting database connection...\")\n    self.connection = await connect()\n    logger.info(\"Database connection established\")\n</code></pre>"},{"location":"guides/application-lifecycle/#4-use-timeouts","title":"4. Use Timeouts","text":"<p>Prevent hanging on startup/shutdown:</p> <pre><code>async def on_startup(self) -&gt; None:\n    try:\n        self.connection = await asyncio.wait_for(\n            connect(), \n            timeout=30.0\n        )\n    except asyncio.TimeoutError:\n        raise StartupError(\"Database connection timed out\")\n</code></pre>"},{"location":"guides/application-lifecycle/#testing-with-lifecycle","title":"Testing with Lifecycle","text":"<p>In tests, you can mock or stub lifecycle dependencies:</p> <pre><code>class StubDatabase(HasLifecycle):\n    async def on_startup(self) -&gt; None:\n        pass  # No-op for tests\n\n    async def on_shutdown(self) -&gt; None:\n        pass\n\n@pytest.fixture\ndef app():\n    return (\n        ApplicationBuilder()\n        .register_dependency(DatabaseConnection, StubDatabase)\n        .build()\n    )\n\nasync def test_with_lifecycle(app):\n    async with app:\n        # Test your application\n        pass\n</code></pre>"},{"location":"guides/application-lifecycle/#further-reading","title":"Further Reading","text":"<ul> <li>Database Integrations \u2014 Backend implementations with lifecycle support</li> <li>Tutorial: Structuring Your Application \u2014 Application setup patterns</li> </ul>"},{"location":"guides/custom-middleware/","title":"Custom Middleware","text":"<p>Build custom middleware to handle cross-cutting concerns in your application.</p>"},{"location":"guides/custom-middleware/#goal","title":"Goal","text":"<p>Create middleware that intercepts command and query execution for logging,  validation, authorization, caching, and more.</p>"},{"location":"guides/custom-middleware/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of Commands and Queries</li> <li>Familiarity with the Tutorial: Middleware</li> </ul>"},{"location":"guides/custom-middleware/#what-is-middleware","title":"What is Middleware?","text":"<p>Middleware wraps command and query execution in a chain, allowing you to:</p> <ul> <li>Execute code before the message reaches its handler</li> <li>Execute code after the message has been handled</li> <li>Short-circuit execution (reject messages, return cached values)</li> <li>Transform messages before they're handled</li> <li>Handle exceptions from downstream handlers</li> </ul> <p>The same middleware chain serves both commands (write operations) and queries  (read operations), enabling unified cross-cutting concerns.</p>"},{"location":"guides/custom-middleware/#creating-custom-middleware","title":"Creating Custom Middleware","text":"<p>Middleware extends <code>Middleware</code> and uses the <code>@intercepts</code> decorator to  mark interceptor methods:</p> <pre><code>from interlock.application.middleware import Middleware, Handler\nfrom interlock.routing import intercepts\nfrom interlock.domain import Command, Query\nfrom pydantic import BaseModel\n\nclass TimingMiddleware(Middleware):\n    \"\"\"Measure and log execution time for commands and queries.\"\"\"\n\n    @intercepts\n    async def time_command(\n        self, \n        command: Command,  # (1)!\n        next: Handler  # (2)!\n    ):\n        import time\n\n        start = time.perf_counter()\n        try:\n            return await next(command)  # (3)!\n        finally:\n            elapsed = time.perf_counter() - start\n            print(f\"Command {type(command).__name__} completed in {elapsed:.3f}s\")\n\n    @intercepts\n    async def time_query(\n        self, \n        query: Query,  # (4)!\n        next: Handler\n    ):\n        import time\n\n        start = time.perf_counter()\n        try:\n            return await next(query)\n        finally:\n            elapsed = time.perf_counter() - start\n            print(f\"Query {type(query).__name__} completed in {elapsed:.3f}s\")\n</code></pre> <ol> <li>Type annotation determines which messages are intercepted</li> <li><code>next</code> is the next handler in the chain (middleware, aggregate, or projection)</li> <li>Call <code>await next(message)</code> to continue the chain; return the result</li> <li>Separate interceptor for queries\u2014or use <code>BaseModel</code> to intercept everything</li> </ol>"},{"location":"guides/custom-middleware/#intercepting-all-messages","title":"Intercepting All Messages","text":"<p>To intercept both commands and queries with a single method, annotate with  <code>BaseModel</code> (the common base of both):</p> <pre><code>class UnifiedTimingMiddleware(Middleware):\n    \"\"\"Time all commands and queries.\"\"\"\n\n    @intercepts\n    async def time_all(self, message: BaseModel, next: Handler):\n        import time\n\n        start = time.perf_counter()\n        try:\n            return await next(message)\n        finally:\n            elapsed = time.perf_counter() - start\n            print(f\"{type(message).__name__} completed in {elapsed:.3f}s\")\n</code></pre>"},{"location":"guides/custom-middleware/#dependency-injection","title":"Dependency Injection","text":"<p>Middleware constructors support dependency injection. Dependencies are resolved  from the DI container when the middleware is instantiated:</p> <pre><code>from abc import ABC, abstractmethod\n\nclass AuditService(ABC):\n    @abstractmethod\n    async def log_operation(self, message: BaseModel, user_id: str) -&gt; None:\n        ...\n\nclass AuditMiddleware(Middleware):\n    \"\"\"Log all commands and queries to an audit trail.\"\"\"\n\n    def __init__(self, audit_service: AuditService):  # (1)!\n        self.audit_service = audit_service\n\n    @intercepts\n    async def audit_command(self, command: Command, next: Handler):\n        user_id = get_current_user_id()\n        await self.audit_service.log_operation(command, user_id)\n        return await next(command)\n\n    @intercepts\n    async def audit_query(self, query: Query, next: Handler):\n        user_id = get_current_user_id()\n        await self.audit_service.log_operation(query, user_id)\n        return await next(query)\n</code></pre> <ol> <li><code>AuditService</code> is automatically injected by the DI container</li> </ol> <p>Register the dependency and middleware:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_dependency(AuditService, DatabaseAuditService)\n    .register_middleware(AuditMiddleware)\n    .build()\n)\n</code></pre>"},{"location":"guides/custom-middleware/#intercepting-specific-message-types","title":"Intercepting Specific Message Types","text":"<p>The type annotation on the message parameter determines which messages the  interceptor handles. You can intercept at different levels of specificity:</p>"},{"location":"guides/custom-middleware/#all-commands","title":"All Commands","text":"<p>Annotate with the base <code>Command</code> type to intercept every command:</p> <pre><code>@intercepts\nasync def intercept_all_commands(self, command: Command, next: Handler):\n    # Runs for ALL commands\n    return await next(command)\n</code></pre>"},{"location":"guides/custom-middleware/#all-queries","title":"All Queries","text":"<p>Annotate with the base <code>Query</code> type to intercept every query:</p> <pre><code>@intercepts\nasync def intercept_all_queries(self, query: Query, next: Handler):\n    # Runs for ALL queries\n    return await next(query)\n</code></pre>"},{"location":"guides/custom-middleware/#specific-message-type","title":"Specific Message Type","text":"<p>Annotate with a specific type to intercept only that message:</p> <pre><code>@intercepts\nasync def intercept_deposit(\n    self, \n    command: DepositMoney,  # Only DepositMoney commands\n    next: Handler\n):\n    if command.amount &gt; 10000:\n        await self.compliance_service.flag_large_deposit(command)\n    return await next(command)\n\n@intercepts\nasync def intercept_balance_query(\n    self, \n    query: GetAccountBalance,  # Only GetAccountBalance queries\n    next: Handler\n) -&gt; int:\n    # Check if caller has permission to view this account\n    if not self.can_view_account(query.account_id):\n        raise PermissionError(\"Not authorized\")\n    return await next(query)\n</code></pre>"},{"location":"guides/custom-middleware/#message-hierarchy","title":"Message Hierarchy","text":"<p>If you have a message hierarchy, you can intercept at any level:</p> <pre><code># Base class for all financial commands\nclass FinancialCommand(Command[None]):\n    amount: int\n\nclass DepositMoney(FinancialCommand):\n    ...\n\nclass WithdrawMoney(FinancialCommand):\n    ...\n\nclass TransferMoney(FinancialCommand):\n    from_account: UUID\n    to_account: UUID\n\n# Middleware that intercepts all financial commands\nclass FinancialComplianceMiddleware(Middleware):\n    @intercepts\n    async def check_compliance(\n        self, \n        command: FinancialCommand,  # All DepositMoney, WithdrawMoney, TransferMoney\n        next: Handler\n    ):\n        if command.amount &gt; 10000:\n            await self.report_to_compliance(command)\n        return await next(command)\n</code></pre>"},{"location":"guides/custom-middleware/#multiple-interceptors","title":"Multiple Interceptors","text":"<p>A single middleware can have multiple interceptor methods for different types:</p> <pre><code>class TransactionLimitsMiddleware(Middleware):\n    @intercepts\n    async def check_deposit_limit(\n        self, \n        command: DepositMoney, \n        next: Handler\n    ):\n        if command.amount &gt; 50000:\n            raise DepositLimitExceeded(command.amount)\n        return await next(command)\n\n    @intercepts\n    async def check_withdrawal_limit(\n        self, \n        command: WithdrawMoney, \n        next: Handler\n    ):\n        if command.amount &gt; 10000:\n            raise WithdrawalLimitExceeded(command.amount)\n        return await next(command)\n</code></pre>"},{"location":"guides/custom-middleware/#understanding-middleware-order","title":"Understanding Middleware Order","text":"<p>Middleware executes in registration order. The first registered middleware  is the outermost wrapper:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_middleware(LoggingMiddleware)      # Runs 1st (outermost)\n    .register_middleware(AuthenticationMiddleware)  # Runs 2nd\n    .register_middleware(ValidationMiddleware)   # Runs 3rd\n    .register_aggregate(BankAccount)             # Command handler (innermost)\n    .register_projection(AccountBalanceProjection)  # Query handler\n    .build()\n)\n</code></pre> <p>The execution flow looks like this:</p> <pre><code>Command \u2192 Logging \u2192 Authentication \u2192 Validation \u2192 Aggregate\n                                                      \u2193\nResponse \u2190 Logging \u2190 Authentication \u2190 Validation \u2190 Aggregate\n\nQuery \u2192 Logging \u2192 Authentication \u2192 Validation \u2192 Projection\n                                                     \u2193\nResponse \u2190 Logging \u2190 Authentication \u2190 Validation \u2190 Projection\n</code></pre>"},{"location":"guides/custom-middleware/#order-matters","title":"Order Matters","text":"<p>Consider these scenarios:</p> Scenario Recommended Order Log all requests including failures Logging first Only log authenticated requests Authentication before Logging Validate before expensive auth check Validation before Authentication Retry after transient failures Retry outermost (wraps everything) Cache query results Caching outermost for queries <pre><code># Retry wraps everything - retries the whole chain on failure\napp = (\n    ApplicationBuilder()\n    .register_middleware(RetryMiddleware)        # Outermost - retries everything\n    .register_middleware(CachingMiddleware)      # Cache query results\n    .register_middleware(LoggingMiddleware)      # Logs each attempt\n    .register_middleware(AuthenticationMiddleware)\n    .register_middleware(ValidationMiddleware)\n    .build()\n)\n</code></pre>"},{"location":"guides/custom-middleware/#common-middleware-patterns","title":"Common Middleware Patterns","text":""},{"location":"guides/custom-middleware/#caching-queries","title":"Caching Queries","text":"<p>Cache query results to improve performance:</p> <pre><code>class QueryCachingMiddleware(Middleware):\n    \"\"\"Cache query results.\"\"\"\n\n    def __init__(self):\n        self.cache: dict[str, Any] = {}\n\n    @intercepts\n    async def cache_queries(self, query: Query, next: Handler):\n        cache_key = f\"{type(query).__name__}:{query.model_dump_json()}\"\n\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        result = await next(query)\n        self.cache[cache_key] = result\n        return result\n</code></pre>"},{"location":"guides/custom-middleware/#authorization","title":"Authorization","text":"<p>Check permissions for both commands and queries:</p> <pre><code>class AuthorizationMiddleware(Middleware):\n    \"\"\"Enforce authorization rules.\"\"\"\n\n    def __init__(self, auth_service: AuthService):\n        self.auth_service = auth_service\n\n    @intercepts\n    async def authorize_command(self, command: Command, next: Handler):\n        user = get_current_user()\n        if not self.auth_service.can_execute(user, command):\n            raise PermissionError(f\"Not authorized: {type(command).__name__}\")\n        return await next(command)\n\n    @intercepts\n    async def authorize_query(self, query: Query, next: Handler):\n        user = get_current_user()\n        if not self.auth_service.can_read(user, query):\n            raise PermissionError(f\"Not authorized: {type(query).__name__}\")\n        return await next(query)\n</code></pre>"},{"location":"guides/custom-middleware/#rate-limiting","title":"Rate Limiting","text":"<p>Throttle requests to protect resources:</p> <pre><code>class RateLimitMiddleware(Middleware):\n    \"\"\"Rate limit commands and queries.\"\"\"\n\n    def __init__(self, limiter: RateLimiter):\n        self.limiter = limiter\n\n    @intercepts\n    async def rate_limit(self, message: BaseModel, next: Handler):\n        user = get_current_user()\n        if not await self.limiter.allow(user.id):\n            raise RateLimitExceeded()\n        return await next(message)\n</code></pre>"},{"location":"guides/custom-middleware/#when-to-use-middleware","title":"When to Use Middleware","text":"<p>Middleware is ideal for cross-cutting concerns that apply to many operations.  However, not every problem requires middleware.</p>"},{"location":"guides/custom-middleware/#use-middleware-for","title":"Use Middleware For","text":"Concern Example Logging/Tracing Log all operations with correlation IDs Authentication Verify user identity before processing Authorization Check permissions for message types Validation Apply business rules across messages Rate Limiting Throttle request frequency Metrics Track latency and counts Retry Logic Handle transient failures Idempotency Prevent duplicate command processing Caching Cache query results"},{"location":"guides/custom-middleware/#dont-use-middleware-for","title":"Don't Use Middleware For","text":"Concern Better Alternative Domain logic Put it in the aggregate's command handler Single-message behavior Handle in the specific handler Event reactions Use an Event Processor Multi-aggregate coordination Use a Saga Read model updates Use a Projection"},{"location":"guides/custom-middleware/#decision-guide","title":"Decision Guide","text":"<pre><code>Is this concern...\n    \u2514\u2500 Specific to one message type?\n        \u2514\u2500 Yes \u2192 Handle in the aggregate/projection\n        \u2514\u2500 No \u2192 Could be middleware\n            \u2514\u2500 Does it need aggregate/projection state?\n                \u2514\u2500 Yes \u2192 Handle in the aggregate/projection\n                \u2514\u2500 No \u2192 Middleware is appropriate\n</code></pre>"},{"location":"guides/custom-middleware/#built-in-middleware","title":"Built-in Middleware","text":"<p>Interlock provides several middleware out of the box:</p> Middleware Purpose <code>LoggingMiddleware</code> Log operations with correlation context <code>IdempotencyMiddleware</code> Prevent duplicate command processing <code>ConcurrencyRetryMiddleware</code> Retry on optimistic concurrency conflicts <code>ContextPropagationMiddleware</code> Propagate correlation/causation IDs <pre><code>from interlock.application.middleware import (\n    LoggingMiddleware,\n    IdempotencyMiddleware,\n    ConcurrencyRetryMiddleware,\n    ContextPropagationMiddleware,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_middleware(ContextPropagationMiddleware)\n    .register_middleware(LoggingMiddleware)\n    .register_middleware(IdempotencyMiddleware)\n    .register_middleware(ConcurrencyRetryMiddleware)\n    .build()\n)\n</code></pre>"},{"location":"guides/custom-middleware/#testing-middleware","title":"Testing Middleware","text":"<p>Test middleware by building an application with your middleware and stub  dependencies:</p> <pre><code>import pytest\nfrom interlock.application import ApplicationBuilder\n\nclass StubAuditService(AuditService):\n    def __init__(self):\n        self.logged_operations = []\n\n    async def log_operation(self, message: BaseModel, user_id: str) -&gt; None:\n        self.logged_operations.append((message, user_id))\n\n@pytest.fixture\ndef app_with_audit():\n    stub = StubAuditService()\n    return (\n        ApplicationBuilder()\n        .register_aggregate(BankAccount)\n        .register_projection(AccountBalanceProjection)\n        .register_dependency(AuditService, lambda: stub)\n        .register_middleware(AuditMiddleware)\n        .build()\n    ), stub\n\n@pytest.mark.asyncio\nasync def test_audit_middleware_logs_commands(app_with_audit):\n    app, stub = app_with_audit\n\n    async with app:\n        await app.dispatch(DepositMoney(aggregate_id=uuid4(), amount=100))\n\n    assert len(stub.logged_operations) == 1\n    assert isinstance(stub.logged_operations[0][0], DepositMoney)\n\n@pytest.mark.asyncio\nasync def test_audit_middleware_logs_queries(app_with_audit):\n    app, stub = app_with_audit\n    account_id = uuid4()\n\n    async with app:\n        # Set up account first\n        await app.dispatch(OpenAccount(aggregate_id=account_id, owner=\"Test\"))\n\n        # Query should be logged\n        await app.query(GetAccountBalance(account_id=account_id))\n\n    # One command + one query logged\n    assert len(stub.logged_operations) == 2\n    assert isinstance(stub.logged_operations[1][0], GetAccountBalance)\n</code></pre>"},{"location":"guides/custom-middleware/#summary","title":"Summary","text":"Concept Description <code>Middleware</code> Base class for middleware <code>@intercepts</code> Decorator marking interceptor methods Type annotation Determines which commands/queries are intercepted <code>next(message)</code> Continues to the next handler in the chain Registration order First registered = outermost wrapper"},{"location":"guides/custom-middleware/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial: Middleware \u2014 Hands-on middleware example</li> <li>Commands \u2014 Write operations</li> <li>Queries \u2014 Read operations</li> <li>API Reference \u2014 Complete API documentation</li> </ul>"},{"location":"guides/database-integrations/","title":"Database Integrations","text":"<p>Connect Interlock to various databases and message brokers for production deployments.</p>"},{"location":"guides/database-integrations/#goal","title":"Goal","text":"<p>Configure Interlock to persist events, state, and caches using your infrastructure of choice.</p>"},{"location":"guides/database-integrations/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of Event Sourcing</li> <li>Basic knowledge of your target technology</li> </ul>"},{"location":"guides/database-integrations/#pluggable-backends","title":"Pluggable Backends","text":"<p>Interlock uses abstract base classes for all IO-related components. You can swap  implementations to match your infrastructure:</p> Component Purpose <code>EventStore</code> Persist and load domain events <code>EventTransport</code> Publish events to subscribers (messaging) <code>SagaStateStore</code> Persist saga state across steps <code>AggregateSnapshotStorageBackend</code> Store aggregate snapshots <code>AggregateCacheBackend</code> Cache aggregates in memory or distributed cache <code>IdempotencyStorageBackend</code> Track processed commands for idempotency"},{"location":"guides/database-integrations/#support-matrix","title":"Support Matrix","text":"Component MongoDB Neo4j Kafka Redis SQLite <code>EventStore</code> \u2705 \ud83d\udfe1 \u274c \u274c \ud83d\udfe1 <code>EventTransport</code> \u274c \u274c \ud83d\udfe1 \u274c \u274c <code>SagaStateStore</code> \u2705 \ud83d\udfe1 \u274c \ud83d\udfe1 \ud83d\udfe1 <code>AggregateSnapshotStorageBackend</code> \u2705 \ud83d\udfe1 \u274c \ud83d\udfe1 \ud83d\udfe1 <code>AggregateCacheBackend</code> \u274c \u274c \u274c \ud83d\udfe1 \u274c <code>IdempotencyStorageBackend</code> \u2705 \u274c \u274c \ud83d\udfe1 \ud83d\udfe1 <p>Legend: \u2705 Supported | \ud83d\udfe1 Planned | \u274c Not Applicable</p>"},{"location":"guides/database-integrations/#configuration","title":"Configuration","text":"<p>Each integration provides a <code>*Configuration</code> class (e.g., <code>MongoConfiguration</code>,  <code>RedisConfiguration</code>) that uses pydantic-settings  to read connection details from environment variables. Register the configuration  class and the backends will receive it via dependency injection\u2014no hardcoded  values needed.</p>"},{"location":"guides/database-integrations/#in-memory-default","title":"In-Memory (Default)","text":"<p>All components default to in-memory implementations for development and testing:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .build()  # Uses in-memory backends by default\n)\n</code></pre> <p>Not for Production</p> <p>In-memory backends lose all data when the application stops. Use persistent  backends for production.</p>"},{"location":"guides/database-integrations/#mongodb","title":"MongoDB","text":"<p>A document database well-suited for storing events and state.</p>"},{"location":"guides/database-integrations/#installation","title":"Installation","text":"<pre><code>pip install interlock[mongodb]\n# or\nuv add interlock[mongodb]\n</code></pre>"},{"location":"guides/database-integrations/#interlock-roles","title":"Interlock Roles","text":"Component Fit <code>EventStore</code> \u2705 Excellent \u2014 High write throughput, flexible event payloads <code>SagaStateStore</code> \u2705 Excellent \u2014 Document model matches saga state well <code>AggregateSnapshotStorageBackend</code> \u2705 Good \u2014 Efficient storage and retrieval <code>IdempotencyStorageBackend</code> \u2705 Good \u2014 TTL indexes for automatic cleanup"},{"location":"guides/database-integrations/#when-to-use","title":"When to Use","text":"<ul> <li>Your primary event store in most production deployments</li> <li>Saga state when you need durability across restarts</li> <li>Snapshots for aggregates with long event histories</li> </ul>"},{"location":"guides/database-integrations/#status","title":"Status","text":"Component Status <code>EventStore</code> \u2705 Supported <code>SagaStateStore</code> \u2705 Supported <code>AggregateSnapshotStorageBackend</code> \u2705 Supported <code>IdempotencyStorageBackend</code> \u2705 Supported"},{"location":"guides/database-integrations/#usage","title":"Usage","text":"<pre><code>from interlock import ApplicationBuilder\nfrom interlock.application.events import EventStore\nfrom interlock.application.events.processing import SagaStateStore\nfrom interlock.application.aggregates.repository.snapshot import AggregateSnapshotStorageBackend\nfrom interlock.application.middleware import IdempotencyStorageBackend\nfrom interlock.integrations.mongodb import (\n    MongoConfiguration,\n    MongoEventStore,\n    MongoSagaStateStore,\n    MongoSnapshotStorage,\n    MongoIdempotencyStorage,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(MongoConfiguration)  # Reads from environment\n    .register_dependency(EventStore, MongoEventStore)\n    .register_dependency(SagaStateStore, MongoSagaStateStore)\n    .register_dependency(AggregateSnapshotStorageBackend, MongoSnapshotStorage)\n    .register_dependency(IdempotencyStorageBackend, MongoIdempotencyStorage)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#configuration_1","title":"Configuration","text":"<p><code>MongoConfiguration</code> reads from environment variables with the <code>INTERLOCK_MONGO_</code> prefix:</p> Environment Variable Default Description <code>INTERLOCK_MONGO_URI</code> <code>mongodb://localhost:27017</code> MongoDB connection URI <code>INTERLOCK_MONGO_DATABASE</code> <code>interlock</code> Database name <code>INTERLOCK_MONGO_EVENTS_COLLECTION</code> <code>events</code> Collection for events <code>INTERLOCK_MONGO_SAGA_STATES_COLLECTION</code> <code>saga_states</code> Collection for saga state <code>INTERLOCK_MONGO_SNAPSHOTS_COLLECTION</code> <code>snapshots</code> Collection for snapshots <code>INTERLOCK_MONGO_IDEMPOTENCY_KEYS_COLLECTION</code> <code>idempotency_keys</code> Collection for idempotency keys <code>INTERLOCK_MONGO_SNAPSHOT_MODE</code> <code>single</code> <code>single</code> (overwrite) or <code>multiple</code> (keep history) <code>INTERLOCK_MONGO_IDEMPOTENCY_TTL_SECONDS</code> <code>86400</code> TTL for idempotency keys (24 hours)"},{"location":"guides/database-integrations/#snapshot-modes","title":"Snapshot Modes","text":"<p>The snapshot storage supports two modes:</p> <ul> <li><code>single</code> (default): One snapshot per aggregate. Overwrites on save. Lower storage, simpler queries.</li> <li><code>multiple</code>: Keeps version history. Supports loading snapshots at specific versions for debugging or replay.</li> </ul> <pre><code># Configure via environment\n# INTERLOCK_MONGO_SNAPSHOT_MODE=multiple\n\n# Or programmatically\nconfig = MongoConfiguration(snapshot_mode=\"multiple\")\n</code></pre>"},{"location":"guides/database-integrations/#indexes","title":"Indexes","text":"<p>Indexes are created automatically on first use:</p> <ul> <li>Events: Unique compound index on <code>(aggregate_id, sequence_number)</code> for optimistic concurrency</li> <li>Snapshots: Unique index on <code>aggregate_id</code> (single mode) or <code>(aggregate_id, version)</code> (multiple mode)</li> <li>Idempotency: TTL index on <code>created_at</code> for automatic cleanup</li> </ul>"},{"location":"guides/database-integrations/#neo4j","title":"Neo4j","text":"<p>A graph database suited for relationship-heavy state and projections.</p>"},{"location":"guides/database-integrations/#interlock-roles_1","title":"Interlock Roles","text":"Component Fit <code>EventStore</code> \u26a0\ufe0f Possible \u2014 Works, but not optimized for append-heavy writes <code>SagaStateStore</code> \u2705 Good \u2014 Useful when saga state involves relationships <code>AggregateSnapshotStorageBackend</code> \u2705 Good \u2014 Snapshots with graph structure"},{"location":"guides/database-integrations/#when-to-use_1","title":"When to Use","text":"<ul> <li>Saga state that tracks relationships between entities</li> <li>Snapshots for aggregates with complex relationship graphs</li> <li>As a secondary event store when you need graph traversal queries</li> </ul> <p>Consider Your Primary Store</p> <p>Neo4j works best alongside a primary <code>EventStore</code> like MongoDB or SQLite.  Use Neo4j for components where graph relationships matter.</p>"},{"location":"guides/database-integrations/#status_1","title":"Status","text":"Component Status <code>EventStore</code> \ud83d\udfe1 Planned <code>SagaStateStore</code> \ud83d\udfe1 Planned <code>AggregateSnapshotStorageBackend</code> \ud83d\udfe1 Planned <pre><code># Coming soon\nfrom interlock.integrations.neo4j import (\n    Neo4jConfiguration,\n    Neo4jEventStore,\n    Neo4jSagaStateStore,\n    Neo4jSnapshotStorage,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(Neo4jConfiguration)\n    .register_dependency(EventStore, Neo4jEventStore)\n    .register_dependency(SagaStateStore, Neo4jSagaStateStore)\n    .register_dependency(AggregateSnapshotStorageBackend, Neo4jSnapshotStorage)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#kafka","title":"Kafka","text":"<p>A distributed streaming platform for event transport between services.</p>"},{"location":"guides/database-integrations/#interlock-roles_2","title":"Interlock Roles","text":"Component Fit <code>EventTransport</code> \u2705 Excellent \u2014 The standard for inter-service messaging <p>Kafka is only applicable to <code>EventTransport</code>. It's designed for publishing  events to other services, not for storing or querying events by aggregate ID.</p>"},{"location":"guides/database-integrations/#when-to-use_2","title":"When to Use","text":"<ul> <li>Microservices architectures where events flow between services</li> <li>Event broadcasting to multiple consumers (projections, notifications, etc.)</li> <li>Cross-service sagas that need reliable event delivery</li> </ul>"},{"location":"guides/database-integrations/#when-not-to-use","title":"When NOT to Use","text":"<ul> <li>Single-service applications \u2014 The in-memory transport is simpler</li> <li>As your <code>EventStore</code> \u2014 Use MongoDB or SQLite for that</li> </ul>"},{"location":"guides/database-integrations/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Service A     \u2502         \u2502   Service B     \u2502\n\u2502                 \u2502         \u2502                 \u2502\n\u2502 EventStore \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500Kafka\u2500\u2500\u253c\u2500\u25b6 Projections   \u2502\n\u2502   (MongoDB)     \u2502         \u2502    (MongoDB)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/database-integrations/#status_2","title":"Status","text":"Component Status <code>EventTransport</code> \ud83d\udfe1 Planned <pre><code># Coming soon\nfrom interlock.integrations.kafka import (\n    KafkaConfiguration,\n    KafkaEventTransport,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(KafkaConfiguration)\n    .register_dependency(EventTransport, KafkaEventTransport)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#redis","title":"Redis","text":"<p>An in-memory data store ideal for caching and fast ephemeral state.</p>"},{"location":"guides/database-integrations/#interlock-roles_3","title":"Interlock Roles","text":"Component Fit <code>AggregateCacheBackend</code> \u2705 Excellent \u2014 Sub-millisecond aggregate lookups <code>SagaStateStore</code> \u2705 Good \u2014 Fast access for active sagas <code>IdempotencyStorageBackend</code> \u2705 Excellent \u2014 TTL-based automatic cleanup <code>AggregateSnapshotStorageBackend</code> \u26a0\ufe0f Possible \u2014 Consider durability needs"},{"location":"guides/database-integrations/#when-to-use_3","title":"When to Use","text":"<ul> <li>Aggregate caching to reduce load on your primary event store</li> <li>Idempotency tracking with automatic expiration of old entries</li> <li>Saga state for high-throughput, short-lived workflows</li> </ul>"},{"location":"guides/database-integrations/#when-not-to-use_1","title":"When NOT to Use","text":"<ul> <li>As your <code>EventStore</code> \u2014 Redis is memory-based; events need durable storage</li> <li>Long-term snapshots \u2014 Consider whether you need data to survive restarts</li> </ul> <p>Cache, Not Primary Storage</p> <p>Redis complements your primary storage. Use it to cache aggregates and  track idempotency, with MongoDB or SQLite as your <code>EventStore</code>.</p>"},{"location":"guides/database-integrations/#status_3","title":"Status","text":"Component Status <code>AggregateCacheBackend</code> \ud83d\udfe1 Planned <code>SagaStateStore</code> \ud83d\udfe1 Planned <code>IdempotencyStorageBackend</code> \ud83d\udfe1 Planned <code>AggregateSnapshotStorageBackend</code> \ud83d\udfe1 Planned <pre><code># Coming soon\nfrom interlock.integrations.redis import (\n    RedisConfiguration,\n    RedisAggregateCache,\n    RedisSagaStateStore,\n    RedisIdempotencyStorage,\n    RedisSnapshotStorage,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(RedisConfiguration)\n    .register_dependency(AggregateCacheBackend, RedisAggregateCache)\n    .register_dependency(SagaStateStore, RedisSagaStateStore)\n    .register_dependency(IdempotencyStorageBackend, RedisIdempotencyStorage)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#sqlite","title":"SQLite","text":"<p>An embedded SQL database\u2014zero configuration, single file, surprisingly capable.</p>"},{"location":"guides/database-integrations/#interlock-roles_4","title":"Interlock Roles","text":"Component Fit <code>EventStore</code> \u2705 Excellent \u2014 Simple, durable, fast for single-node <code>SagaStateStore</code> \u2705 Excellent \u2014 ACID transactions for saga state <code>AggregateSnapshotStorageBackend</code> \u2705 Good \u2014 Reliable snapshot storage <code>IdempotencyStorageBackend</code> \u2705 Good \u2014 SQL queries for cleanup"},{"location":"guides/database-integrations/#when-to-use_4","title":"When to Use","text":"<ul> <li>Local development with persistence (unlike in-memory)</li> <li>Single-node production for small-to-medium applications</li> <li>Desktop/mobile apps where you need an embedded event store</li> <li>CI/CD testing with isolated, fast databases</li> </ul>"},{"location":"guides/database-integrations/#when-not-to-use_2","title":"When NOT to Use","text":"<ul> <li>Multi-node deployments \u2014 SQLite doesn't replicate; use MongoDB</li> <li>High write concurrency \u2014 Single-writer lock can be a bottleneck</li> </ul>"},{"location":"guides/database-integrations/#choosing-between-sqlite-and-mongodb","title":"Choosing Between SQLite and MongoDB","text":"Scenario Recommendation Single server, low-to-medium traffic SQLite Multiple servers or high traffic MongoDB Local development with persistence SQLite Need horizontal scaling MongoDB"},{"location":"guides/database-integrations/#status_4","title":"Status","text":"Component Status <code>EventStore</code> \ud83d\udfe1 Planned <code>SagaStateStore</code> \ud83d\udfe1 Planned <code>AggregateSnapshotStorageBackend</code> \ud83d\udfe1 Planned <code>IdempotencyStorageBackend</code> \ud83d\udfe1 Planned <pre><code># Coming soon\nfrom interlock.integrations.sqlite import (\n    SqliteConfiguration,\n    SqliteEventStore,\n    SqliteSagaStateStore,\n    SqliteSnapshotStorage,\n    SqliteIdempotencyStorage,\n)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(SqliteConfiguration)\n    .register_dependency(EventStore, SqliteEventStore)\n    .register_dependency(SagaStateStore, SqliteSagaStateStore)\n    .register_dependency(AggregateSnapshotStorageBackend, SqliteSnapshotStorage)\n    .register_dependency(IdempotencyStorageBackend, SqliteIdempotencyStorage)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#implementing-custom-backends","title":"Implementing Custom Backends","text":"<p>All backends are abstract base classes. Implement the required methods for your  infrastructure:</p> <pre><code>from interlock.application.events import EventStore\nfrom interlock.domain import Event\nfrom uuid import UUID, uuid4\n\nclass MyCustomEventStore(EventStore):\n    async def save_events(\n        self, \n        events: list[Event], \n        expected_version: int\n    ) -&gt; None:\n        # Persist events to your storage\n        # Use events[0].aggregate_id to get the aggregate\n        ...\n\n    async def load_events(\n        self, \n        aggregate_id: UUID, \n        min_version: int\n    ) -&gt; list[Event]:\n        # Load events from your storage\n        ...\n\n    async def rewrite_events(self, events: list[Event]) -&gt; None:\n        # Update existing events in place (for schema migration)\n        ...\n</code></pre> <p>Register your implementation:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_dependency(EventStore, MyCustomEventStore)\n    .build()\n)\n</code></pre>"},{"location":"guides/database-integrations/#next-steps","title":"Next Steps","text":"<ul> <li>Event Sourcing Concept</li> <li>Sagas Guide \u2014 Uses <code>SagaStateStore</code></li> <li>API Reference</li> </ul>"},{"location":"guides/dependency-injection/","title":"Dependency Injection","text":"<p>Interlock uses dependency injection (DI) to wire up your application components. This guide explains how DI works and how to use it effectively.</p>"},{"location":"guides/dependency-injection/#what-is-dependency-injection","title":"What is Dependency Injection?","text":"<p>Dependency injection is a pattern where objects receive their dependencies from an external source rather than creating them internally:</p> <pre><code># Without DI - tightly coupled\nclass AccountBalanceProjection:\n    def __init__(self):\n        self.repository = PostgresBalanceRepository()  # Hard-coded!\n\n# With DI - loosely coupled\nclass AccountBalanceProjection:\n    def __init__(self, repository: BalanceRepository):\n        self.repository = repository  # Injected!\n</code></pre> <p>Benefits:</p> <ul> <li>Testability: Swap real implementations for test doubles</li> <li>Flexibility: Change implementations without modifying consumers</li> <li>Explicit dependencies: Easy to see what a class needs</li> </ul>"},{"location":"guides/dependency-injection/#how-interlock-di-works","title":"How Interlock DI Works","text":"<p>Interlock uses constructor injection with type hints. When you register a component, Interlock inspects its <code>__init__</code> signature and resolves dependencies automatically:</p> <pre><code>class AccountBalanceProjection(EventProcessor):\n    def __init__(self, repository: BalanceRepository):  # Type hint\n        self.repository = repository\n</code></pre> <p>When Interlock creates <code>AccountBalanceProjection</code>, it:</p> <ol> <li>Inspects the constructor signature</li> <li>Finds <code>repository: BalanceRepository</code></li> <li>Looks up the registered implementation for <code>BalanceRepository</code></li> <li>Creates and injects that implementation</li> </ol>"},{"location":"guides/dependency-injection/#registering-dependencies","title":"Registering Dependencies","text":"<p>Use <code>register_dependency()</code> to tell Interlock how to create instances:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(BalanceRepository, PostgresBalanceRepository)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#interface-and-implementation","title":"Interface and Implementation","text":"<p>The most common pattern registers an abstract base class (interface) with a concrete implementation:</p> <pre><code>from abc import ABC, abstractmethod\n\n# Interface\nclass EmailService(ABC):\n    @abstractmethod\n    async def send(self, to: str, subject: str, body: str) -&gt; None: ...\n\n# Implementation\nclass SendGridEmailService(EmailService):\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n\n    async def send(self, to: str, subject: str, body: str) -&gt; None:\n        # Send via SendGrid API\n        ...\n\n# Registration\napp = (\n    ApplicationBuilder()\n    .register_dependency(EmailService, SendGridEmailService)\n    .build()\n)\n</code></pre> <p>Now any component requesting <code>EmailService</code> receives a <code>SendGridEmailService</code> instance.</p>"},{"location":"guides/dependency-injection/#self-registration","title":"Self-Registration","text":"<p>If no factory is provided, the type is used directly:</p> <pre><code># These are equivalent:\n.register_dependency(MyService, MyService)\n.register_dependency(MyService)\n</code></pre>"},{"location":"guides/dependency-injection/#factory-functions","title":"Factory Functions","text":"<p>For complex initialization, use a factory function:</p> <pre><code>def create_email_service() -&gt; EmailService:\n    api_key = os.environ[\"SENDGRID_API_KEY\"]\n    return SendGridEmailService(api_key)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(EmailService, create_email_service)\n    .build()\n)\n</code></pre> <p>Factory functions can also receive dependencies:</p> <pre><code>def create_notification_service(\n    email: EmailService,  # Injected!\n    config: AppConfig     # Injected!\n) -&gt; NotificationService:\n    return NotificationService(email, config.notification_settings)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(EmailService, SendGridEmailService)\n    .register_dependency(AppConfig)\n    .register_dependency(NotificationService, create_notification_service)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#lambda-factories","title":"Lambda Factories","text":"<p>For simple cases, use lambdas:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_dependency(\n        EmailService, \n        lambda: SendGridEmailService(os.environ[\"API_KEY\"])\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#where-di-is-used","title":"Where DI is Used","text":""},{"location":"guides/dependency-injection/#event-processors","title":"Event Processors","text":"<p>Event processors commonly need repositories, services, or clients:</p> <pre><code>class AccountBalanceProjection(EventProcessor):\n    def __init__(self, repository: BalanceRepository):\n        self.repository = repository\n\n    @handles_event\n    async def on_deposit(self, event: MoneyDeposited) -&gt; None:\n        current = self.repository.get_balance(event.account_id)\n        self.repository.set_balance(event.account_id, current + event.amount)\n\n# Register the processor and its dependency\napp = (\n    ApplicationBuilder()\n    .register_dependency(BalanceRepository, InMemoryBalanceRepository)\n    .register_event_processor(AccountBalanceProjection)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#middleware","title":"Middleware","text":"<p>Middleware can inject services for cross-cutting concerns:</p> <pre><code>class FraudDetectionMiddleware(CommandMiddleware):\n    def __init__(self, fraud_service: FraudService):\n        self.fraud_service = fraud_service\n\n    @intercepts\n    async def check_fraud(self, command: DepositMoney, next: CommandHandler) -&gt; None:\n        if await self.fraud_service.is_suspicious(command):\n            raise FraudDetectedError(\"Transaction flagged\")\n        await next(command)\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(FraudService, MLFraudService)\n    .register_middleware(FraudDetectionMiddleware)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#sagas","title":"Sagas","text":"<p>Sagas often need to dispatch commands or access external services:</p> <pre><code>class MoneyTransferSaga(Saga[TransferState]):\n    def __init__(self, state_store: SagaStateStore, command_bus: CommandBus):\n        super().__init__(state_store)\n        self.command_bus = command_bus\n\n    @saga_step\n    async def on_transfer_initiated(self, event: TransferInitiated) -&gt; TransferState:\n        await self.command_bus.dispatch(\n            WithdrawMoney(aggregate_id=event.from_account, amount=event.amount)\n        )\n        return TransferState(...)\n</code></pre>"},{"location":"guides/dependency-injection/#event-upcasters","title":"Event Upcasters","text":"<p>Upcasters can inject services for async data enrichment:</p> <pre><code>class MoneyDepositedV1ToV2(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    def __init__(self, account_service: AccountLookupService):\n        self.account_service = account_service\n\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        email = await self.account_service.get_email(data.account_id)\n        return MoneyDepositedV2(amount=data.amount, email=email)\n</code></pre>"},{"location":"guides/dependency-injection/#resolving-dependencies-manually","title":"Resolving Dependencies Manually","text":"<p>Use <code>app.resolve()</code> to get instances directly:</p> <pre><code>async with app:\n    email_service = app.resolve(EmailService)\n    await email_service.send(\"user@example.com\", \"Hello\", \"Welcome!\")\n</code></pre> <p>This is useful for:</p> <ul> <li>Integration tests that need to verify service state</li> <li>Manual service access outside the normal flow</li> <li>Debugging</li> </ul>"},{"location":"guides/dependency-injection/#singleton-behavior","title":"Singleton Behavior","text":"<p>All registered dependencies are singletons within the application. The same instance is returned for every resolution:</p> <pre><code>app = ApplicationBuilder().register_dependency(EmailService, SendGridEmailService).build()\n\nasync with app:\n    service1 = app.resolve(EmailService)\n    service2 = app.resolve(EmailService)\n    assert service1 is service2  # Same instance!\n</code></pre>"},{"location":"guides/dependency-injection/#testing-with-di","title":"Testing with DI","text":"<p>DI makes testing straightforward\u2014swap real implementations for test doubles:</p> <pre><code>import pytest\nfrom interlock.application import ApplicationBuilder\n\n# Test double\nclass StubEmailService(EmailService):\n    def __init__(self):\n        self.sent_emails = []\n\n    async def send(self, to: str, subject: str, body: str) -&gt; None:\n        self.sent_emails.append((to, subject, body))\n\n@pytest.fixture\ndef app():\n    return (\n        ApplicationBuilder()\n        .register_dependency(EmailService, StubEmailService)\n        .register_event_processor(NotificationProcessor)\n        .build()\n    )\n\nasync def test_sends_notification_email(app):\n    async with app:\n        # Trigger event processing...\n\n        # Verify via the stub\n        email_service = app.resolve(EmailService)\n        assert len(email_service.sent_emails) == 1\n        assert email_service.sent_emails[0][1] == \"Order Confirmed\"\n</code></pre>"},{"location":"guides/dependency-injection/#using-scenario-helpers","title":"Using Scenario Helpers","text":"<p>Interlock's test scenarios automatically use the registered dependencies:</p> <pre><code>@pytest.fixture\ndef app():\n    return (\n        ApplicationBuilder()\n        .register_dependency(BalanceRepository, InMemoryBalanceRepository)\n        .register_event_processor(AccountBalanceProjection)\n        .build()\n    )\n\nasync def test_projection_updates_balance(app):\n    async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        scenario \\\n            .given(MoneyDeposited(account_id=account_id, amount=100)) \\\n            .should_have_state(\n                lambda p: p.repository.get_balance(account_id) == 100\n            )\n</code></pre>"},{"location":"guides/dependency-injection/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/dependency-injection/#configuration-objects","title":"Configuration Objects","text":"<p>Use Pydantic settings for configuration:</p> <pre><code>from pydantic_settings import BaseSettings\n\nclass AppConfig(BaseSettings):\n    database_url: str\n    redis_url: str\n    sendgrid_api_key: str\n\n    model_config = {\"env_prefix\": \"APP_\"}\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(AppConfig)  # Reads from environment\n    .register_dependency(EmailService, lambda config: SendGridEmailService(config.sendgrid_api_key))\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#layered-dependencies","title":"Layered Dependencies","text":"<p>Build complex dependency graphs:</p> <pre><code>app = (\n    ApplicationBuilder()\n    # Infrastructure layer\n    .register_dependency(DatabasePool, create_db_pool)\n    .register_dependency(RedisClient, create_redis_client)\n\n    # Repository layer\n    .register_dependency(AccountRepository, PostgresAccountRepository)\n    .register_dependency(TransactionRepository, PostgresTransactionRepository)\n\n    # Service layer\n    .register_dependency(AccountService, DefaultAccountService)\n    .register_dependency(FraudService, MLFraudService)\n\n    # Application layer\n    .register_event_processor(AccountBalanceProjection)\n    .register_middleware(FraudDetectionMiddleware)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#environment-specific-registration","title":"Environment-Specific Registration","text":"<p>Swap implementations based on environment:</p> <pre><code>import os\n\nbuilder = ApplicationBuilder()\n\nif os.environ.get(\"ENV\") == \"production\":\n    builder.register_dependency(EmailService, SendGridEmailService)\n    builder.register_dependency(FraudService, MLFraudService)\nelse:\n    builder.register_dependency(EmailService, ConsoleEmailService)\n    builder.register_dependency(FraudService, NoOpFraudService)\n\napp = builder.build()\n</code></pre>"},{"location":"guides/dependency-injection/#best-practices","title":"Best Practices","text":""},{"location":"guides/dependency-injection/#depend-on-abstractions","title":"Depend on Abstractions","text":"<p>Prefer abstract base classes over concrete implementations:</p> <pre><code># Good - depends on abstraction\ndef __init__(self, repository: BalanceRepository): ...\n\n# Avoid - depends on concrete class\ndef __init__(self, repository: PostgresBalanceRepository): ...\n</code></pre>"},{"location":"guides/dependency-injection/#keep-constructors-simple","title":"Keep Constructors Simple","text":"<p>Constructors should only assign dependencies, not perform logic:</p> <pre><code># Good\ndef __init__(self, service: EmailService):\n    self.service = service\n\n# Avoid - logic in constructor\ndef __init__(self, api_key: str):\n    self.service = EmailService(api_key)\n    self.service.connect()  # Side effect!\n</code></pre>"},{"location":"guides/dependency-injection/#use-factory-functions-for-complex-setup","title":"Use Factory Functions for Complex Setup","text":"<p>When initialization is complex, extract it to a factory:</p> <pre><code>def create_database_pool(config: AppConfig) -&gt; DatabasePool:\n    pool = DatabasePool(\n        host=config.db_host,\n        port=config.db_port,\n        user=config.db_user,\n        password=config.db_password,\n    )\n    pool.set_max_connections(config.db_max_connections)\n    return pool\n\napp = (\n    ApplicationBuilder()\n    .register_dependency(AppConfig)\n    .register_dependency(DatabasePool, create_database_pool)\n    .build()\n)\n</code></pre>"},{"location":"guides/dependency-injection/#further-reading","title":"Further Reading","text":"<ul> <li>Application Lifecycle \u2014 Startup/shutdown with DI</li> <li>Writing Tests \u2014 Testing with dependency injection</li> <li>Custom Middleware \u2014 Middleware with injected services</li> </ul>"},{"location":"guides/event-upcasting/","title":"Event Upcasting","text":"<p>Learn how to evolve your event schemas while maintaining compatibility with historical events.</p>"},{"location":"guides/event-upcasting/#goal","title":"Goal","text":"<p>Modify event schemas without breaking existing stored events or requiring data migrations.</p>"},{"location":"guides/event-upcasting/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of Events</li> <li>Familiarity with event versioning concepts</li> </ul>"},{"location":"guides/event-upcasting/#the-problem","title":"The Problem","text":"<p>Events are immutable\u2014once stored, they never change. But your domain model evolves.  When you need to add, remove, or restructure fields in an event, old events in the  store won't match your new schema.</p> <p>Consider a <code>MoneyDeposited</code> event that originally only tracked the amount:</p> <pre><code>from pydantic import BaseModel\n\nclass MoneyDeposited(BaseModel):\n    amount: int\n</code></pre> <p>Later, you need to track the deposit source for compliance:</p> <pre><code>class MoneyDeposited(BaseModel):\n    amount: int\n    source: str  # New required field!\n</code></pre> <p>Now you have a problem: historical events don't have a <code>source</code> field. Loading them  will fail with a validation error.</p>"},{"location":"guides/event-upcasting/#do-you-actually-need-upcasting","title":"Do You Actually Need Upcasting?","text":"<p>Before reaching for upcasters, ask yourself: can Pydantic handle this?</p> <p>Since Interlock uses Pydantic models for events, many simple schema changes are  handled automatically with default values:</p> <pre><code>class MoneyDeposited(BaseModel):\n    amount: int\n    source: str = \"unknown\"  # Default handles missing field!\n</code></pre> <p>Old events without <code>source</code> will load successfully\u2014Pydantic fills in the default.</p>"},{"location":"guides/event-upcasting/#when-pydantic-defaults-are-enough","title":"When Pydantic Defaults Are Enough","text":"Change Solution Add optional field <code>new_field: str \\| None = None</code> Add field with sensible default <code>status: str = \"pending\"</code> Make field optional <code>field: str</code> \u2192 <code>field: str \\| None = None</code>"},{"location":"guides/event-upcasting/#when-you-need-upcasting","title":"When You Need Upcasting","text":"Change Why Upcasting Rename a field <code>owner_name</code> \u2192 <code>holder_name</code> Split a field <code>full_name</code> \u2192 <code>first_name</code> + <code>last_name</code> Change field type <code>price: float</code> \u2192 <code>price_cents: int</code> Compute derived value Need to look up data from a service Complex conditional logic Different defaults based on other fields <p>Start Simple</p> <p>Default to Pydantic defaults. Only introduce upcasters when the transformation  requires logic that can't be expressed as a simple default value.</p>"},{"location":"guides/event-upcasting/#solution-event-upcasting","title":"Solution: Event Upcasting","text":"<p>Upcasting transforms old event versions into new versions when loading from the  event store. Instead of migrating your data, you migrate your events on-the-fly.</p> <p>The key insight is that you keep both event versions in your codebase and define  a transformation between them:</p> <pre><code>from pydantic import BaseModel\n\n# Keep the old version (rename it to indicate version)\nclass MoneyDepositedV1(BaseModel):\n    amount: int\n\n# Define the new version\nclass MoneyDepositedV2(BaseModel):\n    amount: int\n    source: str\n</code></pre>"},{"location":"guides/event-upcasting/#creating-an-upcaster","title":"Creating an Upcaster","text":"<p>Upcasters inherit from <code>EventUpcaster[SourceType, TargetType]</code> and implement  the <code>upcast_payload</code> method:</p> <pre><code>from interlock.application.events.upcasting import EventUpcaster\n\nclass MoneyDepositedV1ToV2(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    \"\"\"Transform MoneyDeposited from V1 to V2.\"\"\"\n\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        return MoneyDepositedV2(\n            amount=data.amount,\n            source=\"unknown\"  # Default for historical events\n        )\n</code></pre> <p>The framework automatically:</p> <ul> <li>Extracts the source and target types from the generic parameters</li> <li>Preserves event metadata (id, aggregate_id, timestamp, sequence_number)</li> <li>Chains multiple upcasters together (V1\u2192V2\u2192V3)</li> </ul>"},{"location":"guides/event-upcasting/#registering-upcasters","title":"Registering Upcasters","text":"<p>Register upcasters with the <code>ApplicationBuilder</code>:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_upcaster(MoneyDepositedV1ToV2)\n    .build()\n)\n</code></pre> <p>Register the Type, Not an Instance</p> <p>Pass the upcaster class, not an instance. The framework instantiates it  and injects any dependencies via the DI container.</p>"},{"location":"guides/event-upcasting/#chaining-upcasters","title":"Chaining Upcasters","text":"<p>Upcasters automatically chain. If you have V1\u2192V2 and V2\u2192V3 upcasters, a V1 event  will be transformed through both to reach V3:</p> <pre><code>class MoneyDepositedV1(BaseModel):\n    amount: int\n\nclass MoneyDepositedV2(BaseModel):\n    amount: int\n    source: str\n\nclass MoneyDepositedV3(BaseModel):\n    amount: int\n    source: str\n    currency: str\n\nclass MoneyDepositedV1ToV2(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        return MoneyDepositedV2(amount=data.amount, source=\"unknown\")\n\nclass MoneyDepositedV2ToV3(EventUpcaster[MoneyDepositedV2, MoneyDepositedV3]):\n    async def upcast_payload(self, data: MoneyDepositedV2) -&gt; MoneyDepositedV3:\n        return MoneyDepositedV3(\n            amount=data.amount, \n            source=data.source, \n            currency=\"USD\"\n        )\n\n# Register both - order doesn't matter\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_upcaster(MoneyDepositedV1ToV2)\n    .register_upcaster(MoneyDepositedV2ToV3)\n    .build()\n)\n</code></pre> <p>When a V1 event is loaded, it flows through: V1 \u2192 V2 \u2192 V3.</p> <p>Always Chain, Never Skip</p> <p>Create upcasters for each version step (V1\u2192V2, V2\u2192V3), not direct jumps  (V1\u2192V3). This keeps each transformation simple and testable.</p>"},{"location":"guides/event-upcasting/#async-upcasters-with-dependencies","title":"Async Upcasters with Dependencies","text":"<p>Upcasters can be async and inject dependencies\u2014useful when transformations  need external data or services.</p>"},{"location":"guides/event-upcasting/#example-enriching-events-with-account-data","title":"Example: Enriching Events with Account Data","text":"<p>Suppose your V1 events only stored an account number, but V2 needs the account  holder's name. You can inject a service to look up this information:</p> <pre><code>from abc import ABC, abstractmethod\n\nclass AccountLookupService(ABC):\n    \"\"\"Service to look up account information.\"\"\"\n\n    @abstractmethod\n    async def get_account_holder(self, account_number: str) -&gt; str:\n        \"\"\"Look up the account holder's name.\"\"\"\n        ...\n\nclass DatabaseAccountLookup(AccountLookupService):\n    \"\"\"Production implementation that queries the database.\"\"\"\n\n    def __init__(self, db_connection: DatabaseConnection):\n        self.db = db_connection\n\n    async def get_account_holder(self, account_number: str) -&gt; str:\n        result = await self.db.query(\n            \"SELECT holder_name FROM accounts WHERE number = ?\",\n            account_number\n        )\n        return result[\"holder_name\"] if result else \"Unknown\"\n</code></pre> <p>Now define an upcaster that uses this service:</p> <pre><code>class AccountOpenedV1(BaseModel):\n    account_number: str\n\nclass AccountOpenedV2(BaseModel):\n    account_number: str\n    holder_name: str\n\nclass AccountOpenedV1ToV2(EventUpcaster[AccountOpenedV1, AccountOpenedV2]):\n    \"\"\"Enrich V1 events with account holder name from database.\"\"\"\n\n    def __init__(self, lookup_service: AccountLookupService):  # (1)!\n        self.lookup_service = lookup_service\n\n    async def upcast_payload(self, data: AccountOpenedV1) -&gt; AccountOpenedV2:\n        # Async call to look up the holder name\n        holder_name = await self.lookup_service.get_account_holder(\n            data.account_number\n        )\n        return AccountOpenedV2(\n            account_number=data.account_number,\n            holder_name=holder_name\n        )\n</code></pre> <ol> <li>Dependencies are injected by the DI container when the upcaster is instantiated</li> </ol> <p>Register the service and upcaster:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(AccountLookupService, DatabaseAccountLookup)\n    .register_upcaster(AccountOpenedV1ToV2)\n    .build()\n)\n</code></pre> <p>Performance Consideration</p> <p>Async upcasters with I/O can add latency to event loading. Consider caching  lookup results or using batch loading strategies for high-volume scenarios.</p>"},{"location":"guides/event-upcasting/#conditional-upcasting","title":"Conditional Upcasting","text":"<p>Sometimes you only want to upcast certain events. Override <code>can_upcast</code> to  add conditions:</p> <pre><code>class LegacyDepositUpcaster(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    \"\"\"Only upcast events from before the schema change.\"\"\"\n\n    async def can_upcast(self, event: Event[MoneyDepositedV1]) -&gt; bool:\n        # Only upcast events from before 2024\n        cutoff = datetime(2024, 1, 1, tzinfo=timezone.utc)\n        return event.timestamp &lt; cutoff\n\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        return MoneyDepositedV2(amount=data.amount, source=\"legacy\")\n</code></pre>"},{"location":"guides/event-upcasting/#upcasting-strategies","title":"Upcasting Strategies","text":"<p>Interlock provides two built-in strategies that control when upcasting occurs:</p>"},{"location":"guides/event-upcasting/#lazy-strategy-recommended","title":"Lazy Strategy (Recommended)","text":"<pre><code>from interlock.application.events.upcasting import LazyUpcastingStrategy\n</code></pre> <p>Upcasts on read only. Old events remain in storage with their original schema  and are transformed on-the-fly when loaded.</p> Advantages Disadvantages No need to rewrite event store Slight performance cost on reads Supports multiple concurrent versions Old event types must remain in codebase Can evolve upcasting logic over time \u2014 <p>This is the default and recommended strategy for most applications.</p>"},{"location":"guides/event-upcasting/#eager-strategy","title":"Eager Strategy","text":"<pre><code>from interlock.application.events.upcasting import EagerUpcastingStrategy\n</code></pre> <p>Upcasts on both read and write. New events are written in the latest schema,  and old events are transformed when loaded.</p> Advantages Disadvantages Event store gradually migrates to new schema More complex to reason about Eventually can remove old event types May conflict with event immutability principles \u2014 Requires careful handling <p>Use this when you have a clear migration timeline and want to eventually remove  old event types from your codebase.</p>"},{"location":"guides/event-upcasting/#custom-strategies","title":"Custom Strategies","text":"<p>You can create custom strategies by implementing the <code>UpcastingStrategy</code> interface:</p> <pre><code>from interlock.application.events.upcasting import UpcastingStrategy\n\nclass CustomUpcastingStrategy(UpcastingStrategy):\n    \"\"\"Custom strategy based on environment.\"\"\"\n\n    def __init__(self, is_migration_mode: bool):\n        self.is_migration_mode = is_migration_mode\n\n    def should_upcast_on_read(self) -&gt; bool:\n        return True  # Always upcast on read\n\n    def should_upcast_on_write(self) -&gt; bool:\n        return self.is_migration_mode  # Only during migration\n</code></pre> <p>Register a custom strategy per-upcaster:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_upcaster(MoneyDepositedV1ToV2, CustomUpcastingStrategy)\n    .build()\n)\n</code></pre>"},{"location":"guides/event-upcasting/#the-trade-off-keeping-old-event-types","title":"The Trade-off: Keeping Old Event Types","text":"<p>Upcasting requires keeping old event type definitions in your codebase. This is  the fundamental trade-off:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your Codebase                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  MoneyDepositedV1  \u2500\u2500\u2500\u2500\u2500\u2500\u25ba MoneyDepositedV1ToV2 \u2500\u2500\u2500\u2500\u2500\u2500\u25ba        \u2502\n\u2502  MoneyDepositedV2  \u2500\u2500\u2500\u2500\u2500\u2500\u25ba MoneyDepositedV2ToV3 \u2500\u2500\u2500\u2500\u2500\u2500\u25ba        \u2502\n\u2502  MoneyDepositedV3  (current version, used by aggregates)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can't delete <code>MoneyDepositedV1</code> until no V1 events exist in your event store.</p>"},{"location":"guides/event-upcasting/#when-is-it-safe-to-delete-old-event-types","title":"When Is It Safe to Delete Old Event Types?","text":"<p>You can remove an old event type when:</p> <ol> <li>All events have been migrated \u2014 No V1 events remain in storage</li> <li>No replay is needed \u2014 You won't need to rebuild state from scratch</li> <li>Snapshots are current \u2014 All aggregates have recent snapshots past the old events</li> </ol>"},{"location":"guides/event-upcasting/#migration-strategies","title":"Migration Strategies","text":""},{"location":"guides/event-upcasting/#option-1-natural-migration-lazy-strategy","title":"Option 1: Natural Migration (Lazy Strategy)","text":"<p>With lazy upcasting, old events are never rewritten. They stay in storage  indefinitely, and you keep the old types forever. This is simple but means  carrying legacy code.</p>"},{"location":"guides/event-upcasting/#option-2-gradual-migration-eager-strategy","title":"Option 2: Gradual Migration (Eager Strategy)","text":"<p>With eager upcasting, events are rewritten when loaded. Over time, as aggregates  are accessed, the store migrates naturally. However, rarely-accessed aggregates  may retain old events indefinitely.</p>"},{"location":"guides/event-upcasting/#option-3-batch-migration-job","title":"Option 3: Batch Migration Job","text":"<p>Run a one-time migration job to upcast all events:</p> <pre><code>async def migrate_all_events(app: Application):\n    \"\"\"Migrate all events to latest schema.\"\"\"\n\n    # Get all aggregate IDs (implementation depends on your store)\n    aggregate_ids = await get_all_aggregate_ids()\n\n    for aggregate_id in aggregate_ids:\n        # Loading events triggers upcasting\n        events = await app.event_bus.load_events(aggregate_id, min_version=0)\n\n        # If using eager strategy, events are already rewritten\n        # If using lazy strategy, you need to explicitly rewrite:\n        if should_persist_upcasted:\n            await app.event_store.rewrite_events(aggregate_id, events)\n\n    print(f\"Migrated {len(aggregate_ids)} aggregates\")\n</code></pre> <p>Batch Migration Considerations</p> <ul> <li>Run during low-traffic periods</li> <li>Consider pagination for large event stores</li> <li>Verify the migration with checksums or counts</li> <li>Keep backups before rewriting events</li> </ul>"},{"location":"guides/event-upcasting/#option-4-snapshot-based-retirement","title":"Option 4: Snapshot-Based Retirement","text":"<p>If you use snapshots, old events become irrelevant once an aggregate has a  snapshot past all V1 events:</p> <pre><code>sequenceDiagram\n    participant Store as Event Store\n    participant Snap as Snapshot Store\n\n    Note over Store: V1, V1, V2, V3, V3, V3...\n    Note over Snap: Snapshot at V3 position\n\n    Store-&gt;&gt;Snap: Load snapshot\n    Snap--&gt;&gt;Store: Aggregate state at V3\n    Note over Store: Only load events after V3\n    Note over Store: V1 events never loaded!</code></pre> <p>Once all aggregates have snapshots past V1 events, you can:</p> <ol> <li>Stop registering the V1\u2192V2 upcaster</li> <li>Archive or delete the V1 event type code</li> </ol>"},{"location":"guides/event-upcasting/#best-practices-for-event-type-lifecycle","title":"Best Practices for Event Type Lifecycle","text":"<ol> <li>Version your event types explicitly: Use <code>V1</code>, <code>V2</code> suffixes or a version field</li> <li>Document the migration timeline: Track when each version was introduced</li> <li>Monitor event versions in production: Log which versions are still being loaded</li> <li>Clean up systematically: Remove old types only after confirming they're unused</li> </ol> <pre><code># Example: Logging to track event version usage\nclass MonitoredUpcaster(EventUpcaster[MoneyDepositedV1, MoneyDepositedV2]):\n    def __init__(self, metrics: MetricsService):\n        self.metrics = metrics\n\n    async def upcast_payload(self, data: MoneyDepositedV1) -&gt; MoneyDepositedV2:\n        self.metrics.increment(\"events.upcasted.MoneyDepositedV1\")\n        return MoneyDepositedV2(amount=data.amount, source=\"unknown\")\n</code></pre> <p>When the counter stops increasing for an extended period, it's safe to consider  removing that event type.</p>"},{"location":"guides/event-upcasting/#testing-upcasters","title":"Testing Upcasters","text":"<p>Test upcasters like any other unit:</p> <pre><code>import pytest\nfrom uuid import UUID, uuid4\nfrom interlock.domain import Event\n\n@pytest.mark.asyncio\nasync def test_upcaster_transforms_data():\n    upcaster = MoneyDepositedV1ToV2()\n\n    v1_data = MoneyDepositedV1(amount=100)\n    v2_data = await upcaster.upcast_payload(v1_data)\n\n    assert v2_data.amount == 100\n    assert v2_data.source == \"unknown\"\n\n@pytest.mark.asyncio\nasync def test_upcaster_preserves_event_metadata():\n    upcaster = MoneyDepositedV1ToV2()\n\n    original = Event(\n        aggregate_id=uuid4(),\n        data=MoneyDepositedV1(amount=100),\n        sequence_number=5,\n    )\n\n    upcasted = await upcaster.upcast_event(original)\n\n    # Metadata preserved\n    assert upcasted.aggregate_id == original.aggregate_id\n    assert upcasted.sequence_number == original.sequence_number\n    assert upcasted.timestamp == original.timestamp\n\n    # Data transformed\n    assert isinstance(upcasted.data, MoneyDepositedV2)\n</code></pre> <p>For upcasters with dependencies, inject mocks or stubs:</p> <pre><code>@pytest.mark.asyncio\nasync def test_upcaster_with_service_dependency():\n    # Create a stub service\n    class StubAccountLookup(AccountLookupService):\n        async def get_account_holder(self, account_number: str) -&gt; str:\n            return \"Jane Doe\"\n\n    upcaster = AccountOpenedV1ToV2(StubAccountLookup())\n\n    v1_data = AccountOpenedV1(account_number=\"123456\")\n    v2_data = await upcaster.upcast_payload(v1_data)\n\n    assert v2_data.holder_name == \"Jane Doe\"\n</code></pre>"},{"location":"guides/event-upcasting/#summary","title":"Summary","text":"Concept Description EventUpcaster[T, U] Base class for transforming event type T to type U upcast_payload() Async method implementing the transformation logic can_upcast() Optional method for conditional upcasting LazyUpcastingStrategy Upcast on read only (recommended) EagerUpcastingStrategy Upcast on read and write Chaining V1\u2192V2\u2192V3 happens automatically"},{"location":"guides/event-upcasting/#next-steps","title":"Next Steps","text":"<ul> <li>Events Concept \u2014 Deep dive into event design</li> <li>Tutorial: Events &amp; Sourcing \u2014 Hands-on event sourcing</li> <li>API Reference \u2014 Complete API documentation</li> </ul>"},{"location":"guides/processor-catchup/","title":"Event Processor Catchup","text":"<p>Event processors can fall behind the event stream or start after events have already been published. Catchup mechanisms help processors synchronize with the event store.</p>"},{"location":"guides/processor-catchup/#the-problem","title":"The Problem","text":"<p>Event processors can become out of sync with the write model when:</p> <ul> <li>They're created after events have already been published</li> <li>They experience downtime while events continue flowing</li> <li>They process slower than events are produced</li> </ul> <pre><code>sequenceDiagram\n    participant Write as Write Model\n    participant Store as Event Store\n    participant Proc as Processor\n\n    Write-&gt;&gt;Store: Event 1\n    Write-&gt;&gt;Store: Event 2\n    Write-&gt;&gt;Store: Event 3\n    Note over Proc: Processor starts here\n    Write-&gt;&gt;Store: Event 4\n    Proc-&gt;&gt;Store: Subscribe (misses 1-3!)\n    Store-&gt;&gt;Proc: Event 4\n    Note over Proc: Projection incomplete</code></pre> <p>The processor misses events 1-3, resulting in an incomplete projection.</p>"},{"location":"guides/processor-catchup/#catchup-conditions","title":"Catchup Conditions","text":"<p>A catchup condition determines when to trigger catchup based on processor lag metrics.</p>"},{"location":"guides/processor-catchup/#lag-metrics","title":"Lag Metrics","text":"<p>Interlock measures two dimensions of processor lag:</p> Metric What it measures Indicates <code>unprocessed_events</code> Queue depth (events waiting) Volume problem (backlog) <code>average_event_age</code> Mean age of recent events Latency problem (slowness) <p>These metrics are captured in a <code>Lag</code> dataclass:</p> <pre><code>from datetime import timedelta\nfrom interlock.application.events.processing import Lag\n\nlag = Lag(\n    unprocessed_events=5000,\n    average_event_age=timedelta(minutes=3)\n)\n\n# Helper methods for evaluation\nlag.unprocessed_events_is_greater_than(1000)  # True\nlag.average_age_is_older_than(timedelta(minutes=5))  # False\n</code></pre>"},{"location":"guides/processor-catchup/#available-conditions","title":"Available Conditions","text":""},{"location":"guides/processor-catchup/#never-default","title":"<code>Never</code> (default)","text":"<p>Never trigger catchup\u2014processor only handles new events:</p> <pre><code>from interlock.application.events.processing import Never\n\n# Disable catchup entirely\ncondition = Never()\n</code></pre> <p>Use when:</p> <ul> <li>Processor only needs new events (e.g., notifications)</li> <li>Catchup is managed externally</li> <li>Testing scenarios</li> </ul>"},{"location":"guides/processor-catchup/#afterneventsn","title":"<code>AfterNEvents(n)</code>","text":"<p>Trigger when unprocessed event count exceeds a threshold:</p> <pre><code>from interlock.application.events.processing import AfterNEvents\n\n# Catchup if backlog exceeds 10,000 events\ncondition = AfterNEvents(10_000)\n</code></pre> <p>Use when:</p> <ul> <li>Preventing unbounded queue growth</li> <li>Volume-based catchup policies</li> </ul>"},{"location":"guides/processor-catchup/#afternagetimedelta","title":"<code>AfterNAge(timedelta)</code>","text":"<p>Trigger when average event age exceeds a threshold:</p> <pre><code>from interlock.application.events.processing import AfterNAge\nfrom datetime import timedelta\n\n# Catchup if events are &gt; 5 minutes old on average\ncondition = AfterNAge(timedelta(minutes=5))\n</code></pre> <p>Use when:</p> <ul> <li>Ensuring data freshness</li> <li>Time-based SLA requirements</li> </ul>"},{"location":"guides/processor-catchup/#anyofconditions","title":"<code>AnyOf(*conditions)</code>","text":"<p>Trigger if any condition is met (OR logic):</p> <pre><code>from interlock.application.events.processing import AnyOf, AfterNEvents, AfterNAge\nfrom datetime import timedelta\n\n# Catchup if EITHER queue &gt; 5000 OR events &gt; 10min old\ncondition = AnyOf(\n    AfterNEvents(5000),\n    AfterNAge(timedelta(minutes=10))\n)\n</code></pre>"},{"location":"guides/processor-catchup/#allofconditions","title":"<code>AllOf(*conditions)</code>","text":"<p>Trigger only if all conditions are met (AND logic):</p> <pre><code>from interlock.application.events.processing import AllOf, AfterNEvents, AfterNAge\nfrom datetime import timedelta\n\n# Catchup only if BOTH queue &gt; 1000 AND events &gt; 5min old\ncondition = AllOf(\n    AfterNEvents(1000),\n    AfterNAge(timedelta(minutes=5))\n)\n</code></pre>"},{"location":"guides/processor-catchup/#configuring-conditions","title":"Configuring Conditions","text":"<p>Register conditions when adding processors:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.events.processing import AfterNEvents\n\napp = (\n    ApplicationBuilder()\n    .register_event_processor(\n        AccountBalanceProjection,\n        catchup_condition=AfterNEvents(10_000),\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/processor-catchup/#catchup-strategies","title":"Catchup Strategies","text":"<p>A catchup strategy defines how to catch up when the condition is triggered.</p>"},{"location":"guides/processor-catchup/#nocatchup-default","title":"<code>NoCatchup</code> (default)","text":"<p>No catchup\u2014processor starts from current position:</p> <pre><code>from interlock.application.events.processing import NoCatchup\n\nstrategy = NoCatchup()\n</code></pre> <p>The processor will miss any events that occurred before it subscribed.</p>"},{"location":"guides/processor-catchup/#custom-catchup-strategies","title":"Custom Catchup Strategies","text":"<p>For processors that need historical data, implement a custom <code>CatchupStrategy</code>:</p> <pre><code>from interlock.application.events.processing import CatchupStrategy, CatchupResult\nfrom datetime import datetime\n\nclass SnapshotCatchupStrategy(CatchupStrategy):\n    \"\"\"Load pre-built snapshots instead of replaying events.\"\"\"\n\n    def __init__(self, snapshot_store):\n        self.snapshot_store = snapshot_store\n\n    async def catchup(self, processor) -&gt; CatchupResult | None:\n        # Load the latest snapshot for this processor\n        snapshot = await self.snapshot_store.load_latest(\n            processor.__class__.__name__\n        )\n\n        if snapshot:\n            # Restore processor state from snapshot\n            processor.restore_from_snapshot(snapshot.data)\n\n            # Return skip window to avoid re-processing\n            return CatchupResult(skip_before=snapshot.timestamp)\n\n        return None\n</code></pre>"},{"location":"guides/processor-catchup/#the-catchupresult","title":"The <code>CatchupResult</code>","text":"<p>When catchup loads historical data, it returns a <code>CatchupResult</code> with a skip window:</p> <pre><code>from interlock.application.events.processing import CatchupResult\nfrom datetime import datetime\n\n# Events with timestamp &lt;= skip_before are skipped\nresult = CatchupResult(skip_before=datetime(2025, 1, 1, 10, 0, 0))\n\n# The executor checks each event\nif result.should_skip(event):\n    continue  # Already processed via catchup\nelse:\n    await processor.handle(event.data)\n</code></pre> <p>This prevents double-processing events that were already incorporated during catchup.</p>"},{"location":"guides/processor-catchup/#configuring-strategies","title":"Configuring Strategies","text":"<p>Register strategies when adding processors:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.events.processing import AfterNEvents\n\napp = (\n    ApplicationBuilder()\n    .register_event_processor(\n        AccountBalanceProjection,\n        catchup_condition=AfterNEvents(10_000),\n        catchup_strategy=SnapshotCatchupStrategy(snapshot_store),\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/processor-catchup/#how-it-works","title":"How It Works","text":"<p>The <code>EventProcessorExecutor</code> orchestrates event processing and catchup:</p> <pre><code>flowchart TD\n    START[Start Processor] --&gt; INIT_CATCHUP[Initial Catchup]\n    INIT_CATCHUP --&gt; LOOP[Process Event Batch]\n    LOOP --&gt; MEASURE[Measure Lag]\n    MEASURE --&gt; CHECK{Condition Met?}\n    CHECK --&gt;|No| LOOP\n    CHECK --&gt;|Yes| CATCHUP[Execute Catchup]\n    CATCHUP --&gt; LOOP</code></pre> <ol> <li>Initial Catchup: On startup, the strategy's <code>catchup()</code> is called</li> <li>Batch Processing: Events are processed in configurable batch sizes</li> <li>Lag Measurement: After each batch, lag metrics are calculated</li> <li>Condition Check: If the condition evaluates to <code>True</code>, catchup runs</li> </ol>"},{"location":"guides/processor-catchup/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/processor-catchup/#notification-processor-no-catchup","title":"Notification Processor (No Catchup)","text":"<p>For processors that only handle new events:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_event_processor(\n        EmailNotificationProcessor,\n        # Defaults: Never condition, NoCatchup strategy\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/processor-catchup/#projection-with-backlog-protection","title":"Projection with Backlog Protection","text":"<p>For projections that need to stay current:</p> <pre><code>from interlock.application.events.processing import AnyOf, AfterNEvents, AfterNAge\nfrom datetime import timedelta\n\napp = (\n    ApplicationBuilder()\n    .register_event_processor(\n        AccountBalanceProjection,\n        catchup_condition=AnyOf(\n            AfterNEvents(10_000),       # Don't let backlog grow too large\n            AfterNAge(timedelta(minutes=5))  # Don't let data get too stale\n        ),\n        catchup_strategy=SnapshotCatchupStrategy(snapshot_store),\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/processor-catchup/#analytics-processor-eventual-consistency-ok","title":"Analytics Processor (Eventual Consistency OK)","text":"<p>For analytics that can tolerate some lag:</p> <pre><code>from interlock.application.events.processing import AfterNAge\nfrom datetime import timedelta\n\napp = (\n    ApplicationBuilder()\n    .register_event_processor(\n        AnalyticsProcessor,\n        catchup_condition=AfterNAge(timedelta(hours=1)),  # Allow up to 1 hour lag\n        catchup_strategy=FullReplayStrategy(event_store),\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/processor-catchup/#best-practices","title":"Best Practices","text":""},{"location":"guides/processor-catchup/#choosing-conditions","title":"Choosing Conditions","text":"Scenario Recommended Condition Real-time requirements <code>AfterNAge(timedelta(seconds=30))</code> High throughput, eventual consistency OK <code>AfterNEvents(50_000)</code> Balanced approach <code>AnyOf(AfterNEvents(...), AfterNAge(...))</code> Notifications only <code>Never()</code>"},{"location":"guides/processor-catchup/#designing-catchup-strategies","title":"Designing Catchup Strategies","text":"<ol> <li>Make catchup idempotent: Running catchup multiple times should be safe</li> <li>Use snapshots when possible: Faster than replaying all events</li> <li>Track catchup progress: Enable resuming after failures</li> <li>Return accurate skip windows: Prevent double-processing</li> </ol>"},{"location":"guides/processor-catchup/#monitoring","title":"Monitoring","text":"<p>Track these metrics to tune your catchup configuration:</p> <ul> <li>Unprocessed event count over time</li> <li>Average event age</li> <li>Catchup trigger frequency</li> <li>Catchup duration</li> </ul>"},{"location":"guides/processor-catchup/#further-reading","title":"Further Reading","text":"<ul> <li>Event Processors Concept \u2014 Understanding processors</li> <li>Aggregate Optimization \u2014 Snapshots for aggregates</li> <li>Database Integrations \u2014 Storage backends</li> </ul>"},{"location":"guides/sagas/","title":"Sagas","text":"<p>Orchestrate long-running, multi-step business processes that span multiple aggregates.</p>"},{"location":"guides/sagas/#goal","title":"Goal","text":"<p>Implement complex workflows that coordinate multiple aggregates while maintaining  consistency through stateful, event-driven orchestration.</p>"},{"location":"guides/sagas/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of Event Processors</li> <li>Familiarity with the Tutorial</li> </ul>"},{"location":"guides/sagas/#what-is-a-saga","title":"What is a Saga?","text":"<p>A saga is a stateful event processor that coordinates long-running business  processes spanning multiple aggregates. Unlike simple event processors that react  to individual events, sagas:</p> <ul> <li>Maintain state across multiple events</li> <li>Track progress through multi-step workflows</li> <li>Handle failures with compensation logic</li> <li>Guarantee idempotency \u2014 each step runs exactly once</li> </ul> <p>Think of a saga as a state machine driven by domain events.</p>"},{"location":"guides/sagas/#when-to-use-sagas","title":"When to Use Sagas","text":"Use Sagas When Use Event Processors When Process spans multiple aggregates Reacting to single events Need to track progress across steps Building read models (projections) Require compensation on failure Sending notifications Order of operations matters No state between events needed"},{"location":"guides/sagas/#example-money-transfer","title":"Example: Money Transfer","text":"<p>Let's build a saga that coordinates transferring money between two bank accounts. The saga listens to events from both accounts and tracks progress:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant Source as Source Account\n    participant Saga as TransferSaga\n    participant Target as Target Account\n\n    Client-&gt;&gt;Source: WithdrawMoney\n    Source--&gt;&gt;Saga: MoneyWithdrawn\n    Note right of Saga: state.source_withdrawn = true\n\n    Saga-&gt;&gt;Target: DepositMoney\n    Target--&gt;&gt;Saga: MoneyDeposited\n    Note right of Saga: state.completed = true\n\n    rect rgb(255, 230, 230)\n        Note over Source,Target: Failure Path\n        Target--&gt;&gt;Saga: DepositFailed\n        Saga-&gt;&gt;Source: RefundMoney (compensation)\n        Note right of Saga: state deleted\n    end</code></pre> <p>The saga acts as an orchestrator: it receives events from aggregates and  dispatches commands to coordinate the workflow.</p>"},{"location":"guides/sagas/#defining-saga-state","title":"Defining Saga State","text":"<p>First, define the state your saga needs to track:</p> <pre><code>from pydantic import BaseModel\nfrom decimal import Decimal\nfrom uuid import UUID, uuid4\n\nclass TransferState(BaseModel):\n    \"\"\"State for a money transfer saga.\"\"\"\n    transfer_id: str\n    from_account: UUID\n    to_account: UUID\n    amount: Decimal\n    source_withdrawn: bool = False\n    target_deposited: bool = False\n    completed: bool = False\n</code></pre> <p>The state is a Pydantic model that gets persisted between events.</p>"},{"location":"guides/sagas/#defining-events","title":"Defining Events","text":"<p>Events that drive the saga need a <code>saga_id</code> property to correlate them with  the correct saga instance. You have two options:</p>"},{"location":"guides/sagas/#option-1-direct-field","title":"Option 1: Direct Field","text":"<p>Add a <code>saga_id</code> field directly:</p> <pre><code>from pydantic import BaseModel\nfrom decimal import Decimal\n\nclass TransferInitiated(BaseModel):\n    saga_id: str  # Direct field\n    from_account: str\n    to_account: str\n    amount: Decimal\n\nclass TransferCompleted(BaseModel):\n    saga_id: str\n\nclass TransferFailed(BaseModel):\n    saga_id: str\n    reason: str\n</code></pre>"},{"location":"guides/sagas/#option-2-computed-property","title":"Option 2: Computed Property","text":"<p>Use a computed property when the saga ID derives from another field:</p> <pre><code>class OrderShipped(BaseModel):\n    order_id: str\n    tracking_number: str\n\n    @property\n    def saga_id(self) -&gt; str:\n        return self.order_id  # Computed from order_id\n</code></pre> <p>This keeps your domain events clean while satisfying the saga convention.</p> <p>Custom Extractor (Escape Hatch)</p> <p>Use the <code>saga_id</code> parameter on <code>@saga_step</code> when:</p> <ul> <li>An event participates in multiple sagas that need different correlation IDs</li> <li>You can't modify the event class</li> </ul> <pre><code>@saga_step(saga_id=lambda e: f\"order-{e.order_id}\")\nasync def on_payment_received(self, event: PaymentReceived) -&gt; State:\n    ...\n</code></pre>"},{"location":"guides/sagas/#implementing-the-saga","title":"Implementing the Saga","text":"<p>Sagas extend <code>Saga[StateType]</code> and use the <code>@saga_step</code> decorator:</p> <pre><code>from interlock.application.events.processing import Saga, SagaStateStore, saga_step\n\nclass MoneyTransferSaga(Saga[TransferState]):\n    \"\"\"Coordinates money transfer between accounts.\"\"\"\n\n    def __init__(self, state_store: SagaStateStore):\n        super().__init__(state_store)\n\n    @saga_step  # (1)!\n    async def on_transfer_initiated(\n        self, \n        event: TransferInitiated\n    ) -&gt; TransferState:\n        \"\"\"First step: create initial state.\"\"\"\n        return TransferState(\n            transfer_id=event.saga_id,\n            from_account=event.from_account,\n            to_account=event.to_account,\n            amount=event.amount,\n        )\n\n    @saga_step\n    async def on_source_withdrawn(\n        self, \n        event: SourceWithdrawn, \n        state: TransferState  # (2)!\n    ) -&gt; TransferState:\n        \"\"\"Subsequent step: receives existing state.\"\"\"\n        state.source_withdrawn = True\n        return state\n\n    @saga_step\n    async def on_target_deposited(\n        self, \n        event: TargetDeposited, \n        state: TransferState\n    ) -&gt; TransferState:\n        \"\"\"Mark transfer as complete.\"\"\"\n        state.target_deposited = True\n        state.completed = True\n        return state\n\n    @saga_step\n    async def on_transfer_failed(\n        self, \n        event: TransferFailed, \n        state: TransferState\n    ) -&gt; None:  # (3)!\n        \"\"\"Cleanup: return None to delete state.\"\"\"\n        # Compensation logic would go here\n        return None\n</code></pre> <ol> <li><code>@saga_step</code> provides automatic event routing, idempotency, and state management</li> <li>Subsequent steps receive the current state as a parameter</li> <li>Return <code>None</code> to delete state (cleanup after completion or failure)</li> </ol>"},{"location":"guides/sagas/#handler-patterns","title":"Handler Patterns","text":"<p>The <code>@saga_step</code> decorator infers behavior from your function signature:</p> Signature Behavior <code>async def handler(self, event) -&gt; State</code> Initial step: Creates new state <code>async def handler(self, event, state) -&gt; State</code> Subsequent step: Receives and updates state <code>async def handler(self, event, state) -&gt; None</code> Cleanup step: Deletes state"},{"location":"guides/sagas/#automatic-idempotency","title":"Automatic Idempotency","text":"<p>Each saga step runs exactly once per saga instance. If the same event is  processed again (e.g., due to retries), the step is skipped:</p> <pre><code># First time: step executes\nawait saga.handle(TransferInitiated(saga_id=\"t-1\", ...))\n\n# Second time: step skipped (idempotent)\nawait saga.handle(TransferInitiated(saga_id=\"t-1\", ...))\n</code></pre> <p>The <code>SagaStateStore</code> tracks which steps have completed for each saga instance.</p>"},{"location":"guides/sagas/#registering-sagas","title":"Registering Sagas","text":"<p>Sagas are registered like any other event processor:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.events.processing import SagaStateStore\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_event_processor(MoneyTransferSaga)  # (1)!\n    .build()\n)\n</code></pre> <ol> <li>Sagas are just specialized event processors \u2014 no special registration needed</li> </ol> <p>The <code>SagaStateStore</code> is automatically provided (in-memory by default). For  production, register a persistent implementation:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_dependency(SagaStateStore, PostgresSagaStateStore)\n    .register_event_processor(MoneyTransferSaga)\n    .build()\n)\n</code></pre>"},{"location":"guides/sagas/#testing-sagas","title":"Testing Sagas","text":"<p>Use <code>SagaScenario</code> or <code>app.saga_scenario()</code> for testing:</p> <pre><code>import pytest\nfrom interlock.application.events.processing import SagaStateStore\nfrom interlock.testing import SagaScenario\n\n@pytest.fixture\ndef app():\n    return (\n        ApplicationBuilder()\n        .register_event_processor(MoneyTransferSaga)\n        .build()\n    )\n\n@pytest.mark.asyncio\nasync def test_transfer_creates_initial_state(app):\n    async with app.saga_scenario(MoneyTransferSaga) as scenario:\n        scenario \\\n            .given(\n                TransferInitiated(\n                    saga_id=\"transfer-1\",\n                    from_account=\"acc-1\",\n                    to_account=\"acc-2\",\n                    amount=Decimal(\"100.00\"),\n                )\n            ) \\\n            .should_have_state(\n                \"transfer-1\",  # saga_id to check\n                lambda s: s.transfer_id == \"transfer-1\" and not s.completed\n            )\n\n@pytest.mark.asyncio\nasync def test_transfer_completes_successfully(app):\n    async with app.saga_scenario(MoneyTransferSaga) as scenario:\n        scenario \\\n            .given(\n                TransferInitiated(\n                    saga_id=\"transfer-1\",\n                    from_account=\"acc-1\",\n                    to_account=\"acc-2\",\n                    amount=Decimal(\"100.00\"),\n                ),\n                SourceWithdrawn(saga_id=\"transfer-1\"),\n                TargetDeposited(saga_id=\"transfer-1\"),\n            ) \\\n            .should_have_state(\"transfer-1\", lambda s: s.completed)\n\n@pytest.mark.asyncio\nasync def test_failed_transfer_cleans_up_state(app):\n    async with app.saga_scenario(MoneyTransferSaga) as scenario:\n        scenario \\\n            .given(\n                TransferInitiated(\n                    saga_id=\"transfer-1\",\n                    from_account=\"acc-1\",\n                    to_account=\"acc-2\",\n                    amount=Decimal(\"100.00\"),\n                ),\n                TransferFailed(saga_id=\"transfer-1\", reason=\"Insufficient funds\"),\n            ) \\\n            .should_have_state(\"transfer-1\", lambda s: s is None)  # State deleted\n</code></pre>"},{"location":"guides/sagas/#understanding-compensation","title":"Understanding Compensation","text":"<p>In distributed systems, you can't use traditional database transactions across  multiple aggregates or services. Instead, sagas use compensation\u2014the process  of semantically undoing the effects of previous steps when a later step fails.</p>"},{"location":"guides/sagas/#why-compensation","title":"Why Compensation?","text":"<p>Consider our money transfer saga:</p> <ol> <li>\u2705 Step 1: Withdraw $100 from Account A \u2192 <code>MoneyWithdrawn</code></li> <li>\u274c Step 2: Deposit $100 to Account B \u2192 <code>DepositFailed</code> (account frozen!)</li> </ol> <p>At this point, we've taken money from Account A but failed to deliver it to  Account B. The money is \"in limbo.\" We need to compensate Step 1 by  depositing the money back into Account A.</p> <pre><code>sequenceDiagram\n    participant A as Account A\n    participant Saga as TransferSaga\n    participant B as Account B\n\n    A-&gt;&gt;Saga: MoneyWithdrawn \u2713\n    Note right of Saga: $100 deducted from A\n\n    Saga-&gt;&gt;B: DepositMoney\n    B--&gt;&gt;Saga: DepositFailed \u2717\n    Note right of Saga: B is frozen!\n\n    rect rgb(255, 240, 200)\n        Note over A,B: Compensation\n        Saga-&gt;&gt;A: DepositMoney (refund)\n        A--&gt;&gt;Saga: MoneyDeposited \u2713\n        Note right of Saga: $100 returned to A\n    end</code></pre>"},{"location":"guides/sagas/#compensation-vs-rollback","title":"Compensation vs Rollback","text":"Database Rollback Saga Compensation Automatically undoes all changes You must explicitly define undo logic All-or-nothing Each step may partially complete Synchronous Asynchronous, eventual consistency Hidden from domain Part of your domain model"},{"location":"guides/sagas/#designing-compensating-actions","title":"Designing Compensating Actions","text":"<p>Every saga step that changes state should have a corresponding compensation:</p> Forward Action Compensating Action <code>WithdrawMoney</code> <code>DepositMoney</code> (refund) <code>ReserveInventory</code> <code>ReleaseInventory</code> <code>ChargePayment</code> <code>RefundPayment</code> <code>SendEmail</code> (often not compensatable) <p>Not Everything Can Be Compensated</p> <p>Some actions are inherently non-compensatable (sending an email, calling  an external API). Design your saga to perform these last, or accept that  some compensations are \"best effort.\"</p>"},{"location":"guides/sagas/#compensation-patterns","title":"Compensation Patterns","text":"<p>Now let's look at how to implement compensation in your sagas:</p>"},{"location":"guides/sagas/#pattern-1-inject-commandbus-recommended","title":"Pattern 1: Inject CommandBus (Recommended)","text":"<p>Inject the <code>CommandBus</code> to dispatch compensation commands:</p> <pre><code>from interlock.application.commands import CommandBus\n\nclass MoneyTransferSaga(Saga[TransferState]):\n    def __init__(self, state_store: SagaStateStore, command_bus: CommandBus):\n        super().__init__(state_store)\n        self.command_bus = command_bus\n\n    @saga_step\n    async def on_transfer_failed(\n        self, \n        event: TransferFailed, \n        state: TransferState\n    ) -&gt; None:\n        if state.source_withdrawn:\n            # Compensate: refund the source account\n            await self.command_bus.dispatch(\n                DepositMoney(\n                    aggregate_id=state.from_account,  # Already a UUID\n                    amount=int(state.amount),\n                )\n            )\n        return None\n</code></pre> <p>The <code>CommandBus</code> is automatically registered by the framework\u2014no extra setup needed:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .register_event_processor(MoneyTransferSaga)  # CommandBus injected automatically\n    .build()\n)\n</code></pre> <p>Depend on What You Need</p> <p>Injecting <code>CommandBus</code> instead of <code>Application</code> follows the principle of  minimal dependencies. The saga only needs to dispatch commands, not access  the entire application.</p>"},{"location":"guides/sagas/#pattern-2-external-compensation-service","title":"Pattern 2: External Compensation Service","text":"<p>For complex compensation logic, use a dedicated service:</p> <pre><code>class CompensationService(ABC):\n    @abstractmethod\n    async def compensate_transfer(self, state: TransferState) -&gt; None:\n        ...\n\nclass MoneyTransferSaga(Saga[TransferState]):\n    def __init__(\n        self, \n        state_store: SagaStateStore, \n        compensation: CompensationService\n    ):\n        super().__init__(state_store)\n        self.compensation = compensation\n\n    @saga_step\n    async def on_transfer_failed(\n        self, \n        event: TransferFailed, \n        state: TransferState\n    ) -&gt; None:\n        await self.compensation.compensate_transfer(state)\n        return None\n</code></pre>"},{"location":"guides/sagas/#custom-saga-id-extraction","title":"Custom Saga ID Extraction","text":"<p>The custom <code>saga_id</code> extractor is an escape hatch for special cases:</p>"},{"location":"guides/sagas/#event-participates-in-multiple-sagas","title":"Event Participates in Multiple Sagas","text":"<p>When the same event drives different sagas with different correlation:</p> <pre><code>class PaymentReceived(BaseModel):\n    payment_id: str\n    order_id: str\n    subscription_id: str\n\n# Order fulfillment saga uses order_id\nclass OrderFulfillmentSaga(Saga[OrderState]):\n    @saga_step(saga_id=lambda e: e.order_id)\n    async def on_payment_received(self, event: PaymentReceived) -&gt; OrderState:\n        ...\n\n# Subscription saga uses subscription_id\nclass SubscriptionSaga(Saga[SubscriptionState]):\n    @saga_step(saga_id=lambda e: e.subscription_id)\n    async def on_payment_received(self, event: PaymentReceived) -&gt; SubscriptionState:\n        ...\n</code></pre>"},{"location":"guides/sagas/#cant-modify-the-event-class","title":"Can't Modify the Event Class","text":"<p>When working with events from external systems or shared libraries:</p> <pre><code># External event you can't modify\nclass ExternalOrderEvent(BaseModel):\n    order_number: str  # No saga_id property\n    status: str\n\nclass OrderSaga(Saga[OrderState]):\n    @saga_step(saga_id=lambda e: e.order_number)\n    async def on_external_order(self, event: ExternalOrderEvent) -&gt; OrderState:\n        ...\n</code></pre> <p>Prefer the Convention</p> <p>When possible, add a <code>saga_id</code> field or computed property to your events. The custom extractor adds indirection and is harder to trace.</p>"},{"location":"guides/sagas/#state-store-implementations","title":"State Store Implementations","text":"<p>The default in-memory store is good for development and testing:</p> <pre><code>from interlock.application.events.processing import SagaStateStore\n\nstore = SagaStateStore.in_memory()\n</code></pre> <p>Not for Production</p> <p>The in-memory store loses all data when the application stops.</p> <p>For production, see Database Integrations for persistent  <code>SagaStateStore</code> implementations.</p>"},{"location":"guides/sagas/#best-practices","title":"Best Practices","text":"<ol> <li>Design for failure: Every step that changes state should have a compensation path</li> <li>Keep steps small: Each step should do one thing well</li> <li>Use meaningful step names: They appear in logs and state tracking</li> <li>Test compensation paths: Don't just test the happy path</li> <li>Monitor saga progress: Log state transitions for debugging</li> <li>Set timeouts: Handle sagas that get stuck (external monitoring)</li> <li>Idempotent compensations: Compensation steps may also be retried</li> </ol>"},{"location":"guides/sagas/#summary","title":"Summary","text":"Concept Description Saga[TState] Base class for stateful sagas @saga_step Decorator for saga event handlers SagaStateStore Abstract storage for saga state saga_id Correlates events to saga instances Initial step <code>handler(event) -&gt; State</code> \u2014 creates state Subsequent step <code>handler(event, state) -&gt; State</code> \u2014 updates state Cleanup step <code>handler(event, state) -&gt; None</code> \u2014 deletes state"},{"location":"guides/sagas/#next-steps","title":"Next Steps","text":"<ul> <li>Event Processors \u2014 Simpler event handling</li> <li>Writing Tests \u2014 Testing strategies</li> <li>API Reference \u2014 Complete API documentation</li> </ul>"},{"location":"guides/writing-tests/","title":"Writing Tests","text":"<p>Write effective, expressive tests for your event-sourced domain.</p>"},{"location":"guides/writing-tests/#goal","title":"Goal","text":"<p>Test aggregates, event processors, and sagas using Interlock's testing utilities.</p>"},{"location":"guides/writing-tests/#prerequisites","title":"Prerequisites","text":"<ul> <li>Familiarity with pytest</li> <li>Understanding of Aggregates and Events</li> </ul>"},{"location":"guides/writing-tests/#testing-philosophy","title":"Testing Philosophy","text":"<p>Event-sourced systems follow the Given-When-Then pattern naturally:</p> <ul> <li>Given: A sequence of past events</li> <li>When: A command is executed</li> <li>Then: Specific events are emitted (or errors raised)</li> </ul>"},{"location":"guides/writing-tests/#aggregate-testing","title":"Aggregate Testing","text":"<p>Use <code>AggregateScenario</code> for behavior-driven aggregate tests:</p> <pre><code>import pytest\nfrom interlock.testing import AggregateScenario\n\n@pytest.mark.asyncio\nasync def test_deposit_emits_event():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given_no_events() \\\n            .when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100)) \\\n            .should_emit(MoneyDeposited)\n\n@pytest.mark.asyncio\nasync def test_multiple_deposits():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=50)) \\\n            .should_have_state(lambda acc: acc.balance.amount == 150)\n</code></pre> <p>The scenario automatically generates an <code>aggregate_id</code> accessible via <code>scenario.aggregate_id</code>.</p>"},{"location":"guides/writing-tests/#state-assertions","title":"State Assertions","text":"<p>Check aggregate state after command execution:</p> <pre><code>@pytest.mark.asyncio\nasync def test_balance_after_operations():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .when(WithdrawMoney(aggregate_id=scenario.aggregate_id, amount=30)) \\\n            .should_emit(MoneyWithdrawn) \\\n            .should_have_state(lambda acc: acc.balance.amount == 70)\n</code></pre>"},{"location":"guides/writing-tests/#processor-testing","title":"Processor Testing","text":"<p>For processors with dependencies, use <code>app.processor_scenario()</code> to leverage DI:</p> <pre><code>@pytest.mark.asyncio\nasync def test_projection_tracks_balance():\n    app = (\n        ApplicationBuilder()\n        .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n        .register_event_processor(AccountBalanceProjection)\n        .build()\n    )\n\n    async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .should_have_state(\n                lambda p: p.repository.get_balance(scenario.aggregate_id) == 100\n            )\n</code></pre> <p>For simple processors without dependencies, instantiate directly:</p> <pre><code>from interlock.testing import ProcessorScenario\n\n@pytest.mark.asyncio\nasync def test_simple_processor():\n    async with ProcessorScenario(CountingProcessor()) as scenario:\n        scenario \\\n            .given(SomeEvent()) \\\n            .should_have_state(lambda p: p.count == 1)\n</code></pre>"},{"location":"guides/writing-tests/#saga-testing","title":"Saga Testing","text":"<p>For sagas, use <code>app.saga_scenario()</code> for DI or instantiate with a state store:</p> <pre><code>from interlock.application.events.processing import SagaStateStore\nfrom interlock.testing import SagaScenario\n\n@pytest.mark.asyncio\nasync def test_saga_state_transition():\n    saga = OrderSaga(SagaStateStore.in_memory())\n\n    async with SagaScenario(saga) as scenario:\n        scenario \\\n            .given(OrderPlaced(saga_id=\"order-123\")) \\\n            .should_have_state(\"order-123\", lambda s: s.status == \"placed\")\n</code></pre>"},{"location":"guides/writing-tests/#best-practices","title":"Best Practices","text":"<ol> <li>Test behaviors, not implementation: Focus on what events are emitted</li> <li>Use descriptive names: <code>test_cannot_withdraw_more_than_balance</code></li> <li>One scenario per test: Keep tests focused</li> <li>Test edge cases: Empty state, boundaries, error conditions</li> <li>Use DI for complex processors: Build an app and use <code>app.processor_scenario()</code></li> </ol>"},{"location":"guides/writing-tests/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial: Events &amp; Sourcing - See TDD in action</li> <li>API Reference</li> </ul>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#interlock","title":"interlock","text":"<p>Interlock - Event Sourcing and CQRS Framework for Python.</p> <p>This module provides the public API for building event-sourced applications.</p>"},{"location":"reference/#interlock.Application","title":"Application","text":"<pre><code>Application(contextual_binding: ContextualBinding)\n</code></pre> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self, contextual_binding: ContextualBinding):\n    self.contextual_binding = contextual_binding\n    self.command_bus = self.resolve(CommandBus)\n    self.event_bus = self.resolve(EventBus)\n    self.query_bus = self.resolve(QueryBus)\n</code></pre>"},{"location":"reference/#interlock.Application.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(command: Command[T]) -&gt; T\n</code></pre> <p>Dispatch a command to the application.</p> <p>This method will dispatch a command to the application. The command will be dispatched to the command bus and the command bus will dispatch the command to the appropriate aggregate and middleware chain.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to dispatch.</p> <p> TYPE: <code>Command[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def dispatch(self, command: Command[T]) -&gt; T:\n    \"\"\"Dispatch a command to the application.\n\n    This method will dispatch a command to the application. The command\n    will be dispatched to the command bus and the command bus will dispatch\n    the command to the appropriate aggregate and middleware chain.\n\n    Args:\n        command: The command to dispatch.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    return await self.command_bus.dispatch(command)\n</code></pre>"},{"location":"reference/#interlock.Application.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Execute a query against the application.</p> <p>This method will dispatch a query to the application. The query will be dispatched to the query bus and routed through middleware to the appropriate projection.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to execute.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Execute a query against the application.\n\n    This method will dispatch a query to the application. The query\n    will be dispatched to the query bus and routed through middleware\n    to the appropriate projection.\n\n    Args:\n        query: The query to execute.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n    \"\"\"\n    return await self.query_bus.dispatch(query)\n</code></pre>"},{"location":"reference/#interlock.Application.resolve","title":"resolve","text":"<pre><code>resolve(type_to_resolve: type[T]) -&gt; T\n</code></pre> <p>Resolve a dependency from the application.</p> <p>This method will resolve a dependency from the application. The dependency will be resolved from the contextual binding and will be returned.</p> PARAMETER DESCRIPTION <code>type_to_resolve</code> <p>The type of the dependency to resolve.</p> <p> TYPE: <code>type[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The resolved dependency.</p> RAISES DESCRIPTION <code>DependencyNotFoundError</code> <p>If the dependency cannot be resolved.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def resolve(self, type_to_resolve: type[T]) -&gt; T:\n    \"\"\"Resolve a dependency from the application.\n\n    This method will resolve a dependency from the application.\n    The dependency will be resolved from the contextual binding\n    and will be returned.\n\n    Args:\n        type_to_resolve: The type of the dependency to resolve.\n\n    Returns:\n        The resolved dependency.\n\n    Raises:\n        DependencyNotFoundError: If the dependency cannot be\n            resolved.\n    \"\"\"\n    return self.contextual_binding.resolve(type_to_resolve)\n</code></pre>"},{"location":"reference/#interlock.Application.startup","title":"startup  <code>async</code>","text":"<pre><code>startup() -&gt; None\n</code></pre> <p>Startup the application.</p> <p>This method will startup the application. The application will be started by calling the on_startup method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are started in the order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Startup the application.\n\n    This method will startup the application. The application will be\n    started by calling the on_startup method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are started\n    in the order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in dependencies:\n        await dependency.on_startup()\n</code></pre>"},{"location":"reference/#interlock.Application.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown() -&gt; None\n</code></pre> <p>Shutdown the application.</p> <p>This method will shutdown the application. The application will be shutdown by calling the on_shutdown method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are shutdown in the reverse order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the application.\n\n    This method will shutdown the application. The application will be\n    shutdown by calling the on_shutdown method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are shutdown\n    in the reverse order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in reversed(dependencies):\n        await dependency.on_shutdown()\n</code></pre>"},{"location":"reference/#interlock.Application.run_event_processors","title":"run_event_processors  <code>async</code>","text":"<pre><code>run_event_processors(\n    *processors: type[EventProcessor],\n) -&gt; None\n</code></pre> <p>Run the event processors for the application.</p> <p>This method will run the event processors for the application of the given types. The event processors are run asynchronously and will continue to run until the application is stopped or all run methods have completed. The event processors are run in the order they were registered.</p> PARAMETER DESCRIPTION <code>*processors</code> <p>The event processors to run.</p> <p> TYPE: <code>type[EventProcessor]</code> DEFAULT: <code>()</code> </p> RAISES DESCRIPTION <code>Exception</code> <p>Any exceptions raised by the event processors will be propagated to the caller.</p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def run_event_processors(self, *processors: type[EventProcessor]) -&gt; None:\n    \"\"\"Run the event processors for the application.\n\n    This method will run the event processors for the application of the\n    given types. The event processors are run asynchronously and will\n    continue to run until the application is stopped or all run methods\n    have completed. The event processors are run in the order they were\n    registered.\n\n    Args:\n        *processors: The event processors to run.\n\n    Raises:\n        Exception: Any exceptions raised by the event processors will be\n            propagated to the caller.\n\n    Returns:\n        None\n    \"\"\"\n    # We will resolve each processors executor from its own container\n    # context and then subscribe to the event transport for the processor.\n    executors = [\n        self.contextual_binding.container_for(processor).resolve(EventProcessorExecutor)\n        for processor in processors\n    ]\n\n    transport = self.contextual_binding.resolve(EventTransport)\n    subscriptions = [\n        await transport.subscribe(executor.processor.__class__.__name__)\n        for executor in executors\n    ]\n\n    # Now that we have a subscription for each processor, we can run the\n    # processors in their own async tasks. We will gather the tasks and\n    # await them all to complete (This will probably be 'forever' since\n    # the processors are expected to run until the application is stopped).\n    tasks = [\n        executor.run(subscription)\n        for executor, subscription in zip(executors, subscriptions, strict=False)\n    ]\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"reference/#interlock.Application.aggregate_scenario","title":"aggregate_scenario","text":"<pre><code>aggregate_scenario(\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; AggregateScenario\n</code></pre> <p>Create a test scenario for an aggregate.</p> <p>This provides a consistent testing API across all Interlock components. Aggregates don't have constructor dependencies, so this is equivalent to creating an AggregateScenario directly.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class to test.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>aggregate_id</code> <p>Optional specific ID for the aggregate.</p> <p> TYPE: <code>UUID | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AggregateScenario</code> <p>An AggregateScenario ready for Given-When-Then testing.</p> Example <p>async with app.aggregate_scenario(BankAccount) as scenario: ...     scenario.given_no_events() ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100)) ...     scenario.should_emit(MoneyDeposited)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def aggregate_scenario(\n    self,\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; \"AggregateScenario\":\n    \"\"\"Create a test scenario for an aggregate.\n\n    This provides a consistent testing API across all Interlock components.\n    Aggregates don't have constructor dependencies, so this is equivalent\n    to creating an AggregateScenario directly.\n\n    Args:\n        aggregate_type: The aggregate class to test.\n        aggregate_id: Optional specific ID for the aggregate.\n\n    Returns:\n        An AggregateScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.aggregate_scenario(BankAccount) as scenario:\n        ...     scenario.given_no_events()\n        ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100))\n        ...     scenario.should_emit(MoneyDeposited)\n    \"\"\"\n    from ..testing import AggregateScenario\n\n    return AggregateScenario(aggregate_type, aggregate_id)\n</code></pre>"},{"location":"reference/#interlock.Application.processor_scenario","title":"processor_scenario","text":"<pre><code>processor_scenario(\n    processor_type: type[EventProcessor],\n) -&gt; ProcessorScenario\n</code></pre> <p>Create a test scenario for an event processor with DI.</p> <p>The processor is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The event processor class to test.</p> <p> TYPE: <code>type[EventProcessor]</code> </p> RETURNS DESCRIPTION <code>ProcessorScenario</code> <p>A ProcessorScenario ready for Given-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository) ...     .register_event_processor(AccountBalanceProjection) ...     .build() ... ) async with app.processor_scenario(AccountBalanceProjection) as scenario: ...     scenario.given(MoneyDeposited(account_id=id, amount=100)) ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def processor_scenario(\n    self,\n    processor_type: type[EventProcessor],\n) -&gt; \"ProcessorScenario\":\n    \"\"\"Create a test scenario for an event processor with DI.\n\n    The processor is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        processor_type: The event processor class to test.\n\n    Returns:\n        A ProcessorScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n        ...     .register_event_processor(AccountBalanceProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        ...     scenario.given(MoneyDeposited(account_id=id, amount=100))\n        ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)\n    \"\"\"\n    from ..testing import ProcessorScenario\n\n    # Resolve the processor from the DI container\n    processor = self.contextual_binding.container_for(processor_type).resolve(processor_type)\n    return ProcessorScenario(processor)\n</code></pre>"},{"location":"reference/#interlock.Application.saga_scenario","title":"saga_scenario","text":"<pre><code>saga_scenario(saga_type: type) -&gt; SagaScenario\n</code></pre> <p>Create a test scenario for a saga with DI.</p> <p>The saga is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>saga_type</code> <p>The saga class to test.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>SagaScenario</code> <p>A SagaScenario ready for Given-Then testing.</p> Example <p>async with app.saga_scenario(OrderFulfillmentSaga) as scenario: ...     scenario.given(OrderPlaced(order_id=\"123\")) ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")</p> Source code in <code>interlock/application/application.py</code> <pre><code>def saga_scenario(\n    self,\n    saga_type: type,\n) -&gt; \"SagaScenario\":\n    \"\"\"Create a test scenario for a saga with DI.\n\n    The saga is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        saga_type: The saga class to test.\n\n    Returns:\n        A SagaScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.saga_scenario(OrderFulfillmentSaga) as scenario:\n        ...     scenario.given(OrderPlaced(order_id=\"123\"))\n        ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")\n    \"\"\"\n    from ..testing import SagaScenario\n    from .events.processing import Saga\n\n    # Resolve the saga from the DI container\n    saga = self.contextual_binding.container_for(saga_type).resolve(saga_type)\n    if not isinstance(saga, Saga):\n        raise TypeError(f\"Expected Saga instance, got {type(saga).__name__}\")\n    return SagaScenario(saga)\n</code></pre>"},{"location":"reference/#interlock.Application.projection_scenario","title":"projection_scenario","text":"<pre><code>projection_scenario(\n    projection_type: type[Projection],\n) -&gt; ProjectionScenario\n</code></pre> <p>Create a test scenario for a projection with DI.</p> <p>The projection is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to test.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionScenario</code> <p>A ProjectionScenario ready for Given-When-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_projection(UserProjection) ...     .build() ... ) async with app.projection_scenario(UserProjection) as scenario: ...     scenario.given(UserCreated(user_id=id, name=\"Alice\")) ...     result = await scenario.when(GetUserById(user_id=id)) ...     assert result.name == \"Alice\"</p> Source code in <code>interlock/application/application.py</code> <pre><code>def projection_scenario(\n    self,\n    projection_type: type[Projection],\n) -&gt; \"ProjectionScenario\":\n    \"\"\"Create a test scenario for a projection with DI.\n\n    The projection is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        projection_type: The projection class to test.\n\n    Returns:\n        A ProjectionScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_projection(UserProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.projection_scenario(UserProjection) as scenario:\n        ...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n        ...     result = await scenario.when(GetUserById(user_id=id))\n        ...     assert result.name == \"Alice\"\n    \"\"\"\n    from ..testing import ProjectionScenario\n\n    # Resolve the projection from the DI container\n    projection = self.contextual_binding.container_for(projection_type).resolve(projection_type)\n    return ProjectionScenario(projection)\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder","title":"ApplicationBuilder","text":"<pre><code>ApplicationBuilder()\n</code></pre> <p>Builder for creating Application instances.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.container = DependencyContainer()\n    self.contextual_binding = ContextualBinding(self.container)\n\n    # Event Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=UpcastingStrategy,\n        factory=LazyUpcastingStrategy,\n    )\n    self.container.register_singleton(\n        dependency_type=EventTransport,\n        factory=InMemoryEventTransport,\n    )\n    self.container.register_singleton(\n        dependency_type=EventStore,\n        factory=InMemoryEventStore,\n    )\n    self.container.register_singleton(\n        dependency_type=UpcasterMap,\n        factory=self._build_upcaster_map,\n    )\n    self.container.register_singleton(UpcastingPipeline)\n    self.container.register_singleton(\n        dependency_type=EventDelivery,\n        factory=self._build_synchronous_delivery,\n    )\n    self.container.register_singleton(EventBus)\n\n    # Aggregate Repository Defaults:\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStrategy,\n        factory=AggregateSnapshotStrategy.never,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateCacheBackend,\n        factory=AggregateCacheBackend.null,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStorageBackend,\n        factory=AggregateSnapshotStorageBackend.null,\n    )\n\n    # Event Processor Defaults:\n    self.container.register_singleton(\n        dependency_type=CatchupCondition,\n        factory=Never,\n    )\n    self.container.register_singleton(\n        dependency_type=CatchupStrategy,\n        factory=NoCatchup,\n    )\n    self.container.register_singleton(\n        dependency_type=CacheStrategy,\n        factory=CacheStrategy.never,\n    )\n\n    # Command Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=CommandToAggregateMap,\n        factory=self._build_command_to_aggregate_map,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateToRepositoryMap,\n        factory=self._build_aggregate_to_repository_map,\n    )\n    self.container.register_singleton(DelegateToAggregate)\n    self.container.register_singleton(\n        dependency_type=CommandBus,\n        factory=self._build_command_bus,\n    )\n\n    self.container.register_singleton(SagaStateStore, SagaStateStore.in_memory)\n\n    # Query Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=QueryToProjectionMap,\n        factory=self._build_query_to_projection_map,\n    )\n    self.container.register_singleton(\n        dependency_type=ProjectionRegistry,\n        factory=self._build_projection_registry,\n    )\n    self.container.register_singleton(DelegateToProjection)\n    self.container.register_singleton(\n        dependency_type=QueryBus,\n        factory=self._build_query_bus,\n    )\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_dependency","title":"register_dependency","text":"<pre><code>register_dependency(\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a dependency with the application.</p> <p>This method will register a dependency with the application. All dependencies are registered as singletons and the provided factory will be used to create the dependency when it is resolved for the first time. If no factory is provided, the dependency will be resolved by calling the init method of the dependency type. Regardless of dependecies of that function will be resolved by the container.</p> PARAMETER DESCRIPTION <code>dependency_type</code> <p>The type to register</p> <p> TYPE: <code>type[T]</code> </p> <code>factory</code> <p>The factory function to create the dependency</p> <p> TYPE: <code>Callable[..., T] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_dependency(\n    self,\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a dependency with the application.\n\n    This method will register a dependency with the application.\n    All dependencies are registered as singletons and the provided\n    factory will be used to create the dependency when it is\n    resolved for the first time. If no factory is provided, the\n    dependency will be resolved by calling the __init__ method of\n    the dependency type. Regardless of dependecies of that function\n    will be resolved by the container.\n\n    Args:\n        dependency_type: The type to register\n        factory: The factory function to create the dependency\n\n    Returns:\n        The application builder\n    \"\"\"\n    self.container.register_singleton(dependency_type, factory or dependency_type)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_aggregate","title":"register_aggregate","text":"<pre><code>register_aggregate(\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: (\n        type[AggregateSnapshotStrategy] | None\n    ) = None,\n    cache_backend: (\n        type[AggregateCacheBackend] | None\n    ) = None,\n    snapshot_backend: (\n        type[AggregateSnapshotStorageBackend] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Add an aggregate to the application.</p> <p>This method will register an aggregate with the application. The aggregate will be registered with the application and will be available to be resolved. In addition to registering the aggregate, you can also configure related dependencies for the aggregate such as the cache and snapshot configurations.</p> <p>If the aggregate was already registered, this method will update the dependencies for the aggregate. Thefore it is fine to have multiple calls to this method for the same aggregate type.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The type of aggregate to add.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>cache_strategy</code> <p>The type of cache strategy to use.</p> <p> TYPE: <code>type[CacheStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_strategy</code> <p>The type of snapshot strategy to use.</p> <p> TYPE: <code>type[AggregateSnapshotStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>cache_backend</code> <p>The type of cache backend to use.</p> <p> TYPE: <code>type[AggregateCacheBackend] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_backend</code> <p>The type of snapshot backend to use.</p> <p> TYPE: <code>type[AggregateSnapshotStorageBackend] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_aggregate(\n    self,\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: type[AggregateSnapshotStrategy] | None = None,\n    cache_backend: type[AggregateCacheBackend] | None = None,\n    snapshot_backend: type[AggregateSnapshotStorageBackend] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Add an aggregate to the application.\n\n    This method will register an aggregate with the application. The\n    aggregate will be registered with the application and will be\n    available to be resolved. In addition to registering the aggregate,\n    you can also configure related dependencies for the aggregate such as\n    the cache and snapshot configurations.\n\n    If the aggregate was already registered, this method will update the\n    dependencies for the aggregate. Thefore it is fine to have\n    multiple calls to this method for the same aggregate type.\n\n    Args:\n        aggregate_type: The type of aggregate to add.\n        cache_strategy: The type of cache strategy to use.\n        snapshot_strategy: The type of snapshot strategy to use.\n        cache_backend: The type of cache backend to use.\n        snapshot_backend: The type of snapshot backend to use.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(aggregate_type)\n    container.register_singleton(AggregateFactory, lambda: AggregateFactory(aggregate_type))\n    container.register_singleton(Aggregate, aggregate_type)\n    container.register_singleton(AggregateRepository)\n    if cache_strategy:\n        container.register_singleton(\n            dependency_type=CacheStrategy,\n            factory=cache_strategy,\n        )\n    if snapshot_strategy:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStrategy,\n            factory=snapshot_strategy,\n        )\n    if cache_backend:\n        container.register_singleton(\n            dependency_type=AggregateCacheBackend,\n            factory=cache_backend,\n        )\n    if snapshot_backend:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStorageBackend,\n            factory=snapshot_backend,\n        )\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_middleware","title":"register_middleware","text":"<pre><code>register_middleware(\n    middleware_type: type[Middleware],\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register middleware with the application.</p> <p>This method will register middleware with the application. The middleware will be registered with the application and will be available to be resolved. Middleware uses annotation-based routing with @intercepts decorator to determine which commands or queries to intercept.</p> PARAMETER DESCRIPTION <code>middleware_type</code> <p>The type of middleware to register</p> <p> TYPE: <code>type[Middleware]</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_middleware(\n    self,\n    middleware_type: type[Middleware],\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register middleware with the application.\n\n    This method will register middleware with the application. The\n    middleware will be registered with the application and will be\n    available to be resolved. Middleware uses annotation-based routing\n    with @intercepts decorator to determine which commands or queries\n    to intercept.\n\n    Args:\n        middleware_type: The type of middleware to register\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(middleware_type)\n    container.register_singleton(middleware_type)\n    container.register_singleton(Middleware, middleware_type)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_event_processor","title":"register_event_processor","text":"<pre><code>register_event_processor(\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Creates or updates the registration of an event processor.</p> <p>The processor will be registered with the application and will be avaiable to be resolved. In addition to registering the processor, you can also configure the processor's execution configuration via setting any of the relevant optional parameters on the CatchupCondition and CatchupStrategy objects.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The type of the event processor to register</p> <p> TYPE: <code>type[EventProcessor]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_event_processor(\n    self,\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Creates or updates the registration of an event processor.\n\n    The processor will be registered with the application and will be\n    avaiable to be resolved. In addition to registering the processor,\n    you can also configure the processor's execution configuration\n    via setting any of the relevant optional parameters on the\n    CatchupCondition and CatchupStrategy objects.\n\n    Args:\n        processor_type: The type of the event processor to register\n        catchup_condition: The condition to trigger catchup\n        catchup_strategy: The strategy to use for catchup\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(processor_type)\n    container.register_singleton(processor_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_projection","title":"register_projection","text":"<pre><code>register_projection(\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a projection with the application.</p> <p>Projections combine event handling (building read models) with query handling (serving reads). This method registers both capabilities.</p> <p>The projection will be available for: - Event processing via run_event_processors() - Query handling via Application.query()</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to register.</p> <p> TYPE: <code>type[Projection]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup.</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup.</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_projection(\n    self,\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a projection with the application.\n\n    Projections combine event handling (building read models) with\n    query handling (serving reads). This method registers both\n    capabilities.\n\n    The projection will be available for:\n    - Event processing via run_event_processors()\n    - Query handling via Application.query()\n\n    Args:\n        projection_type: The projection class to register.\n        catchup_condition: The condition to trigger catchup.\n        catchup_strategy: The strategy to use for catchup.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    # Register as both a projection (for queries) and event processor\n    container = self.contextual_binding.container_for(projection_type)\n    container.register_singleton(projection_type)\n    container.register_singleton(Projection, projection_type)\n    container.register_singleton(EventProcessor, projection_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.register_upcaster","title":"register_upcaster","text":"<pre><code>register_upcaster(\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: (\n        type[UpcastingStrategy] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register an upcaster with the application.</p> <p>This method will register an upcaster with the application. The upcaster will be registered with the application and will be available to be resolved. In addition to registering the upcaster, you can also configure the upcaster's upcasting strategy via setting the relevant optional parameter.</p> <p>If the upcaster was already registered, this method will update the upcasting strategy for the upcaster. Thefore it is fine to have multiple calls to this method for the same upcaster type.</p> PARAMETER DESCRIPTION <code>upcaster</code> <p>The type of the upcaster to register</p> <p> TYPE: <code>type[EventUpcaster[Any, Any]]</code> </p> <code>upcasting_strategy</code> <p>The type of the upcasting strategy to register</p> <p> TYPE: <code>type[UpcastingStrategy] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_upcaster(\n    self,\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: type[UpcastingStrategy] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register an upcaster with the application.\n\n    This method will register an upcaster with the application. The\n    upcaster will be registered with the application and will be available\n    to be resolved. In addition to registering the upcaster, you can also\n    configure the upcaster's upcasting strategy via setting the relevant\n    optional parameter.\n\n    If the upcaster was already registered, this method will update the\n    upcasting strategy for the upcaster. Thefore it is fine to have\n    multiple calls to this method for the same upcaster type.\n\n    Args:\n        upcaster: The type of the upcaster to register\n        upcasting_strategy: The type of the upcasting strategy to register\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(upcaster)\n    container.register_singleton(upcaster, upcaster)\n    if upcasting_strategy:\n        container.register_singleton(UpcastingStrategy, upcasting_strategy)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.convention_based","title":"convention_based","text":"<pre><code>convention_based(package_name: str) -&gt; ApplicationBuilder\n</code></pre> <p>Load aggregates, commands, etc from convention based modules.</p> <p>This method will load aggregates, commands, middleware, event processors, upcasters, configs, and services from a package based on the conventions of the package. The package will be scanned recursively for the relevant components.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>The name of the package to load components from.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def convention_based(self, package_name: str) -&gt; \"ApplicationBuilder\":\n    \"\"\"Load aggregates, commands, etc from convention based modules.\n\n    This method will load aggregates, commands, middleware, event\n    processors, upcasters, configs, and services from a package based on\n    the conventions of the package. The package will be scanned\n    recursively for the relevant components.\n\n    Args:\n        package_name: The name of the package to load components from.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    from .configurators import ApplicationProfile\n\n    for profile in ApplicationProfile.convention_based(package_name):\n        profile.configure(self)\n    return self\n</code></pre>"},{"location":"reference/#interlock.ApplicationBuilder.build","title":"build","text":"<pre><code>build() -&gt; Application\n</code></pre> <p>Build the application with dependency injection.</p> <p>This method will resolve all dependencies and return an Application instance. If any dependencies cannot be resolved, an error will be raised. The Application instance will be fully configured and ready to use.</p> RETURNS DESCRIPTION <code>Application</code> <p>The configured Application instance</p> RAISES DESCRIPTION <code>ValueError</code> <p>If dependencies cannot be resolved (missing, etc.)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def build(self) -&gt; Application:\n    \"\"\"Build the application with dependency injection.\n\n    This method will resolve all dependencies and return an Application\n    instance. If any dependencies cannot be resolved, an error will be\n    raised. The Application instance will be fully configured and ready to\n    use.\n\n    Returns:\n        The configured Application instance\n\n    Raises:\n        ValueError: If dependencies cannot be resolved (missing, etc.)\n    \"\"\"\n    return Application(self.contextual_binding)\n</code></pre>"},{"location":"reference/#interlock.Aggregate","title":"Aggregate","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all aggregates in the event sourcing system.</p> <p>Aggregates are the core domain objects that maintain consistency boundaries and emit domain events when their state changes. Each aggregate has a unique identifier and maintains its version through event sequencing.</p> <p>The aggregate pattern ensures that all business rules and invariants are enforced within a single consistency boundary. State changes are expressed as events that are applied to update the aggregate's state.</p> <p>Command and event handling is automatically routed based on method decorators. Use @handles_command to mark command handler methods and @applies_event to mark event applier methods. The framework will automatically route commands and events to the appropriate methods based on their type annotations.</p> <p>Examples:</p> <p>Create a simple bank account aggregate:</p> <pre><code>&gt;&gt;&gt; from decimal import Decimal\n&gt;&gt;&gt; from interlock.routing import handles_command, applies_event\n&gt;&gt;&gt;\n&gt;&gt;&gt; class DepositMoney(Command):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MoneyDeposited(BaseModel):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     balance: Decimal = Decimal(\"0.00\")\n...\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         if cmd.amount &lt;= 0:\n...             raise ValueError(\"Amount must be positive\")\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n...\n...     @applies_event\n...     def apply_deposited(self, evt: MoneyDeposited) -&gt; None:\n...         self.balance += evt.amount\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.handle(DepositMoney(aggregate_id=account.id, amount=Decimal(\"100.00\")))\n&gt;&gt;&gt; print(account.balance)\n100.00\n</code></pre> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this aggregate instance. Auto-generated if not provided.</p> <p> TYPE: <code>UUID</code> </p> <code>version</code> <p>Current version number, incremented with each event. Used for optimistic concurrency control.</p> <p> TYPE: <code>int</code> </p> <code>last_snapshot_time</code> <p>Timestamp of the last snapshot creation. Used for snapshot management.</p> <p> TYPE: <code>datetime</code> </p> <code>last_event_time</code> <p>Timestamp of the most recent event. Used for tracking aggregate activity.</p> <p> TYPE: <code>datetime</code> </p> <code>uncommitted_events</code> <p>List of events that have been emitted but not yet persisted to the event store. This field is excluded from serialization.</p> <p> TYPE: <code>list[Event[Any]]</code> </p>"},{"location":"reference/#interlock.Aggregate.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up command and event routing when a subclass is defined.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up command and event routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)  # type: ignore[arg-type]\n    cls._command_router = setup_command_routing(cls)\n    cls._event_router = setup_event_applying(cls)\n</code></pre>"},{"location":"reference/#interlock.Aggregate.handle","title":"handle","text":"<pre><code>handle(command: BaseModel) -&gt; object\n</code></pre> <p>Route a command to its registered handler method.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to handle.</p> <p> TYPE: <code>BaseModel</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for this command type.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def handle(self, command: BaseModel) -&gt; object:\n    \"\"\"Route a command to its registered handler method.\n\n    Args:\n        command: The command to handle.\n\n    Raises:\n        NotImplementedError: If no handler is registered for this command type.\n    \"\"\"\n    return self._command_router.route(self, command)\n</code></pre>"},{"location":"reference/#interlock.Aggregate.apply","title":"apply","text":"<pre><code>apply(event: BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered applier method.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to apply to the aggregate state.</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def apply(self, event: BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered applier method.\n\n    Args:\n        event: The event to apply to the aggregate state.\n    \"\"\"\n    return self._event_router.route(self, event)\n</code></pre>"},{"location":"reference/#interlock.Aggregate.emit","title":"emit","text":"<pre><code>emit(data: T) -&gt; None\n</code></pre> <p>Emit a domain event and apply it to the aggregate state.</p> <p>This method should be called by business logic methods when the aggregate's state needs to change. It increments the version, creates an event with proper metadata, adds it to uncommitted events, and applies the event.</p> <p>The emit method automatically populates correlation_id and causation_id from the current execution context: - correlation_id is inherited from the context (traces the entire operation) - causation_id is set to the command_id from context (the command that caused this event)</p> PARAMETER DESCRIPTION <code>data</code> <p>The event data as a Pydantic model representing what happened.</p> <p> TYPE: <code>T</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class AccountOpened(BaseModel):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def emit(self, data: T) -&gt; None:\n    \"\"\"Emit a domain event and apply it to the aggregate state.\n\n    This method should be called by business logic methods when the aggregate's\n    state needs to change. It increments the version, creates an event with\n    proper metadata, adds it to uncommitted events, and applies the event.\n\n    The emit method automatically populates correlation_id and causation_id from\n    the current execution context:\n    - correlation_id is inherited from the context (traces the entire operation)\n    - causation_id is set to the command_id from context (the command that caused this event)\n\n    Args:\n        data: The event data as a Pydantic model representing what happened.\n\n    Examples:\n        &gt;&gt;&gt; class AccountOpened(BaseModel):\n        ...     owner: str\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n        &gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n    \"\"\"\n    self.version += 1\n    current_time = utc_now()\n\n    # Get context for correlation/causation tracking\n    ctx = get_context()\n\n    event: Event[T] = Event(\n        aggregate_id=self.id,\n        sequence_number=self.version,\n        data=data,\n        timestamp=current_time,\n        correlation_id=ctx.correlation_id,\n        causation_id=ctx.command_id,  # The command caused this event\n    )\n    self.last_event_time = current_time\n    self.uncommitted_events.append(event)\n    self.apply(data)\n</code></pre>"},{"location":"reference/#interlock.Aggregate.changed_since","title":"changed_since","text":"<pre><code>changed_since(version: int) -&gt; bool\n</code></pre> <p>Check if the aggregate has changed since a specific version.</p> PARAMETER DESCRIPTION <code>version</code> <p>The version number to compare against.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the current version is greater than the provided version,</p> <code>bool</code> <p>False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n&gt;&gt;&gt; account.changed_since(0)\nTrue\n&gt;&gt;&gt; account.changed_since(1)\nFalse\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def changed_since(self, version: int) -&gt; bool:\n    \"\"\"Check if the aggregate has changed since a specific version.\n\n    Args:\n        version: The version number to compare against.\n\n    Returns:\n        True if the current version is greater than the provided version,\n        False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n        &gt;&gt;&gt; account.changed_since(0)\n        True\n        &gt;&gt;&gt; account.changed_since(1)\n        False\n    \"\"\"\n    return self.version &gt; version\n</code></pre>"},{"location":"reference/#interlock.Aggregate.mark_snapshot","title":"mark_snapshot","text":"<pre><code>mark_snapshot() -&gt; None\n</code></pre> <p>Mark the current time as when a snapshot was taken.</p> <p>This method is typically called by the repository after creating a snapshot of the aggregate's current state.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def mark_snapshot(self) -&gt; None:\n    \"\"\"Mark the current time as when a snapshot was taken.\n\n    This method is typically called by the repository after creating\n    a snapshot of the aggregate's current state.\n    \"\"\"\n    self.last_snapshot_time = utc_now()\n</code></pre>"},{"location":"reference/#interlock.Aggregate.get_uncommitted_events","title":"get_uncommitted_events","text":"<pre><code>get_uncommitted_events() -&gt; list[Event[Any]]\n</code></pre> <p>Get the list of events that haven't been persisted yet.</p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of uncommitted event objects.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def get_uncommitted_events(self) -&gt; list[Event[Any]]:\n    \"\"\"Get the list of events that haven't been persisted yet.\n\n    Returns:\n        List of uncommitted event objects.\n    \"\"\"\n    return self.uncommitted_events\n</code></pre>"},{"location":"reference/#interlock.Aggregate.clear_uncommitted_events","title":"clear_uncommitted_events","text":"<pre><code>clear_uncommitted_events() -&gt; None\n</code></pre> <p>Clear the list of uncommitted events.</p> <p>This is typically called after events have been successfully persisted to the event store.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def clear_uncommitted_events(self) -&gt; None:\n    \"\"\"Clear the list of uncommitted events.\n\n    This is typically called after events have been successfully\n    persisted to the event store.\n    \"\"\"\n    self.uncommitted_events.clear()\n</code></pre>"},{"location":"reference/#interlock.Aggregate.replay_events","title":"replay_events","text":"<pre><code>replay_events(events: list[BaseModel]) -&gt; None\n</code></pre> <p>Replay a sequence of events to rebuild the aggregate's state.</p> <p>This method is called when loading an aggregate from the event store. It applies each event in order to reconstruct the current state.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of event data objects to replay.</p> <p> TYPE: <code>list[BaseModel]</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def replay_events(self, events: list[BaseModel]) -&gt; None:\n    \"\"\"Replay a sequence of events to rebuild the aggregate's state.\n\n    This method is called when loading an aggregate from the event store.\n    It applies each event in order to reconstruct the current state.\n\n    Args:\n        events: List of event data objects to replay.\n    \"\"\"\n    for event in events:\n        self.apply(event)\n</code></pre>"},{"location":"reference/#interlock.Command","title":"Command","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all commands in the system.</p> <p>Commands represent intentions to change state and are dispatched to command handlers. All commands must include an aggregate_id to identify which aggregate instance to operate on.</p> <p>Commands are generic over their response type <code>TResponse</code>, allowing handlers to return typed results. Use <code>Command[None]</code> for commands that don't return a value.</p> ATTRIBUTE DESCRIPTION <code>aggregate_id</code> <p>UUID of the aggregate that should handle this command.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this command.</p> <p> TYPE: <code>UUID | None</code> </p> <code>command_id</code> <p>Unique identifier for this command instance.</p> <p> TYPE: <code>UUID</code> </p> <p>Examples:</p> <p>Command that returns the new aggregate ID:</p> <pre><code>&gt;&gt;&gt; class CreateAccount(Command[UUID]):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_create(self, cmd: CreateAccount) -&gt; UUID:\n...         self.emit(AccountCreated(owner=cmd.owner))\n...         return self.id\n</code></pre> <p>Command that returns nothing:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n</code></pre>"},{"location":"reference/#interlock.Event","title":"Event","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Immutable record of a state change in an aggregate.</p> <p>Event is the core data structure in event sourcing. Each event represents a fact that occurred in the past - a state transition in an aggregate's lifecycle. Events are:</p> <ul> <li>Immutable: Once created, events cannot be modified</li> <li>Ordered: Events have sequence numbers for ordering within an aggregate</li> <li>Typed: Generic type parameter T specifies the event data schema</li> <li>Timestamped: All events record when they occurred (UTC)</li> <li>Identifiable: Each event has a unique ID and belongs to an aggregate</li> <li>Traceable: Events can include correlation/causation IDs for distributed tracing</li> </ul> <p>The Event class is a generic wrapper that combines event metadata (id, aggregate_id, sequence_number, timestamp) with strongly-typed event data. The type parameter <code>T</code> is a Pydantic BaseModel subclass defining the event data schema.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this specific event instance</p> <p> TYPE: <code>UUID</code> </p> <code>aggregate_id</code> <p>ID of the aggregate that produced this event</p> <p> TYPE: <code>UUID</code> </p> <code>data</code> <p>Typed event data (e.g., AccountCreated, MoneyDeposited)</p> <p> TYPE: <code>T</code> </p> <code>sequence_number</code> <p>Position in the aggregate's event stream (1-indexed)</p> <p> TYPE: <code>int</code> </p> <code>timestamp</code> <p>When the event occurred (UTC timezone)</p> <p> TYPE: <code>datetime</code> </p> <code>correlation_id</code> <p>Optional correlation ID for tracing the entire logical operation</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this event (typically the command_id)</p> <p> TYPE: <code>UUID | None</code> </p> Note <p>Events are typically created by aggregates via the <code>emit()</code> method, not constructed directly. The EventBus handles persistence and delivery. The Aggregate.emit() method automatically populates correlation_id and causation_id from the current execution context.</p> <p>Examples:</p> <p>Event created by aggregate (context auto-populated):</p> <pre><code>&gt;&gt;&gt; # Inside aggregate command handler\n&gt;&gt;&gt; self.emit(AccountCreated(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically set from context\n</code></pre> <p>Event created manually with full context:</p> <pre><code>&gt;&gt;&gt; event = Event(\n...     aggregate_id=account_id,\n...     data=MoneyDeposited(amount=100),\n...     sequence_number=5,\n...     correlation_id=correlation_id,\n...     causation_id=command_id\n... )\n</code></pre>"},{"location":"reference/#interlock.Query","title":"Query","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all queries in the system.</p> <p>Queries represent requests for data and are dispatched to projections. Each query is generic over its response type, providing type safety for query handlers.</p> <p>Unlike commands, queries: - Do not mutate state - Return typed responses - Are routed to projections (not aggregates)</p> <p>The type parameter <code>TResponse</code> specifies the type returned by query handlers for this query.</p> ATTRIBUTE DESCRIPTION <code>query_id</code> <p>Unique identifier for this query instance.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this query.</p> <p> TYPE: <code>UUID | None</code> </p> <p>Examples:</p> <p>Define a query with a typed response:</p> <pre><code>&gt;&gt;&gt; class GetUserById(Query[UserProfile]):\n...     user_id: UUID\n&gt;&gt;&gt;\n&gt;&gt;&gt; class GetUserByEmail(Query[UUID | None]):\n...     email: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Query handlers must return the declared response type\n&gt;&gt;&gt; class UserProjection(Projection):\n...     @handles_query\n...     async def get_user_by_id(self, query: GetUserById) -&gt; UserProfile:\n...         return self.users[query.user_id]\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>application<ul> <li>aggregates<ul> <li>repository<ul> <li>cache</li> <li>repository</li> <li>snapshot</li> </ul> </li> </ul> </li> <li>application</li> <li>commands<ul> <li>bus</li> </ul> </li> <li>configurators</li> <li>container</li> <li>discovery</li> <li>events<ul> <li>bus</li> <li>delivery</li> <li>processing<ul> <li>conditions</li> <li>executor</li> <li>processor</li> <li>saga</li> <li>strategies</li> </ul> </li> <li>store</li> <li>transport</li> <li>upcasting<ul> <li>pipeline</li> <li>strategies</li> </ul> </li> </ul> </li> <li>middleware<ul> <li>base</li> <li>concurrency</li> <li>context</li> <li>idempotency</li> <li>logging</li> </ul> </li> <li>projections<ul> <li>bus</li> <li>projection</li> </ul> </li> </ul> </li> <li>context</li> <li>domain<ul> <li>aggregate</li> <li>command</li> <li>event</li> <li>exceptions</li> <li>query</li> </ul> </li> <li>integrations<ul> <li>mongodb<ul> <li>collection</li> <li>config</li> <li>event_store</li> <li>idempotency</li> <li>saga_store</li> <li>snapshot_storage</li> <li>type_loader</li> </ul> </li> </ul> </li> <li>routing</li> <li>testing<ul> <li>aggregate_scenario</li> <li>core</li> <li>processor_scenario</li> </ul> </li> </ul>"},{"location":"reference/context/","title":"context","text":""},{"location":"reference/context/#interlock.context","title":"context","text":""},{"location":"reference/context/#interlock.context.ExecutionContext","title":"ExecutionContext  <code>dataclass</code>","text":"<pre><code>ExecutionContext(\n    correlation_id: UUID | None = None,\n    causation_id: UUID | None = None,\n    command_id: UUID | None = None,\n)\n</code></pre> <p>Immutable context for tracking request flow through the system.</p> <p>ExecutionContext captures the causal relationship between commands and events as they flow through the system, enabling distributed tracing and debugging.</p> ATTRIBUTE DESCRIPTION <code>correlation_id</code> <p>Unique ID that traces an entire logical operation across all commands, events, and services. Remains constant throughout the flow.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>ID of what directly caused this operation. For events, this is the command_id that triggered them. For saga commands, this is the event ID that triggered them.</p> <p> TYPE: <code>UUID | None</code> </p> <code>command_id</code> <p>Unique identifier for the current command being executed. When this command emits events, this becomes their causation_id.</p> <p> TYPE: <code>UUID | None</code> </p> <p>Examples:</p> <p>Create a new context at system entry point:</p> <pre><code>&gt;&gt;&gt; ctx = ExecutionContext.create()\n&gt;&gt;&gt; print(ctx.correlation_id)  # Auto-generated UUID\n</code></pre> <p>Create context with specific IDs:</p> <pre><code>&gt;&gt;&gt; ctx = ExecutionContext(\n...     correlation_id=uuid4(),\n...     causation_id=uuid4(),\n...     command_id=uuid4()\n... )\n</code></pre> <p>Create a child context for an event:</p> <pre><code>&gt;&gt;&gt; event_ctx = ctx.for_event(event_id=uuid4())\n&gt;&gt;&gt; # correlation_id stays the same\n&gt;&gt;&gt; # causation_id becomes the event_id\n&gt;&gt;&gt; # command_id is cleared\n</code></pre>"},{"location":"reference/context/#interlock.context.ExecutionContext.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(\n    correlation_id: UUID | None = None,\n) -&gt; ExecutionContext\n</code></pre> <p>Create a new context, typically at a system entry point.</p> PARAMETER DESCRIPTION <code>correlation_id</code> <p>Optional correlation ID. If not provided, a new UUID is generated. At entry points, causation_id is set to correlation_id (self-referencing).</p> <p> TYPE: <code>UUID | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>A new ExecutionContext instance.</p> Example Source code in <code>interlock/context.py</code> <pre><code>@classmethod\ndef create(cls, correlation_id: UUID | None = None) -&gt; \"ExecutionContext\":\n    \"\"\"Create a new context, typically at a system entry point.\n\n    Args:\n        correlation_id: Optional correlation ID. If not provided, a new UUID\n            is generated. At entry points, causation_id is set to correlation_id\n            (self-referencing).\n\n    Returns:\n        A new ExecutionContext instance.\n\n    Example:\n        &gt;&gt;&gt; # At HTTP endpoint\n        &gt;&gt;&gt; ctx = ExecutionContext.create()\n        &gt;&gt;&gt; command = MyCommand(\n        ...     aggregate_id=...,\n        ...     correlation_id=ctx.correlation_id,\n        ...     causation_id=ctx.correlation_id\n        ... )\n    \"\"\"\n    if correlation_id is None:\n        correlation_id = uuid4()\n\n    return cls(\n        correlation_id=correlation_id,\n        causation_id=correlation_id,  # Self-referencing at entry\n        command_id=None,\n    )\n</code></pre>"},{"location":"reference/context/#interlock.context.ExecutionContext.create--at-http-endpoint","title":"At HTTP endpoint","text":"<p>ctx = ExecutionContext.create() command = MyCommand( ...     aggregate_id=..., ...     correlation_id=ctx.correlation_id, ...     causation_id=ctx.correlation_id ... )</p>"},{"location":"reference/context/#interlock.context.ExecutionContext.for_command","title":"for_command","text":"<pre><code>for_command(command_id: UUID) -&gt; ExecutionContext\n</code></pre> <p>Create a child context for executing a command.</p> <p>The correlation_id is inherited. The command_id is set. When the command has a causation_id from the original command, that becomes the causation.</p> PARAMETER DESCRIPTION <code>command_id</code> <p>The ID of the command being executed.</p> <p> TYPE: <code>UUID</code> </p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>A new ExecutionContext with command_id set.</p> Example <p>ctx = get_context() cmd_ctx = ctx.for_command(command.command_id) set_context(cmd_ctx)</p> Source code in <code>interlock/context.py</code> <pre><code>def for_command(self, command_id: UUID) -&gt; \"ExecutionContext\":\n    \"\"\"Create a child context for executing a command.\n\n    The correlation_id is inherited. The command_id is set. When the command\n    has a causation_id from the original command, that becomes the causation.\n\n    Args:\n        command_id: The ID of the command being executed.\n\n    Returns:\n        A new ExecutionContext with command_id set.\n\n    Example:\n        &gt;&gt;&gt; ctx = get_context()\n        &gt;&gt;&gt; cmd_ctx = ctx.for_command(command.command_id)\n        &gt;&gt;&gt; set_context(cmd_ctx)\n    \"\"\"\n    return replace(self, command_id=command_id)\n</code></pre>"},{"location":"reference/context/#interlock.context.ExecutionContext.for_event","title":"for_event","text":"<pre><code>for_event(event_id: UUID) -&gt; ExecutionContext\n</code></pre> <p>Create a child context for processing an event.</p> <p>The correlation_id is inherited. The causation_id becomes the event_id. The command_id is cleared (since we're not in a command context).</p> PARAMETER DESCRIPTION <code>event_id</code> <p>The ID of the event being processed.</p> <p> TYPE: <code>UUID</code> </p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>A new ExecutionContext with causation_id set to event_id.</p> Example Source code in <code>interlock/context.py</code> <pre><code>def for_event(self, event_id: UUID) -&gt; \"ExecutionContext\":\n    \"\"\"Create a child context for processing an event.\n\n    The correlation_id is inherited. The causation_id becomes the event_id.\n    The command_id is cleared (since we're not in a command context).\n\n    Args:\n        event_id: The ID of the event being processed.\n\n    Returns:\n        A new ExecutionContext with causation_id set to event_id.\n\n    Example:\n        &gt;&gt;&gt; # In event processor\n        &gt;&gt;&gt; ctx = get_context()\n        &gt;&gt;&gt; event_ctx = ctx.for_event(event.id)\n        &gt;&gt;&gt; set_context(event_ctx)\n    \"\"\"\n    return replace(self, causation_id=event_id, command_id=None)\n</code></pre>"},{"location":"reference/context/#interlock.context.ExecutionContext.for_event--in-event-processor","title":"In event processor","text":"<p>ctx = get_context() event_ctx = ctx.for_event(event.id) set_context(event_ctx)</p>"},{"location":"reference/context/#interlock.context.ExecutionContext.with_causation","title":"with_causation","text":"<pre><code>with_causation(causation_id: UUID) -&gt; ExecutionContext\n</code></pre> <p>Create a new context with updated causation_id.</p> PARAMETER DESCRIPTION <code>causation_id</code> <p>The new causation ID.</p> <p> TYPE: <code>UUID</code> </p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>A new ExecutionContext with updated causation_id.</p> Example <p>ctx = ctx.with_causation(command.command_id)</p> Source code in <code>interlock/context.py</code> <pre><code>def with_causation(self, causation_id: UUID) -&gt; \"ExecutionContext\":\n    \"\"\"Create a new context with updated causation_id.\n\n    Args:\n        causation_id: The new causation ID.\n\n    Returns:\n        A new ExecutionContext with updated causation_id.\n\n    Example:\n        &gt;&gt;&gt; ctx = ctx.with_causation(command.command_id)\n    \"\"\"\n    return replace(self, causation_id=causation_id)\n</code></pre>"},{"location":"reference/context/#interlock.context.get_context","title":"get_context","text":"<pre><code>get_context() -&gt; ExecutionContext\n</code></pre> <p>Get the current execution context.</p> <p>If no context has been set, returns an empty ExecutionContext with all fields None.</p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>The current ExecutionContext instance.</p> Example <p>ctx = get_context() if ctx.correlation_id: ...     logger.info(\"Processing request\", correlation_id=str(ctx.correlation_id))</p> Source code in <code>interlock/context.py</code> <pre><code>def get_context() -&gt; ExecutionContext:\n    \"\"\"Get the current execution context.\n\n    If no context has been set, returns an empty ExecutionContext with all fields None.\n\n    Returns:\n        The current ExecutionContext instance.\n\n    Example:\n        &gt;&gt;&gt; ctx = get_context()\n        &gt;&gt;&gt; if ctx.correlation_id:\n        ...     logger.info(\"Processing request\", correlation_id=str(ctx.correlation_id))\n    \"\"\"\n    ctx = _context.get()\n    if ctx is None:\n        return ExecutionContext()\n    return ctx\n</code></pre>"},{"location":"reference/context/#interlock.context.set_context","title":"set_context","text":"<pre><code>set_context(context: ExecutionContext) -&gt; None\n</code></pre> <p>Set the current execution context.</p> PARAMETER DESCRIPTION <code>context</code> <p>The ExecutionContext to set.</p> <p> TYPE: <code>ExecutionContext</code> </p> Example <p>ctx = ExecutionContext.create() set_context(ctx)</p> Source code in <code>interlock/context.py</code> <pre><code>def set_context(context: ExecutionContext) -&gt; None:\n    \"\"\"Set the current execution context.\n\n    Args:\n        context: The ExecutionContext to set.\n\n    Example:\n        &gt;&gt;&gt; ctx = ExecutionContext.create()\n        &gt;&gt;&gt; set_context(ctx)\n    \"\"\"\n    _context.set(context)\n</code></pre>"},{"location":"reference/context/#interlock.context.clear_context","title":"clear_context","text":"<pre><code>clear_context() -&gt; None\n</code></pre> <p>Clear the current execution context.</p> <p>This is useful for cleanup or testing.</p> Example <p>clear_context()</p> Source code in <code>interlock/context.py</code> <pre><code>def clear_context() -&gt; None:\n    \"\"\"Clear the current execution context.\n\n    This is useful for cleanup or testing.\n\n    Example:\n        &gt;&gt;&gt; clear_context()\n    \"\"\"\n    _context.set(None)\n</code></pre>"},{"location":"reference/context/#interlock.context.get_or_create_context","title":"get_or_create_context","text":"<pre><code>get_or_create_context() -&gt; ExecutionContext\n</code></pre> <p>Get the current context, or create a new one if not set.</p> <p>This is useful at system entry points where a new logical operation begins. If a context already exists, it is returned. Otherwise, a new context is created with a generated correlation_id and set as the current context.</p> RETURNS DESCRIPTION <code>ExecutionContext</code> <p>The current or newly created ExecutionContext.</p> Example Source code in <code>interlock/context.py</code> <pre><code>def get_or_create_context() -&gt; ExecutionContext:\n    \"\"\"Get the current context, or create a new one if not set.\n\n    This is useful at system entry points where a new logical operation begins.\n    If a context already exists, it is returned. Otherwise, a new context is\n    created with a generated correlation_id and set as the current context.\n\n    Returns:\n        The current or newly created ExecutionContext.\n\n    Example:\n        &gt;&gt;&gt; # At HTTP entry point\n        &gt;&gt;&gt; ctx = get_or_create_context()\n        &gt;&gt;&gt; command = MyCommand(\n        ...     aggregate_id=...,\n        ...     correlation_id=ctx.correlation_id,\n        ...     causation_id=ctx.causation_id\n        ... )\n    \"\"\"\n    ctx = _context.get()\n    if ctx is None:\n        ctx = ExecutionContext.create()\n        set_context(ctx)\n    return ctx\n</code></pre>"},{"location":"reference/context/#interlock.context.get_or_create_context--at-http-entry-point","title":"At HTTP entry point","text":"<p>ctx = get_or_create_context() command = MyCommand( ...     aggregate_id=..., ...     correlation_id=ctx.correlation_id, ...     causation_id=ctx.causation_id ... )</p>"},{"location":"reference/routing/","title":"routing","text":""},{"location":"reference/routing/#interlock.routing","title":"routing","text":""},{"location":"reference/routing/#interlock.routing.DefaultHandler","title":"DefaultHandler","text":"<pre><code>DefaultHandler(base_type: type, operation_name: str)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base handler for unregistered message types.</p> PARAMETER DESCRIPTION <code>base_type</code> <p>The base type for messages (e.g., Command, BaseModel).</p> <p> TYPE: <code>type</code> </p> <code>operation_name</code> <p>Name of the operation for error messages.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/routing.py</code> <pre><code>def __init__(self, base_type: type, operation_name: str):\n    \"\"\"Initialize the default handler.\n\n    Args:\n        base_type: The base type for messages (e.g., Command,\n            BaseModel).\n        operation_name: Name of the operation for error\n            messages.\n    \"\"\"\n    self.base_type = base_type\n    self.operation_name = operation_name\n</code></pre>"},{"location":"reference/routing/#interlock.routing.DefaultHandler.__call__","title":"__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(\n    message: Any, instance: Any, *args: Any, **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Handle an unregistered message type.</p> PARAMETER DESCRIPTION <code>message</code> <p>The message to handle.</p> <p> TYPE: <code>Any</code> </p> <code>instance</code> <p>The instance handling the message.</p> <p> TYPE: <code>Any</code> </p> <code>*args</code> <p>Additional positional arguments (ignored).</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Additional keyword arguments (ignored).</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result of handling the message.</p> Source code in <code>interlock/routing.py</code> <pre><code>@abstractmethod\ndef __call__(self, message: Any, instance: Any, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Handle an unregistered message type.\n\n    Args:\n        message: The message to handle.\n        instance: The instance handling the message.\n        *args: Additional positional arguments (ignored).\n        **kwargs: Additional keyword arguments (ignored).\n\n    Returns:\n        The result of handling the message.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/routing/#interlock.routing.RaiseHandler","title":"RaiseHandler","text":"<pre><code>RaiseHandler(base_type: type, operation_name: str)\n</code></pre> <p>               Bases: <code>DefaultHandler</code></p> <p>Raise NotImplementedError for unregistered message types.</p> Source code in <code>interlock/routing.py</code> <pre><code>def __init__(self, base_type: type, operation_name: str):\n    \"\"\"Initialize the default handler.\n\n    Args:\n        base_type: The base type for messages (e.g., Command,\n            BaseModel).\n        operation_name: Name of the operation for error\n            messages.\n    \"\"\"\n    self.base_type = base_type\n    self.operation_name = operation_name\n</code></pre>"},{"location":"reference/routing/#interlock.routing.IgnoreHandler","title":"IgnoreHandler","text":"<pre><code>IgnoreHandler(base_type: type, operation_name: str)\n</code></pre> <p>               Bases: <code>DefaultHandler</code></p> <p>Silently ignore unregistered message types.</p> Source code in <code>interlock/routing.py</code> <pre><code>def __init__(self, base_type: type, operation_name: str):\n    \"\"\"Initialize the default handler.\n\n    Args:\n        base_type: The base type for messages (e.g., Command,\n            BaseModel).\n        operation_name: Name of the operation for error\n            messages.\n    \"\"\"\n    self.base_type = base_type\n    self.operation_name = operation_name\n</code></pre>"},{"location":"reference/routing/#interlock.routing.MessageRouter","title":"MessageRouter","text":"<pre><code>MessageRouter(default_handler: DefaultHandler)\n</code></pre> <p>Generic router for dispatching messages to type-specific handlers.</p> <p>This class uses singledispatch to route messages (commands, events, etc.) to registered handler methods based on their type annotations.</p> <p>For event handlers, supports passing either the event payload or the full Event wrapper based on the handler's type annotation.</p> PARAMETER DESCRIPTION <code>default_handler</code> <p>Handler for unregistered message types.</p> <p> TYPE: <code>DefaultHandler</code> </p> Source code in <code>interlock/routing.py</code> <pre><code>def __init__(\n    self,\n    default_handler: DefaultHandler,\n):\n    \"\"\"Initialize the message router.\n\n    Args:\n        default_handler: Handler for unregistered message types.\n    \"\"\"\n\n    # Create singledispatch function with the default handler\n    @singledispatch\n    def dispatch(message: object, instance: object, *args: Any, **kwargs: Any) -&gt; object:\n        return default_handler(message, instance, *args, **kwargs)\n\n    self._dispatch = dispatch\n</code></pre>"},{"location":"reference/routing/#interlock.routing.MessageRouter.register","title":"register","text":"<pre><code>register(\n    message_type: type,\n    handler: Callable[[object, object], object],\n    wants_wrapper: bool = False,\n) -&gt; None\n</code></pre> <p>Register a handler for a specific message type.</p> PARAMETER DESCRIPTION <code>message_type</code> <p>The message class this handler processes.</p> <p> TYPE: <code>type</code> </p> <code>handler</code> <p>The method to call when handling this message type.</p> <p> TYPE: <code>Callable[[object, object], object]</code> </p> <code>wants_wrapper</code> <p>If True, handler receives Event wrapper via 'event_wrapper' kwarg. If False, receives just the payload.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>interlock/routing.py</code> <pre><code>def register(\n    self,\n    message_type: type,\n    handler: Callable[[object, object], object],\n    wants_wrapper: bool = False,\n) -&gt; None:\n    \"\"\"Register a handler for a specific message type.\n\n    Args:\n        message_type: The message class this handler processes.\n        handler: The method to call when handling this message type.\n        wants_wrapper: If True, handler receives Event wrapper via\n            'event_wrapper' kwarg. If False, receives just the payload.\n    \"\"\"\n    # Register directly - singledispatch will handle the lookup\n    # efficiently. We create a minimal wrapper to swap argument\n    # order and pass through any additional arguments\n    if wants_wrapper:\n        # Handler wants the Event wrapper - pass it via event_wrapper kwarg\n        def wrapper(\n            msg: object, inst: object, *args: Any, h: Any = handler, **kwargs: Any\n        ) -&gt; object:\n            # The event_wrapper kwarg contains the full Event object\n            event_wrapper = kwargs.pop(\"event_wrapper\", None)\n            if event_wrapper is not None:\n                return h(inst, event_wrapper, *args, **kwargs)\n            else:\n                # Fallback if no wrapper provided (e.g., testing)\n                return h(inst, msg, *args, **kwargs)\n\n        self._dispatch.register(message_type)(wrapper)\n    else:\n        # Handler wants just the payload - strip event_wrapper if present\n        def payload_wrapper(\n            msg: object, inst: object, *args: Any, h: Any = handler, **kwargs: Any\n        ) -&gt; object:\n            kwargs.pop(\"event_wrapper\", None)  # Remove if present\n            return h(inst, msg, *args, **kwargs)\n\n        self._dispatch.register(message_type)(payload_wrapper)\n</code></pre>"},{"location":"reference/routing/#interlock.routing.MessageRouter.route","title":"route","text":"<pre><code>route(\n    instance: Any, message: Any, *args: Any, **kwargs: Any\n) -&gt; object\n</code></pre> <p>Route a message to its registered handler.</p> PARAMETER DESCRIPTION <code>instance</code> <p>The instance to call the handler on (self).</p> <p> TYPE: <code>Any</code> </p> <code>message</code> <p>The message to route (the payload for events).</p> <p> TYPE: <code>Any</code> </p> <code>*args</code> <p>Additional positional arguments to pass to handler.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Additional keyword arguments to pass to handler. For events, pass event_wrapper= to provide the full wrapper to handlers that want it. <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>object</code> <p>The result of the handler method.</p> Source code in <code>interlock/routing.py</code> <pre><code>def route(self, instance: Any, message: Any, *args: Any, **kwargs: Any) -&gt; object:\n    \"\"\"Route a message to its registered handler.\n\n    Args:\n        instance: The instance to call the handler on (self).\n        message: The message to route (the payload for events).\n        *args: Additional positional arguments to pass to handler.\n        **kwargs: Additional keyword arguments to pass to handler.\n            For events, pass event_wrapper=&lt;Event&gt; to provide the\n            full wrapper to handlers that want it.\n\n    Returns:\n        The result of the handler method.\n    \"\"\"\n    return self._dispatch(message, instance, *args, **kwargs)\n</code></pre>"},{"location":"reference/routing/#interlock.routing.HandlerDecorator","title":"HandlerDecorator","text":"<pre><code>HandlerDecorator(marker_attr: str, type_attr: str)\n</code></pre> <p>Base class for handler decorators.</p> <p>This class encapsulates the logic for creating decorators that mark methods as handlers for specific message types.</p> PARAMETER DESCRIPTION <code>marker_attr</code> <p>Attribute name to mark decorated methods (e.g., '_is_command_handler').</p> <p> TYPE: <code>str</code> </p> <code>type_attr</code> <p>Attribute name to store the message type (e.g., '_handles_command_type').</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/routing.py</code> <pre><code>def __init__(self, marker_attr: str, type_attr: str):\n    \"\"\"Initialize the decorator.\n\n    Args:\n        marker_attr: Attribute name to mark decorated methods\n            (e.g., '_is_command_handler').\n        type_attr: Attribute name to store the message type\n            (e.g., '_handles_command_type').\n    \"\"\"\n    self.marker_attr = marker_attr\n    self.type_attr = type_attr\n</code></pre>"},{"location":"reference/routing/#interlock.routing.HandlerDecorator.__call__","title":"__call__","text":"<pre><code>__call__(func: Callable[..., T]) -&gt; Callable[..., T]\n</code></pre> <p>Decorate a handler method.</p> PARAMETER DESCRIPTION <code>func</code> <p>The handler method to decorate.</p> <p> TYPE: <code>Callable[..., T]</code> </p> RETURNS DESCRIPTION <code>Callable[..., T]</code> <p>The decorated method with metadata attached.</p> Source code in <code>interlock/routing.py</code> <pre><code>def __call__(self, func: Callable[..., T]) -&gt; Callable[..., T]:\n    \"\"\"Decorate a handler method.\n\n    Args:\n        func: The handler method to decorate.\n\n    Returns:\n        The decorated method with metadata attached.\n    \"\"\"\n    message_type, wants_wrapper = _extract_handler_type(func, param_index=1)\n    setattr(func, self.type_attr, message_type)\n    setattr(func, self.marker_attr, True)\n    setattr(func, _WANTS_EVENT_WRAPPER_ATTR, wants_wrapper)\n    return func\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_routing","title":"setup_routing","text":"<pre><code>setup_routing(\n    cls: type,\n    marker_attr: str,\n    type_attr: str,\n    default_handler: DefaultHandler,\n) -&gt; MessageRouter\n</code></pre> <p>Set up message routing for a class.</p> <p>Scans the class for methods decorated with the specified marker and registers them with a MessageRouter.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to set up routing for.</p> <p> TYPE: <code>type</code> </p> <code>marker_attr</code> <p>Attribute name marking decorated methods.</p> <p> TYPE: <code>str</code> </p> <code>type_attr</code> <p>Attribute name storing the message type.</p> <p> TYPE: <code>str</code> </p> <code>default_handler</code> <p>Handler for unregistered message types.</p> <p> TYPE: <code>DefaultHandler</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_routing(\n    cls: type,\n    marker_attr: str,\n    type_attr: str,\n    default_handler: DefaultHandler,\n) -&gt; MessageRouter:\n    \"\"\"Set up message routing for a class.\n\n    Scans the class for methods decorated with the specified marker and\n    registers them with a MessageRouter.\n\n    Args:\n        cls: The class to set up routing for.\n        marker_attr: Attribute name marking decorated methods.\n        type_attr: Attribute name storing the message type.\n        default_handler: Handler for unregistered message types.\n\n    Returns:\n        A configured MessageRouter.\n    \"\"\"\n    router = MessageRouter(default_handler)\n\n    # Scan all methods in the class hierarchy\n    # Use try/except instead of hasattr for better performance\n    for klass in cls.__mro__:\n        for value in klass.__dict__.values():\n            try:\n                # Check if it has the marker attribute\n                if getattr(value, marker_attr, None):\n                    message_type = getattr(value, type_attr)\n                    wants_wrapper = getattr(value, _WANTS_EVENT_WRAPPER_ATTR, False)\n                    router.register(message_type, value, wants_wrapper=wants_wrapper)\n            except AttributeError:\n                # Not a method or doesn't have the attributes\n                continue\n\n    return router\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_command_routing","title":"setup_command_routing","text":"<pre><code>setup_command_routing(cls: type) -&gt; MessageRouter\n</code></pre> <p>Set up command routing for a class.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to set up routing for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter for commands.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_command_routing(cls: type) -&gt; MessageRouter:\n    \"\"\"Set up command routing for a class.\n\n    Args:\n        cls: The class to set up routing for.\n\n    Returns:\n        A configured MessageRouter for commands.\n    \"\"\"\n    # Import here to avoid circular dependency\n    from .domain import Command\n\n    return setup_routing(\n        cls,\n        marker_attr=\"_is_command_handler\",\n        type_attr=\"_handles_command_type\",\n        default_handler=RaiseHandler(Command, \"handler\"),\n    )\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_event_applying","title":"setup_event_applying","text":"<pre><code>setup_event_applying(cls: type) -&gt; MessageRouter\n</code></pre> <p>Set up event applying for a class.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to set up routing for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter for event appliers.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_event_applying(cls: type) -&gt; MessageRouter:\n    \"\"\"Set up event applying for a class.\n\n    Args:\n        cls: The class to set up routing for.\n\n    Returns:\n        A configured MessageRouter for event appliers.\n    \"\"\"\n    return setup_routing(\n        cls,\n        marker_attr=\"_is_event_applier\",\n        type_attr=\"_applies_event_type\",\n        default_handler=IgnoreHandler(BaseModel, \"applier\"),\n    )\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_event_handling","title":"setup_event_handling","text":"<pre><code>setup_event_handling(cls: type) -&gt; MessageRouter\n</code></pre> <p>Set up event handling for a class.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to set up routing for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter for event handlers.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_event_handling(cls: type) -&gt; MessageRouter:\n    \"\"\"Set up event handling for a class.\n\n    Args:\n        cls: The class to set up routing for.\n\n    Returns:\n        A configured MessageRouter for event handlers.\n    \"\"\"\n    return setup_routing(\n        cls,\n        marker_attr=\"_is_event_handler\",\n        type_attr=\"_handles_event_type\",\n        default_handler=IgnoreHandler(BaseModel, \"handler\"),\n    )\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_query_routing","title":"setup_query_routing","text":"<pre><code>setup_query_routing(cls: type) -&gt; MessageRouter\n</code></pre> <p>Set up query routing for a projection class.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The projection class to set up routing for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter for query handlers.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_query_routing(cls: type) -&gt; MessageRouter:\n    \"\"\"Set up query routing for a projection class.\n\n    Args:\n        cls: The projection class to set up routing for.\n\n    Returns:\n        A configured MessageRouter for query handlers.\n    \"\"\"\n    # Import here to avoid circular dependency\n    from .domain import Query\n\n    return setup_routing(\n        cls,\n        marker_attr=\"_is_query_handler\",\n        type_attr=\"_handles_query_type\",\n        default_handler=RaiseHandler(Query, \"handler\"),\n    )\n</code></pre>"},{"location":"reference/routing/#interlock.routing.setup_middleware_routing","title":"setup_middleware_routing","text":"<pre><code>setup_middleware_routing(cls: type) -&gt; MessageRouter\n</code></pre> <p>Set up message interception routing for middleware.</p> <p>Middleware can intercept both commands and queries using the @intercepts decorator. The routing is based on message type annotations.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The middleware class to set up routing for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>MessageRouter</code> <p>A configured MessageRouter for message interceptors.</p> Source code in <code>interlock/routing.py</code> <pre><code>def setup_middleware_routing(cls: type) -&gt; MessageRouter:\n    \"\"\"Set up message interception routing for middleware.\n\n    Middleware can intercept both commands and queries using the\n    @intercepts decorator. The routing is based on message type\n    annotations.\n\n    Args:\n        cls: The middleware class to set up routing for.\n\n    Returns:\n        A configured MessageRouter for message interceptors.\n    \"\"\"\n    return setup_routing(\n        cls,\n        marker_attr=\"_is_command_interceptor\",\n        type_attr=\"_intercepts_command_type\",\n        default_handler=IgnoreHandler(BaseModel, \"interceptor\"),\n    )\n</code></pre>"},{"location":"reference/application/","title":"application","text":""},{"location":"reference/application/#interlock.application","title":"application","text":"<p>Application bootstrapping and dependency injection for interlock.</p> <p>This package contains the framework infrastructure for building event-sourced applications. It includes command handling, event processing, repository management, projection/query handling, and application lifecycle management.</p>"},{"location":"reference/application/#interlock.application.Application","title":"Application","text":"<pre><code>Application(contextual_binding: ContextualBinding)\n</code></pre> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self, contextual_binding: ContextualBinding):\n    self.contextual_binding = contextual_binding\n    self.command_bus = self.resolve(CommandBus)\n    self.event_bus = self.resolve(EventBus)\n    self.query_bus = self.resolve(QueryBus)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(command: Command[T]) -&gt; T\n</code></pre> <p>Dispatch a command to the application.</p> <p>This method will dispatch a command to the application. The command will be dispatched to the command bus and the command bus will dispatch the command to the appropriate aggregate and middleware chain.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to dispatch.</p> <p> TYPE: <code>Command[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def dispatch(self, command: Command[T]) -&gt; T:\n    \"\"\"Dispatch a command to the application.\n\n    This method will dispatch a command to the application. The command\n    will be dispatched to the command bus and the command bus will dispatch\n    the command to the appropriate aggregate and middleware chain.\n\n    Args:\n        command: The command to dispatch.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    return await self.command_bus.dispatch(command)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Execute a query against the application.</p> <p>This method will dispatch a query to the application. The query will be dispatched to the query bus and routed through middleware to the appropriate projection.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to execute.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Execute a query against the application.\n\n    This method will dispatch a query to the application. The query\n    will be dispatched to the query bus and routed through middleware\n    to the appropriate projection.\n\n    Args:\n        query: The query to execute.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n    \"\"\"\n    return await self.query_bus.dispatch(query)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.resolve","title":"resolve","text":"<pre><code>resolve(type_to_resolve: type[T]) -&gt; T\n</code></pre> <p>Resolve a dependency from the application.</p> <p>This method will resolve a dependency from the application. The dependency will be resolved from the contextual binding and will be returned.</p> PARAMETER DESCRIPTION <code>type_to_resolve</code> <p>The type of the dependency to resolve.</p> <p> TYPE: <code>type[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The resolved dependency.</p> RAISES DESCRIPTION <code>DependencyNotFoundError</code> <p>If the dependency cannot be resolved.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def resolve(self, type_to_resolve: type[T]) -&gt; T:\n    \"\"\"Resolve a dependency from the application.\n\n    This method will resolve a dependency from the application.\n    The dependency will be resolved from the contextual binding\n    and will be returned.\n\n    Args:\n        type_to_resolve: The type of the dependency to resolve.\n\n    Returns:\n        The resolved dependency.\n\n    Raises:\n        DependencyNotFoundError: If the dependency cannot be\n            resolved.\n    \"\"\"\n    return self.contextual_binding.resolve(type_to_resolve)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.startup","title":"startup  <code>async</code>","text":"<pre><code>startup() -&gt; None\n</code></pre> <p>Startup the application.</p> <p>This method will startup the application. The application will be started by calling the on_startup method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are started in the order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Startup the application.\n\n    This method will startup the application. The application will be\n    started by calling the on_startup method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are started\n    in the order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in dependencies:\n        await dependency.on_startup()\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown() -&gt; None\n</code></pre> <p>Shutdown the application.</p> <p>This method will shutdown the application. The application will be shutdown by calling the on_shutdown method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are shutdown in the reverse order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the application.\n\n    This method will shutdown the application. The application will be\n    shutdown by calling the on_shutdown method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are shutdown\n    in the reverse order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in reversed(dependencies):\n        await dependency.on_shutdown()\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.run_event_processors","title":"run_event_processors  <code>async</code>","text":"<pre><code>run_event_processors(\n    *processors: type[EventProcessor],\n) -&gt; None\n</code></pre> <p>Run the event processors for the application.</p> <p>This method will run the event processors for the application of the given types. The event processors are run asynchronously and will continue to run until the application is stopped or all run methods have completed. The event processors are run in the order they were registered.</p> PARAMETER DESCRIPTION <code>*processors</code> <p>The event processors to run.</p> <p> TYPE: <code>type[EventProcessor]</code> DEFAULT: <code>()</code> </p> RAISES DESCRIPTION <code>Exception</code> <p>Any exceptions raised by the event processors will be propagated to the caller.</p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def run_event_processors(self, *processors: type[EventProcessor]) -&gt; None:\n    \"\"\"Run the event processors for the application.\n\n    This method will run the event processors for the application of the\n    given types. The event processors are run asynchronously and will\n    continue to run until the application is stopped or all run methods\n    have completed. The event processors are run in the order they were\n    registered.\n\n    Args:\n        *processors: The event processors to run.\n\n    Raises:\n        Exception: Any exceptions raised by the event processors will be\n            propagated to the caller.\n\n    Returns:\n        None\n    \"\"\"\n    # We will resolve each processors executor from its own container\n    # context and then subscribe to the event transport for the processor.\n    executors = [\n        self.contextual_binding.container_for(processor).resolve(EventProcessorExecutor)\n        for processor in processors\n    ]\n\n    transport = self.contextual_binding.resolve(EventTransport)\n    subscriptions = [\n        await transport.subscribe(executor.processor.__class__.__name__)\n        for executor in executors\n    ]\n\n    # Now that we have a subscription for each processor, we can run the\n    # processors in their own async tasks. We will gather the tasks and\n    # await them all to complete (This will probably be 'forever' since\n    # the processors are expected to run until the application is stopped).\n    tasks = [\n        executor.run(subscription)\n        for executor, subscription in zip(executors, subscriptions, strict=False)\n    ]\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.aggregate_scenario","title":"aggregate_scenario","text":"<pre><code>aggregate_scenario(\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; AggregateScenario\n</code></pre> <p>Create a test scenario for an aggregate.</p> <p>This provides a consistent testing API across all Interlock components. Aggregates don't have constructor dependencies, so this is equivalent to creating an AggregateScenario directly.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class to test.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>aggregate_id</code> <p>Optional specific ID for the aggregate.</p> <p> TYPE: <code>UUID | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AggregateScenario</code> <p>An AggregateScenario ready for Given-When-Then testing.</p> Example <p>async with app.aggregate_scenario(BankAccount) as scenario: ...     scenario.given_no_events() ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100)) ...     scenario.should_emit(MoneyDeposited)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def aggregate_scenario(\n    self,\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; \"AggregateScenario\":\n    \"\"\"Create a test scenario for an aggregate.\n\n    This provides a consistent testing API across all Interlock components.\n    Aggregates don't have constructor dependencies, so this is equivalent\n    to creating an AggregateScenario directly.\n\n    Args:\n        aggregate_type: The aggregate class to test.\n        aggregate_id: Optional specific ID for the aggregate.\n\n    Returns:\n        An AggregateScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.aggregate_scenario(BankAccount) as scenario:\n        ...     scenario.given_no_events()\n        ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100))\n        ...     scenario.should_emit(MoneyDeposited)\n    \"\"\"\n    from ..testing import AggregateScenario\n\n    return AggregateScenario(aggregate_type, aggregate_id)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.processor_scenario","title":"processor_scenario","text":"<pre><code>processor_scenario(\n    processor_type: type[EventProcessor],\n) -&gt; ProcessorScenario\n</code></pre> <p>Create a test scenario for an event processor with DI.</p> <p>The processor is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The event processor class to test.</p> <p> TYPE: <code>type[EventProcessor]</code> </p> RETURNS DESCRIPTION <code>ProcessorScenario</code> <p>A ProcessorScenario ready for Given-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository) ...     .register_event_processor(AccountBalanceProjection) ...     .build() ... ) async with app.processor_scenario(AccountBalanceProjection) as scenario: ...     scenario.given(MoneyDeposited(account_id=id, amount=100)) ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def processor_scenario(\n    self,\n    processor_type: type[EventProcessor],\n) -&gt; \"ProcessorScenario\":\n    \"\"\"Create a test scenario for an event processor with DI.\n\n    The processor is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        processor_type: The event processor class to test.\n\n    Returns:\n        A ProcessorScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n        ...     .register_event_processor(AccountBalanceProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        ...     scenario.given(MoneyDeposited(account_id=id, amount=100))\n        ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)\n    \"\"\"\n    from ..testing import ProcessorScenario\n\n    # Resolve the processor from the DI container\n    processor = self.contextual_binding.container_for(processor_type).resolve(processor_type)\n    return ProcessorScenario(processor)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.saga_scenario","title":"saga_scenario","text":"<pre><code>saga_scenario(saga_type: type) -&gt; SagaScenario\n</code></pre> <p>Create a test scenario for a saga with DI.</p> <p>The saga is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>saga_type</code> <p>The saga class to test.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>SagaScenario</code> <p>A SagaScenario ready for Given-Then testing.</p> Example <p>async with app.saga_scenario(OrderFulfillmentSaga) as scenario: ...     scenario.given(OrderPlaced(order_id=\"123\")) ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")</p> Source code in <code>interlock/application/application.py</code> <pre><code>def saga_scenario(\n    self,\n    saga_type: type,\n) -&gt; \"SagaScenario\":\n    \"\"\"Create a test scenario for a saga with DI.\n\n    The saga is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        saga_type: The saga class to test.\n\n    Returns:\n        A SagaScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.saga_scenario(OrderFulfillmentSaga) as scenario:\n        ...     scenario.given(OrderPlaced(order_id=\"123\"))\n        ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")\n    \"\"\"\n    from ..testing import SagaScenario\n    from .events.processing import Saga\n\n    # Resolve the saga from the DI container\n    saga = self.contextual_binding.container_for(saga_type).resolve(saga_type)\n    if not isinstance(saga, Saga):\n        raise TypeError(f\"Expected Saga instance, got {type(saga).__name__}\")\n    return SagaScenario(saga)\n</code></pre>"},{"location":"reference/application/#interlock.application.Application.projection_scenario","title":"projection_scenario","text":"<pre><code>projection_scenario(\n    projection_type: type[Projection],\n) -&gt; ProjectionScenario\n</code></pre> <p>Create a test scenario for a projection with DI.</p> <p>The projection is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to test.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionScenario</code> <p>A ProjectionScenario ready for Given-When-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_projection(UserProjection) ...     .build() ... ) async with app.projection_scenario(UserProjection) as scenario: ...     scenario.given(UserCreated(user_id=id, name=\"Alice\")) ...     result = await scenario.when(GetUserById(user_id=id)) ...     assert result.name == \"Alice\"</p> Source code in <code>interlock/application/application.py</code> <pre><code>def projection_scenario(\n    self,\n    projection_type: type[Projection],\n) -&gt; \"ProjectionScenario\":\n    \"\"\"Create a test scenario for a projection with DI.\n\n    The projection is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        projection_type: The projection class to test.\n\n    Returns:\n        A ProjectionScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_projection(UserProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.projection_scenario(UserProjection) as scenario:\n        ...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n        ...     result = await scenario.when(GetUserById(user_id=id))\n        ...     assert result.name == \"Alice\"\n    \"\"\"\n    from ..testing import ProjectionScenario\n\n    # Resolve the projection from the DI container\n    projection = self.contextual_binding.container_for(projection_type).resolve(projection_type)\n    return ProjectionScenario(projection)\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder","title":"ApplicationBuilder","text":"<pre><code>ApplicationBuilder()\n</code></pre> <p>Builder for creating Application instances.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.container = DependencyContainer()\n    self.contextual_binding = ContextualBinding(self.container)\n\n    # Event Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=UpcastingStrategy,\n        factory=LazyUpcastingStrategy,\n    )\n    self.container.register_singleton(\n        dependency_type=EventTransport,\n        factory=InMemoryEventTransport,\n    )\n    self.container.register_singleton(\n        dependency_type=EventStore,\n        factory=InMemoryEventStore,\n    )\n    self.container.register_singleton(\n        dependency_type=UpcasterMap,\n        factory=self._build_upcaster_map,\n    )\n    self.container.register_singleton(UpcastingPipeline)\n    self.container.register_singleton(\n        dependency_type=EventDelivery,\n        factory=self._build_synchronous_delivery,\n    )\n    self.container.register_singleton(EventBus)\n\n    # Aggregate Repository Defaults:\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStrategy,\n        factory=AggregateSnapshotStrategy.never,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateCacheBackend,\n        factory=AggregateCacheBackend.null,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStorageBackend,\n        factory=AggregateSnapshotStorageBackend.null,\n    )\n\n    # Event Processor Defaults:\n    self.container.register_singleton(\n        dependency_type=CatchupCondition,\n        factory=Never,\n    )\n    self.container.register_singleton(\n        dependency_type=CatchupStrategy,\n        factory=NoCatchup,\n    )\n    self.container.register_singleton(\n        dependency_type=CacheStrategy,\n        factory=CacheStrategy.never,\n    )\n\n    # Command Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=CommandToAggregateMap,\n        factory=self._build_command_to_aggregate_map,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateToRepositoryMap,\n        factory=self._build_aggregate_to_repository_map,\n    )\n    self.container.register_singleton(DelegateToAggregate)\n    self.container.register_singleton(\n        dependency_type=CommandBus,\n        factory=self._build_command_bus,\n    )\n\n    self.container.register_singleton(SagaStateStore, SagaStateStore.in_memory)\n\n    # Query Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=QueryToProjectionMap,\n        factory=self._build_query_to_projection_map,\n    )\n    self.container.register_singleton(\n        dependency_type=ProjectionRegistry,\n        factory=self._build_projection_registry,\n    )\n    self.container.register_singleton(DelegateToProjection)\n    self.container.register_singleton(\n        dependency_type=QueryBus,\n        factory=self._build_query_bus,\n    )\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_dependency","title":"register_dependency","text":"<pre><code>register_dependency(\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a dependency with the application.</p> <p>This method will register a dependency with the application. All dependencies are registered as singletons and the provided factory will be used to create the dependency when it is resolved for the first time. If no factory is provided, the dependency will be resolved by calling the init method of the dependency type. Regardless of dependecies of that function will be resolved by the container.</p> PARAMETER DESCRIPTION <code>dependency_type</code> <p>The type to register</p> <p> TYPE: <code>type[T]</code> </p> <code>factory</code> <p>The factory function to create the dependency</p> <p> TYPE: <code>Callable[..., T] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_dependency(\n    self,\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a dependency with the application.\n\n    This method will register a dependency with the application.\n    All dependencies are registered as singletons and the provided\n    factory will be used to create the dependency when it is\n    resolved for the first time. If no factory is provided, the\n    dependency will be resolved by calling the __init__ method of\n    the dependency type. Regardless of dependecies of that function\n    will be resolved by the container.\n\n    Args:\n        dependency_type: The type to register\n        factory: The factory function to create the dependency\n\n    Returns:\n        The application builder\n    \"\"\"\n    self.container.register_singleton(dependency_type, factory or dependency_type)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_aggregate","title":"register_aggregate","text":"<pre><code>register_aggregate(\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: (\n        type[AggregateSnapshotStrategy] | None\n    ) = None,\n    cache_backend: (\n        type[AggregateCacheBackend] | None\n    ) = None,\n    snapshot_backend: (\n        type[AggregateSnapshotStorageBackend] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Add an aggregate to the application.</p> <p>This method will register an aggregate with the application. The aggregate will be registered with the application and will be available to be resolved. In addition to registering the aggregate, you can also configure related dependencies for the aggregate such as the cache and snapshot configurations.</p> <p>If the aggregate was already registered, this method will update the dependencies for the aggregate. Thefore it is fine to have multiple calls to this method for the same aggregate type.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The type of aggregate to add.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>cache_strategy</code> <p>The type of cache strategy to use.</p> <p> TYPE: <code>type[CacheStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_strategy</code> <p>The type of snapshot strategy to use.</p> <p> TYPE: <code>type[AggregateSnapshotStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>cache_backend</code> <p>The type of cache backend to use.</p> <p> TYPE: <code>type[AggregateCacheBackend] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_backend</code> <p>The type of snapshot backend to use.</p> <p> TYPE: <code>type[AggregateSnapshotStorageBackend] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_aggregate(\n    self,\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: type[AggregateSnapshotStrategy] | None = None,\n    cache_backend: type[AggregateCacheBackend] | None = None,\n    snapshot_backend: type[AggregateSnapshotStorageBackend] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Add an aggregate to the application.\n\n    This method will register an aggregate with the application. The\n    aggregate will be registered with the application and will be\n    available to be resolved. In addition to registering the aggregate,\n    you can also configure related dependencies for the aggregate such as\n    the cache and snapshot configurations.\n\n    If the aggregate was already registered, this method will update the\n    dependencies for the aggregate. Thefore it is fine to have\n    multiple calls to this method for the same aggregate type.\n\n    Args:\n        aggregate_type: The type of aggregate to add.\n        cache_strategy: The type of cache strategy to use.\n        snapshot_strategy: The type of snapshot strategy to use.\n        cache_backend: The type of cache backend to use.\n        snapshot_backend: The type of snapshot backend to use.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(aggregate_type)\n    container.register_singleton(AggregateFactory, lambda: AggregateFactory(aggregate_type))\n    container.register_singleton(Aggregate, aggregate_type)\n    container.register_singleton(AggregateRepository)\n    if cache_strategy:\n        container.register_singleton(\n            dependency_type=CacheStrategy,\n            factory=cache_strategy,\n        )\n    if snapshot_strategy:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStrategy,\n            factory=snapshot_strategy,\n        )\n    if cache_backend:\n        container.register_singleton(\n            dependency_type=AggregateCacheBackend,\n            factory=cache_backend,\n        )\n    if snapshot_backend:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStorageBackend,\n            factory=snapshot_backend,\n        )\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_middleware","title":"register_middleware","text":"<pre><code>register_middleware(\n    middleware_type: type[Middleware],\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register middleware with the application.</p> <p>This method will register middleware with the application. The middleware will be registered with the application and will be available to be resolved. Middleware uses annotation-based routing with @intercepts decorator to determine which commands or queries to intercept.</p> PARAMETER DESCRIPTION <code>middleware_type</code> <p>The type of middleware to register</p> <p> TYPE: <code>type[Middleware]</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_middleware(\n    self,\n    middleware_type: type[Middleware],\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register middleware with the application.\n\n    This method will register middleware with the application. The\n    middleware will be registered with the application and will be\n    available to be resolved. Middleware uses annotation-based routing\n    with @intercepts decorator to determine which commands or queries\n    to intercept.\n\n    Args:\n        middleware_type: The type of middleware to register\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(middleware_type)\n    container.register_singleton(middleware_type)\n    container.register_singleton(Middleware, middleware_type)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_event_processor","title":"register_event_processor","text":"<pre><code>register_event_processor(\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Creates or updates the registration of an event processor.</p> <p>The processor will be registered with the application and will be avaiable to be resolved. In addition to registering the processor, you can also configure the processor's execution configuration via setting any of the relevant optional parameters on the CatchupCondition and CatchupStrategy objects.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The type of the event processor to register</p> <p> TYPE: <code>type[EventProcessor]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_event_processor(\n    self,\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Creates or updates the registration of an event processor.\n\n    The processor will be registered with the application and will be\n    avaiable to be resolved. In addition to registering the processor,\n    you can also configure the processor's execution configuration\n    via setting any of the relevant optional parameters on the\n    CatchupCondition and CatchupStrategy objects.\n\n    Args:\n        processor_type: The type of the event processor to register\n        catchup_condition: The condition to trigger catchup\n        catchup_strategy: The strategy to use for catchup\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(processor_type)\n    container.register_singleton(processor_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_projection","title":"register_projection","text":"<pre><code>register_projection(\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a projection with the application.</p> <p>Projections combine event handling (building read models) with query handling (serving reads). This method registers both capabilities.</p> <p>The projection will be available for: - Event processing via run_event_processors() - Query handling via Application.query()</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to register.</p> <p> TYPE: <code>type[Projection]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup.</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup.</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_projection(\n    self,\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a projection with the application.\n\n    Projections combine event handling (building read models) with\n    query handling (serving reads). This method registers both\n    capabilities.\n\n    The projection will be available for:\n    - Event processing via run_event_processors()\n    - Query handling via Application.query()\n\n    Args:\n        projection_type: The projection class to register.\n        catchup_condition: The condition to trigger catchup.\n        catchup_strategy: The strategy to use for catchup.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    # Register as both a projection (for queries) and event processor\n    container = self.contextual_binding.container_for(projection_type)\n    container.register_singleton(projection_type)\n    container.register_singleton(Projection, projection_type)\n    container.register_singleton(EventProcessor, projection_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.register_upcaster","title":"register_upcaster","text":"<pre><code>register_upcaster(\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: (\n        type[UpcastingStrategy] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register an upcaster with the application.</p> <p>This method will register an upcaster with the application. The upcaster will be registered with the application and will be available to be resolved. In addition to registering the upcaster, you can also configure the upcaster's upcasting strategy via setting the relevant optional parameter.</p> <p>If the upcaster was already registered, this method will update the upcasting strategy for the upcaster. Thefore it is fine to have multiple calls to this method for the same upcaster type.</p> PARAMETER DESCRIPTION <code>upcaster</code> <p>The type of the upcaster to register</p> <p> TYPE: <code>type[EventUpcaster[Any, Any]]</code> </p> <code>upcasting_strategy</code> <p>The type of the upcasting strategy to register</p> <p> TYPE: <code>type[UpcastingStrategy] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_upcaster(\n    self,\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: type[UpcastingStrategy] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register an upcaster with the application.\n\n    This method will register an upcaster with the application. The\n    upcaster will be registered with the application and will be available\n    to be resolved. In addition to registering the upcaster, you can also\n    configure the upcaster's upcasting strategy via setting the relevant\n    optional parameter.\n\n    If the upcaster was already registered, this method will update the\n    upcasting strategy for the upcaster. Thefore it is fine to have\n    multiple calls to this method for the same upcaster type.\n\n    Args:\n        upcaster: The type of the upcaster to register\n        upcasting_strategy: The type of the upcasting strategy to register\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(upcaster)\n    container.register_singleton(upcaster, upcaster)\n    if upcasting_strategy:\n        container.register_singleton(UpcastingStrategy, upcasting_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.convention_based","title":"convention_based","text":"<pre><code>convention_based(package_name: str) -&gt; ApplicationBuilder\n</code></pre> <p>Load aggregates, commands, etc from convention based modules.</p> <p>This method will load aggregates, commands, middleware, event processors, upcasters, configs, and services from a package based on the conventions of the package. The package will be scanned recursively for the relevant components.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>The name of the package to load components from.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def convention_based(self, package_name: str) -&gt; \"ApplicationBuilder\":\n    \"\"\"Load aggregates, commands, etc from convention based modules.\n\n    This method will load aggregates, commands, middleware, event\n    processors, upcasters, configs, and services from a package based on\n    the conventions of the package. The package will be scanned\n    recursively for the relevant components.\n\n    Args:\n        package_name: The name of the package to load components from.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    from .configurators import ApplicationProfile\n\n    for profile in ApplicationProfile.convention_based(package_name):\n        profile.configure(self)\n    return self\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationBuilder.build","title":"build","text":"<pre><code>build() -&gt; Application\n</code></pre> <p>Build the application with dependency injection.</p> <p>This method will resolve all dependencies and return an Application instance. If any dependencies cannot be resolved, an error will be raised. The Application instance will be fully configured and ready to use.</p> RETURNS DESCRIPTION <code>Application</code> <p>The configured Application instance</p> RAISES DESCRIPTION <code>ValueError</code> <p>If dependencies cannot be resolved (missing, etc.)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def build(self) -&gt; Application:\n    \"\"\"Build the application with dependency injection.\n\n    This method will resolve all dependencies and return an Application\n    instance. If any dependencies cannot be resolved, an error will be\n    raised. The Application instance will be fully configured and ready to\n    use.\n\n    Returns:\n        The configured Application instance\n\n    Raises:\n        ValueError: If dependencies cannot be resolved (missing, etc.)\n    \"\"\"\n    return Application(self.contextual_binding)\n</code></pre>"},{"location":"reference/application/#interlock.application.HasLifecycle","title":"HasLifecycle","text":"<p>               Bases: <code>Protocol</code></p>"},{"location":"reference/application/#interlock.application.HasLifecycle.on_startup","title":"on_startup  <code>async</code>","text":"<pre><code>on_startup() -&gt; None\n</code></pre> <p>Called when the application is started.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def on_startup(self) -&gt; None:\n    \"\"\"Called when the application is started.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/#interlock.application.HasLifecycle.on_shutdown","title":"on_shutdown  <code>async</code>","text":"<pre><code>on_shutdown() -&gt; None\n</code></pre> <p>Called when the application is shutdown.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def on_shutdown(self) -&gt; None:\n    \"\"\"Called when the application is shutdown.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/#interlock.application.ApplicationProfile","title":"ApplicationProfile","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for application configuration profiles.</p> <p>Profiles encapsulate a set of configuration logic that can be applied to an ApplicationBuilder. This allows for reusable, composable configuration.</p>"},{"location":"reference/application/#interlock.application.ApplicationProfile.configure","title":"configure  <code>abstractmethod</code>","text":"<pre><code>configure(builder: ApplicationBuilder) -&gt; None\n</code></pre> <p>Apply this profile's configuration to the builder.</p> PARAMETER DESCRIPTION <code>builder</code> <p>ApplicationBuilder to configure</p> <p> TYPE: <code>ApplicationBuilder</code> </p> Source code in <code>interlock/application/configurators.py</code> <pre><code>@abstractmethod\ndef configure(self, builder: ApplicationBuilder) -&gt; None:\n    \"\"\"Apply this profile's configuration to the builder.\n\n    Args:\n        builder: ApplicationBuilder to configure\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/application/#interlock.application.ConcurrencyRetryMiddleware","title":"ConcurrencyRetryMiddleware","text":"<pre><code>ConcurrencyRetryMiddleware(\n    max_attempts: int, retry_delay: float\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that retries commands that fail due to concurrency issues.</p> <p>This middleware retries commands that fail due to concurrency conflicts. It will attempt the command up to <code>max_attempts</code> times with a delay between attempts. If the command still fails after all attempts, it will raise a ConcurrencyError.</p> ATTRIBUTE DESCRIPTION <code>max_attempts</code> <p>The maximum number of attempts (initial + retries). Must be positive. For example, max_attempts=3 means 1 initial attempt + up to 2 retries.</p> <p> </p> <code>retry_delay</code> <p>The delay in seconds between retry attempts. Must be non-negative.</p> <p> </p> <p>Examples:</p> <p>Retry up to 3 times with 0.1s delay:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=3, retry_delay=0.1)\n</code></pre> <p>No delay between retries:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=5, retry_delay=0.0)\n</code></pre> PARAMETER DESCRIPTION <code>max_attempts</code> <p>Maximum number of attempts (must be positive).</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Delay in seconds between retries (must be non-negative).</p> <p> TYPE: <code>float</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If max_attempts &lt;= 0 or retry_delay &lt; 0.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>def __init__(self, max_attempts: int, retry_delay: float):\n    \"\"\"Initialize the concurrency retry middleware.\n\n    Args:\n        max_attempts: Maximum number of attempts (must be positive).\n        retry_delay: Delay in seconds between retries (must be non-negative).\n\n    Raises:\n        ValueError: If max_attempts &lt;= 0 or retry_delay &lt; 0.\n    \"\"\"\n    if max_attempts &lt;= 0:\n        raise ValueError(\"max_attempts must be positive\")\n    if retry_delay &lt; 0:\n        raise ValueError(\"retry_delay must be non-negative\")\n    self.max_attempts = max_attempts\n    self.retry_delay = retry_delay\n</code></pre>"},{"location":"reference/application/#interlock.application.ConcurrencyRetryMiddleware.retry_on_concurrency","title":"retry_on_concurrency  <code>async</code>","text":"<pre><code>retry_on_concurrency(\n    command: Command, next: Handler\n) -&gt; Any\n</code></pre> <p>Intercept all commands and retry on concurrency errors.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If all attempts fail due to concurrency conflicts.</p> <code>Exception</code> <p>Any non-ConcurrencyError exceptions are re-raised immediately.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>@intercepts\nasync def retry_on_concurrency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Intercept all commands and retry on concurrency errors.\n\n    Args:\n        command: The command to process.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n\n    Raises:\n        ConcurrencyError: If all attempts fail due to concurrency conflicts.\n        Exception: Any non-ConcurrencyError exceptions are re-raised immediately.\n    \"\"\"\n    last_error: ConcurrencyError | None = None\n    for attempt in range(self.max_attempts):\n        try:\n            return await next(command)\n        except ConcurrencyError as e:\n            last_error = e\n            LOGGER.warning(\n                f\"Concurrency error on attempt {attempt + 1}/{self.max_attempts}: {e}\"\n            )\n            # Don't sleep after the last attempt\n            if attempt &lt; self.max_attempts - 1:\n                await asyncio.sleep(self.retry_delay)\n    raise ConcurrencyError(f\"Max attempts ({self.max_attempts}) reached\") from last_error\n</code></pre>"},{"location":"reference/application/#interlock.application.ContextPropagationMiddleware","title":"ContextPropagationMiddleware","text":"<p>               Bases: <code>Middleware</code></p> <p>Middleware that propagates execution context from commands.</p> <p>This middleware extracts correlation_id, causation_id, and command_id from incoming commands and sets up the execution context before the command is handled. This enables:</p> <ol> <li>Distributed Tracing: Track entire operations across    services</li> <li>Causation Tracking: Understand what caused each    command/event</li> <li>Automatic Context Flow: Events emitted by aggregates    automatically inherit the context set by this middleware</li> </ol> <p>Context Setup: - If command has correlation_id: use it - If command has no correlation_id: generate a new one   (entry point) - If command has causation_id: use it - If command has no causation_id: use correlation_id   (self-referencing entry point) - Always use command.command_id for tracking</p> <p>Context Cleanup: The middleware ensures the context is cleared after command execution (even if the command fails) to prevent context leakage between operations.</p> <p>Middleware Order: This middleware should typically run early in the middleware chain, before logging or other cross-cutting concerns that might need access to context.</p> <p>Examples:</p> <p>Add to all commands:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .build())\n</code></pre> <p>Add with other middleware:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>This middleware is automatically registered when using ApplicationBuilder.use_correlation_tracking().</p>"},{"location":"reference/application/#interlock.application.ContextPropagationMiddleware.propagate_context","title":"propagate_context  <code>async</code>","text":"<pre><code>propagate_context(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Set up execution context and pass command to next handler.</p> <p>The context is cleared after command execution (even on failure) to prevent context leakage.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process. Context is extracted from its correlation_id, causation_id, and command_id fields.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/context.py</code> <pre><code>@intercepts\nasync def propagate_context(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Set up execution context and pass command to next handler.\n\n    The context is cleared after command execution (even on\n    failure) to prevent context leakage.\n\n    Args:\n        command: The command to process. Context is extracted from\n            its correlation_id, causation_id, and command_id\n            fields.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Extract context from command, generate defaults for missing values\n    correlation_id = command.correlation_id\n    if correlation_id is None:\n        # Entry point: generate new correlation_id\n        correlation_id = uuid4()\n\n    causation_id = command.causation_id\n    if causation_id is None:\n        # Entry point: self-referencing causation\n        causation_id = correlation_id\n\n    # Create and set execution context\n    ctx = ExecutionContext(\n        correlation_id=correlation_id,\n        causation_id=causation_id,\n        command_id=command.command_id,\n    )\n    set_context(ctx)\n\n    try:\n        # Pass to next handler with context set\n        return await next(command)\n    finally:\n        # Always clear context after command execution to prevent leakage\n        clear_context()\n</code></pre>"},{"location":"reference/application/#interlock.application.HasIdempotencyKey","title":"HasIdempotencyKey","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for commands that have an idempotency key.</p> <p>Commands can provide idempotency tracking by having an <code>idempotency_key</code> attribute (field or property). The idempotency middleware will detect this and use it to prevent duplicate processing.</p> <p>Examples:</p> <p>Field-based idempotency key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n</code></pre> <p>Property-based idempotency key (computed):</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account_id: UUID\n...     to_account_id: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account_id}-{self.to_account_id}-{self.amount}\"\n</code></pre>"},{"location":"reference/application/#interlock.application.HasIdempotencyKey.idempotency_key","title":"idempotency_key  <code>property</code>","text":"<pre><code>idempotency_key: str\n</code></pre> <p>The idempotency key for this command.</p>"},{"location":"reference/application/#interlock.application.IdempotencyMiddleware","title":"IdempotencyMiddleware","text":"<pre><code>IdempotencyMiddleware(\n    idempotency_storage_backend: IdempotencyStorageBackend,\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that ensures commands are idempotent.</p> <p>This middleware intercepts commands that have an <code>idempotency_key</code> attribute (field or property) and ensures they are only processed once.</p> <p>Commands without an idempotency_key are passed through unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; app = (\n...     ApplicationBuilder()\n...     .register_dependency(IdempotencyStorageBackend, InMemoryIdempotencyStorageBackend)\n...     .register_middleware(IdempotencyMiddleware)\n...     .build()\n... )\n</code></pre> <p>Field-based key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n...\n&gt;&gt;&gt; await app.dispatch(DepositMoney(aggregate_id=id, amount=100, idempotency_key=\"dep-123\"))\n</code></pre> <p>Property-based key:</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account: UUID\n...     to_account: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account}-{self.to_account}-{self.amount}\"\n</code></pre> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self, idempotency_storage_backend: IdempotencyStorageBackend):\n    self.idempotency_storage_backend = idempotency_storage_backend\n</code></pre>"},{"location":"reference/application/#interlock.application.IdempotencyMiddleware.ensure_idempotency","title":"ensure_idempotency  <code>async</code>","text":"<pre><code>ensure_idempotency(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Check idempotency and process command if not processed.</p> <p>Commands with an <code>idempotency_key</code> attribute are checked against the storage backend. Commands without this attribute are passed through unchanged.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to check.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler, or None if skipped.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@intercepts\nasync def ensure_idempotency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Check idempotency and process command if not processed.\n\n    Commands with an `idempotency_key` attribute are checked against\n    the storage backend. Commands without this attribute are passed\n    through unchanged.\n\n    Args:\n        command: The command to check.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler, or None if skipped.\n    \"\"\"\n    # Check if command has idempotency tracking\n    if not isinstance(command, HasIdempotencyKey):\n        return await next(command)\n\n    idempotency_key = command.idempotency_key\n\n    if await self.idempotency_storage_backend.has_idempotency_key(idempotency_key):\n        LOGGER.warning(\n            \"Skipping previously processed command\",\n            extra={\"idempotency_key\": idempotency_key},\n        )\n        return None\n\n    result = await next(command)\n    await self.idempotency_storage_backend.store_idempotency_key(idempotency_key)\n    return result\n</code></pre>"},{"location":"reference/application/#interlock.application.IdempotencyStorageBackend","title":"IdempotencyStorageBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for idempotency storage backends.</p> <p>This backend is used to store idempotency keys for commands. It will store the idempotency key for a command and return it when the command is dispatched.</p>"},{"location":"reference/application/#interlock.application.IdempotencyStorageBackend.store_idempotency_key","title":"store_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>store_idempotency_key(key: str) -&gt; None\n</code></pre> <p>Store an idempotency key as processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def store_idempotency_key(self, key: str) -&gt; None:\n    \"\"\"Store an idempotency key as processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/#interlock.application.IdempotencyStorageBackend.has_idempotency_key","title":"has_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>has_idempotency_key(key: str) -&gt; bool\n</code></pre> <p>Check if an idempotency key has been processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def has_idempotency_key(self, key: str) -&gt; bool:\n    \"\"\"Check if an idempotency key has been processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/#interlock.application.InMemoryIdempotencyStorageBackend","title":"InMemoryIdempotencyStorageBackend","text":"<pre><code>InMemoryIdempotencyStorageBackend()\n</code></pre> <p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>In-memory implementation of the idempotency storage backend.</p> <p>This backend stores idempotency keys in memory. Suitable for single-process applications and testing.</p> Note <p>Keys are lost on application restart. For production use, implement a persistent backend (Redis, database, etc.).</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self):\n    self.idempotency_keys: set[str] = set()\n</code></pre>"},{"location":"reference/application/#interlock.application.LoggingMiddleware","title":"LoggingMiddleware","text":"<pre><code>LoggingMiddleware(level: str)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that logs command execution with correlation.</p> <p>Logs each command received at the specified logging level with the command type and correlation/causation IDs for distributed tracing. Command data is NOT logged to avoid exposing PII or sensitive information.</p> ATTRIBUTE DESCRIPTION <code>level</code> <p>The numeric logging level (e.g., logging.INFO, logging.DEBUG).</p> <p> </p> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> <p>With correlation tracking:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .use_correlation_tracking()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>For correlation tracking to work, ContextPropagationMiddleware should be registered before LoggingMiddleware in the middleware chain.</p> PARAMETER DESCRIPTION <code>level</code> <p>String representation of the log level (e.g., \"INFO\", \"DEBUG\"). Case-insensitive.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>def __init__(self, level: str):\n    \"\"\"Initialize the logging middleware.\n\n    Args:\n        level: String representation of the log level (e.g.,\n            \"INFO\", \"DEBUG\"). Case-insensitive.\n    \"\"\"\n    self.level = getattr(logging, level.upper())\n</code></pre>"},{"location":"reference/application/#interlock.application.LoggingMiddleware.log_command","title":"log_command  <code>async</code>","text":"<pre><code>log_command(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Log the command type with correlation context.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to log and process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>@intercepts\nasync def log_command(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Log the command type with correlation context.\n\n    Args:\n        command: The command to log and process.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Build log extra with command type and aggregate_id only\n    extra = {\n        \"command_type\": type(command).__name__,\n        \"aggregate_id\": str(command.aggregate_id),\n    }\n\n    # Add correlation context if available\n    ctx = get_context()\n    if ctx.correlation_id is not None:\n        extra[\"correlation_id\"] = str(ctx.correlation_id)\n    if ctx.causation_id is not None:\n        extra[\"causation_id\"] = str(ctx.causation_id)\n    if ctx.command_id is not None:\n        extra[\"command_id\"] = str(ctx.command_id)\n\n    LOGGER.log(self.level, \"Received Command\", extra=extra)\n    return await next(command)\n</code></pre>"},{"location":"reference/application/#interlock.application.Middleware","title":"Middleware","text":"<p>Base class for middleware with annotation-based routing.</p> <p>Middleware components wrap handlers to provide cross-cutting concerns like logging, validation, authentication, or transaction management. They follow the chain of responsibility pattern.</p> <p>Middleware can intercept both commands and queries using the @intercepts decorator. The framework automatically routes messages to the appropriate methods based on their type annotations.</p> <p>By default, if no interceptor matches the message type, the middleware forwards to the next handler (pass-through behavior).</p> <p>Examples:</p> <p>Intercept all commands:</p> <pre><code>&gt;&gt;&gt; class LoggingMiddleware(Middleware):\n...     @intercepts\n...     async def log_command(self, cmd: Command, next: Handler) -&gt; Any:\n...         print(f\"Command: {type(cmd).__name__}\")\n...         return await next(cmd)\n</code></pre> <p>Intercept specific command type:</p> <pre><code>&gt;&gt;&gt; class AdminOnlyMiddleware(Middleware):\n...     @intercepts\n...     async def check_admin(self, cmd: DeleteUser, next: Handler) -&gt; Any:\n...         if not self.is_admin(cmd.requester_id):\n...             raise PermissionError(\"Admin required\")\n...         return await next(cmd)\n</code></pre> <p>Intercept queries:</p> <pre><code>&gt;&gt;&gt; class CachingMiddleware(Middleware):\n...     @intercepts\n...     async def cache_query(self, query: Query, next: Handler) -&gt; Any:\n...         if cached := self.cache.get(query):\n...             return cached\n...         result = await next(query)\n...         self.cache.set(query, result)\n...         return result\n</code></pre>"},{"location":"reference/application/#interlock.application.Middleware.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up routing when a subclass is defined.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    from ...routing import setup_middleware_routing\n\n    cls._command_router = setup_middleware_routing(cls)\n</code></pre>"},{"location":"reference/application/#interlock.application.Middleware.intercept","title":"intercept  <code>async</code>","text":"<pre><code>intercept(message: BaseModel, next: Handler) -&gt; Any\n</code></pre> <p>Route message to interceptor method or forward to next.</p> <p>This method is called by the bus for each message. It uses the routing table to find an appropriate interceptor method based on the message type. If no interceptor is registered for the message type, it forwards to the next handler.</p> PARAMETER DESCRIPTION <code>message</code> <p>The command or query to intercept.</p> <p> TYPE: <code>BaseModel</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the interceptor or next handler.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>async def intercept(self, message: BaseModel, next: Handler) -&gt; Any:\n    \"\"\"Route message to interceptor method or forward to next.\n\n    This method is called by the bus for each message. It uses the\n    routing table to find an appropriate interceptor method based\n    on the message type. If no interceptor is registered for the\n    message type, it forwards to the next handler.\n\n    Args:\n        message: The command or query to intercept.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the interceptor or next handler.\n    \"\"\"\n    # Route to interceptor, passing next as an extra argument\n    result = self._command_router.route(self, message, next)\n\n    # If router returned None (IgnoreHandler), forward to next\n    if result is None:\n        return await next(message)\n    elif inspect.isawaitable(result):\n        # Router returned coroutine (async interceptor), await it\n        return await result\n    else:\n        return result\n</code></pre>"},{"location":"reference/application/#interlock.application.NullIdempotencyStorageBackend","title":"NullIdempotencyStorageBackend","text":"<p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>A null implementation that never detects duplicates.</p> <p>Use this to effectively disable idempotency checking.</p>"},{"location":"reference/application/#interlock.application.DelegateToProjection","title":"DelegateToProjection","text":"<pre><code>DelegateToProjection(\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n)\n</code></pre> <p>Root handler that delegates queries to the appropriate projection.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n):\n    self.query_to_projection_map = query_to_projection_map\n    self.projection_registry = projection_registry\n</code></pre>"},{"location":"reference/application/#interlock.application.DelegateToProjection.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch a query to its projection handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def handle(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch a query to its projection handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The query result.\n    \"\"\"\n    projection_type = self.query_to_projection_map.get(type(query))\n    projection = self.projection_registry.get(projection_type)\n    return await projection.query(query)\n</code></pre>"},{"location":"reference/application/#interlock.application.Projection","title":"Projection","text":"<p>               Bases: <code>EventProcessor</code></p> <p>Base class for read models that handle events and serve queries.</p> <p>Projections are the read side of CQRS. They: 1. Subscribe to events and update their internal state (read model) 2. Serve queries by returning data from their read model</p> <p>Unlike aggregates which enforce invariants and emit events, projections are optimized for reads. They maintain denormalized views that can be queried efficiently.</p> <p>Event Handling: Use @handles_event to mark methods that process events:</p> <pre><code>@handles_event\nasync def on_user_created(self, event: UserCreated) -&gt; None:\n    self.users[event.user_id] = UserProfile(\n        id=event.user_id,\n        name=event.name,\n        email=event.email\n    )\n</code></pre> <p>Query Handling: Use @handles_query to mark methods that serve queries:</p> <pre><code>@handles_query\nasync def get_user(self, query: GetUserById) -&gt; UserProfile:\n    return self.users[query.user_id]\n</code></pre> <p>State Management: Projections are responsible for their own state persistence. Inject repositories or database clients via dependency injection:</p> <pre><code>class UserProjection(Projection):\n    def __init__(self, repository: UserRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_user_created(self, event: UserCreated) -&gt; None:\n        await self.repository.save(UserProfile(...))\n\n    @handles_query\n    async def get_user(self, query: GetUserById) -&gt; UserProfile:\n        return await self.repository.get(query.user_id)\n</code></pre> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Routing table for event handlers (inherited)</p> <p> TYPE: <code>MessageRouter</code> </p> <code>_query_router</code> <p>Routing table for query handlers</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock import Projection, handles_event, handles_query from interlock.domain import Query</p> <p>class GetUserById(Query[UserProfile]): ...     user_id: UUID</p> <p>class GetUserByEmail(Query[UUID | None]): ...     email: str</p> <p>class UserProjection(Projection): ...     def init(self): ...         super().init() ...         self.users: dict[UUID, UserProfile] = {} ...         self.email_index: dict[str, UUID] = {} ... ...     @handles_event ...     async def on_user_created(self, event: UserCreated) -&gt; None: ...         profile = UserProfile( ...             id=event.user_id, ...             name=event.name, ...             email=event.email ...         ) ...         self.users[event.user_id] = profile ...         self.email_index[event.email] = event.user_id ... ...     @handles_query ...     async def get_user(self, query: GetUserById) -&gt; UserProfile: ...         return self.users[query.user_id] ... ...     @handles_query ...     async def find_by_email(self, q: GetUserByEmail) -&gt; UUID | None: ...         return self.email_index.get(q.email)</p>"},{"location":"reference/application/#interlock.application.Projection.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event and query routing when a subclass is defined.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event and query routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    # Event routing is set up by EventProcessor.__init_subclass__\n    # We need to set up query routing here\n    cls._query_router = setup_query_routing(cls)\n</code></pre>"},{"location":"reference/application/#interlock.application.Projection.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Route a query to its registered handler method.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to handle.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for the query.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Route a query to its registered handler method.\n\n    Args:\n        query: The query to handle.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n\n    Raises:\n        NotImplementedError: If no handler is registered for the query.\n    \"\"\"\n    result = self._query_router.route(self, query)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/application/#interlock.application.ProjectionRegistry","title":"ProjectionRegistry","text":"<pre><code>ProjectionRegistry()\n</code></pre> <p>Registry of projection instances for query dispatch.</p> <p>This is the query-side equivalent of AggregateToRepositoryMap. Unlike aggregates which are loaded per-request, projections are typically long-lived singletons that maintain read model state.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.projections: dict[type[Projection], Projection] = {}\n</code></pre>"},{"location":"reference/application/#interlock.application.ProjectionRegistry.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[Projection],\n) -&gt; ProjectionRegistry\n</code></pre> <p>Build a registry from a list of projection instances.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection instances to register.</p> <p> TYPE: <code>list[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionRegistry</code> <p>A configured ProjectionRegistry.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[Projection],\n) -&gt; \"ProjectionRegistry\":\n    \"\"\"Build a registry from a list of projection instances.\n\n    Args:\n        projections: List of projection instances to register.\n\n    Returns:\n        A configured ProjectionRegistry.\n    \"\"\"\n    registry = ProjectionRegistry()\n    for projection in projections:\n        registry.add(projection)\n    return registry\n</code></pre>"},{"location":"reference/application/#interlock.application.ProjectionRegistry.add","title":"add","text":"<pre><code>add(projection: Projection) -&gt; None\n</code></pre> <p>Register a projection instance.</p> PARAMETER DESCRIPTION <code>projection</code> <p>The projection instance to register.</p> <p> TYPE: <code>Projection</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection: Projection) -&gt; None:\n    \"\"\"Register a projection instance.\n\n    Args:\n        projection: The projection instance to register.\n    \"\"\"\n    self.projections[type(projection)] = projection\n</code></pre>"},{"location":"reference/application/#interlock.application.ProjectionRegistry.get","title":"get","text":"<pre><code>get(projection_type: type[Projection]) -&gt; Projection\n</code></pre> <p>Get a projection instance by type.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to look up.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>Projection</code> <p>The registered projection instance.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection of this type is registered.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, projection_type: type[Projection]) -&gt; Projection:\n    \"\"\"Get a projection instance by type.\n\n    Args:\n        projection_type: The projection class to look up.\n\n    Returns:\n        The registered projection instance.\n\n    Raises:\n        KeyError: If no projection of this type is registered.\n    \"\"\"\n    return self.projections[projection_type]\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryBus","title":"QueryBus","text":"<pre><code>QueryBus(\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n)\n</code></pre> <p>Routes queries through middleware to projections.</p> <p>The QueryBus manages the middleware chain and delegates queries to the appropriate projection for handling. Middleware is applied in registration order, with each middleware deciding via annotation- based routing whether to intercept a query.</p> PARAMETER DESCRIPTION <code>root_handler</code> <p>The final handler that delegates to projections.</p> <p> TYPE: <code>DelegateToProjection</code> </p> <code>middleware</code> <p>List of middleware to apply (in order).</p> <p> TYPE: <code>list[Middleware]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n):\n    self.root_handler = root_handler\n    self.middleware = middleware\n    # Build the middleware chain by reducing from right to left\n    self.chain: Callable[[Query[Any]], Coroutine[Any, Any, Any]] = reduce(\n        lambda next, mw: lambda q, n=next, m=mw: m.intercept(q, n),\n        reversed(middleware),\n        self.root_handler.handle,\n    )\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryBus.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch query through the middleware chain to handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the query handler.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def dispatch(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch query through the middleware chain to handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The result from the query handler.\n    \"\"\"\n    return await self.chain(query)\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryToProjectionMap","title":"QueryToProjectionMap","text":"<pre><code>QueryToProjectionMap()\n</code></pre> <p>Maps query types to projection types.</p> <p>This is the query-side equivalent of CommandToAggregateMap. It scans projection classes for @handles_query decorated methods and builds a routing table.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.query_to_projection_map: dict[type[Query[Any]], type[Projection]] = {}\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryToProjectionMap.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[type[Projection]],\n) -&gt; QueryToProjectionMap\n</code></pre> <p>Build a map from a list of projection types.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection classes to scan.</p> <p> TYPE: <code>list[type[Projection]]</code> </p> RETURNS DESCRIPTION <code>QueryToProjectionMap</code> <p>A configured QueryToProjectionMap.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[type[Projection]],\n) -&gt; \"QueryToProjectionMap\":\n    \"\"\"Build a map from a list of projection types.\n\n    Args:\n        projections: List of projection classes to scan.\n\n    Returns:\n        A configured QueryToProjectionMap.\n    \"\"\"\n    map = QueryToProjectionMap()\n    for projection in projections:\n        map.add(projection)\n    return map\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryToProjectionMap.add","title":"add","text":"<pre><code>add(projection_type: type[Projection]) -&gt; None\n</code></pre> <p>Register a projection's query handlers.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to scan for handlers.</p> <p> TYPE: <code>type[Projection]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection_type: type[Projection]) -&gt; None:\n    \"\"\"Register a projection's query handlers.\n\n    Args:\n        projection_type: The projection class to scan for handlers.\n    \"\"\"\n    for value in projection_type.__dict__.values():\n        if hasattr(value, \"_handles_query_type\"):\n            query_type = value._handles_query_type\n            self.query_to_projection_map[query_type] = projection_type\n</code></pre>"},{"location":"reference/application/#interlock.application.QueryToProjectionMap.get","title":"get","text":"<pre><code>get(query_type: type[Query[Any]]) -&gt; type[Projection]\n</code></pre> <p>Get the projection type that handles a query type.</p> PARAMETER DESCRIPTION <code>query_type</code> <p>The query class to look up.</p> <p> TYPE: <code>type[Query[Any]]</code> </p> RETURNS DESCRIPTION <code>type[Projection]</code> <p>The projection type that handles this query.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection handles this query type.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, query_type: type[Query[Any]]) -&gt; type[Projection]:\n    \"\"\"Get the projection type that handles a query type.\n\n    Args:\n        query_type: The query class to look up.\n\n    Returns:\n        The projection type that handles this query.\n\n    Raises:\n        KeyError: If no projection handles this query type.\n    \"\"\"\n    return self.query_to_projection_map[query_type]\n</code></pre>"},{"location":"reference/application/application/","title":"application","text":""},{"location":"reference/application/application/#interlock.application.application","title":"application","text":""},{"location":"reference/application/application/#interlock.application.application.HasLifecycle","title":"HasLifecycle","text":"<p>               Bases: <code>Protocol</code></p>"},{"location":"reference/application/application/#interlock.application.application.HasLifecycle.on_startup","title":"on_startup  <code>async</code>","text":"<pre><code>on_startup() -&gt; None\n</code></pre> <p>Called when the application is started.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def on_startup(self) -&gt; None:\n    \"\"\"Called when the application is started.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.HasLifecycle.on_shutdown","title":"on_shutdown  <code>async</code>","text":"<pre><code>on_shutdown() -&gt; None\n</code></pre> <p>Called when the application is shutdown.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def on_shutdown(self) -&gt; None:\n    \"\"\"Called when the application is shutdown.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application","title":"Application","text":"<pre><code>Application(contextual_binding: ContextualBinding)\n</code></pre> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self, contextual_binding: ContextualBinding):\n    self.contextual_binding = contextual_binding\n    self.command_bus = self.resolve(CommandBus)\n    self.event_bus = self.resolve(EventBus)\n    self.query_bus = self.resolve(QueryBus)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(command: Command[T]) -&gt; T\n</code></pre> <p>Dispatch a command to the application.</p> <p>This method will dispatch a command to the application. The command will be dispatched to the command bus and the command bus will dispatch the command to the appropriate aggregate and middleware chain.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to dispatch.</p> <p> TYPE: <code>Command[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def dispatch(self, command: Command[T]) -&gt; T:\n    \"\"\"Dispatch a command to the application.\n\n    This method will dispatch a command to the application. The command\n    will be dispatched to the command bus and the command bus will dispatch\n    the command to the appropriate aggregate and middleware chain.\n\n    Args:\n        command: The command to dispatch.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    return await self.command_bus.dispatch(command)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Execute a query against the application.</p> <p>This method will dispatch a query to the application. The query will be dispatched to the query bus and routed through middleware to the appropriate projection.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to execute.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Execute a query against the application.\n\n    This method will dispatch a query to the application. The query\n    will be dispatched to the query bus and routed through middleware\n    to the appropriate projection.\n\n    Args:\n        query: The query to execute.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n    \"\"\"\n    return await self.query_bus.dispatch(query)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.resolve","title":"resolve","text":"<pre><code>resolve(type_to_resolve: type[T]) -&gt; T\n</code></pre> <p>Resolve a dependency from the application.</p> <p>This method will resolve a dependency from the application. The dependency will be resolved from the contextual binding and will be returned.</p> PARAMETER DESCRIPTION <code>type_to_resolve</code> <p>The type of the dependency to resolve.</p> <p> TYPE: <code>type[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The resolved dependency.</p> RAISES DESCRIPTION <code>DependencyNotFoundError</code> <p>If the dependency cannot be resolved.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def resolve(self, type_to_resolve: type[T]) -&gt; T:\n    \"\"\"Resolve a dependency from the application.\n\n    This method will resolve a dependency from the application.\n    The dependency will be resolved from the contextual binding\n    and will be returned.\n\n    Args:\n        type_to_resolve: The type of the dependency to resolve.\n\n    Returns:\n        The resolved dependency.\n\n    Raises:\n        DependencyNotFoundError: If the dependency cannot be\n            resolved.\n    \"\"\"\n    return self.contextual_binding.resolve(type_to_resolve)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.startup","title":"startup  <code>async</code>","text":"<pre><code>startup() -&gt; None\n</code></pre> <p>Startup the application.</p> <p>This method will startup the application. The application will be started by calling the on_startup method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are started in the order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Startup the application.\n\n    This method will startup the application. The application will be\n    started by calling the on_startup method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are started\n    in the order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in dependencies:\n        await dependency.on_startup()\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown() -&gt; None\n</code></pre> <p>Shutdown the application.</p> <p>This method will shutdown the application. The application will be shutdown by calling the on_shutdown method on all dependencies that implement the <code>HasLifecycle</code> protocol. The dependencies are shutdown in the reverse order of their registration.</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the application.\n\n    This method will shutdown the application. The application will be\n    shutdown by calling the on_shutdown method on all dependencies that\n    implement the `HasLifecycle` protocol. The dependencies are shutdown\n    in the reverse order of their registration.\n    \"\"\"\n    dependencies = self.contextual_binding.resolve_all_of_type(HasLifecycle)\n    for dependency in reversed(dependencies):\n        await dependency.on_shutdown()\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.run_event_processors","title":"run_event_processors  <code>async</code>","text":"<pre><code>run_event_processors(\n    *processors: type[EventProcessor],\n) -&gt; None\n</code></pre> <p>Run the event processors for the application.</p> <p>This method will run the event processors for the application of the given types. The event processors are run asynchronously and will continue to run until the application is stopped or all run methods have completed. The event processors are run in the order they were registered.</p> PARAMETER DESCRIPTION <code>*processors</code> <p>The event processors to run.</p> <p> TYPE: <code>type[EventProcessor]</code> DEFAULT: <code>()</code> </p> RAISES DESCRIPTION <code>Exception</code> <p>Any exceptions raised by the event processors will be propagated to the caller.</p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/application.py</code> <pre><code>async def run_event_processors(self, *processors: type[EventProcessor]) -&gt; None:\n    \"\"\"Run the event processors for the application.\n\n    This method will run the event processors for the application of the\n    given types. The event processors are run asynchronously and will\n    continue to run until the application is stopped or all run methods\n    have completed. The event processors are run in the order they were\n    registered.\n\n    Args:\n        *processors: The event processors to run.\n\n    Raises:\n        Exception: Any exceptions raised by the event processors will be\n            propagated to the caller.\n\n    Returns:\n        None\n    \"\"\"\n    # We will resolve each processors executor from its own container\n    # context and then subscribe to the event transport for the processor.\n    executors = [\n        self.contextual_binding.container_for(processor).resolve(EventProcessorExecutor)\n        for processor in processors\n    ]\n\n    transport = self.contextual_binding.resolve(EventTransport)\n    subscriptions = [\n        await transport.subscribe(executor.processor.__class__.__name__)\n        for executor in executors\n    ]\n\n    # Now that we have a subscription for each processor, we can run the\n    # processors in their own async tasks. We will gather the tasks and\n    # await them all to complete (This will probably be 'forever' since\n    # the processors are expected to run until the application is stopped).\n    tasks = [\n        executor.run(subscription)\n        for executor, subscription in zip(executors, subscriptions, strict=False)\n    ]\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.aggregate_scenario","title":"aggregate_scenario","text":"<pre><code>aggregate_scenario(\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; AggregateScenario\n</code></pre> <p>Create a test scenario for an aggregate.</p> <p>This provides a consistent testing API across all Interlock components. Aggregates don't have constructor dependencies, so this is equivalent to creating an AggregateScenario directly.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class to test.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>aggregate_id</code> <p>Optional specific ID for the aggregate.</p> <p> TYPE: <code>UUID | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AggregateScenario</code> <p>An AggregateScenario ready for Given-When-Then testing.</p> Example <p>async with app.aggregate_scenario(BankAccount) as scenario: ...     scenario.given_no_events() ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100)) ...     scenario.should_emit(MoneyDeposited)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def aggregate_scenario(\n    self,\n    aggregate_type: type[Aggregate],\n    aggregate_id: UUID | None = None,\n) -&gt; \"AggregateScenario\":\n    \"\"\"Create a test scenario for an aggregate.\n\n    This provides a consistent testing API across all Interlock components.\n    Aggregates don't have constructor dependencies, so this is equivalent\n    to creating an AggregateScenario directly.\n\n    Args:\n        aggregate_type: The aggregate class to test.\n        aggregate_id: Optional specific ID for the aggregate.\n\n    Returns:\n        An AggregateScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.aggregate_scenario(BankAccount) as scenario:\n        ...     scenario.given_no_events()\n        ...     scenario.when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=100))\n        ...     scenario.should_emit(MoneyDeposited)\n    \"\"\"\n    from ..testing import AggregateScenario\n\n    return AggregateScenario(aggregate_type, aggregate_id)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.processor_scenario","title":"processor_scenario","text":"<pre><code>processor_scenario(\n    processor_type: type[EventProcessor],\n) -&gt; ProcessorScenario\n</code></pre> <p>Create a test scenario for an event processor with DI.</p> <p>The processor is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The event processor class to test.</p> <p> TYPE: <code>type[EventProcessor]</code> </p> RETURNS DESCRIPTION <code>ProcessorScenario</code> <p>A ProcessorScenario ready for Given-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository) ...     .register_event_processor(AccountBalanceProjection) ...     .build() ... ) async with app.processor_scenario(AccountBalanceProjection) as scenario: ...     scenario.given(MoneyDeposited(account_id=id, amount=100)) ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def processor_scenario(\n    self,\n    processor_type: type[EventProcessor],\n) -&gt; \"ProcessorScenario\":\n    \"\"\"Create a test scenario for an event processor with DI.\n\n    The processor is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        processor_type: The event processor class to test.\n\n    Returns:\n        A ProcessorScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n        ...     .register_event_processor(AccountBalanceProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        ...     scenario.given(MoneyDeposited(account_id=id, amount=100))\n        ...     scenario.should_have_state(lambda p: p.repository.get_balance(id) == 100)\n    \"\"\"\n    from ..testing import ProcessorScenario\n\n    # Resolve the processor from the DI container\n    processor = self.contextual_binding.container_for(processor_type).resolve(processor_type)\n    return ProcessorScenario(processor)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.saga_scenario","title":"saga_scenario","text":"<pre><code>saga_scenario(saga_type: type) -&gt; SagaScenario\n</code></pre> <p>Create a test scenario for a saga with DI.</p> <p>The saga is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>saga_type</code> <p>The saga class to test.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>SagaScenario</code> <p>A SagaScenario ready for Given-Then testing.</p> Example <p>async with app.saga_scenario(OrderFulfillmentSaga) as scenario: ...     scenario.given(OrderPlaced(order_id=\"123\")) ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")</p> Source code in <code>interlock/application/application.py</code> <pre><code>def saga_scenario(\n    self,\n    saga_type: type,\n) -&gt; \"SagaScenario\":\n    \"\"\"Create a test scenario for a saga with DI.\n\n    The saga is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        saga_type: The saga class to test.\n\n    Returns:\n        A SagaScenario ready for Given-Then testing.\n\n    Example:\n        &gt;&gt;&gt; async with app.saga_scenario(OrderFulfillmentSaga) as scenario:\n        ...     scenario.given(OrderPlaced(order_id=\"123\"))\n        ...     scenario.should_have_state(\"123\", lambda s: s.status == \"processing\")\n    \"\"\"\n    from ..testing import SagaScenario\n    from .events.processing import Saga\n\n    # Resolve the saga from the DI container\n    saga = self.contextual_binding.container_for(saga_type).resolve(saga_type)\n    if not isinstance(saga, Saga):\n        raise TypeError(f\"Expected Saga instance, got {type(saga).__name__}\")\n    return SagaScenario(saga)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.Application.projection_scenario","title":"projection_scenario","text":"<pre><code>projection_scenario(\n    projection_type: type[Projection],\n) -&gt; ProjectionScenario\n</code></pre> <p>Create a test scenario for a projection with DI.</p> <p>The projection is instantiated using the application's dependency injection container, so all registered dependencies are automatically injected.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to test.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionScenario</code> <p>A ProjectionScenario ready for Given-When-Then testing.</p> Example <p>app = ( ...     ApplicationBuilder() ...     .register_projection(UserProjection) ...     .build() ... ) async with app.projection_scenario(UserProjection) as scenario: ...     scenario.given(UserCreated(user_id=id, name=\"Alice\")) ...     result = await scenario.when(GetUserById(user_id=id)) ...     assert result.name == \"Alice\"</p> Source code in <code>interlock/application/application.py</code> <pre><code>def projection_scenario(\n    self,\n    projection_type: type[Projection],\n) -&gt; \"ProjectionScenario\":\n    \"\"\"Create a test scenario for a projection with DI.\n\n    The projection is instantiated using the application's dependency\n    injection container, so all registered dependencies are automatically\n    injected.\n\n    Args:\n        projection_type: The projection class to test.\n\n    Returns:\n        A ProjectionScenario ready for Given-When-Then testing.\n\n    Example:\n        &gt;&gt;&gt; app = (\n        ...     ApplicationBuilder()\n        ...     .register_projection(UserProjection)\n        ...     .build()\n        ... )\n        &gt;&gt;&gt; async with app.projection_scenario(UserProjection) as scenario:\n        ...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n        ...     result = await scenario.when(GetUserById(user_id=id))\n        ...     assert result.name == \"Alice\"\n    \"\"\"\n    from ..testing import ProjectionScenario\n\n    # Resolve the projection from the DI container\n    projection = self.contextual_binding.container_for(projection_type).resolve(projection_type)\n    return ProjectionScenario(projection)\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder","title":"ApplicationBuilder","text":"<pre><code>ApplicationBuilder()\n</code></pre> <p>Builder for creating Application instances.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.container = DependencyContainer()\n    self.contextual_binding = ContextualBinding(self.container)\n\n    # Event Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=UpcastingStrategy,\n        factory=LazyUpcastingStrategy,\n    )\n    self.container.register_singleton(\n        dependency_type=EventTransport,\n        factory=InMemoryEventTransport,\n    )\n    self.container.register_singleton(\n        dependency_type=EventStore,\n        factory=InMemoryEventStore,\n    )\n    self.container.register_singleton(\n        dependency_type=UpcasterMap,\n        factory=self._build_upcaster_map,\n    )\n    self.container.register_singleton(UpcastingPipeline)\n    self.container.register_singleton(\n        dependency_type=EventDelivery,\n        factory=self._build_synchronous_delivery,\n    )\n    self.container.register_singleton(EventBus)\n\n    # Aggregate Repository Defaults:\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStrategy,\n        factory=AggregateSnapshotStrategy.never,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateCacheBackend,\n        factory=AggregateCacheBackend.null,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateSnapshotStorageBackend,\n        factory=AggregateSnapshotStorageBackend.null,\n    )\n\n    # Event Processor Defaults:\n    self.container.register_singleton(\n        dependency_type=CatchupCondition,\n        factory=Never,\n    )\n    self.container.register_singleton(\n        dependency_type=CatchupStrategy,\n        factory=NoCatchup,\n    )\n    self.container.register_singleton(\n        dependency_type=CacheStrategy,\n        factory=CacheStrategy.never,\n    )\n\n    # Command Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=CommandToAggregateMap,\n        factory=self._build_command_to_aggregate_map,\n    )\n    self.container.register_singleton(\n        dependency_type=AggregateToRepositoryMap,\n        factory=self._build_aggregate_to_repository_map,\n    )\n    self.container.register_singleton(DelegateToAggregate)\n    self.container.register_singleton(\n        dependency_type=CommandBus,\n        factory=self._build_command_bus,\n    )\n\n    self.container.register_singleton(SagaStateStore, SagaStateStore.in_memory)\n\n    # Query Bus Defaults:\n    self.container.register_singleton(\n        dependency_type=QueryToProjectionMap,\n        factory=self._build_query_to_projection_map,\n    )\n    self.container.register_singleton(\n        dependency_type=ProjectionRegistry,\n        factory=self._build_projection_registry,\n    )\n    self.container.register_singleton(DelegateToProjection)\n    self.container.register_singleton(\n        dependency_type=QueryBus,\n        factory=self._build_query_bus,\n    )\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_dependency","title":"register_dependency","text":"<pre><code>register_dependency(\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a dependency with the application.</p> <p>This method will register a dependency with the application. All dependencies are registered as singletons and the provided factory will be used to create the dependency when it is resolved for the first time. If no factory is provided, the dependency will be resolved by calling the init method of the dependency type. Regardless of dependecies of that function will be resolved by the container.</p> PARAMETER DESCRIPTION <code>dependency_type</code> <p>The type to register</p> <p> TYPE: <code>type[T]</code> </p> <code>factory</code> <p>The factory function to create the dependency</p> <p> TYPE: <code>Callable[..., T] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_dependency(\n    self,\n    dependency_type: type[T],\n    factory: Callable[..., T] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a dependency with the application.\n\n    This method will register a dependency with the application.\n    All dependencies are registered as singletons and the provided\n    factory will be used to create the dependency when it is\n    resolved for the first time. If no factory is provided, the\n    dependency will be resolved by calling the __init__ method of\n    the dependency type. Regardless of dependecies of that function\n    will be resolved by the container.\n\n    Args:\n        dependency_type: The type to register\n        factory: The factory function to create the dependency\n\n    Returns:\n        The application builder\n    \"\"\"\n    self.container.register_singleton(dependency_type, factory or dependency_type)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_aggregate","title":"register_aggregate","text":"<pre><code>register_aggregate(\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: (\n        type[AggregateSnapshotStrategy] | None\n    ) = None,\n    cache_backend: (\n        type[AggregateCacheBackend] | None\n    ) = None,\n    snapshot_backend: (\n        type[AggregateSnapshotStorageBackend] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Add an aggregate to the application.</p> <p>This method will register an aggregate with the application. The aggregate will be registered with the application and will be available to be resolved. In addition to registering the aggregate, you can also configure related dependencies for the aggregate such as the cache and snapshot configurations.</p> <p>If the aggregate was already registered, this method will update the dependencies for the aggregate. Thefore it is fine to have multiple calls to this method for the same aggregate type.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The type of aggregate to add.</p> <p> TYPE: <code>type[Aggregate]</code> </p> <code>cache_strategy</code> <p>The type of cache strategy to use.</p> <p> TYPE: <code>type[CacheStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_strategy</code> <p>The type of snapshot strategy to use.</p> <p> TYPE: <code>type[AggregateSnapshotStrategy] | None</code> DEFAULT: <code>None</code> </p> <code>cache_backend</code> <p>The type of cache backend to use.</p> <p> TYPE: <code>type[AggregateCacheBackend] | None</code> DEFAULT: <code>None</code> </p> <code>snapshot_backend</code> <p>The type of snapshot backend to use.</p> <p> TYPE: <code>type[AggregateSnapshotStorageBackend] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_aggregate(\n    self,\n    aggregate_type: type[Aggregate],\n    cache_strategy: type[CacheStrategy] | None = None,\n    snapshot_strategy: type[AggregateSnapshotStrategy] | None = None,\n    cache_backend: type[AggregateCacheBackend] | None = None,\n    snapshot_backend: type[AggregateSnapshotStorageBackend] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Add an aggregate to the application.\n\n    This method will register an aggregate with the application. The\n    aggregate will be registered with the application and will be\n    available to be resolved. In addition to registering the aggregate,\n    you can also configure related dependencies for the aggregate such as\n    the cache and snapshot configurations.\n\n    If the aggregate was already registered, this method will update the\n    dependencies for the aggregate. Thefore it is fine to have\n    multiple calls to this method for the same aggregate type.\n\n    Args:\n        aggregate_type: The type of aggregate to add.\n        cache_strategy: The type of cache strategy to use.\n        snapshot_strategy: The type of snapshot strategy to use.\n        cache_backend: The type of cache backend to use.\n        snapshot_backend: The type of snapshot backend to use.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(aggregate_type)\n    container.register_singleton(AggregateFactory, lambda: AggregateFactory(aggregate_type))\n    container.register_singleton(Aggregate, aggregate_type)\n    container.register_singleton(AggregateRepository)\n    if cache_strategy:\n        container.register_singleton(\n            dependency_type=CacheStrategy,\n            factory=cache_strategy,\n        )\n    if snapshot_strategy:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStrategy,\n            factory=snapshot_strategy,\n        )\n    if cache_backend:\n        container.register_singleton(\n            dependency_type=AggregateCacheBackend,\n            factory=cache_backend,\n        )\n    if snapshot_backend:\n        container.register_singleton(\n            dependency_type=AggregateSnapshotStorageBackend,\n            factory=snapshot_backend,\n        )\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_middleware","title":"register_middleware","text":"<pre><code>register_middleware(\n    middleware_type: type[Middleware],\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register middleware with the application.</p> <p>This method will register middleware with the application. The middleware will be registered with the application and will be available to be resolved. Middleware uses annotation-based routing with @intercepts decorator to determine which commands or queries to intercept.</p> PARAMETER DESCRIPTION <code>middleware_type</code> <p>The type of middleware to register</p> <p> TYPE: <code>type[Middleware]</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_middleware(\n    self,\n    middleware_type: type[Middleware],\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register middleware with the application.\n\n    This method will register middleware with the application. The\n    middleware will be registered with the application and will be\n    available to be resolved. Middleware uses annotation-based routing\n    with @intercepts decorator to determine which commands or queries\n    to intercept.\n\n    Args:\n        middleware_type: The type of middleware to register\n\n    Returns:\n        The application builder.\n    \"\"\"\n    container = self.contextual_binding.container_for(middleware_type)\n    container.register_singleton(middleware_type)\n    container.register_singleton(Middleware, middleware_type)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_event_processor","title":"register_event_processor","text":"<pre><code>register_event_processor(\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Creates or updates the registration of an event processor.</p> <p>The processor will be registered with the application and will be avaiable to be resolved. In addition to registering the processor, you can also configure the processor's execution configuration via setting any of the relevant optional parameters on the CatchupCondition and CatchupStrategy objects.</p> PARAMETER DESCRIPTION <code>processor_type</code> <p>The type of the event processor to register</p> <p> TYPE: <code>type[EventProcessor]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_event_processor(\n    self,\n    processor_type: type[EventProcessor],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Creates or updates the registration of an event processor.\n\n    The processor will be registered with the application and will be\n    avaiable to be resolved. In addition to registering the processor,\n    you can also configure the processor's execution configuration\n    via setting any of the relevant optional parameters on the\n    CatchupCondition and CatchupStrategy objects.\n\n    Args:\n        processor_type: The type of the event processor to register\n        catchup_condition: The condition to trigger catchup\n        catchup_strategy: The strategy to use for catchup\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(processor_type)\n    container.register_singleton(processor_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_projection","title":"register_projection","text":"<pre><code>register_projection(\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register a projection with the application.</p> <p>Projections combine event handling (building read models) with query handling (serving reads). This method registers both capabilities.</p> <p>The projection will be available for: - Event processing via run_event_processors() - Query handling via Application.query()</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to register.</p> <p> TYPE: <code>type[Projection]</code> </p> <code>catchup_condition</code> <p>The condition to trigger catchup.</p> <p> TYPE: <code>CatchupCondition | None</code> DEFAULT: <code>None</code> </p> <code>catchup_strategy</code> <p>The strategy to use for catchup.</p> <p> TYPE: <code>CatchupStrategy | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_projection(\n    self,\n    projection_type: type[Projection],\n    catchup_condition: CatchupCondition | None = None,\n    catchup_strategy: CatchupStrategy | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register a projection with the application.\n\n    Projections combine event handling (building read models) with\n    query handling (serving reads). This method registers both\n    capabilities.\n\n    The projection will be available for:\n    - Event processing via run_event_processors()\n    - Query handling via Application.query()\n\n    Args:\n        projection_type: The projection class to register.\n        catchup_condition: The condition to trigger catchup.\n        catchup_strategy: The strategy to use for catchup.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    # Register as both a projection (for queries) and event processor\n    container = self.contextual_binding.container_for(projection_type)\n    container.register_singleton(projection_type)\n    container.register_singleton(Projection, projection_type)\n    container.register_singleton(EventProcessor, projection_type)\n    container.register_singleton(EventProcessorExecutor)\n    if catchup_condition:\n        container.register_singleton(CatchupCondition, lambda: catchup_condition)\n    if catchup_strategy:\n        container.register_singleton(CatchupStrategy, lambda: catchup_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.register_upcaster","title":"register_upcaster","text":"<pre><code>register_upcaster(\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: (\n        type[UpcastingStrategy] | None\n    ) = None,\n) -&gt; ApplicationBuilder\n</code></pre> <p>Register an upcaster with the application.</p> <p>This method will register an upcaster with the application. The upcaster will be registered with the application and will be available to be resolved. In addition to registering the upcaster, you can also configure the upcaster's upcasting strategy via setting the relevant optional parameter.</p> <p>If the upcaster was already registered, this method will update the upcasting strategy for the upcaster. Thefore it is fine to have multiple calls to this method for the same upcaster type.</p> PARAMETER DESCRIPTION <code>upcaster</code> <p>The type of the upcaster to register</p> <p> TYPE: <code>type[EventUpcaster[Any, Any]]</code> </p> <code>upcasting_strategy</code> <p>The type of the upcasting strategy to register</p> <p> TYPE: <code>type[UpcastingStrategy] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder</p> Source code in <code>interlock/application/application.py</code> <pre><code>def register_upcaster(\n    self,\n    upcaster: type[EventUpcaster[Any, Any]],\n    upcasting_strategy: type[UpcastingStrategy] | None = None,\n) -&gt; \"ApplicationBuilder\":\n    \"\"\"Register an upcaster with the application.\n\n    This method will register an upcaster with the application. The\n    upcaster will be registered with the application and will be available\n    to be resolved. In addition to registering the upcaster, you can also\n    configure the upcaster's upcasting strategy via setting the relevant\n    optional parameter.\n\n    If the upcaster was already registered, this method will update the\n    upcasting strategy for the upcaster. Thefore it is fine to have\n    multiple calls to this method for the same upcaster type.\n\n    Args:\n        upcaster: The type of the upcaster to register\n        upcasting_strategy: The type of the upcasting strategy to register\n\n    Returns:\n        The application builder\n    \"\"\"\n    container = self.contextual_binding.container_for(upcaster)\n    container.register_singleton(upcaster, upcaster)\n    if upcasting_strategy:\n        container.register_singleton(UpcastingStrategy, upcasting_strategy)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.convention_based","title":"convention_based","text":"<pre><code>convention_based(package_name: str) -&gt; ApplicationBuilder\n</code></pre> <p>Load aggregates, commands, etc from convention based modules.</p> <p>This method will load aggregates, commands, middleware, event processors, upcasters, configs, and services from a package based on the conventions of the package. The package will be scanned recursively for the relevant components.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>The name of the package to load components from.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>ApplicationBuilder</code> <p>The application builder.</p> Source code in <code>interlock/application/application.py</code> <pre><code>def convention_based(self, package_name: str) -&gt; \"ApplicationBuilder\":\n    \"\"\"Load aggregates, commands, etc from convention based modules.\n\n    This method will load aggregates, commands, middleware, event\n    processors, upcasters, configs, and services from a package based on\n    the conventions of the package. The package will be scanned\n    recursively for the relevant components.\n\n    Args:\n        package_name: The name of the package to load components from.\n\n    Returns:\n        The application builder.\n    \"\"\"\n    from .configurators import ApplicationProfile\n\n    for profile in ApplicationProfile.convention_based(package_name):\n        profile.configure(self)\n    return self\n</code></pre>"},{"location":"reference/application/application/#interlock.application.application.ApplicationBuilder.build","title":"build","text":"<pre><code>build() -&gt; Application\n</code></pre> <p>Build the application with dependency injection.</p> <p>This method will resolve all dependencies and return an Application instance. If any dependencies cannot be resolved, an error will be raised. The Application instance will be fully configured and ready to use.</p> RETURNS DESCRIPTION <code>Application</code> <p>The configured Application instance</p> RAISES DESCRIPTION <code>ValueError</code> <p>If dependencies cannot be resolved (missing, etc.)</p> Source code in <code>interlock/application/application.py</code> <pre><code>def build(self) -&gt; Application:\n    \"\"\"Build the application with dependency injection.\n\n    This method will resolve all dependencies and return an Application\n    instance. If any dependencies cannot be resolved, an error will be\n    raised. The Application instance will be fully configured and ready to\n    use.\n\n    Returns:\n        The configured Application instance\n\n    Raises:\n        ValueError: If dependencies cannot be resolved (missing, etc.)\n    \"\"\"\n    return Application(self.contextual_binding)\n</code></pre>"},{"location":"reference/application/configurators/","title":"configurators","text":""},{"location":"reference/application/configurators/#interlock.application.configurators","title":"configurators","text":""},{"location":"reference/application/configurators/#interlock.application.configurators.ApplicationProfile","title":"ApplicationProfile","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for application configuration profiles.</p> <p>Profiles encapsulate a set of configuration logic that can be applied to an ApplicationBuilder. This allows for reusable, composable configuration.</p>"},{"location":"reference/application/configurators/#interlock.application.configurators.ApplicationProfile.configure","title":"configure  <code>abstractmethod</code>","text":"<pre><code>configure(builder: ApplicationBuilder) -&gt; None\n</code></pre> <p>Apply this profile's configuration to the builder.</p> PARAMETER DESCRIPTION <code>builder</code> <p>ApplicationBuilder to configure</p> <p> TYPE: <code>ApplicationBuilder</code> </p> Source code in <code>interlock/application/configurators.py</code> <pre><code>@abstractmethod\ndef configure(self, builder: ApplicationBuilder) -&gt; None:\n    \"\"\"Apply this profile's configuration to the builder.\n\n    Args:\n        builder: ApplicationBuilder to configure\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/application/container/","title":"container","text":""},{"location":"reference/application/container/#interlock.application.container","title":"container","text":""},{"location":"reference/application/discovery/","title":"discovery","text":""},{"location":"reference/application/discovery/#interlock.application.discovery","title":"discovery","text":"<p>Module and class discovery utilities for convention-based configuration.</p> <p>This module provides tools to automatically scan Python packages and discover framework components like aggregates, commands, services, etc.</p>"},{"location":"reference/application/discovery/#interlock.application.discovery.ModuleScanner","title":"ModuleScanner","text":"<pre><code>ModuleScanner(package_name: str)\n</code></pre> <p>Recursively scan packages for Python modules.</p> <p>Handles various package structures: - Direct files: myapp/aggregates.py - Packages: myapp/aggregates/init.py - Nested packages: myapp/aggregates/banking/account.py (recursive)</p> <p>Automatically skips: - Test files (test_.py) - Private modules (_.py, except init.py)</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Fully qualified package name (e.g., \"myapp.domain\")</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ImportError</code> <p>If the package cannot be imported</p> Source code in <code>interlock/application/discovery.py</code> <pre><code>def __init__(self, package_name: str):\n    \"\"\"Initialize scanner for a package.\n\n    Args:\n        package_name: Fully qualified package name (e.g., \"myapp.domain\")\n\n    Raises:\n        ImportError: If the package cannot be imported\n    \"\"\"\n    self.package_name = package_name\n    self.root_module = importlib.import_module(package_name)\n</code></pre>"},{"location":"reference/application/discovery/#interlock.application.discovery.ModuleScanner.find_modules","title":"find_modules","text":"<pre><code>find_modules(subpackage: str) -&gt; Iterable[ModuleType]\n</code></pre> <p>Find all modules in a subpackage.</p> <p>Supports both singular and plural forms (e.g., 'aggregate' and 'aggregates'). Searches recursively through all subpackages.</p> PARAMETER DESCRIPTION <code>subpackage</code> <p>Name of subpackage to scan (e.g., \"aggregates\")</p> <p> TYPE: <code>str</code> </p> YIELDS DESCRIPTION <code>ModuleType</code> <p>Discovered modules</p> <p> TYPE:: <code>Iterable[ModuleType]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scanner = ModuleScanner(\"myapp\")\n&gt;&gt;&gt; for module in scanner.find_modules(\"aggregates\"):\n...     print(module.__name__)\nmyapp.aggregates.bank_account\nmyapp.aggregates.shopping_cart\n</code></pre> Source code in <code>interlock/application/discovery.py</code> <pre><code>def find_modules(self, subpackage: str) -&gt; Iterable[ModuleType]:\n    \"\"\"Find all modules in a subpackage.\n\n    Supports both singular and plural forms\n    (e.g., 'aggregate' and 'aggregates').\n    Searches recursively through all subpackages.\n\n    Args:\n        subpackage: Name of subpackage to scan (e.g., \"aggregates\")\n\n    Yields:\n        ModuleType: Discovered modules\n\n    Examples:\n        &gt;&gt;&gt; scanner = ModuleScanner(\"myapp\")\n        &gt;&gt;&gt; for module in scanner.find_modules(\"aggregates\"):\n        ...     print(module.__name__)\n        myapp.aggregates.bank_account\n        myapp.aggregates.shopping_cart\n    \"\"\"\n    for variant in _get_module_variants(subpackage):\n        module_path = f\"{self.package_name}.{variant}\"\n        module = _try_import_module(module_path)\n\n        if module is None:\n            continue\n\n        # Yield the module itself if it's not skippable\n        basename = module.__name__.split(\".\")[-1]\n        if not _should_skip_module(basename):\n            yield module\n\n        # If it's a package, recursively scan submodules\n        if hasattr(module, \"__path__\"):\n            yield from self._scan_package_recursive(module)\n</code></pre>"},{"location":"reference/application/discovery/#interlock.application.discovery.ModuleScanner.scan_all_modules","title":"scan_all_modules","text":"<pre><code>scan_all_modules() -&gt; Iterable[ModuleType]\n</code></pre> <p>Scan all non-private modules in the package recursively.</p> YIELDS DESCRIPTION <code>ModuleType</code> <p>All discovered modules</p> <p> TYPE:: <code>Iterable[ModuleType]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scanner = ModuleScanner(\"myapp\")\n&gt;&gt;&gt; for module in scanner.scan_all_modules():\n...     print(module.__name__)\n</code></pre> Source code in <code>interlock/application/discovery.py</code> <pre><code>def scan_all_modules(self) -&gt; Iterable[ModuleType]:\n    \"\"\"Scan all non-private modules in the package recursively.\n\n    Yields:\n        ModuleType: All discovered modules\n\n    Examples:\n        &gt;&gt;&gt; scanner = ModuleScanner(\"myapp\")\n        &gt;&gt;&gt; for module in scanner.scan_all_modules():\n        ...     print(module.__name__)\n    \"\"\"\n    yield self.root_module\n    yield from self._scan_package_recursive(self.root_module)\n</code></pre>"},{"location":"reference/application/discovery/#interlock.application.discovery.ClassScanner","title":"ClassScanner","text":"<p>Extract classes from modules by type.</p>"},{"location":"reference/application/discovery/#interlock.application.discovery.ClassScanner.find_subclasses","title":"find_subclasses  <code>staticmethod</code>","text":"<pre><code>find_subclasses(\n    module: ModuleType, base_class: type[T]\n) -&gt; Iterable[type[T]]\n</code></pre> <p>Find all subclasses of base_class in module.</p> <p>Filters out: - The base class itself - Abstract classes (with abstractmethod decorators) - Private classes (names starting with _) - Classes not defined in the module (imported from elsewhere)</p> PARAMETER DESCRIPTION <code>module</code> <p>Module to scan</p> <p> TYPE: <code>ModuleType</code> </p> <code>base_class</code> <p>Base class to find subclasses of</p> <p> TYPE: <code>type[T]</code> </p> YIELDS DESCRIPTION <code>Iterable[type[T]]</code> <p>type[T]: Subclasses of base_class</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; module = importlib.import_module(\"myapp.aggregates\")\n&gt;&gt;&gt; classes = ClassScanner.find_subclasses(module, Aggregate)\n&gt;&gt;&gt; for cls in classes:\n...     print(cls.__name__)\nBankAccount\nShoppingCart\n</code></pre> Source code in <code>interlock/application/discovery.py</code> <pre><code>@staticmethod\ndef find_subclasses(module: ModuleType, base_class: type[T]) -&gt; Iterable[type[T]]:\n    \"\"\"Find all subclasses of base_class in module.\n\n    Filters out:\n    - The base class itself\n    - Abstract classes (with abstractmethod decorators)\n    - Private classes (names starting with _)\n    - Classes not defined in the module (imported from elsewhere)\n\n    Args:\n        module: Module to scan\n        base_class: Base class to find subclasses of\n\n    Yields:\n        type[T]: Subclasses of base_class\n\n    Examples:\n        &gt;&gt;&gt; module = importlib.import_module(\"myapp.aggregates\")\n        &gt;&gt;&gt; classes = ClassScanner.find_subclasses(module, Aggregate)\n        &gt;&gt;&gt; for cls in classes:\n        ...     print(cls.__name__)\n        BankAccount\n        ShoppingCart\n    \"\"\"\n    for name, obj in inspect.getmembers(module, inspect.isclass):\n        if _should_include_subclass(obj, name, base_class, module):\n            yield obj\n</code></pre>"},{"location":"reference/application/discovery/#interlock.application.discovery.ClassScanner.find_all_classes","title":"find_all_classes  <code>staticmethod</code>","text":"<pre><code>find_all_classes(module: ModuleType) -&gt; Iterable[type]\n</code></pre> <p>Find all classes in module.</p> <p>Filters out: - Private classes (names starting with _) - Classes not defined in the module (imported from elsewhere)</p> PARAMETER DESCRIPTION <code>module</code> <p>Module to scan</p> <p> TYPE: <code>ModuleType</code> </p> YIELDS DESCRIPTION <code>type</code> <p>Classes defined in the module</p> <p> TYPE:: <code>Iterable[type]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; module = importlib.import_module(\"myapp.services\")\n&gt;&gt;&gt; for cls in ClassScanner.find_all_classes(module):\n...     print(cls.__name__)\nAuditService\nEmailService\n</code></pre> Source code in <code>interlock/application/discovery.py</code> <pre><code>@staticmethod\ndef find_all_classes(module: ModuleType) -&gt; Iterable[type]:\n    \"\"\"Find all classes in module.\n\n    Filters out:\n    - Private classes (names starting with _)\n    - Classes not defined in the module (imported from elsewhere)\n\n    Args:\n        module: Module to scan\n\n    Yields:\n        type: Classes defined in the module\n\n    Examples:\n        &gt;&gt;&gt; module = importlib.import_module(\"myapp.services\")\n        &gt;&gt;&gt; for cls in ClassScanner.find_all_classes(module):\n        ...     print(cls.__name__)\n        AuditService\n        EmailService\n    \"\"\"\n    for name, obj in inspect.getmembers(module, inspect.isclass):\n        if _should_include_class(obj, name, module):\n            yield obj\n</code></pre>"},{"location":"reference/application/discovery/#interlock.application.discovery.ClassScanner.get_registration_type","title":"get_registration_type  <code>staticmethod</code>","text":"<pre><code>get_registration_type() -&gt; type\n</code></pre> <p>Get the type to register a class as for dependency injection.</p> <p>Strategy: 1. Find first ABC or Protocol parent class (interface) 2. If none found, use the class itself (concrete type)</p> <p>This allows registering services by their interface rather than concrete implementation.</p> PARAMETER DESCRIPTION <code>cls</code> <p>Class to determine registration type for</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>type</code> <p>Type to use for DI registration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class IAuditService(ABC):\n...     pass\n&gt;&gt;&gt; class AuditService(IAuditService):\n...     pass\n&gt;&gt;&gt; ClassScanner.get_registration_type(AuditService)\n&lt;class 'IAuditService'&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; class ConcreteService:\n...     pass\n&gt;&gt;&gt; ClassScanner.get_registration_type(ConcreteService)\n&lt;class 'ConcreteService'&gt;\n</code></pre> Source code in <code>interlock/application/discovery.py</code> <pre><code>@staticmethod\ndef get_registration_type(cls: type) -&gt; type:\n    \"\"\"Get the type to register a class as for dependency injection.\n\n    Strategy:\n    1. Find first ABC or Protocol parent class (interface)\n    2. If none found, use the class itself (concrete type)\n\n    This allows registering services by their interface rather than\n    concrete implementation.\n\n    Args:\n        cls: Class to determine registration type for\n\n    Returns:\n        Type to use for DI registration\n\n    Examples:\n        &gt;&gt;&gt; class IAuditService(ABC):\n        ...     pass\n        &gt;&gt;&gt; class AuditService(IAuditService):\n        ...     pass\n        &gt;&gt;&gt; ClassScanner.get_registration_type(AuditService)\n        &lt;class 'IAuditService'&gt;\n\n        &gt;&gt;&gt; class ConcreteService:\n        ...     pass\n        &gt;&gt;&gt; ClassScanner.get_registration_type(ConcreteService)\n        &lt;class 'ConcreteService'&gt;\n    \"\"\"\n    # Get all base classes (excluding object)\n    bases = [base for base in inspect.getmro(cls) if base not in (cls, object)]\n\n    # Find first ABC or Protocol\n    for base in bases:\n        if inspect.isabstract(base) or getattr(base, \"_is_protocol\", False):\n            return base\n\n    # No interface found, use concrete type\n    return cls\n</code></pre>"},{"location":"reference/application/aggregates/","title":"aggregates","text":""},{"location":"reference/application/aggregates/#interlock.application.aggregates","title":"aggregates","text":"<p>Aggregate repository infrastructure.</p>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateCacheBackend","title":"AggregateCacheBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Mechanism for caching aggregates.</p> <p>A cache backend is resposible for store and retrieve aggregates from a cache. All operations are async to support I/O-bound cache backends like Redis or Memcached.</p>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateFactory","title":"AggregateFactory","text":"<pre><code>AggregateFactory(aggregate_type: type[A])\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>Factory for creating aggregate instances of a specific type.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(self, aggregate_type: type[A]):\n    self._aggregate_type = aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateFactory.get_type","title":"get_type","text":"<pre><code>get_type() -&gt; type[A]\n</code></pre> <p>Get the aggregate type this factory produces.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def get_type(self) -&gt; type[A]:\n    \"\"\"Get the aggregate type this factory produces.\"\"\"\n    return self._aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateFactory.create","title":"create","text":"<pre><code>create(aggregate_id: UUID) -&gt; A\n</code></pre> <p>Create a new aggregate instance with the given ID.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def create(self, aggregate_id: UUID) -&gt; A:\n    \"\"\"Create a new aggregate instance with the given ID.\"\"\"\n    return self._aggregate_type(id=aggregate_id)\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateRepository","title":"AggregateRepository","text":"<pre><code>AggregateRepository(\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n)\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>A mechanism for loading and saving aggregates in a consistent way.</p> <p>The aggregate repository only has one main public method, <code>acquire</code>. This encapsulates the entire lifecycle of an aggregate and performs the saving and loading of the aggregate from the event store.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(\n    self,\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n):\n    self.aggregate_type = aggregate_factory.get_type()\n    self.event_bus = event_bus\n    self.snapshot_strategy = snapshot_strategy\n    self.cache_strategy = cache_strategy\n    self.cache_backend = cache_backend\n    self.snapshot_backend = snapshot_backend\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateRepository.list_all_ids","title":"list_all_ids  <code>async</code>","text":"<pre><code>list_all_ids() -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of this repository's type.</p> <p>This queries the snapshot backend for all aggregates of the repository's type that have snapshots. It's primarily used by catchup strategies to discover which aggregates need to be processed.</p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs of this repository's type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist.</p> Example <p>user_repository = AggregateRepositoryUser user_ids = await user_repository.list_all_ids()</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>async def list_all_ids(self) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of this repository's type.\n\n    This queries the snapshot backend for all aggregates of the repository's\n    type that have snapshots. It's primarily used by catchup strategies to\n    discover which aggregates need to be processed.\n\n    Returns:\n        List of aggregate IDs of this repository's type.\n        Returns empty list if no snapshots exist.\n\n    Example:\n        &gt;&gt;&gt; user_repository = AggregateRepository[User](...)\n        &gt;&gt;&gt; user_ids = await user_repository.list_all_ids()\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    return await self.snapshot_backend.list_aggregate_ids_by_type(self.aggregate_type)\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateRepository.list_all_ids--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend","title":"AggregateSnapshotStorageBackend","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend.null","title":"null  <code>staticmethod</code>","text":"<pre><code>null() -&gt; AggregateSnapshotStorageBackend\n</code></pre> <p>A snapshot backend that does not store any snapshots.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@staticmethod\ndef null() -&gt; \"AggregateSnapshotStorageBackend\":\n    \"\"\"A snapshot backend that does not store any snapshots.\"\"\"\n    return NullAggregateSnapshotStorageBackend()\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend.save_snapshot","title":"save_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_snapshot(aggregate: Aggregate) -&gt; None\n</code></pre> <p>Save a snapshot of the aggregate.</p> <p>Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. If you only want to store one copy, you should overwrite the previous snapshot. If you choose to store multiple versions, you should store each snapshot in such a way that the latest snapshot can be retrieved quickly as that will be the most common operation.</p> PARAMETER DESCRIPTION <code>aggregate</code> <p>The aggregate to save.</p> <p> TYPE: <code>Aggregate</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def save_snapshot(self, aggregate: \"Aggregate\") -&gt; None:\n    \"\"\"Save a snapshot of the aggregate.\n\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. If you only want to\n    store one copy, you should overwrite the previous snapshot. If you choose to store\n    multiple versions, you should store each snapshot in such a way that the latest\n    snapshot can be retrieved quickly as that will be the most common operation.\n\n    Args:\n        aggregate (Aggregate): The aggregate to save.\n\n    Returns:\n        None\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend.load_snapshot","title":"load_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_snapshot(\n    aggregate_id: UUID, intended_version: int | None = None\n) -&gt; Optional[Aggregate]\n</code></pre> <p>Load a snapshot of the aggregate.</p> <p>If intended_version is provided, the snapshot must be at most that version. Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. if this is the case, you should return the latest snapshot if the intended_version is greater than or equal to the version of the snapshot stored. If not, return None. The system is able to handle the case where the snapshot is not the intended version by replaying all events.</p> <p>If you choose to store multiple versions, you should return the latest snapshot that is less than or equal to the intended_version. If the intended_version is None, return the latest snapshot. If there is no snapshot, return None.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The id of the aggregate to load.</p> <p> TYPE: <code>UUID</code> </p> <code>intended_version</code> <p>The intended version of the aggregate that is being loaded.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Aggregate]</code> <p>Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def load_snapshot(\n    self,\n    aggregate_id: UUID,\n    intended_version: int | None = None,\n) -&gt; Optional[\"Aggregate\"]:\n    \"\"\"Load a snapshot of the aggregate.\n\n    If intended_version is provided, the snapshot must be at most that version.\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. if this is the case,\n    you should return the latest snapshot if the intended_version is greater than or equal\n    to the version of the snapshot stored. If not, return None. The system is able to\n    handle the case where the snapshot is not the intended version by replaying all\n    events.\n\n    If you choose to store multiple versions, you should return the latest snapshot\n    that is less than or equal to the intended_version. If the intended_version is\n    None, return the latest snapshot. If there is no snapshot, return None.\n\n    Args:\n        aggregate_id (UUID): The id of the aggregate to load.\n        intended_version (Optional[int], optional): The intended version\n            of the aggregate that is being loaded.\n\n    Returns:\n        Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of a given type that have snapshots.</p> <p>This is used by catchup strategies to discover all aggregates of a particular type that need to be processed.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class type (e.g., User, Order)</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs that have snapshots for this type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist for this type.</p> Example <p>from app.aggregates import User user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of a given type that have snapshots.\n\n    This is used by catchup strategies to discover all aggregates of a\n    particular type that need to be processed.\n\n    Args:\n        aggregate_type: The aggregate class type (e.g., User, Order)\n\n    Returns:\n        List of aggregate IDs that have snapshots for this type.\n        Returns empty list if no snapshots exist for this type.\n\n    Example:\n        &gt;&gt;&gt; from app.aggregates import User\n        &gt;&gt;&gt; user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/#interlock.application.aggregates.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/repository/","title":"repository","text":""},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository","title":"repository","text":"<p>Repository infrastructure for aggregate persistence and caching.</p> <p>This package provides: - AggregateRepository: Core repository for loading/saving aggregates - Cache strategies and backends for aggregate caching - Snapshot strategies and backends for aggregate snapshots</p>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateCacheBackend","title":"AggregateCacheBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Mechanism for caching aggregates.</p> <p>A cache backend is resposible for store and retrieve aggregates from a cache. All operations are async to support I/O-bound cache backends like Redis or Memcached.</p>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateFactory","title":"AggregateFactory","text":"<pre><code>AggregateFactory(aggregate_type: type[A])\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>Factory for creating aggregate instances of a specific type.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(self, aggregate_type: type[A]):\n    self._aggregate_type = aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateFactory.get_type","title":"get_type","text":"<pre><code>get_type() -&gt; type[A]\n</code></pre> <p>Get the aggregate type this factory produces.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def get_type(self) -&gt; type[A]:\n    \"\"\"Get the aggregate type this factory produces.\"\"\"\n    return self._aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateFactory.create","title":"create","text":"<pre><code>create(aggregate_id: UUID) -&gt; A\n</code></pre> <p>Create a new aggregate instance with the given ID.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def create(self, aggregate_id: UUID) -&gt; A:\n    \"\"\"Create a new aggregate instance with the given ID.\"\"\"\n    return self._aggregate_type(id=aggregate_id)\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateRepository","title":"AggregateRepository","text":"<pre><code>AggregateRepository(\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n)\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>A mechanism for loading and saving aggregates in a consistent way.</p> <p>The aggregate repository only has one main public method, <code>acquire</code>. This encapsulates the entire lifecycle of an aggregate and performs the saving and loading of the aggregate from the event store.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(\n    self,\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n):\n    self.aggregate_type = aggregate_factory.get_type()\n    self.event_bus = event_bus\n    self.snapshot_strategy = snapshot_strategy\n    self.cache_strategy = cache_strategy\n    self.cache_backend = cache_backend\n    self.snapshot_backend = snapshot_backend\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateRepository.list_all_ids","title":"list_all_ids  <code>async</code>","text":"<pre><code>list_all_ids() -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of this repository's type.</p> <p>This queries the snapshot backend for all aggregates of the repository's type that have snapshots. It's primarily used by catchup strategies to discover which aggregates need to be processed.</p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs of this repository's type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist.</p> Example <p>user_repository = AggregateRepositoryUser user_ids = await user_repository.list_all_ids()</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>async def list_all_ids(self) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of this repository's type.\n\n    This queries the snapshot backend for all aggregates of the repository's\n    type that have snapshots. It's primarily used by catchup strategies to\n    discover which aggregates need to be processed.\n\n    Returns:\n        List of aggregate IDs of this repository's type.\n        Returns empty list if no snapshots exist.\n\n    Example:\n        &gt;&gt;&gt; user_repository = AggregateRepository[User](...)\n        &gt;&gt;&gt; user_ids = await user_repository.list_all_ids()\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    return await self.snapshot_backend.list_aggregate_ids_by_type(self.aggregate_type)\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateRepository.list_all_ids--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend","title":"AggregateSnapshotStorageBackend","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend.null","title":"null  <code>staticmethod</code>","text":"<pre><code>null() -&gt; AggregateSnapshotStorageBackend\n</code></pre> <p>A snapshot backend that does not store any snapshots.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@staticmethod\ndef null() -&gt; \"AggregateSnapshotStorageBackend\":\n    \"\"\"A snapshot backend that does not store any snapshots.\"\"\"\n    return NullAggregateSnapshotStorageBackend()\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend.save_snapshot","title":"save_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_snapshot(aggregate: Aggregate) -&gt; None\n</code></pre> <p>Save a snapshot of the aggregate.</p> <p>Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. If you only want to store one copy, you should overwrite the previous snapshot. If you choose to store multiple versions, you should store each snapshot in such a way that the latest snapshot can be retrieved quickly as that will be the most common operation.</p> PARAMETER DESCRIPTION <code>aggregate</code> <p>The aggregate to save.</p> <p> TYPE: <code>Aggregate</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def save_snapshot(self, aggregate: \"Aggregate\") -&gt; None:\n    \"\"\"Save a snapshot of the aggregate.\n\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. If you only want to\n    store one copy, you should overwrite the previous snapshot. If you choose to store\n    multiple versions, you should store each snapshot in such a way that the latest\n    snapshot can be retrieved quickly as that will be the most common operation.\n\n    Args:\n        aggregate (Aggregate): The aggregate to save.\n\n    Returns:\n        None\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend.load_snapshot","title":"load_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_snapshot(\n    aggregate_id: UUID, intended_version: int | None = None\n) -&gt; Optional[Aggregate]\n</code></pre> <p>Load a snapshot of the aggregate.</p> <p>If intended_version is provided, the snapshot must be at most that version. Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. if this is the case, you should return the latest snapshot if the intended_version is greater than or equal to the version of the snapshot stored. If not, return None. The system is able to handle the case where the snapshot is not the intended version by replaying all events.</p> <p>If you choose to store multiple versions, you should return the latest snapshot that is less than or equal to the intended_version. If the intended_version is None, return the latest snapshot. If there is no snapshot, return None.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The id of the aggregate to load.</p> <p> TYPE: <code>UUID</code> </p> <code>intended_version</code> <p>The intended version of the aggregate that is being loaded.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Aggregate]</code> <p>Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def load_snapshot(\n    self,\n    aggregate_id: UUID,\n    intended_version: int | None = None,\n) -&gt; Optional[\"Aggregate\"]:\n    \"\"\"Load a snapshot of the aggregate.\n\n    If intended_version is provided, the snapshot must be at most that version.\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. if this is the case,\n    you should return the latest snapshot if the intended_version is greater than or equal\n    to the version of the snapshot stored. If not, return None. The system is able to\n    handle the case where the snapshot is not the intended version by replaying all\n    events.\n\n    If you choose to store multiple versions, you should return the latest snapshot\n    that is less than or equal to the intended_version. If the intended_version is\n    None, return the latest snapshot. If there is no snapshot, return None.\n\n    Args:\n        aggregate_id (UUID): The id of the aggregate to load.\n        intended_version (Optional[int], optional): The intended version\n            of the aggregate that is being loaded.\n\n    Returns:\n        Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of a given type that have snapshots.</p> <p>This is used by catchup strategies to discover all aggregates of a particular type that need to be processed.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class type (e.g., User, Order)</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs that have snapshots for this type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist for this type.</p> Example <p>from app.aggregates import User user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of a given type that have snapshots.\n\n    This is used by catchup strategies to discover all aggregates of a\n    particular type that need to be processed.\n\n    Args:\n        aggregate_type: The aggregate class type (e.g., User, Order)\n\n    Returns:\n        List of aggregate IDs that have snapshots for this type.\n        Returns empty list if no snapshots exist for this type.\n\n    Example:\n        &gt;&gt;&gt; from app.aggregates import User\n        &gt;&gt;&gt; user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.InMemoryAggregateSnapshotStorageBackend","title":"InMemoryAggregateSnapshotStorageBackend","text":"<pre><code>InMemoryAggregateSnapshotStorageBackend()\n</code></pre> <p>               Bases: <code>AggregateSnapshotStorageBackend</code></p> <p>A snapshot backend that stores snapshots in memory.</p> <p>This is not intended for production use. It is intended for testing purposes only. However, It does support multiple versions of the same aggregate. It goes without saying that this is neither or persistent nor performant.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.snapshots: dict[UUID, list[Aggregate]] = defaultdict(list)\n</code></pre>"},{"location":"reference/application/aggregates/repository/#interlock.application.aggregates.repository.InMemoryAggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>List all aggregate IDs that have snapshots of the given type.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class to filter by</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs with snapshots of this type</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>async def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"List all aggregate IDs that have snapshots of the given type.\n\n    Args:\n        aggregate_type: The aggregate class to filter by\n\n    Returns:\n        List of aggregate IDs with snapshots of this type\n    \"\"\"\n    result = []\n    for aggregate_id, snapshot_list in self.snapshots.items():\n        if snapshot_list and isinstance(snapshot_list[0], aggregate_type):\n            result.append(aggregate_id)\n    return result\n</code></pre>"},{"location":"reference/application/aggregates/repository/cache/","title":"cache","text":""},{"location":"reference/application/aggregates/repository/cache/#interlock.application.aggregates.repository.cache","title":"cache","text":""},{"location":"reference/application/aggregates/repository/cache/#interlock.application.aggregates.repository.cache.AggregateCacheBackend","title":"AggregateCacheBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Mechanism for caching aggregates.</p> <p>A cache backend is resposible for store and retrieve aggregates from a cache. All operations are async to support I/O-bound cache backends like Redis or Memcached.</p>"},{"location":"reference/application/aggregates/repository/repository/","title":"repository","text":""},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository","title":"repository","text":""},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateFactory","title":"AggregateFactory","text":"<pre><code>AggregateFactory(aggregate_type: type[A])\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>Factory for creating aggregate instances of a specific type.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(self, aggregate_type: type[A]):\n    self._aggregate_type = aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateFactory.get_type","title":"get_type","text":"<pre><code>get_type() -&gt; type[A]\n</code></pre> <p>Get the aggregate type this factory produces.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def get_type(self) -&gt; type[A]:\n    \"\"\"Get the aggregate type this factory produces.\"\"\"\n    return self._aggregate_type\n</code></pre>"},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateFactory.create","title":"create","text":"<pre><code>create(aggregate_id: UUID) -&gt; A\n</code></pre> <p>Create a new aggregate instance with the given ID.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def create(self, aggregate_id: UUID) -&gt; A:\n    \"\"\"Create a new aggregate instance with the given ID.\"\"\"\n    return self._aggregate_type(id=aggregate_id)\n</code></pre>"},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateRepository","title":"AggregateRepository","text":"<pre><code>AggregateRepository(\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n)\n</code></pre> <p>               Bases: <code>Generic[A]</code></p> <p>A mechanism for loading and saving aggregates in a consistent way.</p> <p>The aggregate repository only has one main public method, <code>acquire</code>. This encapsulates the entire lifecycle of an aggregate and performs the saving and loading of the aggregate from the event store.</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>def __init__(\n    self,\n    aggregate_factory: AggregateFactory[A],\n    event_bus: EventBus,\n    snapshot_strategy: AggregateSnapshotStrategy,\n    cache_strategy: CacheStrategy,\n    snapshot_backend: AggregateSnapshotStorageBackend,\n    cache_backend: AggregateCacheBackend,\n):\n    self.aggregate_type = aggregate_factory.get_type()\n    self.event_bus = event_bus\n    self.snapshot_strategy = snapshot_strategy\n    self.cache_strategy = cache_strategy\n    self.cache_backend = cache_backend\n    self.snapshot_backend = snapshot_backend\n</code></pre>"},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateRepository.list_all_ids","title":"list_all_ids  <code>async</code>","text":"<pre><code>list_all_ids() -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of this repository's type.</p> <p>This queries the snapshot backend for all aggregates of the repository's type that have snapshots. It's primarily used by catchup strategies to discover which aggregates need to be processed.</p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs of this repository's type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist.</p> Example <p>user_repository = AggregateRepositoryUser user_ids = await user_repository.list_all_ids()</p> Source code in <code>interlock/application/aggregates/repository/repository.py</code> <pre><code>async def list_all_ids(self) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of this repository's type.\n\n    This queries the snapshot backend for all aggregates of the repository's\n    type that have snapshots. It's primarily used by catchup strategies to\n    discover which aggregates need to be processed.\n\n    Returns:\n        List of aggregate IDs of this repository's type.\n        Returns empty list if no snapshots exist.\n\n    Example:\n        &gt;&gt;&gt; user_repository = AggregateRepository[User](...)\n        &gt;&gt;&gt; user_ids = await user_repository.list_all_ids()\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    return await self.snapshot_backend.list_aggregate_ids_by_type(self.aggregate_type)\n</code></pre>"},{"location":"reference/application/aggregates/repository/repository/#interlock.application.aggregates.repository.repository.AggregateRepository.list_all_ids--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/repository/snapshot/","title":"snapshot","text":""},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot","title":"snapshot","text":""},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend","title":"AggregateSnapshotStorageBackend","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend.null","title":"null  <code>staticmethod</code>","text":"<pre><code>null() -&gt; AggregateSnapshotStorageBackend\n</code></pre> <p>A snapshot backend that does not store any snapshots.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@staticmethod\ndef null() -&gt; \"AggregateSnapshotStorageBackend\":\n    \"\"\"A snapshot backend that does not store any snapshots.\"\"\"\n    return NullAggregateSnapshotStorageBackend()\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend.save_snapshot","title":"save_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_snapshot(aggregate: Aggregate) -&gt; None\n</code></pre> <p>Save a snapshot of the aggregate.</p> <p>Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. If you only want to store one copy, you should overwrite the previous snapshot. If you choose to store multiple versions, you should store each snapshot in such a way that the latest snapshot can be retrieved quickly as that will be the most common operation.</p> PARAMETER DESCRIPTION <code>aggregate</code> <p>The aggregate to save.</p> <p> TYPE: <code>Aggregate</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def save_snapshot(self, aggregate: \"Aggregate\") -&gt; None:\n    \"\"\"Save a snapshot of the aggregate.\n\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. If you only want to\n    store one copy, you should overwrite the previous snapshot. If you choose to store\n    multiple versions, you should store each snapshot in such a way that the latest\n    snapshot can be retrieved quickly as that will be the most common operation.\n\n    Args:\n        aggregate (Aggregate): The aggregate to save.\n\n    Returns:\n        None\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend.load_snapshot","title":"load_snapshot  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_snapshot(\n    aggregate_id: UUID, intended_version: int | None = None\n) -&gt; Optional[Aggregate]\n</code></pre> <p>Load a snapshot of the aggregate.</p> <p>If intended_version is provided, the snapshot must be at most that version. Depending on the objectives of the implementer, you may choose to only store one copy of the aggregate as opposed to multiple versions. if this is the case, you should return the latest snapshot if the intended_version is greater than or equal to the version of the snapshot stored. If not, return None. The system is able to handle the case where the snapshot is not the intended version by replaying all events.</p> <p>If you choose to store multiple versions, you should return the latest snapshot that is less than or equal to the intended_version. If the intended_version is None, return the latest snapshot. If there is no snapshot, return None.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The id of the aggregate to load.</p> <p> TYPE: <code>UUID</code> </p> <code>intended_version</code> <p>The intended version of the aggregate that is being loaded.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Aggregate]</code> <p>Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def load_snapshot(\n    self,\n    aggregate_id: UUID,\n    intended_version: int | None = None,\n) -&gt; Optional[\"Aggregate\"]:\n    \"\"\"Load a snapshot of the aggregate.\n\n    If intended_version is provided, the snapshot must be at most that version.\n    Depending on the objectives of the implementer, you may choose to only store\n    one copy of the aggregate as opposed to multiple versions. if this is the case,\n    you should return the latest snapshot if the intended_version is greater than or equal\n    to the version of the snapshot stored. If not, return None. The system is able to\n    handle the case where the snapshot is not the intended version by replaying all\n    events.\n\n    If you choose to store multiple versions, you should return the latest snapshot\n    that is less than or equal to the intended_version. If the intended_version is\n    None, return the latest snapshot. If there is no snapshot, return None.\n\n    Args:\n        aggregate_id (UUID): The id of the aggregate to load.\n        intended_version (Optional[int], optional): The intended version\n            of the aggregate that is being loaded.\n\n    Returns:\n        Optional[Aggregate]: The aggregate snapshot if it exists, None otherwise.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of a given type that have snapshots.</p> <p>This is used by catchup strategies to discover all aggregates of a particular type that need to be processed.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class type (e.g., User, Order)</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs that have snapshots for this type.</p> <code>list[UUID]</code> <p>Returns empty list if no snapshots exist for this type.</p> Example <p>from app.aggregates import User user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>@abstractmethod\nasync def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of a given type that have snapshots.\n\n    This is used by catchup strategies to discover all aggregates of a\n    particular type that need to be processed.\n\n    Args:\n        aggregate_type: The aggregate class type (e.g., User, Order)\n\n    Returns:\n        List of aggregate IDs that have snapshots for this type.\n        Returns empty list if no snapshots exist for this type.\n\n    Example:\n        &gt;&gt;&gt; from app.aggregates import User\n        &gt;&gt;&gt; user_ids = await snapshot_backend.list_aggregate_ids_by_type(User)\n        &gt;&gt;&gt; # [UUID('...'), UUID('...'), ...]\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.AggregateSnapshotStorageBackend.list_aggregate_ids_by_type--uuid-uuid","title":"[UUID('...'), UUID('...'), ...]","text":""},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.NullAggregateSnapshotStorageBackend","title":"NullAggregateSnapshotStorageBackend","text":"<p>               Bases: <code>AggregateSnapshotStorageBackend</code></p> <p>A snapshot backend that does not store any snapshots.</p>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.NullAggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>No snapshots stored, so return empty list.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>async def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"No snapshots stored, so return empty list.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.InMemoryAggregateSnapshotStorageBackend","title":"InMemoryAggregateSnapshotStorageBackend","text":"<pre><code>InMemoryAggregateSnapshotStorageBackend()\n</code></pre> <p>               Bases: <code>AggregateSnapshotStorageBackend</code></p> <p>A snapshot backend that stores snapshots in memory.</p> <p>This is not intended for production use. It is intended for testing purposes only. However, It does support multiple versions of the same aggregate. It goes without saying that this is neither or persistent nor performant.</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.snapshots: dict[UUID, list[Aggregate]] = defaultdict(list)\n</code></pre>"},{"location":"reference/application/aggregates/repository/snapshot/#interlock.application.aggregates.repository.snapshot.InMemoryAggregateSnapshotStorageBackend.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>List all aggregate IDs that have snapshots of the given type.</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class to filter by</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs with snapshots of this type</p> Source code in <code>interlock/application/aggregates/repository/snapshot.py</code> <pre><code>async def list_aggregate_ids_by_type(self, aggregate_type: type[\"Aggregate\"]) -&gt; list[UUID]:\n    \"\"\"List all aggregate IDs that have snapshots of the given type.\n\n    Args:\n        aggregate_type: The aggregate class to filter by\n\n    Returns:\n        List of aggregate IDs with snapshots of this type\n    \"\"\"\n    result = []\n    for aggregate_id, snapshot_list in self.snapshots.items():\n        if snapshot_list and isinstance(snapshot_list[0], aggregate_type):\n            result.append(aggregate_id)\n    return result\n</code></pre>"},{"location":"reference/application/commands/","title":"commands","text":""},{"location":"reference/application/commands/#interlock.application.commands","title":"commands","text":"<p>Command bus and middleware infrastructure.</p>"},{"location":"reference/application/commands/#interlock.application.commands.CommandBus","title":"CommandBus","text":"<pre><code>CommandBus(\n    root_handler: DelegateToAggregate,\n    middleware: list[Middleware],\n)\n</code></pre> <p>Command bus for dispatching commands through middleware.</p> <p>The CommandBus manages the middleware chain and delegates commands to the appropriate aggregate for handling. Middleware is applied in registration order, with each middleware deciding via annotation- based routing whether to intercept a command.</p> PARAMETER DESCRIPTION <code>root_handler</code> <p>The final handler that delegates to aggregates.</p> <p> TYPE: <code>DelegateToAggregate</code> </p> <code>middleware</code> <p>List of middleware to apply (in order).</p> <p> TYPE: <code>list[Middleware]</code> </p> Source code in <code>interlock/application/commands/bus.py</code> <pre><code>def __init__(\n    self,\n    root_handler: DelegateToAggregate,\n    middleware: list[Middleware],\n):\n    self.root_handler = root_handler\n    self.middleware = middleware\n    # Build the middleware chain by reducing from right to left\n    self.chain: Callable[[Command[Any]], Coroutine[Any, Any, Any]] = reduce(\n        lambda next, mw: lambda cmd, n=next, m=mw: m.intercept(cmd, n),\n        reversed(middleware),\n        self.root_handler.handle,\n    )\n</code></pre>"},{"location":"reference/application/commands/#interlock.application.commands.CommandBus.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(command: Command[T]) -&gt; T\n</code></pre> <p>Dispatch command through the middleware chain to handler.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to dispatch.</p> <p> TYPE: <code>Command[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/commands/bus.py</code> <pre><code>async def dispatch(self, command: Command[T]) -&gt; T:\n    \"\"\"Dispatch command through the middleware chain to handler.\n\n    Args:\n        command: The command to dispatch.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    return await self.chain(command)\n</code></pre>"},{"location":"reference/application/commands/bus/","title":"bus","text":""},{"location":"reference/application/commands/bus/#interlock.application.commands.bus","title":"bus","text":"<p>Command bus and routing infrastructure.</p>"},{"location":"reference/application/commands/bus/#interlock.application.commands.bus.CommandBus","title":"CommandBus","text":"<pre><code>CommandBus(\n    root_handler: DelegateToAggregate,\n    middleware: list[Middleware],\n)\n</code></pre> <p>Command bus for dispatching commands through middleware.</p> <p>The CommandBus manages the middleware chain and delegates commands to the appropriate aggregate for handling. Middleware is applied in registration order, with each middleware deciding via annotation- based routing whether to intercept a command.</p> PARAMETER DESCRIPTION <code>root_handler</code> <p>The final handler that delegates to aggregates.</p> <p> TYPE: <code>DelegateToAggregate</code> </p> <code>middleware</code> <p>List of middleware to apply (in order).</p> <p> TYPE: <code>list[Middleware]</code> </p> Source code in <code>interlock/application/commands/bus.py</code> <pre><code>def __init__(\n    self,\n    root_handler: DelegateToAggregate,\n    middleware: list[Middleware],\n):\n    self.root_handler = root_handler\n    self.middleware = middleware\n    # Build the middleware chain by reducing from right to left\n    self.chain: Callable[[Command[Any]], Coroutine[Any, Any, Any]] = reduce(\n        lambda next, mw: lambda cmd, n=next, m=mw: m.intercept(cmd, n),\n        reversed(middleware),\n        self.root_handler.handle,\n    )\n</code></pre>"},{"location":"reference/application/commands/bus/#interlock.application.commands.bus.CommandBus.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(command: Command[T]) -&gt; T\n</code></pre> <p>Dispatch command through the middleware chain to handler.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to dispatch.</p> <p> TYPE: <code>Command[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/commands/bus.py</code> <pre><code>async def dispatch(self, command: Command[T]) -&gt; T:\n    \"\"\"Dispatch command through the middleware chain to handler.\n\n    Args:\n        command: The command to dispatch.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    return await self.chain(command)\n</code></pre>"},{"location":"reference/application/events/","title":"events","text":""},{"location":"reference/application/events/#interlock.application.events","title":"events","text":"<p>Event sourcing infrastructure for interlock.</p> <p>This package provides the core event sourcing components: - EventStore: Durable event persistence - EventBus: Coordinates persistence, upcasting, and delivery - EventTransport: Real-time event delivery to subscribers - EventProcessor: Process events and maintain read models - Upcasting: Event schema evolution support</p>"},{"location":"reference/application/events/#interlock.application.events.EventBus","title":"EventBus","text":"<pre><code>EventBus(\n    store: EventStore,\n    delivery: EventDelivery,\n    upcasting_pipeline: UpcastingPipeline,\n)\n</code></pre> <p>Coordinates event persistence, upcasting, and delivery.</p> <p>EventBus is the main entry point for publishing and loading events in the event sourcing infrastructure. It orchestrates:</p> <ol> <li>Upcasting: Transforms events to correct schema versions (via pipeline)</li> <li>Persistence: Durably stores events (via EventStore)</li> <li>Delivery: Delivers events to processors (via EventDelivery)</li> </ol> <p>The bus ensures events flow through the upcasting pipeline in both directions - events are upcasted when written (eager strategy) and when read (lazy strategy) based on the configured UpcastingPipeline.</p> <p>Event delivery is controlled by the EventDelivery strategy: - SynchronousDelivery: Processors execute immediately during publish_events() - AsynchronousDelivery: Processors consume via subscriptions (run_event_processors())</p> <p>The delivery strategy determines architectural trade-offs between simplicity (synchronous) and scalability (asynchronous with separate processor execution).</p> PARAMETER DESCRIPTION <code>store</code> <p>Persistent storage for event sourcing</p> <p> TYPE: <code>EventStore</code> </p> <code>delivery</code> <p>Delivery strategy for executing processors</p> <p> TYPE: <code>EventDelivery</code> </p> <code>upcasting_pipeline</code> <p>Pipeline for event schema evolution</p> <p> TYPE: <code>UpcastingPipeline</code> </p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>def __init__(\n    self,\n    store: EventStore,\n    delivery: EventDelivery,\n    upcasting_pipeline: UpcastingPipeline,\n):\n    \"\"\"Initialize the event bus with its dependencies.\n\n    Args:\n        store: Persistent storage for event sourcing\n        delivery: Delivery strategy for executing processors\n        upcasting_pipeline: Pipeline for event schema evolution\n    \"\"\"\n    self.store = store\n    self.delivery = delivery\n    self.upcasting_pipeline = upcasting_pipeline\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventBus.publish_events","title":"publish_events  <code>async</code>","text":"<pre><code>publish_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Publish events to storage and deliver to processors.</p> <p>This method coordinates the full event publishing flow: 1. Upcast events to target versions (based on strategy) 2. Persist events to the event store (with optimistic locking) 3. Deliver events to processors (based on delivery strategy)</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to publish, typically from an aggregate's uncommitted_events after handling a command.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>The aggregate version before these events, used for optimistic concurrency control.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If another process modified the aggregate (expected_version doesn't match current version in store).</p> <code>Exception</code> <p>Any exception raised by the delivery strategy. For SynchronousDelivery, processor errors will fail the command.</p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>async def publish_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Publish events to storage and deliver to processors.\n\n    This method coordinates the full event publishing flow:\n    1. Upcast events to target versions (based on strategy)\n    2. Persist events to the event store (with optimistic locking)\n    3. Deliver events to processors (based on delivery strategy)\n\n    Args:\n        events: List of events to publish, typically from an aggregate's\n            uncommitted_events after handling a command.\n        expected_version: The aggregate version before these events,\n            used for optimistic concurrency control.\n\n    Raises:\n        ConcurrencyError: If another process modified the aggregate\n            (expected_version doesn't match current version in store).\n        Exception: Any exception raised by the delivery strategy.\n            For SynchronousDelivery, processor errors will fail the command.\n    \"\"\"\n    upcasted_events = await self.upcasting_pipeline.write_upcast(events)\n    await self.store.save_events(upcasted_events, expected_version)\n    await self.delivery.deliver(upcasted_events)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventBus.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events from storage with schema evolution applied.</p> <p>This method coordinates event loading: 1. Retrieve events from the event store 2. Upcast events to current schema versions (based on strategy) 3. Optionally rewrite upcasted events back to store (eager migration) 4. Return complete Event objects ready for aggregate reconstruction</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>Unique identifier of the aggregate to load events for</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum event sequence number to load (inclusive). Use 0 to load all events, or snapshot_version + 1 to load only events after a snapshot.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of complete Event objects in sequence order, upcasted to</p> <code>list[Event[Any]]</code> <p>current schema versions, including all metadata (timestamp, etc.).</p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events from storage with schema evolution applied.\n\n    This method coordinates event loading:\n    1. Retrieve events from the event store\n    2. Upcast events to current schema versions (based on strategy)\n    3. Optionally rewrite upcasted events back to store (eager migration)\n    4. Return complete Event objects ready for aggregate reconstruction\n\n    Args:\n        aggregate_id: Unique identifier of the aggregate to load events for\n        min_version: Minimum event sequence number to load (inclusive).\n            Use 0 to load all events, or snapshot_version + 1 to load\n            only events after a snapshot.\n\n    Returns:\n        List of complete Event objects in sequence order, upcasted to\n        current schema versions, including all metadata (timestamp, etc.).\n    \"\"\"\n    events = await self.store.load_events(aggregate_id, min_version)\n    upcasted_events = await self.upcasting_pipeline.read_upcast(events)\n\n    # Gradual migration: rewrite events that were upcasted\n    if self.upcasting_pipeline.upcasting_strategy.should_rewrite_on_load():\n        # Find events whose data type changed (i.e., were actually upcasted)\n        changed_events = [\n            upcasted\n            for original, upcasted in zip(events, upcasted_events, strict=True)\n            if type(original.data) is not type(upcasted.data)\n        ]\n        if changed_events:\n            await self.store.rewrite_events(changed_events)\n\n    return upcasted_events\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AsynchronousDelivery","title":"AsynchronousDelivery","text":"<pre><code>AsynchronousDelivery(transport: EventTransport)\n</code></pre> <p>               Bases: <code>EventDelivery</code></p> <p>Asynchronous event delivery via transport subscriptions.</p> <p>This strategy only publishes events to the transport. Processors run separately by consuming events via subscriptions (typically in separate processes or async tasks via Application.run_event_processors()).</p> <p>Characteristics: - Processors execute independently from command handling - Command latency is minimal (just publish to transport) - Processor failures don't affect command success - Scalable deployment (processors can run in separate containers) - Eventual consistency</p> <p>Use cases: - Production microservice architectures - High-throughput systems - When scaling read and write sides independently - When using external message brokers (Kafka, RabbitMQ)</p> Example <p>transport = KafkaEventTransport(brokers=[\"localhost:9092\"]) delivery = AsynchronousDelivery(transport) await delivery.deliver(events)  # Just publishes</p> PARAMETER DESCRIPTION <code>transport</code> <p>Event transport for publishing and subscriptions</p> <p> TYPE: <code>EventTransport</code> </p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>def __init__(self, transport: EventTransport):\n    \"\"\"Initialize asynchronous delivery.\n\n    Args:\n        transport: Event transport for publishing and subscriptions\n    \"\"\"\n    self.transport = transport\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AsynchronousDelivery--separate-process","title":"Separate process:","text":"<p>subscription = await delivery.subscribe(\"all\") event = await subscription.next() await processor.handle(event.data)</p>"},{"location":"reference/application/events/#interlock.application.events.AsynchronousDelivery.deliver","title":"deliver  <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events to transport without executing processors.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>Processors will consume these events via subscriptions created through subscribe().</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events to transport without executing processors.\n\n    Args:\n        events: Events to deliver\n\n    Note:\n        Processors will consume these events via subscriptions\n        created through subscribe().\n    \"\"\"\n    await self.transport.publish_events(events)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AsynchronousDelivery.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create subscription for consuming events asynchronously.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription from the transport</p> Note <p>This is how processors consume events when using Application.run_event_processors().</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create subscription for consuming events asynchronously.\n\n    Args:\n        identifier: Stream identifier\n\n    Returns:\n        EventSubscription from the transport\n\n    Note:\n        This is how processors consume events when using\n        Application.run_event_processors().\n    \"\"\"\n    return await self.transport.subscribe(identifier)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventDelivery","title":"EventDelivery","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract strategy for delivering events to processors.</p> <p>EventDelivery orchestrates both: 1. Publishing events to transport infrastructure (for durability and subscriptions) 2. Executing processors according to synchronous or asynchronous strategy</p> <p>Implementations: - SynchronousDelivery: Publishes to transport + executes processors immediately - AsynchronousDelivery: Publishes to transport only (processors consume via subscriptions)</p>"},{"location":"reference/application/events/#interlock.application.events.EventDelivery.deliver","title":"deliver  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Deliver events according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver to processors</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>The implementation determines whether processors execute immediately (synchronous) or later via subscriptions (asynchronous).</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>@abstractmethod\nasync def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Deliver events according to the strategy.\n\n    Args:\n        events: Events to deliver to processors\n\n    Note:\n        The implementation determines whether processors execute immediately\n        (synchronous) or later via subscriptions (asynchronous).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventDelivery.subscribe","title":"subscribe  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription for consuming events asynchronously.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier (aggregate ID, event type, or \"all\")</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription for consuming events from the transport</p> Note <p>Used by Application.run_event_processors() to consume events in a separate process or async task.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>@abstractmethod\nasync def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription for consuming events asynchronously.\n\n    Args:\n        identifier: Stream identifier (aggregate ID, event type, or \"all\")\n\n    Returns:\n        EventSubscription for consuming events from the transport\n\n    Note:\n        Used by Application.run_event_processors() to consume events\n        in a separate process or async task.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SynchronousDelivery","title":"SynchronousDelivery","text":"<pre><code>SynchronousDelivery(\n    transport: EventTransport,\n    processors: list[EventProcessor],\n)\n</code></pre> <p>               Bases: <code>EventDelivery</code></p> <p>Synchronous event delivery with immediate processor execution.</p> <p>This strategy publishes events to the transport (for any subscriptions) and immediately executes all registered processors synchronously during the publish_events() call.</p> <p>Characteristics: - Processors execute in the same transaction/process as command handling - Command latency includes all processor execution time - Processor failures cause command to fail - Simple deployment model (single process) - Immediate consistency</p> <p>Use cases: - Simple monolithic applications - Prototyping and development - When immediate consistency is required - When processors are fast and reliable</p> Example <p>transport = InMemoryEventTransport() processors = [MyProcessor()] delivery = SynchronousDelivery(transport, processors) await delivery.deliver(events)  # Processors execute immediately</p> PARAMETER DESCRIPTION <code>transport</code> <p>Event transport for publishing and subscriptions</p> <p> TYPE: <code>EventTransport</code> </p> <code>processors</code> <p>List of processors to execute immediately</p> <p> TYPE: <code>list[EventProcessor]</code> </p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>def __init__(self, transport: EventTransport, processors: list[EventProcessor]):\n    \"\"\"Initialize synchronous delivery.\n\n    Args:\n        transport: Event transport for publishing and subscriptions\n        processors: List of processors to execute immediately\n    \"\"\"\n    self.transport = transport\n    self.processors = processors\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SynchronousDelivery.deliver","title":"deliver  <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events and execute processors immediately.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RAISES DESCRIPTION <code>Exception</code> <p>Any exceptions raised by processors will propagate to the caller.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events and execute processors immediately.\n\n    Args:\n        events: Events to deliver\n\n    Raises:\n        Exception: Any exceptions raised by processors will propagate to\n            the caller.\n    \"\"\"\n    # Publish to transport (for any subscriptions)\n    await self.transport.publish_events(events)\n\n    # Execute all processors immediately\n    for event in events:\n        for processor in self.processors:\n            await processor.handle(event.data)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SynchronousDelivery.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create subscription to the underlying transport.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription from the transport</p> Note <p>While synchronous delivery executes processors immediately, the transport still supports subscriptions for testing or alternative consumption patterns.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create subscription to the underlying transport.\n\n    Args:\n        identifier: Stream identifier\n\n    Returns:\n        EventSubscription from the transport\n\n    Note:\n        While synchronous delivery executes processors immediately,\n        the transport still supports subscriptions for testing or\n        alternative consumption patterns.\n    \"\"\"\n    return await self.transport.subscribe(identifier)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AfterNAge","title":"AfterNAge","text":"<pre><code>AfterNAge(age: timedelta)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when average event age exceeds threshold.</p> <p>This condition triggers based on event staleness, not backlog size. It's useful for ensuring timely processing and data freshness.</p> PARAMETER DESCRIPTION <code>age</code> <p>Maximum acceptable average event age</p> <p> TYPE: <code>timedelta</code> </p> Example PARAMETER DESCRIPTION <code>age</code> <p>Maximum average event age before triggering catchup</p> <p> TYPE: <code>timedelta</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, age: timedelta):\n    \"\"\"Initialize with age threshold.\n\n    Args:\n        age: Maximum average event age before triggering catchup\n    \"\"\"\n    if age.total_seconds() &lt;= 0:\n        raise ValueError(\"Age threshold must be positive\")\n    self.age = age\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AfterNAge--trigger-catchup-if-events-are-5-minutes-old-on-average","title":"Trigger catchup if events are &gt; 5 minutes old on average","text":"<p>condition = AfterNAge(timedelta(minutes=5)) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/#interlock.application.events.AfterNAge.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if average event age exceeds threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.average_event_age &gt; age</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if average event age exceeds threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.average_event_age &gt; age\n    \"\"\"\n    return lag.average_age_is_older_than(self.age)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AfterNEvents","title":"AfterNEvents","text":"<pre><code>AfterNEvents(n: int)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when unprocessed event count exceeds threshold.</p> <p>This condition triggers based on backlog volume, not event age. It's useful for preventing unbounded queue growth.</p> PARAMETER DESCRIPTION <code>n</code> <p>Maximum number of unprocessed events before triggering catchup</p> <p> TYPE: <code>int</code> </p> Example PARAMETER DESCRIPTION <code>n</code> <p>Unprocessed event count threshold (must be &gt; 0)</p> <p> TYPE: <code>int</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, n: int):\n    \"\"\"Initialize with event count threshold.\n\n    Args:\n        n: Unprocessed event count threshold (must be &gt; 0)\n    \"\"\"\n    if n &lt;= 0:\n        raise ValueError(\"Threshold must be positive\")\n    self.n = n\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AfterNEvents--trigger-catchup-if-more-than-10000-events-are-queued","title":"Trigger catchup if more than 10,000 events are queued","text":"<p>condition = AfterNEvents(10_000) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/#interlock.application.events.AfterNEvents.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if unprocessed events exceed threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.unprocessed_events &gt; n</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if unprocessed events exceed threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.unprocessed_events &gt; n\n    \"\"\"\n    return lag.unprocessed_events_is_greater_than(self.n)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AllOf","title":"AllOf","text":"<pre><code>AllOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup only if ALL given conditions are met (AND logic).</p> <p>This allows combining multiple conditions where all conditions must be true to trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AllOf--catchup-only-if-queue-1000-and-events-5min-old","title":"Catchup only if queue &gt; 1000 AND events &gt; 5min old","text":"<p>condition = AllOf( ...     AfterNEvents(1000), ...     AfterNAge(timedelta(minutes=5)) ... )</p>"},{"location":"reference/application/events/#interlock.application.events.AllOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if all conditions are satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if all conditions return True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if all conditions are satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if all conditions return True\n    \"\"\"\n    return all(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AnyOf","title":"AnyOf","text":"<pre><code>AnyOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup if ANY of the given conditions are met (OR logic).</p> <p>This allows combining multiple conditions where any single condition being true will trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.AnyOf--catchup-if-either-queue-5000-or-events-10min-old","title":"Catchup if EITHER queue &gt; 5000 OR events &gt; 10min old","text":"<p>condition = AnyOf( ...     AfterNEvents(5000), ...     AfterNAge(timedelta(minutes=10)) ... )</p>"},{"location":"reference/application/events/#interlock.application.events.AnyOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if any condition is satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if any condition returns True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if any condition is satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if any condition returns True\n    \"\"\"\n    return any(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.CatchupCondition","title":"CatchupCondition","text":"<p>               Bases: <code>ABC</code></p> <p>Condition for triggering catchup operations based on lag metrics.</p> <p>CatchupConditions evaluate processor lag to determine when catchup strategies should be executed. They can be combined using AnyOf/AllOf to create complex triggering logic.</p> <p>Common patterns: - Never: Disable catchup entirely - AfterNEvents: Trigger when backlog exceeds threshold - AfterNAge: Trigger when events get too old - AnyOf/AllOf: Combine multiple conditions with OR/AND logic</p>"},{"location":"reference/application/events/#interlock.application.events.CatchupCondition.should_catchup","title":"should_catchup  <code>abstractmethod</code>","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Evaluate whether catchup should be triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics for the processor</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if catchup should be initiated, False otherwise</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>@abstractmethod\ndef should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Evaluate whether catchup should be triggered.\n\n    Args:\n        lag: Current lag metrics for the processor\n\n    Returns:\n        True if catchup should be initiated, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.CatchupResult","title":"CatchupResult  <code>dataclass</code>","text":"<pre><code>CatchupResult(skip_before: datetime | None = None)\n</code></pre> <p>Result from catchup operation with skip window for avoiding double-processing.</p> <p>When a catchup strategy processes historical data (e.g., loading snapshots), those events have already been incorporated into the processor's state. To avoid processing them again when the executor resumes from the subscription, we need to skip events up to a certain timestamp.</p> ATTRIBUTE DESCRIPTION <code>skip_before</code> <p>Events with timestamp &lt;= this value should be skipped. None means no skipping is needed.</p> <p> TYPE: <code>datetime | None</code> </p> Example"},{"location":"reference/application/events/#interlock.application.events.CatchupResult--catchup-loaded-aggregates-up-to-2025-01-01-100000","title":"Catchup loaded aggregates up to 2025-01-01 10:00:00","text":"<p>result = CatchupResult(skip_before=datetime(2025, 1, 1, 10, 0, 0))</p>"},{"location":"reference/application/events/#interlock.application.events.CatchupResult--executor-checks-each-event","title":"Executor checks each event","text":"<p>if result.should_skip(event): ...     continue  # Already processed via snapshot else: ...     await processor.handle(event.data)  # Process normally</p>"},{"location":"reference/application/events/#interlock.application.events.CatchupResult.should_skip","title":"should_skip","text":"<pre><code>should_skip(event: Event) -&gt; bool\n</code></pre> <p>Check if an event should be skipped (already processed during catchup).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if event.timestamp &lt;= skip_before (already processed),</p> <code>bool</code> <p>False if event should be processed normally</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>def should_skip(self, event: \"Event\") -&gt; bool:\n    \"\"\"Check if an event should be skipped (already processed during catchup).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if event.timestamp &lt;= skip_before (already processed),\n        False if event should be processed normally\n    \"\"\"\n    if self.skip_before is None:\n        return False\n    return event.timestamp &lt;= self.skip_before\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.CatchupStrategy","title":"CatchupStrategy","text":"<p>               Bases: <code>ABC</code>, <code>Generic[P]</code></p> <p>Strategy for catching up an event processor with the event store.</p> <p>Event processors can fall behind the write model when: - They cannot keep up with the event publication rate - They are created after events have already been published - They experience downtime or processing delays</p> <p>Different catchup strategies offer trade-offs between: - Speed: How quickly the processor catches up - Resource usage: Compute and memory requirements - Consistency: Guarantees about event ordering and completeness - Applicability: Which scenarios the strategy works for</p>"},{"location":"reference/application/events/#interlock.application.events.CatchupStrategy.catchup","title":"catchup  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; CatchupResult | None\n</code></pre> <p>Execute the catchup strategy to synchronize with the event store.</p> <p>This method is invoked: - When the processor is first started - When the associated CatchupCondition is met during runtime</p> <p>Implementations should: - Load necessary state to bring the processor up to date - Handle errors gracefully (network issues, missing data, etc.) - Track progress to resume from failures</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor instance to catch up</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>CatchupResult if events should be skipped, None otherwise</p> RAISES DESCRIPTION <code>Exception</code> <p>Implementation-specific exceptions for catchup failures.</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>@abstractmethod\nasync def catchup(self, processor: P) -&gt; CatchupResult | None:\n    \"\"\"Execute the catchup strategy to synchronize with the event store.\n\n    This method is invoked:\n    - When the processor is first started\n    - When the associated CatchupCondition is met during runtime\n\n    Implementations should:\n    - Load necessary state to bring the processor up to date\n    - Handle errors gracefully (network issues, missing data, etc.)\n    - Track progress to resume from failures\n\n    Args:\n        processor: The event processor instance to catch up\n\n    Returns:\n        CatchupResult if events should be skipped, None otherwise\n\n    Raises:\n        Exception: Implementation-specific exceptions for catchup failures.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessor","title":"EventProcessor","text":"<p>Base class for building read models and handling events (CQRS read side).</p> <p>EventProcessors consume events from the event bus and use them to: 1. Build read models - Denormalized views optimized for queries 2. Execute side effects - Send emails, update search indexes, etc. 3. Coordinate sagas - Multi-step business processes</p> <p>In CQRS, processors are the read side that react to events published by the write side (aggregates). They ensure eventual consistency between the write model and read models.</p> <p>How it works: Subclass EventProcessor and use the @handles_event decorator to declare which events the processor is interested in. interlock automatically: - Sets up event routing based on type annotations - Dispatches events to the appropriate handler methods - Manages subscriptions and delivery</p> <p>Event Routing: The @handles_event decorator uses type annotations to determine routing: - Handler parameter type declares which event to handle - Multiple handlers can be defined for different event types - Routing is set up automatically during class definition</p> <p>Execution: Processors run via EventProcessorExecutor, which: - Subscribes to the event stream - Batches events for efficiency - Monitors lag and triggers catchup when needed - Handles errors and retries</p> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Class-level routing table (set by init_subclass)</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock.routing import handles_event</p> <p>class OrderPlaced(BaseModel): ...     order_id: str ...     customer_email: str ...     total_amount: float</p> <p>class OrderCancelled(BaseModel): ...     order_id: str ...     reason: str</p> <p>class EmailNotificationProcessor(EventProcessor): ...     '''Send emails when orders are placed or cancelled.''' ... ...     @handles_event ...     async def on_order_placed(self, event: OrderPlaced) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order confirmed! Total: ${event.total_amount}\" ...         ) ... ...     @handles_event ...     async def on_order_cancelled(self, event: OrderCancelled) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order cancelled: {event.reason}\" ...         ) ... ...     async def send_email(self, to: str, message: str) -&gt; None: ...         # Email sending implementation ...         pass</p> See Also <ul> <li>EventProcessorExecutor: Runtime execution engine</li> <li>@handles_event: Decorator for registering event handlers</li> <li>CatchupStrategy: Strategies for initializing processor state</li> <li>CatchupCondition: Triggers for catchup operations</li> </ul>"},{"location":"reference/application/events/#interlock.application.events.EventProcessor--run-the-processor","title":"Run the processor","text":"<p>executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"orders\"), ...     processor=EmailNotificationProcessor(), ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... ) await executor.run()  # Process events continuously</p>"},{"location":"reference/application/events/#interlock.application.events.EventProcessor.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event routing table when subclass is defined.</p> <p>This is called automatically when a class inherits from EventProcessor. It scans the class for @handles_event decorated methods and builds a routing table based on their type annotations.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>Additional keyword arguments passed to super().init_subclass</p> <p> TYPE: <code>object</code> DEFAULT: <code>{}</code> </p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event routing table when subclass is defined.\n\n    This is called automatically when a class inherits from EventProcessor.\n    It scans the class for @handles_event decorated methods and builds\n    a routing table based on their type annotations.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to super().__init_subclass__\n    \"\"\"\n    super().__init_subclass__(**kwargs)\n    cls._event_router = setup_event_handling(cls)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessor.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(event: Event[BaseModel] | BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered handler method.</p> <p>This is called by EventProcessorExecutor for each event. It uses the routing table to find the appropriate handler method based on the event type and invokes it.</p> <p>Handlers can receive either: - Just the event payload (annotated as <code>def handle(self, event: MyEvent)</code>) - The full Event wrapper (annotated as <code>def handle(self, event: Event[MyEvent])</code>)</p> <p>This method is async to support async event handler methods. If the handler method returns a coroutine, it will be properly awaited.</p> PARAMETER DESCRIPTION <code>event</code> <p>Either the Event wrapper or just the payload. When called from EventProcessorExecutor, this is the full Event wrapper. The router will pass the appropriate value to handlers based on their type annotation.</p> <p> TYPE: <code>Event[BaseModel] | BaseModel</code> </p> RETURNS DESCRIPTION <code>object</code> <p>The return value of the handler method (typically None)</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no handler is registered for the event type</p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>async def handle(self, event: Event[BaseModel] | BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered handler method.\n\n    This is called by EventProcessorExecutor for each event. It uses\n    the routing table to find the appropriate handler method based on\n    the event type and invokes it.\n\n    Handlers can receive either:\n    - Just the event payload (annotated as `def handle(self, event: MyEvent)`)\n    - The full Event wrapper (annotated as `def handle(self, event: Event[MyEvent])`)\n\n    This method is async to support async event handler methods. If the\n    handler method returns a coroutine, it will be properly awaited.\n\n    Args:\n        event: Either the Event wrapper or just the payload.\n            When called from EventProcessorExecutor, this is the full\n            Event wrapper. The router will pass the appropriate value\n            to handlers based on their type annotation.\n\n    Returns:\n        The return value of the handler method (typically None)\n\n    Raises:\n        KeyError: If no handler is registered for the event type\n    \"\"\"\n    # Determine if we got a wrapped Event or just a payload\n    if isinstance(event, Event):\n        # Route based on the payload type, but pass the wrapper to handlers that want it\n        result = self._event_router.route(self, event.data, event_wrapper=event)\n    else:\n        # Just a payload (backward compatibility / testing)\n        result = self._event_router.route(self, event)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessorExecutor","title":"EventProcessorExecutor","text":"<pre><code>EventProcessorExecutor(\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n)\n</code></pre> <p>               Bases: <code>Generic[P]</code></p> <p>Runtime execution engine for event processors.</p> <p>EventProcessorExecutor manages the continuous processing of events by: 1. Subscribing to an event stream via EventSubscription 2. Batching events for efficient processing 3. Monitoring processor lag (backlog and event age) 4. Triggering catchup strategies when conditions are met</p> <p>This is the \"event loop\" that drives event processors. It runs continuously, pulling events from the subscription and routing them to the processor's handlers.</p> <p>Batching: Events are processed in batches to improve throughput. After each batch, lag metrics are calculated to determine if catchup is needed.</p> <p>Lag Monitoring: After each batch, the executor measures: - Unprocessed events (subscription depth) - Average event age (time from event.timestamp to processing)</p> <p>Catchup Triggering: If the CatchupCondition evaluates to True, the CatchupStrategy is executed. Blocking strategies pause event processing; non-blocking strategies run concurrently.</p> ATTRIBUTE DESCRIPTION <code>subscription</code> <p>Event stream to consume from</p> <p> </p> <code>processor</code> <p>Event processor with handler methods</p> <p> </p> <code>condition</code> <p>Condition for triggering catchup</p> <p> </p> <code>strategy</code> <p>Strategy for catching up when triggered</p> <p> </p> <code>batch_size</code> <p>Number of events to process before checking lag</p> <p> </p> Note <p>The run() method runs indefinitely until interrupted. Use asyncio task cancellation or exception handling to stop it gracefully.</p> PARAMETER DESCRIPTION <code>processor</code> <p>Processor with event handlers</p> <p> TYPE: <code>P</code> </p> <code>condition</code> <p>When to trigger catchup</p> <p> TYPE: <code>CatchupCondition</code> </p> <code>strategy</code> <p>How to catch up when triggered</p> <p> TYPE: <code>CatchupStrategy[P]</code> </p> <code>batch_size</code> <p>Events to process per batch (must be &gt; 0)</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If batch_size &lt;= 0</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>def __init__(\n    self,\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n) -&gt; None:\n    \"\"\"Initialize the executor with its dependencies.\n\n    Args:\n        processor: Processor with event handlers\n        condition: When to trigger catchup\n        strategy: How to catch up when triggered\n        batch_size: Events to process per batch (must be &gt; 0)\n\n    Raises:\n        ValueError: If batch_size &lt;= 0\n    \"\"\"\n    if batch_size &lt;= 0:\n        raise ValueError(\"batch_size must be positive\")\n    self.processor = processor\n    self.condition = condition\n    self.strategy = strategy\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessorExecutor.process_event_batch","title":"process_event_batch  <code>async</code>","text":"<pre><code>process_event_batch(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta\n</code></pre> <p>Process a batch of events and calculate average event age.</p> <p>Pulls batch_size events from the subscription, routes each to the processor's handlers, and calculates the mean age of processed events.</p> <p>If a catchup_result is provided, events in the skip window are skipped to avoid double-processing events that were already incorporated during catchup.</p> <p>For each event, the execution context is restored from the event metadata before processing, allowing processors to: - Access correlation/causation IDs for logging - Dispatch new commands with proper context inheritance - Track the causal chain in sagas and process managers</p> <p>The context is cleared after each event to prevent leakage.</p> PARAMETER DESCRIPTION <code>subscription</code> <p>The subscription to pull events from.</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>The skip window from catchup operation (Optional)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>timedelta</code> <p>Average time between event.timestamp and processing time</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions raised by event handlers.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_event_batch(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta:\n    \"\"\"Process a batch of events and calculate average event age.\n\n    Pulls batch_size events from the subscription, routes each to the\n    processor's handlers, and calculates the mean age of processed events.\n\n    If a catchup_result is provided, events in the skip window are skipped\n    to avoid double-processing events that were already incorporated during\n    catchup.\n\n    For each event, the execution context is restored from the event\n    metadata before processing, allowing processors to:\n    - Access correlation/causation IDs for logging\n    - Dispatch new commands with proper context inheritance\n    - Track the causal chain in sagas and process managers\n\n    The context is cleared after each event to prevent leakage.\n\n    Args:\n        subscription: The subscription to pull events from.\n        catchup_result: The skip window from catchup operation (Optional)\n\n    Returns:\n        Average time between event.timestamp and processing time\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions raised by event handlers.\n    \"\"\"\n    total_lag_time = timedelta()\n    events_processed = 0\n\n    for _ in range(self.batch_size):\n        event = await subscription.next()\n        total_lag_time += utc_now() - event.timestamp\n\n        # Skip events in the skip window (already processed during catchup)\n        if catchup_result and catchup_result.should_skip(event):\n            continue\n\n        events_processed += 1\n\n        # Restore context from event metadata before processing\n        # This allows event processors to dispatch commands with proper\n        # causation\n        context_set = False\n        if event.correlation_id is not None:\n            ctx = ExecutionContext(\n                correlation_id=event.correlation_id,\n                causation_id=event.id,\n                command_id=None,\n            )\n            set_context(ctx)\n            context_set = True\n\n        try:\n            # Pass full event - processor.handle will extract payload for routing\n            # but pass wrapper to handlers that want it (annotated with Event[T])\n            await self.processor.handle(event)\n        finally:\n            # Clear context only if we set it to prevent leakage\n            if context_set:\n                clear_context()\n\n    # If we didn't process any events, avoid division by zero\n    if events_processed == 0:\n        return timedelta()\n\n    return total_lag_time / events_processed\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessorExecutor.process_batch_and_check_catchup","title":"process_batch_and_check_catchup  <code>async</code>","text":"<pre><code>process_batch_and_check_catchup(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None\n</code></pre> <p>Process a batch, measure lag, and trigger catchup if needed.</p> <p>This method encapsulates one iteration of the main event loop: 1. Process a batch of events 2. Measure lag (average age + unprocessed count) 3. Clear skip window after first batch post-catchup 4. Trigger catchup if condition is met</p> PARAMETER DESCRIPTION <code>subscription</code> <p>Event subscription to pull from</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>Skip window from previous catchup (if any)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>New catchup result if catchup was triggered, None otherwise</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_batch_and_check_catchup(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None:\n    \"\"\"Process a batch, measure lag, and trigger catchup if needed.\n\n    This method encapsulates one iteration of the main event loop:\n    1. Process a batch of events\n    2. Measure lag (average age + unprocessed count)\n    3. Clear skip window after first batch post-catchup\n    4. Trigger catchup if condition is met\n\n    Args:\n        subscription: Event subscription to pull from\n        catchup_result: Skip window from previous catchup (if any)\n\n    Returns:\n        New catchup result if catchup was triggered, None otherwise\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Process batch and measure lag\n    average_event_age = await self.process_event_batch(\n        subscription=subscription,\n        catchup_result=catchup_result,\n    )\n    lag = Lag(\n        average_event_age=average_event_age,\n        unprocessed_events=await subscription.depth(),\n    )\n\n    # Clear skip window after first batch (one-time use)\n    # The skip window prevents double-processing events that were\n    # already incorporated during the catchup operation\n    new_catchup_result = None\n\n    # Trigger catchup if condition met\n    if self.condition.should_catchup(lag):\n        new_catchup_result = await self.strategy.catchup(self.processor)\n\n    return new_catchup_result\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventProcessorExecutor.run","title":"run  <code>async</code>","text":"<pre><code>run(subscription: EventSubscription) -&gt; None\n</code></pre> <p>Run the event processing loop continuously.</p> <p>This method runs indefinitely, processing events in batches and triggering catchup when the condition is met. It will only stop if: - The subscription ends (StopAsyncIteration) - An unhandled exception is raised - The async task is cancelled</p> <p>The method performs initial catchup at startup, then enters the main processing loop. If catchup returns a skip window, events in that window are skipped until we encounter an event beyond the window.</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>When subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def run(self, subscription: EventSubscription) -&gt; None:\n    \"\"\"Run the event processing loop continuously.\n\n    This method runs indefinitely, processing events in batches and\n    triggering catchup when the condition is met. It will only stop\n    if:\n    - The subscription ends (StopAsyncIteration)\n    - An unhandled exception is raised\n    - The async task is cancelled\n\n    The method performs initial catchup at startup, then enters the main\n    processing loop. If catchup returns a skip window, events in that\n    window are skipped until we encounter an event beyond the window.\n\n    Raises:\n        StopAsyncIteration: When subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Execute initial catchup at startup\n    catchup_result = await self.strategy.catchup(self.processor)\n\n    while True:\n        catchup_result = await self.process_batch_and_check_catchup(\n            subscription=subscription,\n            catchup_result=catchup_result,\n        )\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemorySagaStateStore","title":"InMemorySagaStateStore","text":"<pre><code>InMemorySagaStateStore()\n</code></pre> <p>               Bases: <code>SagaStateStore</code></p> <p>In-memory saga state store for development and testing.</p> <p>Mirrors InMemoryAggregateSnapshotStorageBackend pattern. Not intended for production use - state is lost on restart.</p> Example <p>store = InMemorySagaStateStore()</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._states: dict[str, BaseModel] = {}\n    self._completed_steps: dict[str, set[str]] = {}\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemorySagaStateStore--save-state","title":"Save state","text":"<p>state = CheckoutState(order_id=\"order-1\", status=\"started\") await store.save(\"order-1\", state)</p>"},{"location":"reference/application/events/#interlock.application.events.InMemorySagaStateStore--load-state","title":"Load state","text":"<p>loaded = await store.load(\"order-1\") assert loaded.order_id == \"order-1\"</p>"},{"location":"reference/application/events/#interlock.application.events.InMemorySagaStateStore--mark-step-complete","title":"Mark step complete","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is True</p>"},{"location":"reference/application/events/#interlock.application.events.InMemorySagaStateStore--check-idempotency","title":"Check idempotency","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is False  # Already complete</p>"},{"location":"reference/application/events/#interlock.application.events.Never","title":"Never","text":"<p>               Bases: <code>CatchupCondition</code></p> <p>Never trigger catchup - disable catchup entirely.</p> <p>Use this when: - Processor only handles new events (no historical state) - Catchup is managed manually or externally - Testing scenarios where catchup is not needed</p> Example <p>executor = EventProcessorExecutor( ...     subscription=subscription, ...     processor=processor, ...     condition=Never(),  # Catchup disabled ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/#interlock.application.events.Never.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Always returns False - catchup never triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Lag metrics (ignored)</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>False</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Always returns False - catchup never triggered.\n\n    Args:\n        lag: Lag metrics (ignored)\n\n    Returns:\n        False\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.NoCatchup","title":"NoCatchup","text":"<p>               Bases: <code>CatchupStrategy</code></p> <p>No catchup - processor starts from current position.</p> <p>Use this strategy when: - The processor only needs to handle new events (not historical) - Historical state is not required for the read model - Testing scenarios where catchup is not needed</p> Example"},{"location":"reference/application/events/#interlock.application.events.NoCatchup--notification-processor-that-only-sends-for-new-events","title":"Notification processor that only sends for new events","text":"<p>processor = NotificationProcessor() executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"notifications\"), ...     processor=processor, ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/#interlock.application.events.NoCatchup.catchup","title":"catchup  <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; None\n</code></pre> <p>No-op - no catchup is performed.</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor (ignored)</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None - no skip window needed</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>async def catchup(self, processor: P) -&gt; None:\n    \"\"\"No-op - no catchup is performed.\n\n    Args:\n        processor: The event processor (ignored)\n\n    Returns:\n        None - no skip window needed\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.Saga","title":"Saga","text":"<pre><code>Saga(state_store: SagaStateStore)\n</code></pre> <p>               Bases: <code>EventProcessor</code>, <code>Generic[TState]</code></p> <p>Base class for stateful sagas with automatic state management.</p> <p>Extends EventProcessor with: - Automatic state persistence via SagaStateStore - Step-level idempotency tracking - Type-safe state access through generics - Automatic event routing via @saga_step decorator</p> <p>Sagas coordinate long-running business processes that span multiple aggregates. They handle compensation (rollback) when steps fail and ensure each step only executes once (idempotency).</p> <p>The Saga class is generic over TState for type safety, but the underlying SagaStateStore works with any BaseModel (like EventStore).</p> <p>Handler Patterns: - First step: Returns initial state - Subsequent steps: Receives and returns modified state - Cleanup steps: Returns None to delete state</p> Example <p>from interlock.application.events import ( ...     Saga, saga_step, SagaStateStore ... ) from pydantic import BaseModel</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False ...     payment_charged: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, state_store: SagaStateStore): ...         super().init(state_store) ... ...     @saga_step  # Step name auto-inferred from function name ...     async def on_checkout_initiated( ...         self, event: CheckoutInitiated ...     ) -&gt; CheckoutState: ...         # First step - return initial state ...         return CheckoutState( ...             order_id=event.saga_id, status=\"started\" ...         ) ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_inventory_reserved( ...         self, event: InventoryReserved, state: CheckoutState ...     ) -&gt; CheckoutState: ...         # Subsequent step - modify and return state ...         state.inventory_reserved = True ...         state.status = \"inventory_reserved\" ...         return state ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_payment_charged( ...         self, event: PaymentCharged, state: CheckoutState ...     ) -&gt; CheckoutState: ...         state.payment_charged = True ...         state.status = \"completed\" ...         return state ... ...     @saga_step ...     async def on_order_cancelled( ...         self, event: OrderCancelled, state: CheckoutState ...     ) -&gt; None: ...         # Cleanup - return None to delete state ...         return None</p> Usage with ApplicationBuilder PARAMETER DESCRIPTION <code>state_store</code> <p>Storage backend for saga state</p> <p> TYPE: <code>SagaStateStore</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self, state_store: SagaStateStore):\n    \"\"\"Initialize saga with state store.\n\n    Args:\n        state_store: Storage backend for saga state\n    \"\"\"\n    super().__init__()\n    self.state_store = state_store\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.Saga--saga-is-just-an-eventprocessor-no-special-handling-needed","title":"Saga is just an EventProcessor - no special handling needed!","text":"<p>app = (ApplicationBuilder() ...     .add_dependency(SagaStateStore, InMemorySagaStateStore()) ...     .add_event_processor(CheckoutSaga) ...     .build())</p>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore","title":"SagaStateStore","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract storage backend for saga state.</p> <p>Similar to AggregateSnapshotStorageBackend but for saga state. Not generic - works with any Pydantic BaseModel state type.</p> <p>Sagas are long-running business processes that coordinate multiple aggregates and handle compensation (rollback) when things fail. This store provides persistent state management for sagas.</p> Example <p>from interlock.events.processing import Saga, SagaStateStore</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, app: Application, state_store: SagaStateStore): ...         super().init(state_store) ...         self.app = app</p>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore--use-in-memory-store-for-development","title":"Use in-memory store for development","text":"<p>store = SagaStateStore.in_memory() saga = CheckoutSaga(app, store)</p>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.in_memory","title":"in_memory  <code>staticmethod</code>","text":"<pre><code>in_memory() -&gt; SagaStateStore\n</code></pre> <p>Create in-memory state store for development/testing.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@staticmethod\ndef in_memory() -&gt; \"SagaStateStore\":\n    \"\"\"Create in-memory state store for development/testing.\"\"\"\n    return InMemorySagaStateStore()\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.load","title":"load  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load(saga_id: str) -&gt; BaseModel | None\n</code></pre> <p>Load saga state by ID.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseModel | None</code> <p>The saga state if found, None otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def load(self, saga_id: str) -&gt; BaseModel | None:\n    \"\"\"Load saga state by ID.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n\n    Returns:\n        The saga state if found, None otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.save","title":"save  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save(saga_id: str, state: BaseModel) -&gt; None\n</code></pre> <p>Save saga state.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>state</code> <p>The state to save (any Pydantic BaseModel)</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def save(self, saga_id: str, state: BaseModel) -&gt; None:\n    \"\"\"Save saga state.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        state: The state to save (any Pydantic BaseModel)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(saga_id: str) -&gt; None\n</code></pre> <p>Delete saga state (cleanup after completion).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def delete(self, saga_id: str) -&gt; None:\n    \"\"\"Delete saga state (cleanup after completion).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.mark_step_complete","title":"mark_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>mark_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Mark a saga step as completed (for idempotency).</p> <p>This ensures that saga steps only execute once, even if the same event is processed multiple times (e.g., due to retries).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to mark complete</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if newly marked, False if already complete</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def mark_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Mark a saga step as completed (for idempotency).\n\n    This ensures that saga steps only execute once, even if the\n    same event is processed multiple times (e.g., due to retries).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to mark complete\n\n    Returns:\n        True if newly marked, False if already complete\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.SagaStateStore.is_step_complete","title":"is_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>is_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Check if a saga step has been completed.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if step is complete, False otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def is_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Check if a saga step has been completed.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to check\n\n    Returns:\n        True if step is complete, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventStore","title":"EventStore","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for durable event persistence.</p> <p>EventStore provides the foundation for event sourcing by persisting events as an immutable, append-only log. Each aggregate's events form a stream that can be replayed to reconstruct aggregate state.</p> <p>Key responsibilities: - Durability: Events survive system failures - Ordering: Events are stored and retrieved in sequence - Concurrency Control: Optimistic locking via expected_version - Immutability: Events cannot be modified after storage</p>"},{"location":"reference/application/events/#interlock.application.events.EventStore.save_events","title":"save_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Persist events to the event store with optimistic concurrency control.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to persist. Each event includes metadata (id, aggregate_id, sequence_number, timestamp) and typed data.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>The version the aggregate is expected to be at before these events are appended. Used for optimistic locking.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version in the store (another process modified the aggregate).</p> Note <p>Events are appended atomically - either all events are saved or none are. The store assigns sequence numbers starting from expected_version + 1.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Persist events to the event store with optimistic concurrency control.\n\n    Args:\n        events: List of events to persist. Each event includes metadata\n            (id, aggregate_id, sequence_number, timestamp) and typed data.\n        expected_version: The version the aggregate is expected to be at\n            before these events are appended. Used for optimistic locking.\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current\n            version in the store (another process modified the aggregate).\n\n    Note:\n        Events are appended atomically - either all events are saved or\n        none are. The store assigns sequence numbers starting from\n        expected_version + 1.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventStore.load_events","title":"load_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate from the event store.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The unique identifier of the aggregate whose events should be loaded.</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>The minimum sequence number to load (inclusive). Use 0 to load all events, or a snapshot version to load only events after the snapshot.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events in sequence order. Events may have been upcasted</p> <code>list[Event[Any]]</code> <p>to newer schema versions by the store implementation.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate from the event store.\n\n    Args:\n        aggregate_id: The unique identifier of the aggregate whose\n            events should be loaded.\n        min_version: The minimum sequence number to load (inclusive).\n            Use 0 to load all events, or a snapshot version to load\n            only events after the snapshot.\n\n    Returns:\n        List of events in sequence order. Events may have been upcasted\n        to newer schema versions by the store implementation.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventStore.rewrite_events","title":"rewrite_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place for schema migration.</p> <p>This method updates existing events in the store with new data, typically after upcasting. It's used by the EagerUpcastingStrategy to gradually migrate the event store to new schemas.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to rewrite. Each event's aggregate_id and sequence_number identify which stored event to update. The event data (and potentially type) may have changed.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>This operation intentionally modifies historical events. Use with caution as it breaks strict event immutability. The event's id, aggregate_id, sequence_number, and timestamp should remain unchanged; only the data payload is updated.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place for schema migration.\n\n    This method updates existing events in the store with new data,\n    typically after upcasting. It's used by the EagerUpcastingStrategy\n    to gradually migrate the event store to new schemas.\n\n    Args:\n        events: Events to rewrite. Each event's aggregate_id and\n            sequence_number identify which stored event to update.\n            The event data (and potentially type) may have changed.\n\n    Note:\n        This operation intentionally modifies historical events.\n        Use with caution as it breaks strict event immutability.\n        The event's id, aggregate_id, sequence_number, and timestamp\n        should remain unchanged; only the data payload is updated.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventStore","title":"InMemoryEventStore","text":"<pre><code>InMemoryEventStore()\n</code></pre> <p>               Bases: <code>EventStore</code></p> <p>Dictionary-based in-memory event store for testing.</p> <p>Stores events in a dictionary keyed by aggregate ID. Each aggregate's events are kept in a list ordered by sequence number.</p> <p>This implementation is suitable for: - Unit tests (fast, no external dependencies) - Development and experimentation - Examples and documentation</p> <p>NOT suitable for production due to: - No durability (data lost on restart) - No optimistic concurrency control (no version checking) - No transaction support (partial writes possible on errors) - Memory usage grows unbounded - No distributed coordination</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize an empty in-memory event store.\"\"\"\n    self.by_aggregate_id: dict[UUID, list[Event[Any]]] = defaultdict(list)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventStore.save_events","title":"save_events  <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Append events to the aggregate's event list with version checking.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to store, typically from an aggregate's uncommitted events</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>Expected current version - must match actual version</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Append events to the aggregate's event list with version checking.\n\n    Args:\n        events: Events to store, typically from an aggregate's uncommitted events\n        expected_version: Expected current version - must match actual version\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current version\n    \"\"\"\n    if not events:\n        return\n\n    aggregate_id = events[0].aggregate_id\n\n    # Check current version matches expected\n    current_events = self.by_aggregate_id[aggregate_id]\n    current_version = current_events[-1].sequence_number if current_events else 0\n\n    if current_version != expected_version:\n        raise ConcurrencyError(f\"Expected version {expected_version}, got {current_version}\")\n\n    # Version matches, safe to append events\n    for event in events:\n        self.by_aggregate_id[aggregate_id].append(event)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventStore.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate starting from a minimum version.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The aggregate whose events to load</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum sequence number (inclusive). Use 0 for all events.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events with sequence_number &gt;= min_version, in order.</p> <code>list[Event[Any]]</code> <p>Returns empty list if aggregate has no events.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate starting from a minimum version.\n\n    Args:\n        aggregate_id: The aggregate whose events to load\n        min_version: Minimum sequence number (inclusive). Use 0 for all events.\n\n    Returns:\n        List of events with sequence_number &gt;= min_version, in order.\n        Returns empty list if aggregate has no events.\n    \"\"\"\n    return [\n        event\n        for event in self.by_aggregate_id[aggregate_id]\n        if event.sequence_number &gt;= min_version\n    ]\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventStore.rewrite_events","title":"rewrite_events  <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place.</p> <p>Updates events in the in-memory store by matching aggregate_id and sequence_number.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events with updated data to write back.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place.\n\n    Updates events in the in-memory store by matching aggregate_id\n    and sequence_number.\n\n    Args:\n        events: Events with updated data to write back.\n    \"\"\"\n    for event in events:\n        stream = self.by_aggregate_id[event.aggregate_id]\n        # Find and replace the event at this sequence number\n        for i, stored_event in enumerate(stream):\n            if stored_event.sequence_number == event.sequence_number:\n                stream[i] = event\n                break\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventSubscription","title":"EventSubscription","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for consuming events from an event stream.</p> <p>EventSubscription provides an async iterator-like interface for reading events from a specific stream or aggregate. Implementations handle backpressure, buffering, and ordering guarantees.</p> <p>This is typically used for: - Read model projections (updating query databases) - Process managers (saga coordination) - Event processors (side effects, notifications)</p>"},{"location":"reference/application/events/#interlock.application.events.EventSubscription.depth","title":"depth  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>depth() -&gt; int\n</code></pre> <p>Get the number of unread events available in the subscription.</p> RETURNS DESCRIPTION <code>int</code> <p>The count of events that can be consumed without blocking.</p> <code>int</code> <p>Returns 0 if no events are currently available.</p> Note <p>This is a snapshot value - the depth may change as new events are published to the stream.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def depth(self) -&gt; int:\n    \"\"\"Get the number of unread events available in the subscription.\n\n    Returns:\n        The count of events that can be consumed without blocking.\n        Returns 0 if no events are currently available.\n\n    Note:\n        This is a snapshot value - the depth may change as new events\n        are published to the stream.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventSubscription.next","title":"next  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>next() -&gt; Event[Any]\n</code></pre> <p>Retrieve the next event from the subscription.</p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The next event in the stream, advancing the subscription position.</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>When the subscription has been closed or the stream has ended.</p> Note <p>This method may block if no events are currently available but the subscription is still active. Use depth() to check availability before calling if non-blocking behavior is required.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def next(self) -&gt; Event[Any]:\n    \"\"\"Retrieve the next event from the subscription.\n\n    Returns:\n        The next event in the stream, advancing the subscription position.\n\n    Raises:\n        StopAsyncIteration: When the subscription has been closed or\n            the stream has ended.\n\n    Note:\n        This method may block if no events are currently available but\n        the subscription is still active. Use depth() to check availability\n        before calling if non-blocking behavior is required.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventTransport","title":"EventTransport","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for event messaging and delivery.</p> <p>EventTransport handles real-time delivery of events to subscribers (projections, process managers, external systems). It's separate from EventStore - while the store provides durable persistence for aggregate reconstruction, the transport provides ephemeral messaging for live updates.</p> <p>Implementations might use: - In-memory queues (for testing or single-process apps) - Message brokers (RabbitMQ, Kafka, AWS SQS/SNS) - Pub/sub systems (Redis, Google Pub/Sub)</p> <p>The transport doesn't guarantee delivery - it's EventStore's job to persist events durably. The transport is best-effort delivery for real-time consumers.</p>"},{"location":"reference/application/events/#interlock.application.events.EventTransport.subscribe","title":"subscribe  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription to an event stream.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier, typically an aggregate ID or event type. The semantics depend on the transport implementation.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>An EventSubscription for consuming events from the stream.</p> Note <p>The subscription may receive events published after subscription creation. Historical events should be loaded from EventStore.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription to an event stream.\n\n    Args:\n        identifier: Stream identifier, typically an aggregate ID or\n            event type. The semantics depend on the transport implementation.\n\n    Returns:\n        An EventSubscription for consuming events from the stream.\n\n    Note:\n        The subscription may receive events published after subscription\n        creation. Historical events should be loaded from EventStore.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventTransport.publish_events","title":"publish_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>publish_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events to subscribers.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to publish. These are typically Event[T] instances, but the transport may handle raw event data.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>This is best-effort delivery. Events are durably stored via EventStore.save_events() - the transport is for real-time notification only.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def publish_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events to subscribers.\n\n    Args:\n        events: List of events to publish. These are typically Event[T]\n            instances, but the transport may handle raw event data.\n\n    Note:\n        This is best-effort delivery. Events are durably stored via\n        EventStore.save_events() - the transport is for real-time\n        notification only.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventTransport","title":"InMemoryEventTransport","text":"<pre><code>InMemoryEventTransport()\n</code></pre> <p>               Bases: <code>EventTransport</code></p> <p>Simple in-memory event transport for testing.</p> <p>Stores all published events in a single ordered list. All subscriptions share the same global event stream regardless of the identifier.</p> <p>This is a minimal implementation for testing - it doesn't support: - Per-stream isolation (all subscriptions see all events) - Concurrent access (no thread safety) - Backpressure or buffering limits - Event filtering by aggregate or type</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize an empty in-memory transport.\"\"\"\n    self.events_in_order: list[Event[Any]] = []\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventTransport.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription to the global event stream.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Identifier is ignored - all subscriptions share the global stream</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>A new InMemoryEventSubscription starting at the beginning of the stream</p> Note <p>The identifier parameter is ignored. All subscriptions receive all events regardless of aggregate ID or event type.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription to the global event stream.\n\n    Args:\n        identifier: Identifier is ignored - all subscriptions share the global stream\n\n    Returns:\n        A new InMemoryEventSubscription starting at the beginning of the stream\n\n    Note:\n        The identifier parameter is ignored. All subscriptions receive\n        all events regardless of aggregate ID or event type.\n    \"\"\"\n    return InMemoryEventSubscription(self)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.InMemoryEventTransport.publish_events","title":"publish_events  <code>async</code>","text":"<pre><code>publish_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Append events to the global event stream.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to publish to all subscribers</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>Events are immediately available to all subscriptions. No validation or filtering is performed.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def publish_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Append events to the global event stream.\n\n    Args:\n        events: Events to publish to all subscribers\n\n    Note:\n        Events are immediately available to all subscriptions.\n        No validation or filtering is performed.\n    \"\"\"\n    self.events_in_order.extend(events)\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EagerUpcastingStrategy","title":"EagerUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Eager upcasting: transform and rewrite events for gradual migration.</p> <p>This strategy applies transformations when events are loaded AND when new events are saved. Crucially, it also rewrites upcasted events back to the store, enabling gradual migration as aggregates are accessed.</p> <p>Advantages: - Event store migrates to new schema over time - Eventually can remove old event types from codebase - No separate migration job needed</p> <p>Disadvantages: - Modifies historical events (breaks strict immutability) - Rarely-accessed aggregates may retain old events indefinitely - Slightly more I/O on reads (for rewriting)</p> <p>Use this when you have a clear migration timeline and want to eventually remove old event types from your codebase.</p>"},{"location":"reference/application/events/#interlock.application.events.EventUpcaster","title":"EventUpcaster","text":"<p>               Bases: <code>Generic[T, U]</code>, <code>ABC</code></p> <p>Base class for transforming events from one schema version to another.</p> <p>Event upcasters handle schema evolution by transforming old event data models into new ones. Each upcaster is typed with source and target event types.</p> <p>The framework automatically extracts these types via introspection, so you only need to implement the upcast_payload method.</p> Example <p>class OrderPlacedV1(BaseModel): ...     product: str ...     price: float ... class OrderPlacedV2(BaseModel): ...     product_id: str ...     price_cents: int ... class OrderPlacedV1ToV2(EventUpcaster[OrderPlacedV1, OrderPlacedV2]): ...     def upcast_payload(self, data: OrderPlacedV1) -&gt; OrderPlacedV2: ...         return OrderPlacedV2( ...             product_id=data.product, ...             price_cents=int(data.price * 100) ...         )</p>"},{"location":"reference/application/events/#interlock.application.events.EventUpcaster.upcast_event","title":"upcast_event  <code>async</code>","text":"<pre><code>upcast_event(event: Event[T]) -&gt; Event[U]\n</code></pre> <p>Transform an entire event from old schema to new schema.</p> <p>This method preserves event metadata (id, aggregate_id, correlation_id, causation_id, sequence_number, timestamp) while transforming the event data payload.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event with old schema data</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>Event[U]</code> <p>A new event with transformed data</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_event(self, event: Event[T]) -&gt; Event[U]:\n    \"\"\"Transform an entire event from old schema to new schema.\n\n    This method preserves event metadata (id, aggregate_id, correlation_id,\n    causation_id, sequence_number, timestamp) while transforming the event\n    data payload.\n\n    Args:\n        event: The event with old schema data\n\n    Returns:\n        A new event with transformed data\n    \"\"\"\n    return Event(\n        id=event.id,\n        aggregate_id=event.aggregate_id,\n        sequence_number=event.sequence_number,\n        timestamp=event.timestamp,\n        correlation_id=event.correlation_id,\n        causation_id=event.causation_id,\n        data=await self.upcast_payload(event.data),\n    )\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventUpcaster.can_upcast","title":"can_upcast  <code>async</code>","text":"<pre><code>can_upcast(event: Event[T]) -&gt; bool\n</code></pre> <p>Check if this upcaster can handle the given event.</p> <p>Override this method if you need conditional upcasting logic (e.g., only upcast events before a certain date).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this upcaster can transform the event</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def can_upcast(self, event: Event[T]) -&gt; bool:\n    \"\"\"Check if this upcaster can handle the given event.\n\n    Override this method if you need conditional upcasting logic\n    (e.g., only upcast events before a certain date).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if this upcaster can transform the event\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.EventUpcaster.upcast_payload","title":"upcast_payload  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>upcast_payload(data: T) -&gt; U\n</code></pre> <p>Transform event data from old schema to new schema.</p> <p>This is the core transformation logic that subclasses must implement.</p> PARAMETER DESCRIPTION <code>data</code> <p>The old event data</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>U</code> <p>The transformed event data with new schema</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>@abstractmethod\nasync def upcast_payload(self, data: T) -&gt; U:\n    \"\"\"Transform event data from old schema to new schema.\n\n    This is the core transformation logic that subclasses must implement.\n\n    Args:\n        data: The old event data\n\n    Returns:\n        The transformed event data with new schema\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.LazyUpcastingStrategy","title":"LazyUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Lazy upcasting: transform events only when reading from storage.</p> <p>This is the recommended default strategy. Old events remain in storage with their original schema, and are transformed on-the-fly when loaded.</p> <p>Advantages: - No need to rewrite event store - Supports multiple concurrent versions - Can evolve upcasting logic over time - Preserves event immutability</p> <p>Disadvantages: - Slight performance cost on reads - Old schemas must remain in codebase forever</p>"},{"location":"reference/application/events/#interlock.application.events.UpcastingPipeline","title":"UpcastingPipeline","text":"<pre><code>UpcastingPipeline(\n    upcasting_strategy: UpcastingStrategy,\n    upcaster_map: UpcasterMap,\n)\n</code></pre> <p>Pipeline for applying event upcasting transformations.</p> <p>The pipeline manages a mapping of upcasters and applies them to events based on the configured strategy. It supports multi-step upcasting chains where events can be transformed through multiple versions (V1\u2192V2\u2192V3).</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>def __init__(self, upcasting_strategy: UpcastingStrategy, upcaster_map: UpcasterMap):\n    self.upcasting_strategy = upcasting_strategy\n    self.upcaster_map = upcaster_map\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingPipeline.upcast","title":"upcast  <code>async</code>","text":"<pre><code>upcast(event: Event[Any]) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations to a single event.</p> <p>Looks up upcasters registered for the event's data type and applies the first matching upcaster. For multi-step chains, call repeatedly.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The upcasted event, or the original if no upcaster found</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast(self, event: Event[Any]) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations to a single event.\n\n    Looks up upcasters registered for the event's data type and applies\n    the first matching upcaster. For multi-step chains, call repeatedly.\n\n    Args:\n        event: The event to upcast\n\n    Returns:\n        The upcasted event, or the original if no upcaster found\n    \"\"\"\n    event_data_type = type(event.data)\n\n    # Find upcasters for this event type\n    for upcaster in self.upcaster_map.get_upcasters(event_data_type):\n        if await upcaster.can_upcast(event):\n            return await upcaster.upcast_event(event)\n\n    # No upcaster found - return unchanged\n    return event\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingPipeline.upcast_chain","title":"upcast_chain  <code>async</code>","text":"<pre><code>upcast_chain(\n    event: Event[Any], max_steps: int = 10\n) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations repeatedly until no more upcasters match.</p> <p>This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying upcasters until the event reaches its final form.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> <code>max_steps</code> <p>Maximum number of upcasting steps (prevents infinite loops)</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The fully upcasted event</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If max_steps is exceeded</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_chain(self, event: Event[Any], max_steps: int = 10) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations repeatedly until no more upcasters match.\n\n    This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying\n    upcasters until the event reaches its final form.\n\n    Args:\n        event: The event to upcast\n        max_steps: Maximum number of upcasting steps (prevents infinite loops)\n\n    Returns:\n        The fully upcasted event\n\n    Raises:\n        RuntimeError: If max_steps is exceeded\n    \"\"\"\n    for _step in range(max_steps):\n        event_data_type = type(event.data)\n        upcasted = await self.upcast(event)\n\n        # If type didn't change, we're done\n        if type(upcasted.data) is event_data_type:\n            return upcasted\n\n        event = upcasted\n\n    raise RuntimeError(\n        f\"Upcasting exceeded max steps ({max_steps}). \"\n        f\"Possible circular upcasting chain for {type(event.data).__name__}\"\n    )\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingPipeline.read_upcast","title":"read_upcast  <code>async</code>","text":"<pre><code>read_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events loaded from the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events loaded from storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def read_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events loaded from the event store according to the strategy.\n\n    Args:\n        events: Events loaded from storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_read():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingPipeline.write_upcast","title":"write_upcast  <code>async</code>","text":"<pre><code>write_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events being saved to the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events being saved to storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def write_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events being saved to the event store according to the strategy.\n\n    Args:\n        events: Events being saved to storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_write():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingStrategy","title":"UpcastingStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Strategy for when to apply upcasting transformations.</p> <p>Strategies control whether upcasting happens when events are read from storage, written to storage, or both. They also control whether upcasted events should be rewritten to the store for gradual migration.</p>"},{"location":"reference/application/events/#interlock.application.events.UpcastingStrategy.should_upcast_on_read","title":"should_upcast_on_read  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_read() -&gt; bool\n</code></pre> <p>Should events be upcasted when loaded from the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_read(self) -&gt; bool:\n    \"\"\"Should events be upcasted when loaded from the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingStrategy.should_upcast_on_write","title":"should_upcast_on_write  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_write() -&gt; bool\n</code></pre> <p>Should events be upcasted when saved to the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_write(self) -&gt; bool:\n    \"\"\"Should events be upcasted when saved to the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/#interlock.application.events.UpcastingStrategy.should_rewrite_on_load","title":"should_rewrite_on_load  <code>abstractmethod</code>","text":"<pre><code>should_rewrite_on_load() -&gt; bool\n</code></pre> <p>Should upcasted events be persisted back to the event store?</p> <p>When True, events that are upcasted during load will be rewritten to the store with their new schema. This enables gradual migration of historical events as aggregates are accessed.</p> RETURNS DESCRIPTION <code>bool</code> <p>True to rewrite upcasted events, False to leave them unchanged.</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_rewrite_on_load(self) -&gt; bool:\n    \"\"\"Should upcasted events be persisted back to the event store?\n\n    When True, events that are upcasted during load will be rewritten\n    to the store with their new schema. This enables gradual migration\n    of historical events as aggregates are accessed.\n\n    Returns:\n        True to rewrite upcasted events, False to leave them unchanged.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/bus/","title":"bus","text":""},{"location":"reference/application/events/bus/#interlock.application.events.bus","title":"bus","text":""},{"location":"reference/application/events/bus/#interlock.application.events.bus.EventBus","title":"EventBus","text":"<pre><code>EventBus(\n    store: EventStore,\n    delivery: EventDelivery,\n    upcasting_pipeline: UpcastingPipeline,\n)\n</code></pre> <p>Coordinates event persistence, upcasting, and delivery.</p> <p>EventBus is the main entry point for publishing and loading events in the event sourcing infrastructure. It orchestrates:</p> <ol> <li>Upcasting: Transforms events to correct schema versions (via pipeline)</li> <li>Persistence: Durably stores events (via EventStore)</li> <li>Delivery: Delivers events to processors (via EventDelivery)</li> </ol> <p>The bus ensures events flow through the upcasting pipeline in both directions - events are upcasted when written (eager strategy) and when read (lazy strategy) based on the configured UpcastingPipeline.</p> <p>Event delivery is controlled by the EventDelivery strategy: - SynchronousDelivery: Processors execute immediately during publish_events() - AsynchronousDelivery: Processors consume via subscriptions (run_event_processors())</p> <p>The delivery strategy determines architectural trade-offs between simplicity (synchronous) and scalability (asynchronous with separate processor execution).</p> PARAMETER DESCRIPTION <code>store</code> <p>Persistent storage for event sourcing</p> <p> TYPE: <code>EventStore</code> </p> <code>delivery</code> <p>Delivery strategy for executing processors</p> <p> TYPE: <code>EventDelivery</code> </p> <code>upcasting_pipeline</code> <p>Pipeline for event schema evolution</p> <p> TYPE: <code>UpcastingPipeline</code> </p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>def __init__(\n    self,\n    store: EventStore,\n    delivery: EventDelivery,\n    upcasting_pipeline: UpcastingPipeline,\n):\n    \"\"\"Initialize the event bus with its dependencies.\n\n    Args:\n        store: Persistent storage for event sourcing\n        delivery: Delivery strategy for executing processors\n        upcasting_pipeline: Pipeline for event schema evolution\n    \"\"\"\n    self.store = store\n    self.delivery = delivery\n    self.upcasting_pipeline = upcasting_pipeline\n</code></pre>"},{"location":"reference/application/events/bus/#interlock.application.events.bus.EventBus.publish_events","title":"publish_events  <code>async</code>","text":"<pre><code>publish_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Publish events to storage and deliver to processors.</p> <p>This method coordinates the full event publishing flow: 1. Upcast events to target versions (based on strategy) 2. Persist events to the event store (with optimistic locking) 3. Deliver events to processors (based on delivery strategy)</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to publish, typically from an aggregate's uncommitted_events after handling a command.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>The aggregate version before these events, used for optimistic concurrency control.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If another process modified the aggregate (expected_version doesn't match current version in store).</p> <code>Exception</code> <p>Any exception raised by the delivery strategy. For SynchronousDelivery, processor errors will fail the command.</p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>async def publish_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Publish events to storage and deliver to processors.\n\n    This method coordinates the full event publishing flow:\n    1. Upcast events to target versions (based on strategy)\n    2. Persist events to the event store (with optimistic locking)\n    3. Deliver events to processors (based on delivery strategy)\n\n    Args:\n        events: List of events to publish, typically from an aggregate's\n            uncommitted_events after handling a command.\n        expected_version: The aggregate version before these events,\n            used for optimistic concurrency control.\n\n    Raises:\n        ConcurrencyError: If another process modified the aggregate\n            (expected_version doesn't match current version in store).\n        Exception: Any exception raised by the delivery strategy.\n            For SynchronousDelivery, processor errors will fail the command.\n    \"\"\"\n    upcasted_events = await self.upcasting_pipeline.write_upcast(events)\n    await self.store.save_events(upcasted_events, expected_version)\n    await self.delivery.deliver(upcasted_events)\n</code></pre>"},{"location":"reference/application/events/bus/#interlock.application.events.bus.EventBus.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events from storage with schema evolution applied.</p> <p>This method coordinates event loading: 1. Retrieve events from the event store 2. Upcast events to current schema versions (based on strategy) 3. Optionally rewrite upcasted events back to store (eager migration) 4. Return complete Event objects ready for aggregate reconstruction</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>Unique identifier of the aggregate to load events for</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum event sequence number to load (inclusive). Use 0 to load all events, or snapshot_version + 1 to load only events after a snapshot.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of complete Event objects in sequence order, upcasted to</p> <code>list[Event[Any]]</code> <p>current schema versions, including all metadata (timestamp, etc.).</p> Source code in <code>interlock/application/events/bus.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events from storage with schema evolution applied.\n\n    This method coordinates event loading:\n    1. Retrieve events from the event store\n    2. Upcast events to current schema versions (based on strategy)\n    3. Optionally rewrite upcasted events back to store (eager migration)\n    4. Return complete Event objects ready for aggregate reconstruction\n\n    Args:\n        aggregate_id: Unique identifier of the aggregate to load events for\n        min_version: Minimum event sequence number to load (inclusive).\n            Use 0 to load all events, or snapshot_version + 1 to load\n            only events after a snapshot.\n\n    Returns:\n        List of complete Event objects in sequence order, upcasted to\n        current schema versions, including all metadata (timestamp, etc.).\n    \"\"\"\n    events = await self.store.load_events(aggregate_id, min_version)\n    upcasted_events = await self.upcasting_pipeline.read_upcast(events)\n\n    # Gradual migration: rewrite events that were upcasted\n    if self.upcasting_pipeline.upcasting_strategy.should_rewrite_on_load():\n        # Find events whose data type changed (i.e., were actually upcasted)\n        changed_events = [\n            upcasted\n            for original, upcasted in zip(events, upcasted_events, strict=True)\n            if type(original.data) is not type(upcasted.data)\n        ]\n        if changed_events:\n            await self.store.rewrite_events(changed_events)\n\n    return upcasted_events\n</code></pre>"},{"location":"reference/application/events/delivery/","title":"delivery","text":""},{"location":"reference/application/events/delivery/#interlock.application.events.delivery","title":"delivery","text":"<p>Event delivery orchestration for executing processors.</p> <p>This module provides the EventDelivery abstraction which orchestrates: - Publishing events to transport infrastructure (Kafka, RabbitMQ, in-memory) - Executing processors according to synchronous or asynchronous strategy - Creating subscriptions for asynchronous processor execution</p> <p>EventDelivery unifies the concepts of EventTransport (infrastructure) and EventDispatchStrategy (execution policy) into a single cohesive abstraction.</p>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.EventDelivery","title":"EventDelivery","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract strategy for delivering events to processors.</p> <p>EventDelivery orchestrates both: 1. Publishing events to transport infrastructure (for durability and subscriptions) 2. Executing processors according to synchronous or asynchronous strategy</p> <p>Implementations: - SynchronousDelivery: Publishes to transport + executes processors immediately - AsynchronousDelivery: Publishes to transport only (processors consume via subscriptions)</p>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.EventDelivery.deliver","title":"deliver  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Deliver events according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver to processors</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>The implementation determines whether processors execute immediately (synchronous) or later via subscriptions (asynchronous).</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>@abstractmethod\nasync def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Deliver events according to the strategy.\n\n    Args:\n        events: Events to deliver to processors\n\n    Note:\n        The implementation determines whether processors execute immediately\n        (synchronous) or later via subscriptions (asynchronous).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.EventDelivery.subscribe","title":"subscribe  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription for consuming events asynchronously.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier (aggregate ID, event type, or \"all\")</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription for consuming events from the transport</p> Note <p>Used by Application.run_event_processors() to consume events in a separate process or async task.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>@abstractmethod\nasync def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription for consuming events asynchronously.\n\n    Args:\n        identifier: Stream identifier (aggregate ID, event type, or \"all\")\n\n    Returns:\n        EventSubscription for consuming events from the transport\n\n    Note:\n        Used by Application.run_event_processors() to consume events\n        in a separate process or async task.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.SynchronousDelivery","title":"SynchronousDelivery","text":"<pre><code>SynchronousDelivery(\n    transport: EventTransport,\n    processors: list[EventProcessor],\n)\n</code></pre> <p>               Bases: <code>EventDelivery</code></p> <p>Synchronous event delivery with immediate processor execution.</p> <p>This strategy publishes events to the transport (for any subscriptions) and immediately executes all registered processors synchronously during the publish_events() call.</p> <p>Characteristics: - Processors execute in the same transaction/process as command handling - Command latency includes all processor execution time - Processor failures cause command to fail - Simple deployment model (single process) - Immediate consistency</p> <p>Use cases: - Simple monolithic applications - Prototyping and development - When immediate consistency is required - When processors are fast and reliable</p> Example <p>transport = InMemoryEventTransport() processors = [MyProcessor()] delivery = SynchronousDelivery(transport, processors) await delivery.deliver(events)  # Processors execute immediately</p> PARAMETER DESCRIPTION <code>transport</code> <p>Event transport for publishing and subscriptions</p> <p> TYPE: <code>EventTransport</code> </p> <code>processors</code> <p>List of processors to execute immediately</p> <p> TYPE: <code>list[EventProcessor]</code> </p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>def __init__(self, transport: EventTransport, processors: list[EventProcessor]):\n    \"\"\"Initialize synchronous delivery.\n\n    Args:\n        transport: Event transport for publishing and subscriptions\n        processors: List of processors to execute immediately\n    \"\"\"\n    self.transport = transport\n    self.processors = processors\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.SynchronousDelivery.deliver","title":"deliver  <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events and execute processors immediately.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RAISES DESCRIPTION <code>Exception</code> <p>Any exceptions raised by processors will propagate to the caller.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events and execute processors immediately.\n\n    Args:\n        events: Events to deliver\n\n    Raises:\n        Exception: Any exceptions raised by processors will propagate to\n            the caller.\n    \"\"\"\n    # Publish to transport (for any subscriptions)\n    await self.transport.publish_events(events)\n\n    # Execute all processors immediately\n    for event in events:\n        for processor in self.processors:\n            await processor.handle(event.data)\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.SynchronousDelivery.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create subscription to the underlying transport.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription from the transport</p> Note <p>While synchronous delivery executes processors immediately, the transport still supports subscriptions for testing or alternative consumption patterns.</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create subscription to the underlying transport.\n\n    Args:\n        identifier: Stream identifier\n\n    Returns:\n        EventSubscription from the transport\n\n    Note:\n        While synchronous delivery executes processors immediately,\n        the transport still supports subscriptions for testing or\n        alternative consumption patterns.\n    \"\"\"\n    return await self.transport.subscribe(identifier)\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.AsynchronousDelivery","title":"AsynchronousDelivery","text":"<pre><code>AsynchronousDelivery(transport: EventTransport)\n</code></pre> <p>               Bases: <code>EventDelivery</code></p> <p>Asynchronous event delivery via transport subscriptions.</p> <p>This strategy only publishes events to the transport. Processors run separately by consuming events via subscriptions (typically in separate processes or async tasks via Application.run_event_processors()).</p> <p>Characteristics: - Processors execute independently from command handling - Command latency is minimal (just publish to transport) - Processor failures don't affect command success - Scalable deployment (processors can run in separate containers) - Eventual consistency</p> <p>Use cases: - Production microservice architectures - High-throughput systems - When scaling read and write sides independently - When using external message brokers (Kafka, RabbitMQ)</p> Example <p>transport = KafkaEventTransport(brokers=[\"localhost:9092\"]) delivery = AsynchronousDelivery(transport) await delivery.deliver(events)  # Just publishes</p> PARAMETER DESCRIPTION <code>transport</code> <p>Event transport for publishing and subscriptions</p> <p> TYPE: <code>EventTransport</code> </p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>def __init__(self, transport: EventTransport):\n    \"\"\"Initialize asynchronous delivery.\n\n    Args:\n        transport: Event transport for publishing and subscriptions\n    \"\"\"\n    self.transport = transport\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.AsynchronousDelivery--separate-process","title":"Separate process:","text":"<p>subscription = await delivery.subscribe(\"all\") event = await subscription.next() await processor.handle(event.data)</p>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.AsynchronousDelivery.deliver","title":"deliver  <code>async</code>","text":"<pre><code>deliver(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events to transport without executing processors.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to deliver</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>Processors will consume these events via subscriptions created through subscribe().</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def deliver(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events to transport without executing processors.\n\n    Args:\n        events: Events to deliver\n\n    Note:\n        Processors will consume these events via subscriptions\n        created through subscribe().\n    \"\"\"\n    await self.transport.publish_events(events)\n</code></pre>"},{"location":"reference/application/events/delivery/#interlock.application.events.delivery.AsynchronousDelivery.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create subscription for consuming events asynchronously.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>EventSubscription from the transport</p> Note <p>This is how processors consume events when using Application.run_event_processors().</p> Source code in <code>interlock/application/events/delivery.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create subscription for consuming events asynchronously.\n\n    Args:\n        identifier: Stream identifier\n\n    Returns:\n        EventSubscription from the transport\n\n    Note:\n        This is how processors consume events when using\n        Application.run_event_processors().\n    \"\"\"\n    return await self.transport.subscribe(identifier)\n</code></pre>"},{"location":"reference/application/events/store/","title":"store","text":""},{"location":"reference/application/events/store/#interlock.application.events.store","title":"store","text":"<p>Event store interfaces and implementations for durable event persistence.</p>"},{"location":"reference/application/events/store/#interlock.application.events.store.EventStore","title":"EventStore","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for durable event persistence.</p> <p>EventStore provides the foundation for event sourcing by persisting events as an immutable, append-only log. Each aggregate's events form a stream that can be replayed to reconstruct aggregate state.</p> <p>Key responsibilities: - Durability: Events survive system failures - Ordering: Events are stored and retrieved in sequence - Concurrency Control: Optimistic locking via expected_version - Immutability: Events cannot be modified after storage</p>"},{"location":"reference/application/events/store/#interlock.application.events.store.EventStore.save_events","title":"save_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Persist events to the event store with optimistic concurrency control.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to persist. Each event includes metadata (id, aggregate_id, sequence_number, timestamp) and typed data.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>The version the aggregate is expected to be at before these events are appended. Used for optimistic locking.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version in the store (another process modified the aggregate).</p> Note <p>Events are appended atomically - either all events are saved or none are. The store assigns sequence numbers starting from expected_version + 1.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Persist events to the event store with optimistic concurrency control.\n\n    Args:\n        events: List of events to persist. Each event includes metadata\n            (id, aggregate_id, sequence_number, timestamp) and typed data.\n        expected_version: The version the aggregate is expected to be at\n            before these events are appended. Used for optimistic locking.\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current\n            version in the store (another process modified the aggregate).\n\n    Note:\n        Events are appended atomically - either all events are saved or\n        none are. The store assigns sequence numbers starting from\n        expected_version + 1.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.EventStore.load_events","title":"load_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate from the event store.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The unique identifier of the aggregate whose events should be loaded.</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>The minimum sequence number to load (inclusive). Use 0 to load all events, or a snapshot version to load only events after the snapshot.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events in sequence order. Events may have been upcasted</p> <code>list[Event[Any]]</code> <p>to newer schema versions by the store implementation.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate from the event store.\n\n    Args:\n        aggregate_id: The unique identifier of the aggregate whose\n            events should be loaded.\n        min_version: The minimum sequence number to load (inclusive).\n            Use 0 to load all events, or a snapshot version to load\n            only events after the snapshot.\n\n    Returns:\n        List of events in sequence order. Events may have been upcasted\n        to newer schema versions by the store implementation.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.EventStore.rewrite_events","title":"rewrite_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place for schema migration.</p> <p>This method updates existing events in the store with new data, typically after upcasting. It's used by the EagerUpcastingStrategy to gradually migrate the event store to new schemas.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to rewrite. Each event's aggregate_id and sequence_number identify which stored event to update. The event data (and potentially type) may have changed.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>This operation intentionally modifies historical events. Use with caution as it breaks strict event immutability. The event's id, aggregate_id, sequence_number, and timestamp should remain unchanged; only the data payload is updated.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>@abstractmethod\nasync def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place for schema migration.\n\n    This method updates existing events in the store with new data,\n    typically after upcasting. It's used by the EagerUpcastingStrategy\n    to gradually migrate the event store to new schemas.\n\n    Args:\n        events: Events to rewrite. Each event's aggregate_id and\n            sequence_number identify which stored event to update.\n            The event data (and potentially type) may have changed.\n\n    Note:\n        This operation intentionally modifies historical events.\n        Use with caution as it breaks strict event immutability.\n        The event's id, aggregate_id, sequence_number, and timestamp\n        should remain unchanged; only the data payload is updated.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.InMemoryEventStore","title":"InMemoryEventStore","text":"<pre><code>InMemoryEventStore()\n</code></pre> <p>               Bases: <code>EventStore</code></p> <p>Dictionary-based in-memory event store for testing.</p> <p>Stores events in a dictionary keyed by aggregate ID. Each aggregate's events are kept in a list ordered by sequence number.</p> <p>This implementation is suitable for: - Unit tests (fast, no external dependencies) - Development and experimentation - Examples and documentation</p> <p>NOT suitable for production due to: - No durability (data lost on restart) - No optimistic concurrency control (no version checking) - No transaction support (partial writes possible on errors) - Memory usage grows unbounded - No distributed coordination</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize an empty in-memory event store.\"\"\"\n    self.by_aggregate_id: dict[UUID, list[Event[Any]]] = defaultdict(list)\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.InMemoryEventStore.save_events","title":"save_events  <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Append events to the aggregate's event list with version checking.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to store, typically from an aggregate's uncommitted events</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>Expected current version - must match actual version</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Append events to the aggregate's event list with version checking.\n\n    Args:\n        events: Events to store, typically from an aggregate's uncommitted events\n        expected_version: Expected current version - must match actual version\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current version\n    \"\"\"\n    if not events:\n        return\n\n    aggregate_id = events[0].aggregate_id\n\n    # Check current version matches expected\n    current_events = self.by_aggregate_id[aggregate_id]\n    current_version = current_events[-1].sequence_number if current_events else 0\n\n    if current_version != expected_version:\n        raise ConcurrencyError(f\"Expected version {expected_version}, got {current_version}\")\n\n    # Version matches, safe to append events\n    for event in events:\n        self.by_aggregate_id[aggregate_id].append(event)\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.InMemoryEventStore.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate starting from a minimum version.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The aggregate whose events to load</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum sequence number (inclusive). Use 0 for all events.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events with sequence_number &gt;= min_version, in order.</p> <code>list[Event[Any]]</code> <p>Returns empty list if aggregate has no events.</p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate starting from a minimum version.\n\n    Args:\n        aggregate_id: The aggregate whose events to load\n        min_version: Minimum sequence number (inclusive). Use 0 for all events.\n\n    Returns:\n        List of events with sequence_number &gt;= min_version, in order.\n        Returns empty list if aggregate has no events.\n    \"\"\"\n    return [\n        event\n        for event in self.by_aggregate_id[aggregate_id]\n        if event.sequence_number &gt;= min_version\n    ]\n</code></pre>"},{"location":"reference/application/events/store/#interlock.application.events.store.InMemoryEventStore.rewrite_events","title":"rewrite_events  <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place.</p> <p>Updates events in the in-memory store by matching aggregate_id and sequence_number.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events with updated data to write back.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Source code in <code>interlock/application/events/store.py</code> <pre><code>async def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place.\n\n    Updates events in the in-memory store by matching aggregate_id\n    and sequence_number.\n\n    Args:\n        events: Events with updated data to write back.\n    \"\"\"\n    for event in events:\n        stream = self.by_aggregate_id[event.aggregate_id]\n        # Find and replace the event at this sequence number\n        for i, stored_event in enumerate(stream):\n            if stored_event.sequence_number == event.sequence_number:\n                stream[i] = event\n                break\n</code></pre>"},{"location":"reference/application/events/transport/","title":"transport","text":""},{"location":"reference/application/events/transport/#interlock.application.events.transport","title":"transport","text":"<p>Event transport and subscription interfaces and implementations.</p> <p>This module provides: - EventSubscription: Abstract interface for consuming events from a stream - EventTransport: Abstract interface for publishing events to subscribers - InMemoryEventTransport: Simple in-memory implementation for testing - InMemoryEventSubscription: Index-based subscription for in-memory transport</p>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventSubscription","title":"EventSubscription","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for consuming events from an event stream.</p> <p>EventSubscription provides an async iterator-like interface for reading events from a specific stream or aggregate. Implementations handle backpressure, buffering, and ordering guarantees.</p> <p>This is typically used for: - Read model projections (updating query databases) - Process managers (saga coordination) - Event processors (side effects, notifications)</p>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventSubscription.depth","title":"depth  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>depth() -&gt; int\n</code></pre> <p>Get the number of unread events available in the subscription.</p> RETURNS DESCRIPTION <code>int</code> <p>The count of events that can be consumed without blocking.</p> <code>int</code> <p>Returns 0 if no events are currently available.</p> Note <p>This is a snapshot value - the depth may change as new events are published to the stream.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def depth(self) -&gt; int:\n    \"\"\"Get the number of unread events available in the subscription.\n\n    Returns:\n        The count of events that can be consumed without blocking.\n        Returns 0 if no events are currently available.\n\n    Note:\n        This is a snapshot value - the depth may change as new events\n        are published to the stream.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventSubscription.next","title":"next  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>next() -&gt; Event[Any]\n</code></pre> <p>Retrieve the next event from the subscription.</p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The next event in the stream, advancing the subscription position.</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>When the subscription has been closed or the stream has ended.</p> Note <p>This method may block if no events are currently available but the subscription is still active. Use depth() to check availability before calling if non-blocking behavior is required.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def next(self) -&gt; Event[Any]:\n    \"\"\"Retrieve the next event from the subscription.\n\n    Returns:\n        The next event in the stream, advancing the subscription position.\n\n    Raises:\n        StopAsyncIteration: When the subscription has been closed or\n            the stream has ended.\n\n    Note:\n        This method may block if no events are currently available but\n        the subscription is still active. Use depth() to check availability\n        before calling if non-blocking behavior is required.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventTransport","title":"EventTransport","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract interface for event messaging and delivery.</p> <p>EventTransport handles real-time delivery of events to subscribers (projections, process managers, external systems). It's separate from EventStore - while the store provides durable persistence for aggregate reconstruction, the transport provides ephemeral messaging for live updates.</p> <p>Implementations might use: - In-memory queues (for testing or single-process apps) - Message brokers (RabbitMQ, Kafka, AWS SQS/SNS) - Pub/sub systems (Redis, Google Pub/Sub)</p> <p>The transport doesn't guarantee delivery - it's EventStore's job to persist events durably. The transport is best-effort delivery for real-time consumers.</p>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventTransport.subscribe","title":"subscribe  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription to an event stream.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Stream identifier, typically an aggregate ID or event type. The semantics depend on the transport implementation.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>An EventSubscription for consuming events from the stream.</p> Note <p>The subscription may receive events published after subscription creation. Historical events should be loaded from EventStore.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription to an event stream.\n\n    Args:\n        identifier: Stream identifier, typically an aggregate ID or\n            event type. The semantics depend on the transport implementation.\n\n    Returns:\n        An EventSubscription for consuming events from the stream.\n\n    Note:\n        The subscription may receive events published after subscription\n        creation. Historical events should be loaded from EventStore.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.EventTransport.publish_events","title":"publish_events  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>publish_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Publish events to subscribers.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to publish. These are typically Event[T] instances, but the transport may handle raw event data.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>This is best-effort delivery. Events are durably stored via EventStore.save_events() - the transport is for real-time notification only.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>@abstractmethod\nasync def publish_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Publish events to subscribers.\n\n    Args:\n        events: List of events to publish. These are typically Event[T]\n            instances, but the transport may handle raw event data.\n\n    Note:\n        This is best-effort delivery. Events are durably stored via\n        EventStore.save_events() - the transport is for real-time\n        notification only.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventTransport","title":"InMemoryEventTransport","text":"<pre><code>InMemoryEventTransport()\n</code></pre> <p>               Bases: <code>EventTransport</code></p> <p>Simple in-memory event transport for testing.</p> <p>Stores all published events in a single ordered list. All subscriptions share the same global event stream regardless of the identifier.</p> <p>This is a minimal implementation for testing - it doesn't support: - Per-stream isolation (all subscriptions see all events) - Concurrent access (no thread safety) - Backpressure or buffering limits - Event filtering by aggregate or type</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize an empty in-memory transport.\"\"\"\n    self.events_in_order: list[Event[Any]] = []\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventTransport.subscribe","title":"subscribe  <code>async</code>","text":"<pre><code>subscribe(identifier: str) -&gt; EventSubscription\n</code></pre> <p>Create a subscription to the global event stream.</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Identifier is ignored - all subscriptions share the global stream</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>EventSubscription</code> <p>A new InMemoryEventSubscription starting at the beginning of the stream</p> Note <p>The identifier parameter is ignored. All subscriptions receive all events regardless of aggregate ID or event type.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def subscribe(self, identifier: str) -&gt; EventSubscription:\n    \"\"\"Create a subscription to the global event stream.\n\n    Args:\n        identifier: Identifier is ignored - all subscriptions share the global stream\n\n    Returns:\n        A new InMemoryEventSubscription starting at the beginning of the stream\n\n    Note:\n        The identifier parameter is ignored. All subscriptions receive\n        all events regardless of aggregate ID or event type.\n    \"\"\"\n    return InMemoryEventSubscription(self)\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventTransport.publish_events","title":"publish_events  <code>async</code>","text":"<pre><code>publish_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Append events to the global event stream.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events to publish to all subscribers</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Note <p>Events are immediately available to all subscriptions. No validation or filtering is performed.</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def publish_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Append events to the global event stream.\n\n    Args:\n        events: Events to publish to all subscribers\n\n    Note:\n        Events are immediately available to all subscriptions.\n        No validation or filtering is performed.\n    \"\"\"\n    self.events_in_order.extend(events)\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventSubscription","title":"InMemoryEventSubscription","text":"<pre><code>InMemoryEventSubscription(\n    transport: InMemoryEventTransport,\n)\n</code></pre> <p>               Bases: <code>EventSubscription</code></p> <p>Index-based subscription to the in-memory event stream.</p> <p>Maintains a read position (index) in the transport's global event list. Each call to next() advances the index and returns the event at that position.</p> <p>Limitations: - No thread safety (concurrent access will cause issues) - Raises IndexError if reading past end of stream - No blocking - fails immediately if no events available</p> PARAMETER DESCRIPTION <code>transport</code> <p>The transport containing the event stream</p> <p> TYPE: <code>InMemoryEventTransport</code> </p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>def __init__(self, transport: InMemoryEventTransport) -&gt; None:\n    \"\"\"Initialize a subscription at the beginning of the stream.\n\n    Args:\n        transport: The transport containing the event stream\n    \"\"\"\n    self.index = 0\n    self.transport = transport\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventSubscription.depth","title":"depth  <code>async</code>","text":"<pre><code>depth() -&gt; int\n</code></pre> <p>Get the number of unread events.</p> RETURNS DESCRIPTION <code>int</code> <p>Count of events from current position to end of stream</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def depth(self) -&gt; int:\n    \"\"\"Get the number of unread events.\n\n    Returns:\n        Count of events from current position to end of stream\n    \"\"\"\n    return len(self.transport.events_in_order) - self.index\n</code></pre>"},{"location":"reference/application/events/transport/#interlock.application.events.transport.InMemoryEventSubscription.next","title":"next  <code>async</code>","text":"<pre><code>next() -&gt; Event[Any]\n</code></pre> <p>Read the next event and advance the subscription position.</p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The event at the current index position</p> RAISES DESCRIPTION <code>IndexError</code> <p>If attempting to read past the end of the stream</p> Source code in <code>interlock/application/events/transport.py</code> <pre><code>async def next(self) -&gt; Event[Any]:\n    \"\"\"Read the next event and advance the subscription position.\n\n    Returns:\n        The event at the current index position\n\n    Raises:\n        IndexError: If attempting to read past the end of the stream\n    \"\"\"\n    event = self.transport.events_in_order[self.index]\n    self.index += 1\n    return event\n</code></pre>"},{"location":"reference/application/events/processing/","title":"processing","text":""},{"location":"reference/application/events/processing/#interlock.application.events.processing","title":"processing","text":"<p>Event processing infrastructure for CQRS read side.</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNAge","title":"AfterNAge","text":"<pre><code>AfterNAge(age: timedelta)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when average event age exceeds threshold.</p> <p>This condition triggers based on event staleness, not backlog size. It's useful for ensuring timely processing and data freshness.</p> PARAMETER DESCRIPTION <code>age</code> <p>Maximum acceptable average event age</p> <p> TYPE: <code>timedelta</code> </p> Example PARAMETER DESCRIPTION <code>age</code> <p>Maximum average event age before triggering catchup</p> <p> TYPE: <code>timedelta</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, age: timedelta):\n    \"\"\"Initialize with age threshold.\n\n    Args:\n        age: Maximum average event age before triggering catchup\n    \"\"\"\n    if age.total_seconds() &lt;= 0:\n        raise ValueError(\"Age threshold must be positive\")\n    self.age = age\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNAge--trigger-catchup-if-events-are-5-minutes-old-on-average","title":"Trigger catchup if events are &gt; 5 minutes old on average","text":"<p>condition = AfterNAge(timedelta(minutes=5)) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNAge.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if average event age exceeds threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.average_event_age &gt; age</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if average event age exceeds threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.average_event_age &gt; age\n    \"\"\"\n    return lag.average_age_is_older_than(self.age)\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNEvents","title":"AfterNEvents","text":"<pre><code>AfterNEvents(n: int)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when unprocessed event count exceeds threshold.</p> <p>This condition triggers based on backlog volume, not event age. It's useful for preventing unbounded queue growth.</p> PARAMETER DESCRIPTION <code>n</code> <p>Maximum number of unprocessed events before triggering catchup</p> <p> TYPE: <code>int</code> </p> Example PARAMETER DESCRIPTION <code>n</code> <p>Unprocessed event count threshold (must be &gt; 0)</p> <p> TYPE: <code>int</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, n: int):\n    \"\"\"Initialize with event count threshold.\n\n    Args:\n        n: Unprocessed event count threshold (must be &gt; 0)\n    \"\"\"\n    if n &lt;= 0:\n        raise ValueError(\"Threshold must be positive\")\n    self.n = n\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNEvents--trigger-catchup-if-more-than-10000-events-are-queued","title":"Trigger catchup if more than 10,000 events are queued","text":"<p>condition = AfterNEvents(10_000) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AfterNEvents.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if unprocessed events exceed threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.unprocessed_events &gt; n</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if unprocessed events exceed threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.unprocessed_events &gt; n\n    \"\"\"\n    return lag.unprocessed_events_is_greater_than(self.n)\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AllOf","title":"AllOf","text":"<pre><code>AllOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup only if ALL given conditions are met (AND logic).</p> <p>This allows combining multiple conditions where all conditions must be true to trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AllOf--catchup-only-if-queue-1000-and-events-5min-old","title":"Catchup only if queue &gt; 1000 AND events &gt; 5min old","text":"<p>condition = AllOf( ...     AfterNEvents(1000), ...     AfterNAge(timedelta(minutes=5)) ... )</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AllOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if all conditions are satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if all conditions return True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if all conditions are satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if all conditions return True\n    \"\"\"\n    return all(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AnyOf","title":"AnyOf","text":"<pre><code>AnyOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup if ANY of the given conditions are met (OR logic).</p> <p>This allows combining multiple conditions where any single condition being true will trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AnyOf--catchup-if-either-queue-5000-or-events-10min-old","title":"Catchup if EITHER queue &gt; 5000 OR events &gt; 10min old","text":"<p>condition = AnyOf( ...     AfterNEvents(5000), ...     AfterNAge(timedelta(minutes=10)) ... )</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.AnyOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if any condition is satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if any condition returns True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if any condition is satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if any condition returns True\n    \"\"\"\n    return any(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupCondition","title":"CatchupCondition","text":"<p>               Bases: <code>ABC</code></p> <p>Condition for triggering catchup operations based on lag metrics.</p> <p>CatchupConditions evaluate processor lag to determine when catchup strategies should be executed. They can be combined using AnyOf/AllOf to create complex triggering logic.</p> <p>Common patterns: - Never: Disable catchup entirely - AfterNEvents: Trigger when backlog exceeds threshold - AfterNAge: Trigger when events get too old - AnyOf/AllOf: Combine multiple conditions with OR/AND logic</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupCondition.should_catchup","title":"should_catchup  <code>abstractmethod</code>","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Evaluate whether catchup should be triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics for the processor</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if catchup should be initiated, False otherwise</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>@abstractmethod\ndef should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Evaluate whether catchup should be triggered.\n\n    Args:\n        lag: Current lag metrics for the processor\n\n    Returns:\n        True if catchup should be initiated, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.Never","title":"Never","text":"<p>               Bases: <code>CatchupCondition</code></p> <p>Never trigger catchup - disable catchup entirely.</p> <p>Use this when: - Processor only handles new events (no historical state) - Catchup is managed manually or externally - Testing scenarios where catchup is not needed</p> Example <p>executor = EventProcessorExecutor( ...     subscription=subscription, ...     processor=processor, ...     condition=Never(),  # Catchup disabled ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.Never.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Always returns False - catchup never triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Lag metrics (ignored)</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>False</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Always returns False - catchup never triggered.\n\n    Args:\n        lag: Lag metrics (ignored)\n\n    Returns:\n        False\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessorExecutor","title":"EventProcessorExecutor","text":"<pre><code>EventProcessorExecutor(\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n)\n</code></pre> <p>               Bases: <code>Generic[P]</code></p> <p>Runtime execution engine for event processors.</p> <p>EventProcessorExecutor manages the continuous processing of events by: 1. Subscribing to an event stream via EventSubscription 2. Batching events for efficient processing 3. Monitoring processor lag (backlog and event age) 4. Triggering catchup strategies when conditions are met</p> <p>This is the \"event loop\" that drives event processors. It runs continuously, pulling events from the subscription and routing them to the processor's handlers.</p> <p>Batching: Events are processed in batches to improve throughput. After each batch, lag metrics are calculated to determine if catchup is needed.</p> <p>Lag Monitoring: After each batch, the executor measures: - Unprocessed events (subscription depth) - Average event age (time from event.timestamp to processing)</p> <p>Catchup Triggering: If the CatchupCondition evaluates to True, the CatchupStrategy is executed. Blocking strategies pause event processing; non-blocking strategies run concurrently.</p> ATTRIBUTE DESCRIPTION <code>subscription</code> <p>Event stream to consume from</p> <p> </p> <code>processor</code> <p>Event processor with handler methods</p> <p> </p> <code>condition</code> <p>Condition for triggering catchup</p> <p> </p> <code>strategy</code> <p>Strategy for catching up when triggered</p> <p> </p> <code>batch_size</code> <p>Number of events to process before checking lag</p> <p> </p> Note <p>The run() method runs indefinitely until interrupted. Use asyncio task cancellation or exception handling to stop it gracefully.</p> PARAMETER DESCRIPTION <code>processor</code> <p>Processor with event handlers</p> <p> TYPE: <code>P</code> </p> <code>condition</code> <p>When to trigger catchup</p> <p> TYPE: <code>CatchupCondition</code> </p> <code>strategy</code> <p>How to catch up when triggered</p> <p> TYPE: <code>CatchupStrategy[P]</code> </p> <code>batch_size</code> <p>Events to process per batch (must be &gt; 0)</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If batch_size &lt;= 0</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>def __init__(\n    self,\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n) -&gt; None:\n    \"\"\"Initialize the executor with its dependencies.\n\n    Args:\n        processor: Processor with event handlers\n        condition: When to trigger catchup\n        strategy: How to catch up when triggered\n        batch_size: Events to process per batch (must be &gt; 0)\n\n    Raises:\n        ValueError: If batch_size &lt;= 0\n    \"\"\"\n    if batch_size &lt;= 0:\n        raise ValueError(\"batch_size must be positive\")\n    self.processor = processor\n    self.condition = condition\n    self.strategy = strategy\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessorExecutor.process_event_batch","title":"process_event_batch  <code>async</code>","text":"<pre><code>process_event_batch(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta\n</code></pre> <p>Process a batch of events and calculate average event age.</p> <p>Pulls batch_size events from the subscription, routes each to the processor's handlers, and calculates the mean age of processed events.</p> <p>If a catchup_result is provided, events in the skip window are skipped to avoid double-processing events that were already incorporated during catchup.</p> <p>For each event, the execution context is restored from the event metadata before processing, allowing processors to: - Access correlation/causation IDs for logging - Dispatch new commands with proper context inheritance - Track the causal chain in sagas and process managers</p> <p>The context is cleared after each event to prevent leakage.</p> PARAMETER DESCRIPTION <code>subscription</code> <p>The subscription to pull events from.</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>The skip window from catchup operation (Optional)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>timedelta</code> <p>Average time between event.timestamp and processing time</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions raised by event handlers.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_event_batch(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta:\n    \"\"\"Process a batch of events and calculate average event age.\n\n    Pulls batch_size events from the subscription, routes each to the\n    processor's handlers, and calculates the mean age of processed events.\n\n    If a catchup_result is provided, events in the skip window are skipped\n    to avoid double-processing events that were already incorporated during\n    catchup.\n\n    For each event, the execution context is restored from the event\n    metadata before processing, allowing processors to:\n    - Access correlation/causation IDs for logging\n    - Dispatch new commands with proper context inheritance\n    - Track the causal chain in sagas and process managers\n\n    The context is cleared after each event to prevent leakage.\n\n    Args:\n        subscription: The subscription to pull events from.\n        catchup_result: The skip window from catchup operation (Optional)\n\n    Returns:\n        Average time between event.timestamp and processing time\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions raised by event handlers.\n    \"\"\"\n    total_lag_time = timedelta()\n    events_processed = 0\n\n    for _ in range(self.batch_size):\n        event = await subscription.next()\n        total_lag_time += utc_now() - event.timestamp\n\n        # Skip events in the skip window (already processed during catchup)\n        if catchup_result and catchup_result.should_skip(event):\n            continue\n\n        events_processed += 1\n\n        # Restore context from event metadata before processing\n        # This allows event processors to dispatch commands with proper\n        # causation\n        context_set = False\n        if event.correlation_id is not None:\n            ctx = ExecutionContext(\n                correlation_id=event.correlation_id,\n                causation_id=event.id,\n                command_id=None,\n            )\n            set_context(ctx)\n            context_set = True\n\n        try:\n            # Pass full event - processor.handle will extract payload for routing\n            # but pass wrapper to handlers that want it (annotated with Event[T])\n            await self.processor.handle(event)\n        finally:\n            # Clear context only if we set it to prevent leakage\n            if context_set:\n                clear_context()\n\n    # If we didn't process any events, avoid division by zero\n    if events_processed == 0:\n        return timedelta()\n\n    return total_lag_time / events_processed\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessorExecutor.process_batch_and_check_catchup","title":"process_batch_and_check_catchup  <code>async</code>","text":"<pre><code>process_batch_and_check_catchup(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None\n</code></pre> <p>Process a batch, measure lag, and trigger catchup if needed.</p> <p>This method encapsulates one iteration of the main event loop: 1. Process a batch of events 2. Measure lag (average age + unprocessed count) 3. Clear skip window after first batch post-catchup 4. Trigger catchup if condition is met</p> PARAMETER DESCRIPTION <code>subscription</code> <p>Event subscription to pull from</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>Skip window from previous catchup (if any)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>New catchup result if catchup was triggered, None otherwise</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_batch_and_check_catchup(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None:\n    \"\"\"Process a batch, measure lag, and trigger catchup if needed.\n\n    This method encapsulates one iteration of the main event loop:\n    1. Process a batch of events\n    2. Measure lag (average age + unprocessed count)\n    3. Clear skip window after first batch post-catchup\n    4. Trigger catchup if condition is met\n\n    Args:\n        subscription: Event subscription to pull from\n        catchup_result: Skip window from previous catchup (if any)\n\n    Returns:\n        New catchup result if catchup was triggered, None otherwise\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Process batch and measure lag\n    average_event_age = await self.process_event_batch(\n        subscription=subscription,\n        catchup_result=catchup_result,\n    )\n    lag = Lag(\n        average_event_age=average_event_age,\n        unprocessed_events=await subscription.depth(),\n    )\n\n    # Clear skip window after first batch (one-time use)\n    # The skip window prevents double-processing events that were\n    # already incorporated during the catchup operation\n    new_catchup_result = None\n\n    # Trigger catchup if condition met\n    if self.condition.should_catchup(lag):\n        new_catchup_result = await self.strategy.catchup(self.processor)\n\n    return new_catchup_result\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessorExecutor.run","title":"run  <code>async</code>","text":"<pre><code>run(subscription: EventSubscription) -&gt; None\n</code></pre> <p>Run the event processing loop continuously.</p> <p>This method runs indefinitely, processing events in batches and triggering catchup when the condition is met. It will only stop if: - The subscription ends (StopAsyncIteration) - An unhandled exception is raised - The async task is cancelled</p> <p>The method performs initial catchup at startup, then enters the main processing loop. If catchup returns a skip window, events in that window are skipped until we encounter an event beyond the window.</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>When subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def run(self, subscription: EventSubscription) -&gt; None:\n    \"\"\"Run the event processing loop continuously.\n\n    This method runs indefinitely, processing events in batches and\n    triggering catchup when the condition is met. It will only stop\n    if:\n    - The subscription ends (StopAsyncIteration)\n    - An unhandled exception is raised\n    - The async task is cancelled\n\n    The method performs initial catchup at startup, then enters the main\n    processing loop. If catchup returns a skip window, events in that\n    window are skipped until we encounter an event beyond the window.\n\n    Raises:\n        StopAsyncIteration: When subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Execute initial catchup at startup\n    catchup_result = await self.strategy.catchup(self.processor)\n\n    while True:\n        catchup_result = await self.process_batch_and_check_catchup(\n            subscription=subscription,\n            catchup_result=catchup_result,\n        )\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessor","title":"EventProcessor","text":"<p>Base class for building read models and handling events (CQRS read side).</p> <p>EventProcessors consume events from the event bus and use them to: 1. Build read models - Denormalized views optimized for queries 2. Execute side effects - Send emails, update search indexes, etc. 3. Coordinate sagas - Multi-step business processes</p> <p>In CQRS, processors are the read side that react to events published by the write side (aggregates). They ensure eventual consistency between the write model and read models.</p> <p>How it works: Subclass EventProcessor and use the @handles_event decorator to declare which events the processor is interested in. interlock automatically: - Sets up event routing based on type annotations - Dispatches events to the appropriate handler methods - Manages subscriptions and delivery</p> <p>Event Routing: The @handles_event decorator uses type annotations to determine routing: - Handler parameter type declares which event to handle - Multiple handlers can be defined for different event types - Routing is set up automatically during class definition</p> <p>Execution: Processors run via EventProcessorExecutor, which: - Subscribes to the event stream - Batches events for efficiency - Monitors lag and triggers catchup when needed - Handles errors and retries</p> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Class-level routing table (set by init_subclass)</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock.routing import handles_event</p> <p>class OrderPlaced(BaseModel): ...     order_id: str ...     customer_email: str ...     total_amount: float</p> <p>class OrderCancelled(BaseModel): ...     order_id: str ...     reason: str</p> <p>class EmailNotificationProcessor(EventProcessor): ...     '''Send emails when orders are placed or cancelled.''' ... ...     @handles_event ...     async def on_order_placed(self, event: OrderPlaced) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order confirmed! Total: ${event.total_amount}\" ...         ) ... ...     @handles_event ...     async def on_order_cancelled(self, event: OrderCancelled) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order cancelled: {event.reason}\" ...         ) ... ...     async def send_email(self, to: str, message: str) -&gt; None: ...         # Email sending implementation ...         pass</p> See Also <ul> <li>EventProcessorExecutor: Runtime execution engine</li> <li>@handles_event: Decorator for registering event handlers</li> <li>CatchupStrategy: Strategies for initializing processor state</li> <li>CatchupCondition: Triggers for catchup operations</li> </ul>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessor--run-the-processor","title":"Run the processor","text":"<p>executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"orders\"), ...     processor=EmailNotificationProcessor(), ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... ) await executor.run()  # Process events continuously</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessor.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event routing table when subclass is defined.</p> <p>This is called automatically when a class inherits from EventProcessor. It scans the class for @handles_event decorated methods and builds a routing table based on their type annotations.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>Additional keyword arguments passed to super().init_subclass</p> <p> TYPE: <code>object</code> DEFAULT: <code>{}</code> </p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event routing table when subclass is defined.\n\n    This is called automatically when a class inherits from EventProcessor.\n    It scans the class for @handles_event decorated methods and builds\n    a routing table based on their type annotations.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to super().__init_subclass__\n    \"\"\"\n    super().__init_subclass__(**kwargs)\n    cls._event_router = setup_event_handling(cls)\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.EventProcessor.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(event: Event[BaseModel] | BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered handler method.</p> <p>This is called by EventProcessorExecutor for each event. It uses the routing table to find the appropriate handler method based on the event type and invokes it.</p> <p>Handlers can receive either: - Just the event payload (annotated as <code>def handle(self, event: MyEvent)</code>) - The full Event wrapper (annotated as <code>def handle(self, event: Event[MyEvent])</code>)</p> <p>This method is async to support async event handler methods. If the handler method returns a coroutine, it will be properly awaited.</p> PARAMETER DESCRIPTION <code>event</code> <p>Either the Event wrapper or just the payload. When called from EventProcessorExecutor, this is the full Event wrapper. The router will pass the appropriate value to handlers based on their type annotation.</p> <p> TYPE: <code>Event[BaseModel] | BaseModel</code> </p> RETURNS DESCRIPTION <code>object</code> <p>The return value of the handler method (typically None)</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no handler is registered for the event type</p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>async def handle(self, event: Event[BaseModel] | BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered handler method.\n\n    This is called by EventProcessorExecutor for each event. It uses\n    the routing table to find the appropriate handler method based on\n    the event type and invokes it.\n\n    Handlers can receive either:\n    - Just the event payload (annotated as `def handle(self, event: MyEvent)`)\n    - The full Event wrapper (annotated as `def handle(self, event: Event[MyEvent])`)\n\n    This method is async to support async event handler methods. If the\n    handler method returns a coroutine, it will be properly awaited.\n\n    Args:\n        event: Either the Event wrapper or just the payload.\n            When called from EventProcessorExecutor, this is the full\n            Event wrapper. The router will pass the appropriate value\n            to handlers based on their type annotation.\n\n    Returns:\n        The return value of the handler method (typically None)\n\n    Raises:\n        KeyError: If no handler is registered for the event type\n    \"\"\"\n    # Determine if we got a wrapped Event or just a payload\n    if isinstance(event, Event):\n        # Route based on the payload type, but pass the wrapper to handlers that want it\n        result = self._event_router.route(self, event.data, event_wrapper=event)\n    else:\n        # Just a payload (backward compatibility / testing)\n        result = self._event_router.route(self, event)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.InMemorySagaStateStore","title":"InMemorySagaStateStore","text":"<pre><code>InMemorySagaStateStore()\n</code></pre> <p>               Bases: <code>SagaStateStore</code></p> <p>In-memory saga state store for development and testing.</p> <p>Mirrors InMemoryAggregateSnapshotStorageBackend pattern. Not intended for production use - state is lost on restart.</p> Example <p>store = InMemorySagaStateStore()</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._states: dict[str, BaseModel] = {}\n    self._completed_steps: dict[str, set[str]] = {}\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.InMemorySagaStateStore--save-state","title":"Save state","text":"<p>state = CheckoutState(order_id=\"order-1\", status=\"started\") await store.save(\"order-1\", state)</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.InMemorySagaStateStore--load-state","title":"Load state","text":"<p>loaded = await store.load(\"order-1\") assert loaded.order_id == \"order-1\"</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.InMemorySagaStateStore--mark-step-complete","title":"Mark step complete","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is True</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.InMemorySagaStateStore--check-idempotency","title":"Check idempotency","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is False  # Already complete</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.Saga","title":"Saga","text":"<pre><code>Saga(state_store: SagaStateStore)\n</code></pre> <p>               Bases: <code>EventProcessor</code>, <code>Generic[TState]</code></p> <p>Base class for stateful sagas with automatic state management.</p> <p>Extends EventProcessor with: - Automatic state persistence via SagaStateStore - Step-level idempotency tracking - Type-safe state access through generics - Automatic event routing via @saga_step decorator</p> <p>Sagas coordinate long-running business processes that span multiple aggregates. They handle compensation (rollback) when steps fail and ensure each step only executes once (idempotency).</p> <p>The Saga class is generic over TState for type safety, but the underlying SagaStateStore works with any BaseModel (like EventStore).</p> <p>Handler Patterns: - First step: Returns initial state - Subsequent steps: Receives and returns modified state - Cleanup steps: Returns None to delete state</p> Example <p>from interlock.application.events import ( ...     Saga, saga_step, SagaStateStore ... ) from pydantic import BaseModel</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False ...     payment_charged: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, state_store: SagaStateStore): ...         super().init(state_store) ... ...     @saga_step  # Step name auto-inferred from function name ...     async def on_checkout_initiated( ...         self, event: CheckoutInitiated ...     ) -&gt; CheckoutState: ...         # First step - return initial state ...         return CheckoutState( ...             order_id=event.saga_id, status=\"started\" ...         ) ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_inventory_reserved( ...         self, event: InventoryReserved, state: CheckoutState ...     ) -&gt; CheckoutState: ...         # Subsequent step - modify and return state ...         state.inventory_reserved = True ...         state.status = \"inventory_reserved\" ...         return state ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_payment_charged( ...         self, event: PaymentCharged, state: CheckoutState ...     ) -&gt; CheckoutState: ...         state.payment_charged = True ...         state.status = \"completed\" ...         return state ... ...     @saga_step ...     async def on_order_cancelled( ...         self, event: OrderCancelled, state: CheckoutState ...     ) -&gt; None: ...         # Cleanup - return None to delete state ...         return None</p> Usage with ApplicationBuilder PARAMETER DESCRIPTION <code>state_store</code> <p>Storage backend for saga state</p> <p> TYPE: <code>SagaStateStore</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self, state_store: SagaStateStore):\n    \"\"\"Initialize saga with state store.\n\n    Args:\n        state_store: Storage backend for saga state\n    \"\"\"\n    super().__init__()\n    self.state_store = state_store\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.Saga--saga-is-just-an-eventprocessor-no-special-handling-needed","title":"Saga is just an EventProcessor - no special handling needed!","text":"<p>app = (ApplicationBuilder() ...     .add_dependency(SagaStateStore, InMemorySagaStateStore()) ...     .add_event_processor(CheckoutSaga) ...     .build())</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore","title":"SagaStateStore","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract storage backend for saga state.</p> <p>Similar to AggregateSnapshotStorageBackend but for saga state. Not generic - works with any Pydantic BaseModel state type.</p> <p>Sagas are long-running business processes that coordinate multiple aggregates and handle compensation (rollback) when things fail. This store provides persistent state management for sagas.</p> Example <p>from interlock.events.processing import Saga, SagaStateStore</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, app: Application, state_store: SagaStateStore): ...         super().init(state_store) ...         self.app = app</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore--use-in-memory-store-for-development","title":"Use in-memory store for development","text":"<p>store = SagaStateStore.in_memory() saga = CheckoutSaga(app, store)</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.in_memory","title":"in_memory  <code>staticmethod</code>","text":"<pre><code>in_memory() -&gt; SagaStateStore\n</code></pre> <p>Create in-memory state store for development/testing.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@staticmethod\ndef in_memory() -&gt; \"SagaStateStore\":\n    \"\"\"Create in-memory state store for development/testing.\"\"\"\n    return InMemorySagaStateStore()\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.load","title":"load  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load(saga_id: str) -&gt; BaseModel | None\n</code></pre> <p>Load saga state by ID.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseModel | None</code> <p>The saga state if found, None otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def load(self, saga_id: str) -&gt; BaseModel | None:\n    \"\"\"Load saga state by ID.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n\n    Returns:\n        The saga state if found, None otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.save","title":"save  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save(saga_id: str, state: BaseModel) -&gt; None\n</code></pre> <p>Save saga state.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>state</code> <p>The state to save (any Pydantic BaseModel)</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def save(self, saga_id: str, state: BaseModel) -&gt; None:\n    \"\"\"Save saga state.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        state: The state to save (any Pydantic BaseModel)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(saga_id: str) -&gt; None\n</code></pre> <p>Delete saga state (cleanup after completion).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def delete(self, saga_id: str) -&gt; None:\n    \"\"\"Delete saga state (cleanup after completion).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.mark_step_complete","title":"mark_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>mark_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Mark a saga step as completed (for idempotency).</p> <p>This ensures that saga steps only execute once, even if the same event is processed multiple times (e.g., due to retries).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to mark complete</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if newly marked, False if already complete</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def mark_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Mark a saga step as completed (for idempotency).\n\n    This ensures that saga steps only execute once, even if the\n    same event is processed multiple times (e.g., due to retries).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to mark complete\n\n    Returns:\n        True if newly marked, False if already complete\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.SagaStateStore.is_step_complete","title":"is_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>is_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Check if a saga step has been completed.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if step is complete, False otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def is_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Check if a saga step has been completed.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to check\n\n    Returns:\n        True if step is complete, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupResult","title":"CatchupResult  <code>dataclass</code>","text":"<pre><code>CatchupResult(skip_before: datetime | None = None)\n</code></pre> <p>Result from catchup operation with skip window for avoiding double-processing.</p> <p>When a catchup strategy processes historical data (e.g., loading snapshots), those events have already been incorporated into the processor's state. To avoid processing them again when the executor resumes from the subscription, we need to skip events up to a certain timestamp.</p> ATTRIBUTE DESCRIPTION <code>skip_before</code> <p>Events with timestamp &lt;= this value should be skipped. None means no skipping is needed.</p> <p> TYPE: <code>datetime | None</code> </p> Example"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupResult--catchup-loaded-aggregates-up-to-2025-01-01-100000","title":"Catchup loaded aggregates up to 2025-01-01 10:00:00","text":"<p>result = CatchupResult(skip_before=datetime(2025, 1, 1, 10, 0, 0))</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupResult--executor-checks-each-event","title":"Executor checks each event","text":"<p>if result.should_skip(event): ...     continue  # Already processed via snapshot else: ...     await processor.handle(event.data)  # Process normally</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupResult.should_skip","title":"should_skip","text":"<pre><code>should_skip(event: Event) -&gt; bool\n</code></pre> <p>Check if an event should be skipped (already processed during catchup).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if event.timestamp &lt;= skip_before (already processed),</p> <code>bool</code> <p>False if event should be processed normally</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>def should_skip(self, event: \"Event\") -&gt; bool:\n    \"\"\"Check if an event should be skipped (already processed during catchup).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if event.timestamp &lt;= skip_before (already processed),\n        False if event should be processed normally\n    \"\"\"\n    if self.skip_before is None:\n        return False\n    return event.timestamp &lt;= self.skip_before\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupStrategy","title":"CatchupStrategy","text":"<p>               Bases: <code>ABC</code>, <code>Generic[P]</code></p> <p>Strategy for catching up an event processor with the event store.</p> <p>Event processors can fall behind the write model when: - They cannot keep up with the event publication rate - They are created after events have already been published - They experience downtime or processing delays</p> <p>Different catchup strategies offer trade-offs between: - Speed: How quickly the processor catches up - Resource usage: Compute and memory requirements - Consistency: Guarantees about event ordering and completeness - Applicability: Which scenarios the strategy works for</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.CatchupStrategy.catchup","title":"catchup  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; CatchupResult | None\n</code></pre> <p>Execute the catchup strategy to synchronize with the event store.</p> <p>This method is invoked: - When the processor is first started - When the associated CatchupCondition is met during runtime</p> <p>Implementations should: - Load necessary state to bring the processor up to date - Handle errors gracefully (network issues, missing data, etc.) - Track progress to resume from failures</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor instance to catch up</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>CatchupResult if events should be skipped, None otherwise</p> RAISES DESCRIPTION <code>Exception</code> <p>Implementation-specific exceptions for catchup failures.</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>@abstractmethod\nasync def catchup(self, processor: P) -&gt; CatchupResult | None:\n    \"\"\"Execute the catchup strategy to synchronize with the event store.\n\n    This method is invoked:\n    - When the processor is first started\n    - When the associated CatchupCondition is met during runtime\n\n    Implementations should:\n    - Load necessary state to bring the processor up to date\n    - Handle errors gracefully (network issues, missing data, etc.)\n    - Track progress to resume from failures\n\n    Args:\n        processor: The event processor instance to catch up\n\n    Returns:\n        CatchupResult if events should be skipped, None otherwise\n\n    Raises:\n        Exception: Implementation-specific exceptions for catchup failures.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.NoCatchup","title":"NoCatchup","text":"<p>               Bases: <code>CatchupStrategy</code></p> <p>No catchup - processor starts from current position.</p> <p>Use this strategy when: - The processor only needs to handle new events (not historical) - Historical state is not required for the read model - Testing scenarios where catchup is not needed</p> Example"},{"location":"reference/application/events/processing/#interlock.application.events.processing.NoCatchup--notification-processor-that-only-sends-for-new-events","title":"Notification processor that only sends for new events","text":"<p>processor = NotificationProcessor() executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"notifications\"), ...     processor=processor, ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.NoCatchup.catchup","title":"catchup  <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; None\n</code></pre> <p>No-op - no catchup is performed.</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor (ignored)</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None - no skip window needed</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>async def catchup(self, processor: P) -&gt; None:\n    \"\"\"No-op - no catchup is performed.\n\n    Args:\n        processor: The event processor (ignored)\n\n    Returns:\n        None - no skip window needed\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/application/events/processing/#interlock.application.events.processing.saga_step","title":"saga_step","text":"<pre><code>saga_step(\n    f: Callable[..., Any] | None = None,\n    *,\n    step_name: str | None = None,\n    saga_id: Callable[[TEvent], str] | None = None\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]\n</code></pre> <p>Decorator for saga steps providing automatic idempotency and state management.</p> <p>This decorator automatically: 1. Applies @handles_event for event routing 2. Infers step name from function name if not provided 3. Extracts saga_id from event (using extractor or convention) 4. Checks if the step has already been completed (idempotency) 5. Loads and passes state to handler if it expects a state parameter 6. Persists state changes based on return value 7. Marks step as complete</p> <p>Handler Signatures: - First step (no existing state):   <code>async def handler(self, event: Event) -&gt; State</code>   Returns the initial state to be persisted. - Subsequent steps:   <code>async def handler(self, event: Event, state: State) -&gt; State | None</code>   Receives current state, returns updated state or None to delete.</p> <p>State Management: - Return a BaseModel: State is automatically saved - Return None: State is automatically deleted - No return (void): State is not modified</p> <p>Saga ID Extraction: - By default, looks for <code>event.saga_id</code> (convention) - If <code>saga_id</code> extractor is provided, uses that instead - Extractor is a lambda/function that takes the event and returns   saga_id</p> PARAMETER DESCRIPTION <code>f</code> <p>Function being decorated (provided when used as @saga_step)</p> <p> TYPE: <code>Callable[..., Any] | None</code> DEFAULT: <code>None</code> </p> <code>step_name</code> <p>Unique name for this step. If None, inferred from function name.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>saga_id</code> <p>Optional function to extract saga_id from event. If None, uses event.saga_id (convention)</p> <p> TYPE: <code>Callable[[TEvent], str] | None</code> DEFAULT: <code>None</code> </p> Example <p>No parameters (step name inferred from function name):</p> <p>@saga_step ... async def on_checkout_initiated( ...     self, event: CheckoutInitiated ... ) -&gt; CheckoutState: ...     # Step name is \"on_checkout_initiated\" ...     return CheckoutState( ...         order_id=event.saga_id, status=\"started\" ...     )</p> <p>With step name:</p> <p>@saga_step(step_name=\"reserve_inventory\") ... async def handle_reservation( ...     self, event: InventoryReserved, state: CheckoutState ... ) -&gt; CheckoutState: ...     state.inventory_reserved = True ...     return state</p> <p>Custom saga_id extractor:</p> <p>@saga_step(saga_id=lambda e: e.order_id) ... async def on_inventory_reserved( ...     self, event: InventoryReserved, state: CheckoutState ... ) -&gt; CheckoutState: ...     state.inventory_reserved = True ...     return state</p> <p>Delete state by returning None:</p> <p>@saga_step ... async def on_order_cancelled( ...     self, event: OrderCancelled, state: CheckoutState ... ) -&gt; None: ...     # Cleanup logic here ...     return None  # State is deleted</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def saga_step(\n    f: Callable[..., Any] | None = None,\n    *,\n    step_name: str | None = None,\n    saga_id: Callable[[TEvent], str] | None = None,\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"Decorator for saga steps providing automatic idempotency\n    and state management.\n\n    This decorator automatically:\n    1. Applies @handles_event for event routing\n    2. Infers step name from function name if not provided\n    3. Extracts saga_id from event (using extractor or convention)\n    4. Checks if the step has already been completed (idempotency)\n    5. Loads and passes state to handler if it expects a state parameter\n    6. Persists state changes based on return value\n    7. Marks step as complete\n\n    **Handler Signatures:**\n    - First step (no existing state):\n      `async def handler(self, event: Event) -&gt; State`\n      Returns the initial state to be persisted.\n    - Subsequent steps:\n      `async def handler(self, event: Event, state: State) -&gt; State | None`\n      Receives current state, returns updated state or None to delete.\n\n    **State Management:**\n    - Return a BaseModel: State is automatically saved\n    - Return None: State is automatically deleted\n    - No return (void): State is not modified\n\n    **Saga ID Extraction:**\n    - By default, looks for `event.saga_id` (convention)\n    - If `saga_id` extractor is provided, uses that instead\n    - Extractor is a lambda/function that takes the event and returns\n      saga_id\n\n    Args:\n        f: Function being decorated (provided when used as @saga_step)\n        step_name: Unique name for this step. If None, inferred from\n            function name.\n        saga_id: Optional function to extract saga_id from event.\n            If None, uses event.saga_id (convention)\n\n    Example:\n        No parameters (step name inferred from function name):\n        &gt;&gt;&gt; @saga_step\n        ... async def on_checkout_initiated(\n        ...     self, event: CheckoutInitiated\n        ... ) -&gt; CheckoutState:\n        ...     # Step name is \"on_checkout_initiated\"\n        ...     return CheckoutState(\n        ...         order_id=event.saga_id, status=\"started\"\n        ...     )\n\n        With step name:\n        &gt;&gt;&gt; @saga_step(step_name=\"reserve_inventory\")\n        ... async def handle_reservation(\n        ...     self, event: InventoryReserved, state: CheckoutState\n        ... ) -&gt; CheckoutState:\n        ...     state.inventory_reserved = True\n        ...     return state\n\n        Custom saga_id extractor:\n        &gt;&gt;&gt; @saga_step(saga_id=lambda e: e.order_id)\n        ... async def on_inventory_reserved(\n        ...     self, event: InventoryReserved, state: CheckoutState\n        ... ) -&gt; CheckoutState:\n        ...     state.inventory_reserved = True\n        ...     return state\n\n        Delete state by returning None:\n        &gt;&gt;&gt; @saga_step\n        ... async def on_order_cancelled(\n        ...     self, event: OrderCancelled, state: CheckoutState\n        ... ) -&gt; None:\n        ...     # Cleanup logic here\n        ...     return None  # State is deleted\n    \"\"\"\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        func_name = getattr(func, \"__name__\", repr(func))\n        resolved_step_name = step_name or func_name\n        variant = SagaStepExecutor.executor_from_function(func)\n        executor = variant(resolved_step_name, saga_id, func)\n\n        @handles_event\n        @wraps(func)\n        async def wrapper(self: Saga[Any], event: BaseModel) -&gt; Any:\n            return await executor.execute(self, event)\n\n        return wrapper\n\n    # If no function is provided, that means we were called like\n    # @saga_step(step_name=\"...\") which means we need to return a decorator.\n    # If the function _is_ provided, that means we were called like @saga_step.\n    # So we need to return a decorated function.\n    return decorator if f is None else decorator(f)\n</code></pre>"},{"location":"reference/application/events/processing/conditions/","title":"conditions","text":""},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions","title":"conditions","text":""},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.Lag","title":"Lag  <code>dataclass</code>","text":"<pre><code>Lag(unprocessed_events: int, average_event_age: timedelta)\n</code></pre> <p>Metrics measuring how far behind a processor is from the write model.</p> <p>Lag is measured in two dimensions: 1. Unprocessed events - How many events are waiting to be processed 2. Average event age - How old the events being processed are</p> <p>Both metrics provide different insights: - High unprocessed count indicates backlog (volume problem) - High average age indicates slowness (latency problem)</p> <p>These metrics are used by CatchupCondition instances to determine when catchup strategies should be triggered.</p> ATTRIBUTE DESCRIPTION <code>unprocessed_events</code> <p>Number of events queued but not yet processed. Calculated as the depth of the event subscription.</p> <p> TYPE: <code>int</code> </p> <code>average_event_age</code> <p>Mean age of recently processed events. Calculated by averaging (utc_now - event.timestamp) over the most recent batch.</p> <p> TYPE: <code>timedelta</code> </p> Example <p>lag = Lag(unprocessed_events=1000, average_event_age=timedelta(minutes=5)) if lag.average_age_is_older_than(timedelta(minutes=10)): ...     print(\"Events are getting stale!\") if lag.unprocessed_events_is_greater_than(5000): ...     print(\"Significant backlog detected!\")</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.Lag.average_age_is_older_than","title":"average_age_is_older_than","text":"<pre><code>average_age_is_older_than(age: timedelta) -&gt; bool\n</code></pre> <p>Check if average event age exceeds a threshold.</p> PARAMETER DESCRIPTION <code>age</code> <p>Threshold to compare against</p> <p> TYPE: <code>timedelta</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if average_event_age &gt; age</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def average_age_is_older_than(self, age: timedelta) -&gt; bool:\n    \"\"\"Check if average event age exceeds a threshold.\n\n    Args:\n        age: Threshold to compare against\n\n    Returns:\n        True if average_event_age &gt; age\n    \"\"\"\n    return self.average_event_age &gt; age\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.Lag.unprocessed_events_is_greater_than","title":"unprocessed_events_is_greater_than","text":"<pre><code>unprocessed_events_is_greater_than(n: int) -&gt; bool\n</code></pre> <p>Check if unprocessed event count exceeds a threshold.</p> PARAMETER DESCRIPTION <code>n</code> <p>Threshold to compare against</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if unprocessed_events &gt; n</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def unprocessed_events_is_greater_than(self, n: int) -&gt; bool:\n    \"\"\"Check if unprocessed event count exceeds a threshold.\n\n    Args:\n        n: Threshold to compare against\n\n    Returns:\n        True if unprocessed_events &gt; n\n    \"\"\"\n    return self.unprocessed_events &gt; n\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.CatchupCondition","title":"CatchupCondition","text":"<p>               Bases: <code>ABC</code></p> <p>Condition for triggering catchup operations based on lag metrics.</p> <p>CatchupConditions evaluate processor lag to determine when catchup strategies should be executed. They can be combined using AnyOf/AllOf to create complex triggering logic.</p> <p>Common patterns: - Never: Disable catchup entirely - AfterNEvents: Trigger when backlog exceeds threshold - AfterNAge: Trigger when events get too old - AnyOf/AllOf: Combine multiple conditions with OR/AND logic</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.CatchupCondition.should_catchup","title":"should_catchup  <code>abstractmethod</code>","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Evaluate whether catchup should be triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics for the processor</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if catchup should be initiated, False otherwise</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>@abstractmethod\ndef should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Evaluate whether catchup should be triggered.\n\n    Args:\n        lag: Current lag metrics for the processor\n\n    Returns:\n        True if catchup should be initiated, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.Never","title":"Never","text":"<p>               Bases: <code>CatchupCondition</code></p> <p>Never trigger catchup - disable catchup entirely.</p> <p>Use this when: - Processor only handles new events (no historical state) - Catchup is managed manually or externally - Testing scenarios where catchup is not needed</p> Example <p>executor = EventProcessorExecutor( ...     subscription=subscription, ...     processor=processor, ...     condition=Never(),  # Catchup disabled ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.Never.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Always returns False - catchup never triggered.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Lag metrics (ignored)</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>False</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Always returns False - catchup never triggered.\n\n    Args:\n        lag: Lag metrics (ignored)\n\n    Returns:\n        False\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNEvents","title":"AfterNEvents","text":"<pre><code>AfterNEvents(n: int)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when unprocessed event count exceeds threshold.</p> <p>This condition triggers based on backlog volume, not event age. It's useful for preventing unbounded queue growth.</p> PARAMETER DESCRIPTION <code>n</code> <p>Maximum number of unprocessed events before triggering catchup</p> <p> TYPE: <code>int</code> </p> Example PARAMETER DESCRIPTION <code>n</code> <p>Unprocessed event count threshold (must be &gt; 0)</p> <p> TYPE: <code>int</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, n: int):\n    \"\"\"Initialize with event count threshold.\n\n    Args:\n        n: Unprocessed event count threshold (must be &gt; 0)\n    \"\"\"\n    if n &lt;= 0:\n        raise ValueError(\"Threshold must be positive\")\n    self.n = n\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNEvents--trigger-catchup-if-more-than-10000-events-are-queued","title":"Trigger catchup if more than 10,000 events are queued","text":"<p>condition = AfterNEvents(10_000) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNEvents.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if unprocessed events exceed threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.unprocessed_events &gt; n</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if unprocessed events exceed threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.unprocessed_events &gt; n\n    \"\"\"\n    return lag.unprocessed_events_is_greater_than(self.n)\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNAge","title":"AfterNAge","text":"<pre><code>AfterNAge(age: timedelta)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup when average event age exceeds threshold.</p> <p>This condition triggers based on event staleness, not backlog size. It's useful for ensuring timely processing and data freshness.</p> PARAMETER DESCRIPTION <code>age</code> <p>Maximum acceptable average event age</p> <p> TYPE: <code>timedelta</code> </p> Example PARAMETER DESCRIPTION <code>age</code> <p>Maximum average event age before triggering catchup</p> <p> TYPE: <code>timedelta</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, age: timedelta):\n    \"\"\"Initialize with age threshold.\n\n    Args:\n        age: Maximum average event age before triggering catchup\n    \"\"\"\n    if age.total_seconds() &lt;= 0:\n        raise ValueError(\"Age threshold must be positive\")\n    self.age = age\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNAge--trigger-catchup-if-events-are-5-minutes-old-on-average","title":"Trigger catchup if events are &gt; 5 minutes old on average","text":"<p>condition = AfterNAge(timedelta(minutes=5)) if condition.should_catchup(lag): ...     await strategy.catchup()</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AfterNAge.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if average event age exceeds threshold.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if lag.average_event_age &gt; age</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if average event age exceeds threshold.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if lag.average_event_age &gt; age\n    \"\"\"\n    return lag.average_age_is_older_than(self.age)\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AnyOf","title":"AnyOf","text":"<pre><code>AnyOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup if ANY of the given conditions are met (OR logic).</p> <p>This allows combining multiple conditions where any single condition being true will trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AnyOf--catchup-if-either-queue-5000-or-events-10min-old","title":"Catchup if EITHER queue &gt; 5000 OR events &gt; 10min old","text":"<p>condition = AnyOf( ...     AfterNEvents(5000), ...     AfterNAge(timedelta(minutes=10)) ... )</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AnyOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if any condition is satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if any condition returns True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if any condition is satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if any condition returns True\n    \"\"\"\n    return any(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AllOf","title":"AllOf","text":"<pre><code>AllOf(*conditions: CatchupCondition)\n</code></pre> <p>               Bases: <code>CatchupCondition</code></p> <p>Trigger catchup only if ALL given conditions are met (AND logic).</p> <p>This allows combining multiple conditions where all conditions must be true to trigger catchup.</p> Example PARAMETER DESCRIPTION <code>*conditions</code> <p>Variable number of CatchupCondition instances</p> <p> TYPE: <code>CatchupCondition</code> DEFAULT: <code>()</code> </p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def __init__(self, *conditions: CatchupCondition):\n    \"\"\"Initialize with conditions to evaluate.\n\n    Args:\n        *conditions: Variable number of CatchupCondition instances\n    \"\"\"\n    if not conditions:\n        raise ValueError(\"Must provide at least one condition\")\n    self.conditions = conditions\n</code></pre>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AllOf--catchup-only-if-queue-1000-and-events-5min-old","title":"Catchup only if queue &gt; 1000 AND events &gt; 5min old","text":"<p>condition = AllOf( ...     AfterNEvents(1000), ...     AfterNAge(timedelta(minutes=5)) ... )</p>"},{"location":"reference/application/events/processing/conditions/#interlock.application.events.processing.conditions.AllOf.should_catchup","title":"should_catchup","text":"<pre><code>should_catchup(lag: Lag) -&gt; bool\n</code></pre> <p>Check if all conditions are satisfied.</p> PARAMETER DESCRIPTION <code>lag</code> <p>Current lag metrics</p> <p> TYPE: <code>Lag</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if all conditions return True</p> Source code in <code>interlock/application/events/processing/conditions.py</code> <pre><code>def should_catchup(self, lag: Lag) -&gt; bool:\n    \"\"\"Check if all conditions are satisfied.\n\n    Args:\n        lag: Current lag metrics\n\n    Returns:\n        True if all conditions return True\n    \"\"\"\n    return all(c.should_catchup(lag) for c in self.conditions)\n</code></pre>"},{"location":"reference/application/events/processing/executor/","title":"executor","text":""},{"location":"reference/application/events/processing/executor/#interlock.application.events.processing.executor","title":"executor","text":""},{"location":"reference/application/events/processing/executor/#interlock.application.events.processing.executor.EventProcessorExecutor","title":"EventProcessorExecutor","text":"<pre><code>EventProcessorExecutor(\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n)\n</code></pre> <p>               Bases: <code>Generic[P]</code></p> <p>Runtime execution engine for event processors.</p> <p>EventProcessorExecutor manages the continuous processing of events by: 1. Subscribing to an event stream via EventSubscription 2. Batching events for efficient processing 3. Monitoring processor lag (backlog and event age) 4. Triggering catchup strategies when conditions are met</p> <p>This is the \"event loop\" that drives event processors. It runs continuously, pulling events from the subscription and routing them to the processor's handlers.</p> <p>Batching: Events are processed in batches to improve throughput. After each batch, lag metrics are calculated to determine if catchup is needed.</p> <p>Lag Monitoring: After each batch, the executor measures: - Unprocessed events (subscription depth) - Average event age (time from event.timestamp to processing)</p> <p>Catchup Triggering: If the CatchupCondition evaluates to True, the CatchupStrategy is executed. Blocking strategies pause event processing; non-blocking strategies run concurrently.</p> ATTRIBUTE DESCRIPTION <code>subscription</code> <p>Event stream to consume from</p> <p> </p> <code>processor</code> <p>Event processor with handler methods</p> <p> </p> <code>condition</code> <p>Condition for triggering catchup</p> <p> </p> <code>strategy</code> <p>Strategy for catching up when triggered</p> <p> </p> <code>batch_size</code> <p>Number of events to process before checking lag</p> <p> </p> Note <p>The run() method runs indefinitely until interrupted. Use asyncio task cancellation or exception handling to stop it gracefully.</p> PARAMETER DESCRIPTION <code>processor</code> <p>Processor with event handlers</p> <p> TYPE: <code>P</code> </p> <code>condition</code> <p>When to trigger catchup</p> <p> TYPE: <code>CatchupCondition</code> </p> <code>strategy</code> <p>How to catch up when triggered</p> <p> TYPE: <code>CatchupStrategy[P]</code> </p> <code>batch_size</code> <p>Events to process per batch (must be &gt; 0)</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If batch_size &lt;= 0</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>def __init__(\n    self,\n    processor: P,\n    condition: CatchupCondition,\n    strategy: CatchupStrategy[P],\n    batch_size: int = 1000,\n) -&gt; None:\n    \"\"\"Initialize the executor with its dependencies.\n\n    Args:\n        processor: Processor with event handlers\n        condition: When to trigger catchup\n        strategy: How to catch up when triggered\n        batch_size: Events to process per batch (must be &gt; 0)\n\n    Raises:\n        ValueError: If batch_size &lt;= 0\n    \"\"\"\n    if batch_size &lt;= 0:\n        raise ValueError(\"batch_size must be positive\")\n    self.processor = processor\n    self.condition = condition\n    self.strategy = strategy\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/application/events/processing/executor/#interlock.application.events.processing.executor.EventProcessorExecutor.process_event_batch","title":"process_event_batch  <code>async</code>","text":"<pre><code>process_event_batch(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta\n</code></pre> <p>Process a batch of events and calculate average event age.</p> <p>Pulls batch_size events from the subscription, routes each to the processor's handlers, and calculates the mean age of processed events.</p> <p>If a catchup_result is provided, events in the skip window are skipped to avoid double-processing events that were already incorporated during catchup.</p> <p>For each event, the execution context is restored from the event metadata before processing, allowing processors to: - Access correlation/causation IDs for logging - Dispatch new commands with proper context inheritance - Track the causal chain in sagas and process managers</p> <p>The context is cleared after each event to prevent leakage.</p> PARAMETER DESCRIPTION <code>subscription</code> <p>The subscription to pull events from.</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>The skip window from catchup operation (Optional)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>timedelta</code> <p>Average time between event.timestamp and processing time</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions raised by event handlers.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_event_batch(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; timedelta:\n    \"\"\"Process a batch of events and calculate average event age.\n\n    Pulls batch_size events from the subscription, routes each to the\n    processor's handlers, and calculates the mean age of processed events.\n\n    If a catchup_result is provided, events in the skip window are skipped\n    to avoid double-processing events that were already incorporated during\n    catchup.\n\n    For each event, the execution context is restored from the event\n    metadata before processing, allowing processors to:\n    - Access correlation/causation IDs for logging\n    - Dispatch new commands with proper context inheritance\n    - Track the causal chain in sagas and process managers\n\n    The context is cleared after each event to prevent leakage.\n\n    Args:\n        subscription: The subscription to pull events from.\n        catchup_result: The skip window from catchup operation (Optional)\n\n    Returns:\n        Average time between event.timestamp and processing time\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions raised by event handlers.\n    \"\"\"\n    total_lag_time = timedelta()\n    events_processed = 0\n\n    for _ in range(self.batch_size):\n        event = await subscription.next()\n        total_lag_time += utc_now() - event.timestamp\n\n        # Skip events in the skip window (already processed during catchup)\n        if catchup_result and catchup_result.should_skip(event):\n            continue\n\n        events_processed += 1\n\n        # Restore context from event metadata before processing\n        # This allows event processors to dispatch commands with proper\n        # causation\n        context_set = False\n        if event.correlation_id is not None:\n            ctx = ExecutionContext(\n                correlation_id=event.correlation_id,\n                causation_id=event.id,\n                command_id=None,\n            )\n            set_context(ctx)\n            context_set = True\n\n        try:\n            # Pass full event - processor.handle will extract payload for routing\n            # but pass wrapper to handlers that want it (annotated with Event[T])\n            await self.processor.handle(event)\n        finally:\n            # Clear context only if we set it to prevent leakage\n            if context_set:\n                clear_context()\n\n    # If we didn't process any events, avoid division by zero\n    if events_processed == 0:\n        return timedelta()\n\n    return total_lag_time / events_processed\n</code></pre>"},{"location":"reference/application/events/processing/executor/#interlock.application.events.processing.executor.EventProcessorExecutor.process_batch_and_check_catchup","title":"process_batch_and_check_catchup  <code>async</code>","text":"<pre><code>process_batch_and_check_catchup(\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None\n</code></pre> <p>Process a batch, measure lag, and trigger catchup if needed.</p> <p>This method encapsulates one iteration of the main event loop: 1. Process a batch of events 2. Measure lag (average age + unprocessed count) 3. Clear skip window after first batch post-catchup 4. Trigger catchup if condition is met</p> PARAMETER DESCRIPTION <code>subscription</code> <p>Event subscription to pull from</p> <p> TYPE: <code>EventSubscription</code> </p> <code>catchup_result</code> <p>Skip window from previous catchup (if any)</p> <p> TYPE: <code>CatchupResult | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>New catchup result if catchup was triggered, None otherwise</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>If subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def process_batch_and_check_catchup(\n    self,\n    subscription: EventSubscription,\n    catchup_result: CatchupResult | None = None,\n) -&gt; CatchupResult | None:\n    \"\"\"Process a batch, measure lag, and trigger catchup if needed.\n\n    This method encapsulates one iteration of the main event loop:\n    1. Process a batch of events\n    2. Measure lag (average age + unprocessed count)\n    3. Clear skip window after first batch post-catchup\n    4. Trigger catchup if condition is met\n\n    Args:\n        subscription: Event subscription to pull from\n        catchup_result: Skip window from previous catchup (if any)\n\n    Returns:\n        New catchup result if catchup was triggered, None otherwise\n\n    Raises:\n        StopAsyncIteration: If subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Process batch and measure lag\n    average_event_age = await self.process_event_batch(\n        subscription=subscription,\n        catchup_result=catchup_result,\n    )\n    lag = Lag(\n        average_event_age=average_event_age,\n        unprocessed_events=await subscription.depth(),\n    )\n\n    # Clear skip window after first batch (one-time use)\n    # The skip window prevents double-processing events that were\n    # already incorporated during the catchup operation\n    new_catchup_result = None\n\n    # Trigger catchup if condition met\n    if self.condition.should_catchup(lag):\n        new_catchup_result = await self.strategy.catchup(self.processor)\n\n    return new_catchup_result\n</code></pre>"},{"location":"reference/application/events/processing/executor/#interlock.application.events.processing.executor.EventProcessorExecutor.run","title":"run  <code>async</code>","text":"<pre><code>run(subscription: EventSubscription) -&gt; None\n</code></pre> <p>Run the event processing loop continuously.</p> <p>This method runs indefinitely, processing events in batches and triggering catchup when the condition is met. It will only stop if: - The subscription ends (StopAsyncIteration) - An unhandled exception is raised - The async task is cancelled</p> <p>The method performs initial catchup at startup, then enters the main processing loop. If catchup returns a skip window, events in that window are skipped until we encounter an event beyond the window.</p> RAISES DESCRIPTION <code>StopAsyncIteration</code> <p>When subscription ends.</p> <code>Exception</code> <p>Any exceptions from event handlers or catchup strategy.</p> Source code in <code>interlock/application/events/processing/executor.py</code> <pre><code>async def run(self, subscription: EventSubscription) -&gt; None:\n    \"\"\"Run the event processing loop continuously.\n\n    This method runs indefinitely, processing events in batches and\n    triggering catchup when the condition is met. It will only stop\n    if:\n    - The subscription ends (StopAsyncIteration)\n    - An unhandled exception is raised\n    - The async task is cancelled\n\n    The method performs initial catchup at startup, then enters the main\n    processing loop. If catchup returns a skip window, events in that\n    window are skipped until we encounter an event beyond the window.\n\n    Raises:\n        StopAsyncIteration: When subscription ends.\n        Exception: Any exceptions from event handlers or catchup strategy.\n    \"\"\"\n    # Execute initial catchup at startup\n    catchup_result = await self.strategy.catchup(self.processor)\n\n    while True:\n        catchup_result = await self.process_batch_and_check_catchup(\n            subscription=subscription,\n            catchup_result=catchup_result,\n        )\n</code></pre>"},{"location":"reference/application/events/processing/processor/","title":"processor","text":""},{"location":"reference/application/events/processing/processor/#interlock.application.events.processing.processor","title":"processor","text":"<p>Event processors for building read models and handling side effects.</p> <p>This module provides the infrastructure for implementing the read side of CQRS: - EventProcessor: Base class for handling events and building read models - CatchupStrategy: Strategies for catching up with the event store - CatchupCondition: Conditions for triggering catchup operations - EventProcessorExecutor: Runtime execution engine for processors</p>"},{"location":"reference/application/events/processing/processor/#interlock.application.events.processing.processor.EventProcessor","title":"EventProcessor","text":"<p>Base class for building read models and handling events (CQRS read side).</p> <p>EventProcessors consume events from the event bus and use them to: 1. Build read models - Denormalized views optimized for queries 2. Execute side effects - Send emails, update search indexes, etc. 3. Coordinate sagas - Multi-step business processes</p> <p>In CQRS, processors are the read side that react to events published by the write side (aggregates). They ensure eventual consistency between the write model and read models.</p> <p>How it works: Subclass EventProcessor and use the @handles_event decorator to declare which events the processor is interested in. interlock automatically: - Sets up event routing based on type annotations - Dispatches events to the appropriate handler methods - Manages subscriptions and delivery</p> <p>Event Routing: The @handles_event decorator uses type annotations to determine routing: - Handler parameter type declares which event to handle - Multiple handlers can be defined for different event types - Routing is set up automatically during class definition</p> <p>Execution: Processors run via EventProcessorExecutor, which: - Subscribes to the event stream - Batches events for efficiency - Monitors lag and triggers catchup when needed - Handles errors and retries</p> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Class-level routing table (set by init_subclass)</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock.routing import handles_event</p> <p>class OrderPlaced(BaseModel): ...     order_id: str ...     customer_email: str ...     total_amount: float</p> <p>class OrderCancelled(BaseModel): ...     order_id: str ...     reason: str</p> <p>class EmailNotificationProcessor(EventProcessor): ...     '''Send emails when orders are placed or cancelled.''' ... ...     @handles_event ...     async def on_order_placed(self, event: OrderPlaced) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order confirmed! Total: ${event.total_amount}\" ...         ) ... ...     @handles_event ...     async def on_order_cancelled(self, event: OrderCancelled) -&gt; None: ...         await self.send_email( ...             event.customer_email, ...             f\"Order cancelled: {event.reason}\" ...         ) ... ...     async def send_email(self, to: str, message: str) -&gt; None: ...         # Email sending implementation ...         pass</p> See Also <ul> <li>EventProcessorExecutor: Runtime execution engine</li> <li>@handles_event: Decorator for registering event handlers</li> <li>CatchupStrategy: Strategies for initializing processor state</li> <li>CatchupCondition: Triggers for catchup operations</li> </ul>"},{"location":"reference/application/events/processing/processor/#interlock.application.events.processing.processor.EventProcessor--run-the-processor","title":"Run the processor","text":"<p>executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"orders\"), ...     processor=EmailNotificationProcessor(), ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... ) await executor.run()  # Process events continuously</p>"},{"location":"reference/application/events/processing/processor/#interlock.application.events.processing.processor.EventProcessor.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event routing table when subclass is defined.</p> <p>This is called automatically when a class inherits from EventProcessor. It scans the class for @handles_event decorated methods and builds a routing table based on their type annotations.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>Additional keyword arguments passed to super().init_subclass</p> <p> TYPE: <code>object</code> DEFAULT: <code>{}</code> </p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event routing table when subclass is defined.\n\n    This is called automatically when a class inherits from EventProcessor.\n    It scans the class for @handles_event decorated methods and builds\n    a routing table based on their type annotations.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to super().__init_subclass__\n    \"\"\"\n    super().__init_subclass__(**kwargs)\n    cls._event_router = setup_event_handling(cls)\n</code></pre>"},{"location":"reference/application/events/processing/processor/#interlock.application.events.processing.processor.EventProcessor.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(event: Event[BaseModel] | BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered handler method.</p> <p>This is called by EventProcessorExecutor for each event. It uses the routing table to find the appropriate handler method based on the event type and invokes it.</p> <p>Handlers can receive either: - Just the event payload (annotated as <code>def handle(self, event: MyEvent)</code>) - The full Event wrapper (annotated as <code>def handle(self, event: Event[MyEvent])</code>)</p> <p>This method is async to support async event handler methods. If the handler method returns a coroutine, it will be properly awaited.</p> PARAMETER DESCRIPTION <code>event</code> <p>Either the Event wrapper or just the payload. When called from EventProcessorExecutor, this is the full Event wrapper. The router will pass the appropriate value to handlers based on their type annotation.</p> <p> TYPE: <code>Event[BaseModel] | BaseModel</code> </p> RETURNS DESCRIPTION <code>object</code> <p>The return value of the handler method (typically None)</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no handler is registered for the event type</p> Source code in <code>interlock/application/events/processing/processor.py</code> <pre><code>async def handle(self, event: Event[BaseModel] | BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered handler method.\n\n    This is called by EventProcessorExecutor for each event. It uses\n    the routing table to find the appropriate handler method based on\n    the event type and invokes it.\n\n    Handlers can receive either:\n    - Just the event payload (annotated as `def handle(self, event: MyEvent)`)\n    - The full Event wrapper (annotated as `def handle(self, event: Event[MyEvent])`)\n\n    This method is async to support async event handler methods. If the\n    handler method returns a coroutine, it will be properly awaited.\n\n    Args:\n        event: Either the Event wrapper or just the payload.\n            When called from EventProcessorExecutor, this is the full\n            Event wrapper. The router will pass the appropriate value\n            to handlers based on their type annotation.\n\n    Returns:\n        The return value of the handler method (typically None)\n\n    Raises:\n        KeyError: If no handler is registered for the event type\n    \"\"\"\n    # Determine if we got a wrapped Event or just a payload\n    if isinstance(event, Event):\n        # Route based on the payload type, but pass the wrapper to handlers that want it\n        result = self._event_router.route(self, event.data, event_wrapper=event)\n    else:\n        # Just a payload (backward compatibility / testing)\n        result = self._event_router.route(self, event)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result\n</code></pre>"},{"location":"reference/application/events/processing/saga/","title":"saga","text":""},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga","title":"saga","text":"<p>Base saga class with state management and step idempotency.</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore","title":"SagaStateStore","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract storage backend for saga state.</p> <p>Similar to AggregateSnapshotStorageBackend but for saga state. Not generic - works with any Pydantic BaseModel state type.</p> <p>Sagas are long-running business processes that coordinate multiple aggregates and handle compensation (rollback) when things fail. This store provides persistent state management for sagas.</p> Example <p>from interlock.events.processing import Saga, SagaStateStore</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, app: Application, state_store: SagaStateStore): ...         super().init(state_store) ...         self.app = app</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore--use-in-memory-store-for-development","title":"Use in-memory store for development","text":"<p>store = SagaStateStore.in_memory() saga = CheckoutSaga(app, store)</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.in_memory","title":"in_memory  <code>staticmethod</code>","text":"<pre><code>in_memory() -&gt; SagaStateStore\n</code></pre> <p>Create in-memory state store for development/testing.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@staticmethod\ndef in_memory() -&gt; \"SagaStateStore\":\n    \"\"\"Create in-memory state store for development/testing.\"\"\"\n    return InMemorySagaStateStore()\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.load","title":"load  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load(saga_id: str) -&gt; BaseModel | None\n</code></pre> <p>Load saga state by ID.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseModel | None</code> <p>The saga state if found, None otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def load(self, saga_id: str) -&gt; BaseModel | None:\n    \"\"\"Load saga state by ID.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n\n    Returns:\n        The saga state if found, None otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.save","title":"save  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save(saga_id: str, state: BaseModel) -&gt; None\n</code></pre> <p>Save saga state.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>state</code> <p>The state to save (any Pydantic BaseModel)</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def save(self, saga_id: str, state: BaseModel) -&gt; None:\n    \"\"\"Save saga state.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        state: The state to save (any Pydantic BaseModel)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(saga_id: str) -&gt; None\n</code></pre> <p>Delete saga state (cleanup after completion).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def delete(self, saga_id: str) -&gt; None:\n    \"\"\"Delete saga state (cleanup after completion).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.mark_step_complete","title":"mark_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>mark_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Mark a saga step as completed (for idempotency).</p> <p>This ensures that saga steps only execute once, even if the same event is processed multiple times (e.g., due to retries).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to mark complete</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if newly marked, False if already complete</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def mark_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Mark a saga step as completed (for idempotency).\n\n    This ensures that saga steps only execute once, even if the\n    same event is processed multiple times (e.g., due to retries).\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to mark complete\n\n    Returns:\n        True if newly marked, False if already complete\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStateStore.is_step_complete","title":"is_step_complete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>is_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Check if a saga step has been completed.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if step is complete, False otherwise</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def is_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Check if a saga step has been completed.\n\n    Args:\n        saga_id: Unique identifier for the saga instance\n        step_name: Name of the step to check\n\n    Returns:\n        True if step is complete, False otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InMemorySagaStateStore","title":"InMemorySagaStateStore","text":"<pre><code>InMemorySagaStateStore()\n</code></pre> <p>               Bases: <code>SagaStateStore</code></p> <p>In-memory saga state store for development and testing.</p> <p>Mirrors InMemoryAggregateSnapshotStorageBackend pattern. Not intended for production use - state is lost on restart.</p> Example <p>store = InMemorySagaStateStore()</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._states: dict[str, BaseModel] = {}\n    self._completed_steps: dict[str, set[str]] = {}\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InMemorySagaStateStore--save-state","title":"Save state","text":"<p>state = CheckoutState(order_id=\"order-1\", status=\"started\") await store.save(\"order-1\", state)</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InMemorySagaStateStore--load-state","title":"Load state","text":"<p>loaded = await store.load(\"order-1\") assert loaded.order_id == \"order-1\"</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InMemorySagaStateStore--mark-step-complete","title":"Mark step complete","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is True</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InMemorySagaStateStore--check-idempotency","title":"Check idempotency","text":"<p>was_new = await store.mark_step_complete(\"order-1\", \"reserve_inventory\") assert was_new is False  # Already complete</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.Saga","title":"Saga","text":"<pre><code>Saga(state_store: SagaStateStore)\n</code></pre> <p>               Bases: <code>EventProcessor</code>, <code>Generic[TState]</code></p> <p>Base class for stateful sagas with automatic state management.</p> <p>Extends EventProcessor with: - Automatic state persistence via SagaStateStore - Step-level idempotency tracking - Type-safe state access through generics - Automatic event routing via @saga_step decorator</p> <p>Sagas coordinate long-running business processes that span multiple aggregates. They handle compensation (rollback) when steps fail and ensure each step only executes once (idempotency).</p> <p>The Saga class is generic over TState for type safety, but the underlying SagaStateStore works with any BaseModel (like EventStore).</p> <p>Handler Patterns: - First step: Returns initial state - Subsequent steps: Receives and returns modified state - Cleanup steps: Returns None to delete state</p> Example <p>from interlock.application.events import ( ...     Saga, saga_step, SagaStateStore ... ) from pydantic import BaseModel</p> <p>class CheckoutState(BaseModel): ...     order_id: str ...     status: str ...     inventory_reserved: bool = False ...     payment_charged: bool = False</p> <p>class CheckoutSaga(Saga[CheckoutState]): ...     def init(self, state_store: SagaStateStore): ...         super().init(state_store) ... ...     @saga_step  # Step name auto-inferred from function name ...     async def on_checkout_initiated( ...         self, event: CheckoutInitiated ...     ) -&gt; CheckoutState: ...         # First step - return initial state ...         return CheckoutState( ...             order_id=event.saga_id, status=\"started\" ...         ) ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_inventory_reserved( ...         self, event: InventoryReserved, state: CheckoutState ...     ) -&gt; CheckoutState: ...         # Subsequent step - modify and return state ...         state.inventory_reserved = True ...         state.status = \"inventory_reserved\" ...         return state ... ...     @saga_step(saga_id=lambda e: e.order_id) ...     async def on_payment_charged( ...         self, event: PaymentCharged, state: CheckoutState ...     ) -&gt; CheckoutState: ...         state.payment_charged = True ...         state.status = \"completed\" ...         return state ... ...     @saga_step ...     async def on_order_cancelled( ...         self, event: OrderCancelled, state: CheckoutState ...     ) -&gt; None: ...         # Cleanup - return None to delete state ...         return None</p> Usage with ApplicationBuilder PARAMETER DESCRIPTION <code>state_store</code> <p>Storage backend for saga state</p> <p> TYPE: <code>SagaStateStore</code> </p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(self, state_store: SagaStateStore):\n    \"\"\"Initialize saga with state store.\n\n    Args:\n        state_store: Storage backend for saga state\n    \"\"\"\n    super().__init__()\n    self.state_store = state_store\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.Saga--saga-is-just-an-eventprocessor-no-special-handling-needed","title":"Saga is just an EventProcessor - no special handling needed!","text":"<p>app = (ApplicationBuilder() ...     .add_dependency(SagaStateStore, InMemorySagaStateStore()) ...     .add_event_processor(CheckoutSaga) ...     .build())</p>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor","title":"SagaStepExecutor","text":"<pre><code>SagaStepExecutor(\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for executing saga steps with idempotency.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(\n    self,\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n):\n    self.step_name = step_name\n    self.saga_id_extractor = saga_id_extractor\n    self.handler_func = handler_func\n    self.logger = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.extract_saga_id","title":"extract_saga_id","text":"<pre><code>extract_saga_id(event: BaseModel) -&gt; str\n</code></pre> <p>Extract saga_id from event using extractor or convention.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def extract_saga_id(self, event: BaseModel) -&gt; str:\n    \"\"\"Extract saga_id from event using extractor or convention.\"\"\"\n    if self.saga_id_extractor is not None:\n        return self.saga_id_extractor(event)  # type: ignore\n\n    saga_id = getattr(event, \"saga_id\", None)\n    if saga_id is None:\n        raise ValueError(\n            f\"Event {type(event).__name__} must have \"\n            f\"'saga_id' field, or provide a custom extractor: \"\n            f\"@saga_step(saga_id=lambda e: e.your_field)\"\n        )\n    return saga_id\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.check_idempotency","title":"check_idempotency  <code>async</code>","text":"<pre><code>check_idempotency(saga: Saga[Any], saga_id: str) -&gt; bool\n</code></pre> <p>Check if step is already complete. Returns True if should skip.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def check_idempotency(self, saga: Saga[Any], saga_id: str) -&gt; bool:\n    \"\"\"Check if step is already complete. Returns True if should skip.\"\"\"\n    if await saga.state_store.is_step_complete(saga_id, self.step_name):\n        self.logger.info(\n            f\"Step '{self.step_name}' already complete for saga {saga_id}, skipping\"\n        )\n        return True\n    return False\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.persist_state","title":"persist_state  <code>async</code>","text":"<pre><code>persist_state(\n    saga: Saga[Any], saga_id: str, result: Any\n) -&gt; None\n</code></pre> <p>Persist state based on handler return value.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def persist_state(self, saga: Saga[Any], saga_id: str, result: Any) -&gt; None:\n    \"\"\"Persist state based on handler return value.\"\"\"\n    if result is None:\n        await saga.state_store.delete(saga_id)\n    elif isinstance(result, BaseModel):\n        await saga.state_store.save(saga_id, result)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.mark_step_completed","title":"mark_step_completed  <code>async</code>","text":"<pre><code>mark_step_completed(saga: Saga[Any], saga_id: str) -&gt; None\n</code></pre> <p>Mark step as complete and log.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def mark_step_completed(self, saga: Saga[Any], saga_id: str) -&gt; None:\n    \"\"\"Mark step as complete and log.\"\"\"\n    await saga.state_store.mark_step_complete(saga_id, self.step_name)\n    self.logger.info(f\"Step '{self.step_name}' completed for saga {saga_id}\")\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.execute_handler","title":"execute_handler  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>execute_handler(\n    saga: Saga[Any], event: BaseModel, saga_id: str\n) -&gt; Any\n</code></pre> <p>Execute the handler function with appropriate parameters.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>@abstractmethod\nasync def execute_handler(self, saga: Saga[Any], event: BaseModel, saga_id: str) -&gt; Any:\n    \"\"\"Execute the handler function with appropriate parameters.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SagaStepExecutor.execute","title":"execute  <code>async</code>","text":"<pre><code>execute(saga: Saga[Any], event: BaseModel) -&gt; Any\n</code></pre> <p>Execute complete saga step with idempotency and state management.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def execute(self, saga: Saga[Any], event: BaseModel) -&gt; Any:\n    \"\"\"Execute complete saga step with idempotency and state management.\"\"\"\n    saga_id = self.extract_saga_id(event)\n    try:\n        if await self.check_idempotency(saga, saga_id):\n            return None\n        result = await self.execute_handler(saga, event, saga_id)\n        await self.mark_step_completed(saga, saga_id)\n        await self.persist_state(saga, saga_id, result)\n        return result\n    except Exception as e:\n        self.logger.error(f\"Step '{self.step_name}' failed for saga {saga_id}: {e}\")\n        raise e\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InitialStepExecutor","title":"InitialStepExecutor","text":"<pre><code>InitialStepExecutor(\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n)\n</code></pre> <p>               Bases: <code>SagaStepExecutor</code></p> <p>Executor for initial saga steps that don't expect existing state.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(\n    self,\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n):\n    self.step_name = step_name\n    self.saga_id_extractor = saga_id_extractor\n    self.handler_func = handler_func\n    self.logger = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.InitialStepExecutor.execute_handler","title":"execute_handler  <code>async</code>","text":"<pre><code>execute_handler(\n    saga: Saga[Any], event: BaseModel, saga_id: str\n) -&gt; Any\n</code></pre> <p>Execute handler without state parameter.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def execute_handler(self, saga: Saga[Any], event: BaseModel, saga_id: str) -&gt; Any:\n    \"\"\"Execute handler without state parameter.\"\"\"\n    return await self.handler_func(saga, event)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SubsequentStepExecutor","title":"SubsequentStepExecutor","text":"<pre><code>SubsequentStepExecutor(\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n)\n</code></pre> <p>               Bases: <code>SagaStepExecutor</code></p> <p>Executor for subsequent saga steps that expect existing state.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def __init__(\n    self,\n    step_name: str,\n    saga_id_extractor: Callable[[BaseModel], str] | None,\n    handler_func: Callable[..., Any],\n):\n    self.step_name = step_name\n    self.saga_id_extractor = saga_id_extractor\n    self.handler_func = handler_func\n    self.logger = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.SubsequentStepExecutor.execute_handler","title":"execute_handler  <code>async</code>","text":"<pre><code>execute_handler(\n    saga: Saga[Any], event: BaseModel, saga_id: str\n) -&gt; Any\n</code></pre> <p>Execute handler with state parameter.</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>async def execute_handler(self, saga: Saga[Any], event: BaseModel, saga_id: str) -&gt; Any:\n    \"\"\"Execute handler with state parameter.\"\"\"\n    state = await saga.state_store.load(saga_id)\n    handler_name = getattr(self.handler_func, \"__name__\", repr(self.handler_func))\n    if state is None:\n        raise ValueError(\n            f\"State not found for saga {saga_id}. \"\n            f\"Handler {handler_name} expects state \"\n            f\"parameter but no state exists.\"\n        )\n    return await self.handler_func(saga, event, state)\n</code></pre>"},{"location":"reference/application/events/processing/saga/#interlock.application.events.processing.saga.saga_step","title":"saga_step","text":"<pre><code>saga_step(\n    f: Callable[..., Any] | None = None,\n    *,\n    step_name: str | None = None,\n    saga_id: Callable[[TEvent], str] | None = None\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]\n</code></pre> <p>Decorator for saga steps providing automatic idempotency and state management.</p> <p>This decorator automatically: 1. Applies @handles_event for event routing 2. Infers step name from function name if not provided 3. Extracts saga_id from event (using extractor or convention) 4. Checks if the step has already been completed (idempotency) 5. Loads and passes state to handler if it expects a state parameter 6. Persists state changes based on return value 7. Marks step as complete</p> <p>Handler Signatures: - First step (no existing state):   <code>async def handler(self, event: Event) -&gt; State</code>   Returns the initial state to be persisted. - Subsequent steps:   <code>async def handler(self, event: Event, state: State) -&gt; State | None</code>   Receives current state, returns updated state or None to delete.</p> <p>State Management: - Return a BaseModel: State is automatically saved - Return None: State is automatically deleted - No return (void): State is not modified</p> <p>Saga ID Extraction: - By default, looks for <code>event.saga_id</code> (convention) - If <code>saga_id</code> extractor is provided, uses that instead - Extractor is a lambda/function that takes the event and returns   saga_id</p> PARAMETER DESCRIPTION <code>f</code> <p>Function being decorated (provided when used as @saga_step)</p> <p> TYPE: <code>Callable[..., Any] | None</code> DEFAULT: <code>None</code> </p> <code>step_name</code> <p>Unique name for this step. If None, inferred from function name.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>saga_id</code> <p>Optional function to extract saga_id from event. If None, uses event.saga_id (convention)</p> <p> TYPE: <code>Callable[[TEvent], str] | None</code> DEFAULT: <code>None</code> </p> Example <p>No parameters (step name inferred from function name):</p> <p>@saga_step ... async def on_checkout_initiated( ...     self, event: CheckoutInitiated ... ) -&gt; CheckoutState: ...     # Step name is \"on_checkout_initiated\" ...     return CheckoutState( ...         order_id=event.saga_id, status=\"started\" ...     )</p> <p>With step name:</p> <p>@saga_step(step_name=\"reserve_inventory\") ... async def handle_reservation( ...     self, event: InventoryReserved, state: CheckoutState ... ) -&gt; CheckoutState: ...     state.inventory_reserved = True ...     return state</p> <p>Custom saga_id extractor:</p> <p>@saga_step(saga_id=lambda e: e.order_id) ... async def on_inventory_reserved( ...     self, event: InventoryReserved, state: CheckoutState ... ) -&gt; CheckoutState: ...     state.inventory_reserved = True ...     return state</p> <p>Delete state by returning None:</p> <p>@saga_step ... async def on_order_cancelled( ...     self, event: OrderCancelled, state: CheckoutState ... ) -&gt; None: ...     # Cleanup logic here ...     return None  # State is deleted</p> Source code in <code>interlock/application/events/processing/saga.py</code> <pre><code>def saga_step(\n    f: Callable[..., Any] | None = None,\n    *,\n    step_name: str | None = None,\n    saga_id: Callable[[TEvent], str] | None = None,\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"Decorator for saga steps providing automatic idempotency\n    and state management.\n\n    This decorator automatically:\n    1. Applies @handles_event for event routing\n    2. Infers step name from function name if not provided\n    3. Extracts saga_id from event (using extractor or convention)\n    4. Checks if the step has already been completed (idempotency)\n    5. Loads and passes state to handler if it expects a state parameter\n    6. Persists state changes based on return value\n    7. Marks step as complete\n\n    **Handler Signatures:**\n    - First step (no existing state):\n      `async def handler(self, event: Event) -&gt; State`\n      Returns the initial state to be persisted.\n    - Subsequent steps:\n      `async def handler(self, event: Event, state: State) -&gt; State | None`\n      Receives current state, returns updated state or None to delete.\n\n    **State Management:**\n    - Return a BaseModel: State is automatically saved\n    - Return None: State is automatically deleted\n    - No return (void): State is not modified\n\n    **Saga ID Extraction:**\n    - By default, looks for `event.saga_id` (convention)\n    - If `saga_id` extractor is provided, uses that instead\n    - Extractor is a lambda/function that takes the event and returns\n      saga_id\n\n    Args:\n        f: Function being decorated (provided when used as @saga_step)\n        step_name: Unique name for this step. If None, inferred from\n            function name.\n        saga_id: Optional function to extract saga_id from event.\n            If None, uses event.saga_id (convention)\n\n    Example:\n        No parameters (step name inferred from function name):\n        &gt;&gt;&gt; @saga_step\n        ... async def on_checkout_initiated(\n        ...     self, event: CheckoutInitiated\n        ... ) -&gt; CheckoutState:\n        ...     # Step name is \"on_checkout_initiated\"\n        ...     return CheckoutState(\n        ...         order_id=event.saga_id, status=\"started\"\n        ...     )\n\n        With step name:\n        &gt;&gt;&gt; @saga_step(step_name=\"reserve_inventory\")\n        ... async def handle_reservation(\n        ...     self, event: InventoryReserved, state: CheckoutState\n        ... ) -&gt; CheckoutState:\n        ...     state.inventory_reserved = True\n        ...     return state\n\n        Custom saga_id extractor:\n        &gt;&gt;&gt; @saga_step(saga_id=lambda e: e.order_id)\n        ... async def on_inventory_reserved(\n        ...     self, event: InventoryReserved, state: CheckoutState\n        ... ) -&gt; CheckoutState:\n        ...     state.inventory_reserved = True\n        ...     return state\n\n        Delete state by returning None:\n        &gt;&gt;&gt; @saga_step\n        ... async def on_order_cancelled(\n        ...     self, event: OrderCancelled, state: CheckoutState\n        ... ) -&gt; None:\n        ...     # Cleanup logic here\n        ...     return None  # State is deleted\n    \"\"\"\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        func_name = getattr(func, \"__name__\", repr(func))\n        resolved_step_name = step_name or func_name\n        variant = SagaStepExecutor.executor_from_function(func)\n        executor = variant(resolved_step_name, saga_id, func)\n\n        @handles_event\n        @wraps(func)\n        async def wrapper(self: Saga[Any], event: BaseModel) -&gt; Any:\n            return await executor.execute(self, event)\n\n        return wrapper\n\n    # If no function is provided, that means we were called like\n    # @saga_step(step_name=\"...\") which means we need to return a decorator.\n    # If the function _is_ provided, that means we were called like @saga_step.\n    # So we need to return a decorated function.\n    return decorator if f is None else decorator(f)\n</code></pre>"},{"location":"reference/application/events/processing/strategies/","title":"strategies","text":""},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies","title":"strategies","text":""},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupResult","title":"CatchupResult  <code>dataclass</code>","text":"<pre><code>CatchupResult(skip_before: datetime | None = None)\n</code></pre> <p>Result from catchup operation with skip window for avoiding double-processing.</p> <p>When a catchup strategy processes historical data (e.g., loading snapshots), those events have already been incorporated into the processor's state. To avoid processing them again when the executor resumes from the subscription, we need to skip events up to a certain timestamp.</p> ATTRIBUTE DESCRIPTION <code>skip_before</code> <p>Events with timestamp &lt;= this value should be skipped. None means no skipping is needed.</p> <p> TYPE: <code>datetime | None</code> </p> Example"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupResult--catchup-loaded-aggregates-up-to-2025-01-01-100000","title":"Catchup loaded aggregates up to 2025-01-01 10:00:00","text":"<p>result = CatchupResult(skip_before=datetime(2025, 1, 1, 10, 0, 0))</p>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupResult--executor-checks-each-event","title":"Executor checks each event","text":"<p>if result.should_skip(event): ...     continue  # Already processed via snapshot else: ...     await processor.handle(event.data)  # Process normally</p>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupResult.should_skip","title":"should_skip","text":"<pre><code>should_skip(event: Event) -&gt; bool\n</code></pre> <p>Check if an event should be skipped (already processed during catchup).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if event.timestamp &lt;= skip_before (already processed),</p> <code>bool</code> <p>False if event should be processed normally</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>def should_skip(self, event: \"Event\") -&gt; bool:\n    \"\"\"Check if an event should be skipped (already processed during catchup).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if event.timestamp &lt;= skip_before (already processed),\n        False if event should be processed normally\n    \"\"\"\n    if self.skip_before is None:\n        return False\n    return event.timestamp &lt;= self.skip_before\n</code></pre>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupStrategy","title":"CatchupStrategy","text":"<p>               Bases: <code>ABC</code>, <code>Generic[P]</code></p> <p>Strategy for catching up an event processor with the event store.</p> <p>Event processors can fall behind the write model when: - They cannot keep up with the event publication rate - They are created after events have already been published - They experience downtime or processing delays</p> <p>Different catchup strategies offer trade-offs between: - Speed: How quickly the processor catches up - Resource usage: Compute and memory requirements - Consistency: Guarantees about event ordering and completeness - Applicability: Which scenarios the strategy works for</p>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.CatchupStrategy.catchup","title":"catchup  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; CatchupResult | None\n</code></pre> <p>Execute the catchup strategy to synchronize with the event store.</p> <p>This method is invoked: - When the processor is first started - When the associated CatchupCondition is met during runtime</p> <p>Implementations should: - Load necessary state to bring the processor up to date - Handle errors gracefully (network issues, missing data, etc.) - Track progress to resume from failures</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor instance to catch up</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>CatchupResult | None</code> <p>CatchupResult if events should be skipped, None otherwise</p> RAISES DESCRIPTION <code>Exception</code> <p>Implementation-specific exceptions for catchup failures.</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>@abstractmethod\nasync def catchup(self, processor: P) -&gt; CatchupResult | None:\n    \"\"\"Execute the catchup strategy to synchronize with the event store.\n\n    This method is invoked:\n    - When the processor is first started\n    - When the associated CatchupCondition is met during runtime\n\n    Implementations should:\n    - Load necessary state to bring the processor up to date\n    - Handle errors gracefully (network issues, missing data, etc.)\n    - Track progress to resume from failures\n\n    Args:\n        processor: The event processor instance to catch up\n\n    Returns:\n        CatchupResult if events should be skipped, None otherwise\n\n    Raises:\n        Exception: Implementation-specific exceptions for catchup failures.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.NoCatchup","title":"NoCatchup","text":"<p>               Bases: <code>CatchupStrategy</code></p> <p>No catchup - processor starts from current position.</p> <p>Use this strategy when: - The processor only needs to handle new events (not historical) - Historical state is not required for the read model - Testing scenarios where catchup is not needed</p> Example"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.NoCatchup--notification-processor-that-only-sends-for-new-events","title":"Notification processor that only sends for new events","text":"<p>processor = NotificationProcessor() executor = EventProcessorExecutor( ...     subscription=event_bus.subscribe(\"notifications\"), ...     processor=processor, ...     condition=Never(), ...     strategy=NoCatchup(), ...     batch_size=10 ... )</p>"},{"location":"reference/application/events/processing/strategies/#interlock.application.events.processing.strategies.NoCatchup.catchup","title":"catchup  <code>async</code>","text":"<pre><code>catchup(processor: P) -&gt; None\n</code></pre> <p>No-op - no catchup is performed.</p> PARAMETER DESCRIPTION <code>processor</code> <p>The event processor (ignored)</p> <p> TYPE: <code>P</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None - no skip window needed</p> Source code in <code>interlock/application/events/processing/strategies.py</code> <pre><code>async def catchup(self, processor: P) -&gt; None:\n    \"\"\"No-op - no catchup is performed.\n\n    Args:\n        processor: The event processor (ignored)\n\n    Returns:\n        None - no skip window needed\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/application/events/upcasting/","title":"upcasting","text":""},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting","title":"upcasting","text":"<p>Event upcasting infrastructure for schema evolution.</p> <p>This package provides: - EventUpcaster: Base class for transforming events between schema versions - UpcastingPipeline: Pipeline for applying upcasting transformations - UpcastingStrategy: Strategies for when to apply upcasting</p>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.EventUpcaster","title":"EventUpcaster","text":"<p>               Bases: <code>Generic[T, U]</code>, <code>ABC</code></p> <p>Base class for transforming events from one schema version to another.</p> <p>Event upcasters handle schema evolution by transforming old event data models into new ones. Each upcaster is typed with source and target event types.</p> <p>The framework automatically extracts these types via introspection, so you only need to implement the upcast_payload method.</p> Example <p>class OrderPlacedV1(BaseModel): ...     product: str ...     price: float ... class OrderPlacedV2(BaseModel): ...     product_id: str ...     price_cents: int ... class OrderPlacedV1ToV2(EventUpcaster[OrderPlacedV1, OrderPlacedV2]): ...     def upcast_payload(self, data: OrderPlacedV1) -&gt; OrderPlacedV2: ...         return OrderPlacedV2( ...             product_id=data.product, ...             price_cents=int(data.price * 100) ...         )</p>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.EventUpcaster.upcast_event","title":"upcast_event  <code>async</code>","text":"<pre><code>upcast_event(event: Event[T]) -&gt; Event[U]\n</code></pre> <p>Transform an entire event from old schema to new schema.</p> <p>This method preserves event metadata (id, aggregate_id, correlation_id, causation_id, sequence_number, timestamp) while transforming the event data payload.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event with old schema data</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>Event[U]</code> <p>A new event with transformed data</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_event(self, event: Event[T]) -&gt; Event[U]:\n    \"\"\"Transform an entire event from old schema to new schema.\n\n    This method preserves event metadata (id, aggregate_id, correlation_id,\n    causation_id, sequence_number, timestamp) while transforming the event\n    data payload.\n\n    Args:\n        event: The event with old schema data\n\n    Returns:\n        A new event with transformed data\n    \"\"\"\n    return Event(\n        id=event.id,\n        aggregate_id=event.aggregate_id,\n        sequence_number=event.sequence_number,\n        timestamp=event.timestamp,\n        correlation_id=event.correlation_id,\n        causation_id=event.causation_id,\n        data=await self.upcast_payload(event.data),\n    )\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.EventUpcaster.can_upcast","title":"can_upcast  <code>async</code>","text":"<pre><code>can_upcast(event: Event[T]) -&gt; bool\n</code></pre> <p>Check if this upcaster can handle the given event.</p> <p>Override this method if you need conditional upcasting logic (e.g., only upcast events before a certain date).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this upcaster can transform the event</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def can_upcast(self, event: Event[T]) -&gt; bool:\n    \"\"\"Check if this upcaster can handle the given event.\n\n    Override this method if you need conditional upcasting logic\n    (e.g., only upcast events before a certain date).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if this upcaster can transform the event\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.EventUpcaster.upcast_payload","title":"upcast_payload  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>upcast_payload(data: T) -&gt; U\n</code></pre> <p>Transform event data from old schema to new schema.</p> <p>This is the core transformation logic that subclasses must implement.</p> PARAMETER DESCRIPTION <code>data</code> <p>The old event data</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>U</code> <p>The transformed event data with new schema</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>@abstractmethod\nasync def upcast_payload(self, data: T) -&gt; U:\n    \"\"\"Transform event data from old schema to new schema.\n\n    This is the core transformation logic that subclasses must implement.\n\n    Args:\n        data: The old event data\n\n    Returns:\n        The transformed event data with new schema\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingPipeline","title":"UpcastingPipeline","text":"<pre><code>UpcastingPipeline(\n    upcasting_strategy: UpcastingStrategy,\n    upcaster_map: UpcasterMap,\n)\n</code></pre> <p>Pipeline for applying event upcasting transformations.</p> <p>The pipeline manages a mapping of upcasters and applies them to events based on the configured strategy. It supports multi-step upcasting chains where events can be transformed through multiple versions (V1\u2192V2\u2192V3).</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>def __init__(self, upcasting_strategy: UpcastingStrategy, upcaster_map: UpcasterMap):\n    self.upcasting_strategy = upcasting_strategy\n    self.upcaster_map = upcaster_map\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingPipeline.upcast","title":"upcast  <code>async</code>","text":"<pre><code>upcast(event: Event[Any]) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations to a single event.</p> <p>Looks up upcasters registered for the event's data type and applies the first matching upcaster. For multi-step chains, call repeatedly.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The upcasted event, or the original if no upcaster found</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast(self, event: Event[Any]) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations to a single event.\n\n    Looks up upcasters registered for the event's data type and applies\n    the first matching upcaster. For multi-step chains, call repeatedly.\n\n    Args:\n        event: The event to upcast\n\n    Returns:\n        The upcasted event, or the original if no upcaster found\n    \"\"\"\n    event_data_type = type(event.data)\n\n    # Find upcasters for this event type\n    for upcaster in self.upcaster_map.get_upcasters(event_data_type):\n        if await upcaster.can_upcast(event):\n            return await upcaster.upcast_event(event)\n\n    # No upcaster found - return unchanged\n    return event\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingPipeline.upcast_chain","title":"upcast_chain  <code>async</code>","text":"<pre><code>upcast_chain(\n    event: Event[Any], max_steps: int = 10\n) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations repeatedly until no more upcasters match.</p> <p>This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying upcasters until the event reaches its final form.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> <code>max_steps</code> <p>Maximum number of upcasting steps (prevents infinite loops)</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The fully upcasted event</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If max_steps is exceeded</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_chain(self, event: Event[Any], max_steps: int = 10) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations repeatedly until no more upcasters match.\n\n    This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying\n    upcasters until the event reaches its final form.\n\n    Args:\n        event: The event to upcast\n        max_steps: Maximum number of upcasting steps (prevents infinite loops)\n\n    Returns:\n        The fully upcasted event\n\n    Raises:\n        RuntimeError: If max_steps is exceeded\n    \"\"\"\n    for _step in range(max_steps):\n        event_data_type = type(event.data)\n        upcasted = await self.upcast(event)\n\n        # If type didn't change, we're done\n        if type(upcasted.data) is event_data_type:\n            return upcasted\n\n        event = upcasted\n\n    raise RuntimeError(\n        f\"Upcasting exceeded max steps ({max_steps}). \"\n        f\"Possible circular upcasting chain for {type(event.data).__name__}\"\n    )\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingPipeline.read_upcast","title":"read_upcast  <code>async</code>","text":"<pre><code>read_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events loaded from the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events loaded from storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def read_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events loaded from the event store according to the strategy.\n\n    Args:\n        events: Events loaded from storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_read():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingPipeline.write_upcast","title":"write_upcast  <code>async</code>","text":"<pre><code>write_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events being saved to the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events being saved to storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def write_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events being saved to the event store according to the strategy.\n\n    Args:\n        events: Events being saved to storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_write():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.EagerUpcastingStrategy","title":"EagerUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Eager upcasting: transform and rewrite events for gradual migration.</p> <p>This strategy applies transformations when events are loaded AND when new events are saved. Crucially, it also rewrites upcasted events back to the store, enabling gradual migration as aggregates are accessed.</p> <p>Advantages: - Event store migrates to new schema over time - Eventually can remove old event types from codebase - No separate migration job needed</p> <p>Disadvantages: - Modifies historical events (breaks strict immutability) - Rarely-accessed aggregates may retain old events indefinitely - Slightly more I/O on reads (for rewriting)</p> <p>Use this when you have a clear migration timeline and want to eventually remove old event types from your codebase.</p>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.LazyUpcastingStrategy","title":"LazyUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Lazy upcasting: transform events only when reading from storage.</p> <p>This is the recommended default strategy. Old events remain in storage with their original schema, and are transformed on-the-fly when loaded.</p> <p>Advantages: - No need to rewrite event store - Supports multiple concurrent versions - Can evolve upcasting logic over time - Preserves event immutability</p> <p>Disadvantages: - Slight performance cost on reads - Old schemas must remain in codebase forever</p>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingStrategy","title":"UpcastingStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Strategy for when to apply upcasting transformations.</p> <p>Strategies control whether upcasting happens when events are read from storage, written to storage, or both. They also control whether upcasted events should be rewritten to the store for gradual migration.</p>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingStrategy.should_upcast_on_read","title":"should_upcast_on_read  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_read() -&gt; bool\n</code></pre> <p>Should events be upcasted when loaded from the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_read(self) -&gt; bool:\n    \"\"\"Should events be upcasted when loaded from the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingStrategy.should_upcast_on_write","title":"should_upcast_on_write  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_write() -&gt; bool\n</code></pre> <p>Should events be upcasted when saved to the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_write(self) -&gt; bool:\n    \"\"\"Should events be upcasted when saved to the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/#interlock.application.events.upcasting.UpcastingStrategy.should_rewrite_on_load","title":"should_rewrite_on_load  <code>abstractmethod</code>","text":"<pre><code>should_rewrite_on_load() -&gt; bool\n</code></pre> <p>Should upcasted events be persisted back to the event store?</p> <p>When True, events that are upcasted during load will be rewritten to the store with their new schema. This enables gradual migration of historical events as aggregates are accessed.</p> RETURNS DESCRIPTION <code>bool</code> <p>True to rewrite upcasted events, False to leave them unchanged.</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_rewrite_on_load(self) -&gt; bool:\n    \"\"\"Should upcasted events be persisted back to the event store?\n\n    When True, events that are upcasted during load will be rewritten\n    to the store with their new schema. This enables gradual migration\n    of historical events as aggregates are accessed.\n\n    Returns:\n        True to rewrite upcasted events, False to leave them unchanged.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/","title":"pipeline","text":""},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline","title":"pipeline","text":""},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.EventUpcaster","title":"EventUpcaster","text":"<p>               Bases: <code>Generic[T, U]</code>, <code>ABC</code></p> <p>Base class for transforming events from one schema version to another.</p> <p>Event upcasters handle schema evolution by transforming old event data models into new ones. Each upcaster is typed with source and target event types.</p> <p>The framework automatically extracts these types via introspection, so you only need to implement the upcast_payload method.</p> Example <p>class OrderPlacedV1(BaseModel): ...     product: str ...     price: float ... class OrderPlacedV2(BaseModel): ...     product_id: str ...     price_cents: int ... class OrderPlacedV1ToV2(EventUpcaster[OrderPlacedV1, OrderPlacedV2]): ...     def upcast_payload(self, data: OrderPlacedV1) -&gt; OrderPlacedV2: ...         return OrderPlacedV2( ...             product_id=data.product, ...             price_cents=int(data.price * 100) ...         )</p>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.EventUpcaster.upcast_event","title":"upcast_event  <code>async</code>","text":"<pre><code>upcast_event(event: Event[T]) -&gt; Event[U]\n</code></pre> <p>Transform an entire event from old schema to new schema.</p> <p>This method preserves event metadata (id, aggregate_id, correlation_id, causation_id, sequence_number, timestamp) while transforming the event data payload.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event with old schema data</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>Event[U]</code> <p>A new event with transformed data</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_event(self, event: Event[T]) -&gt; Event[U]:\n    \"\"\"Transform an entire event from old schema to new schema.\n\n    This method preserves event metadata (id, aggregate_id, correlation_id,\n    causation_id, sequence_number, timestamp) while transforming the event\n    data payload.\n\n    Args:\n        event: The event with old schema data\n\n    Returns:\n        A new event with transformed data\n    \"\"\"\n    return Event(\n        id=event.id,\n        aggregate_id=event.aggregate_id,\n        sequence_number=event.sequence_number,\n        timestamp=event.timestamp,\n        correlation_id=event.correlation_id,\n        causation_id=event.causation_id,\n        data=await self.upcast_payload(event.data),\n    )\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.EventUpcaster.can_upcast","title":"can_upcast  <code>async</code>","text":"<pre><code>can_upcast(event: Event[T]) -&gt; bool\n</code></pre> <p>Check if this upcaster can handle the given event.</p> <p>Override this method if you need conditional upcasting logic (e.g., only upcast events before a certain date).</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to check</p> <p> TYPE: <code>Event[T]</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this upcaster can transform the event</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def can_upcast(self, event: Event[T]) -&gt; bool:\n    \"\"\"Check if this upcaster can handle the given event.\n\n    Override this method if you need conditional upcasting logic\n    (e.g., only upcast events before a certain date).\n\n    Args:\n        event: The event to check\n\n    Returns:\n        True if this upcaster can transform the event\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.EventUpcaster.upcast_payload","title":"upcast_payload  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>upcast_payload(data: T) -&gt; U\n</code></pre> <p>Transform event data from old schema to new schema.</p> <p>This is the core transformation logic that subclasses must implement.</p> PARAMETER DESCRIPTION <code>data</code> <p>The old event data</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>U</code> <p>The transformed event data with new schema</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>@abstractmethod\nasync def upcast_payload(self, data: T) -&gt; U:\n    \"\"\"Transform event data from old schema to new schema.\n\n    This is the core transformation logic that subclasses must implement.\n\n    Args:\n        data: The old event data\n\n    Returns:\n        The transformed event data with new schema\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.UpcastingPipeline","title":"UpcastingPipeline","text":"<pre><code>UpcastingPipeline(\n    upcasting_strategy: UpcastingStrategy,\n    upcaster_map: UpcasterMap,\n)\n</code></pre> <p>Pipeline for applying event upcasting transformations.</p> <p>The pipeline manages a mapping of upcasters and applies them to events based on the configured strategy. It supports multi-step upcasting chains where events can be transformed through multiple versions (V1\u2192V2\u2192V3).</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>def __init__(self, upcasting_strategy: UpcastingStrategy, upcaster_map: UpcasterMap):\n    self.upcasting_strategy = upcasting_strategy\n    self.upcaster_map = upcaster_map\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.UpcastingPipeline.upcast","title":"upcast  <code>async</code>","text":"<pre><code>upcast(event: Event[Any]) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations to a single event.</p> <p>Looks up upcasters registered for the event's data type and applies the first matching upcaster. For multi-step chains, call repeatedly.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The upcasted event, or the original if no upcaster found</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast(self, event: Event[Any]) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations to a single event.\n\n    Looks up upcasters registered for the event's data type and applies\n    the first matching upcaster. For multi-step chains, call repeatedly.\n\n    Args:\n        event: The event to upcast\n\n    Returns:\n        The upcasted event, or the original if no upcaster found\n    \"\"\"\n    event_data_type = type(event.data)\n\n    # Find upcasters for this event type\n    for upcaster in self.upcaster_map.get_upcasters(event_data_type):\n        if await upcaster.can_upcast(event):\n            return await upcaster.upcast_event(event)\n\n    # No upcaster found - return unchanged\n    return event\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.UpcastingPipeline.upcast_chain","title":"upcast_chain  <code>async</code>","text":"<pre><code>upcast_chain(\n    event: Event[Any], max_steps: int = 10\n) -&gt; Event[Any]\n</code></pre> <p>Apply upcasting transformations repeatedly until no more upcasters match.</p> <p>This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying upcasters until the event reaches its final form.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to upcast</p> <p> TYPE: <code>Event[Any]</code> </p> <code>max_steps</code> <p>Maximum number of upcasting steps (prevents infinite loops)</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Event[Any]</code> <p>The fully upcasted event</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If max_steps is exceeded</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def upcast_chain(self, event: Event[Any], max_steps: int = 10) -&gt; Event[Any]:\n    \"\"\"Apply upcasting transformations repeatedly until no more upcasters match.\n\n    This enables multi-step chains like V1\u2192V2\u2192V3 by repeatedly applying\n    upcasters until the event reaches its final form.\n\n    Args:\n        event: The event to upcast\n        max_steps: Maximum number of upcasting steps (prevents infinite loops)\n\n    Returns:\n        The fully upcasted event\n\n    Raises:\n        RuntimeError: If max_steps is exceeded\n    \"\"\"\n    for _step in range(max_steps):\n        event_data_type = type(event.data)\n        upcasted = await self.upcast(event)\n\n        # If type didn't change, we're done\n        if type(upcasted.data) is event_data_type:\n            return upcasted\n\n        event = upcasted\n\n    raise RuntimeError(\n        f\"Upcasting exceeded max steps ({max_steps}). \"\n        f\"Possible circular upcasting chain for {type(event.data).__name__}\"\n    )\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.UpcastingPipeline.read_upcast","title":"read_upcast  <code>async</code>","text":"<pre><code>read_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events loaded from the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events loaded from storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def read_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events loaded from the event store according to the strategy.\n\n    Args:\n        events: Events loaded from storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_read():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.UpcastingPipeline.write_upcast","title":"write_upcast  <code>async</code>","text":"<pre><code>write_upcast(events: list[Event[Any]]) -&gt; list[Event[Any]]\n</code></pre> <p>Upcast events being saved to the event store according to the strategy.</p> PARAMETER DESCRIPTION <code>events</code> <p>Events being saved to storage</p> <p> TYPE: <code>list[Event[Any]]</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>Upcasted events if strategy permits, otherwise original events</p> Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>async def write_upcast(self, events: list[Event[Any]]) -&gt; list[Event[Any]]:\n    \"\"\"Upcast events being saved to the event store according to the strategy.\n\n    Args:\n        events: Events being saved to storage\n\n    Returns:\n        Upcasted events if strategy permits, otherwise original events\n    \"\"\"\n    if self.upcasting_strategy.should_upcast_on_write():\n        return list(await gather(*[self.upcast_chain(event) for event in events]))\n    return events\n</code></pre>"},{"location":"reference/application/events/upcasting/pipeline/#interlock.application.events.upcasting.pipeline.extract_upcaster_types","title":"extract_upcaster_types","text":"<pre><code>extract_upcaster_types(\n    upcaster_class: type,\n) -&gt; tuple[type[BaseModel], type[BaseModel]]\n</code></pre> <p>Extract source and target event types from an EventUpcaster subclass.</p> <p>Introspects the generic type parameters of EventUpcaster[T, U] to determine which event types this upcaster transforms.</p> PARAMETER DESCRIPTION <code>upcaster_class</code> <p>The EventUpcaster subclass to introspect</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>tuple[type[BaseModel], type[BaseModel]]</code> <p>Tuple of (source_type, target_type)</p> RAISES DESCRIPTION <code>ValueError</code> <p>If type parameters cannot be extracted</p> Example <p>class MyUpcaster(EventUpcaster[OldEvent, NewEvent]): ...     pass extract_upcaster_types(MyUpcaster) (, ) Source code in <code>interlock/application/events/upcasting/pipeline.py</code> <pre><code>def extract_upcaster_types(\n    upcaster_class: type,\n) -&gt; tuple[type[BaseModel], type[BaseModel]]:\n    \"\"\"Extract source and target event types from an EventUpcaster subclass.\n\n    Introspects the generic type parameters of EventUpcaster[T, U] to determine\n    which event types this upcaster transforms.\n\n    Args:\n        upcaster_class: The EventUpcaster subclass to introspect\n\n    Returns:\n        Tuple of (source_type, target_type)\n\n    Raises:\n        ValueError: If type parameters cannot be extracted\n\n    Example:\n        &gt;&gt;&gt; class MyUpcaster(EventUpcaster[OldEvent, NewEvent]):\n        ...     pass\n        &gt;&gt;&gt; extract_upcaster_types(MyUpcaster)\n        (&lt;class 'OldEvent'&gt;, &lt;class 'NewEvent'&gt;)\n    \"\"\"\n    # Look for __orig_bases__ which contains the generic parent with type parameters\n    orig_bases = getattr(upcaster_class, \"__orig_bases__\", None)\n    if orig_bases is None:\n        raise ValueError(\n            f\"Cannot extract types from {upcaster_class.__name__}: no __orig_bases__ found\"\n        )\n\n    for base in orig_bases:\n        # Check if this base is EventUpcaster or a subclass of it\n        origin = getattr(base, \"__origin__\", None)\n        if origin is not None:\n            # It's a generic type - check if it's EventUpcaster\n            try:\n                if issubclass(origin, EventUpcaster):\n                    args = get_args(base)\n                    if len(args) == 2:\n                        return (args[0], args[1])\n            except TypeError:\n                # origin is not a class\n                continue\n\n    raise ValueError(\n        f\"Cannot extract types from {upcaster_class.__name__}: \"\n        f\"must inherit from EventUpcaster[SourceType, TargetType]\"\n    )\n</code></pre>"},{"location":"reference/application/events/upcasting/strategies/","title":"strategies","text":""},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies","title":"strategies","text":""},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.UpcastingStrategy","title":"UpcastingStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Strategy for when to apply upcasting transformations.</p> <p>Strategies control whether upcasting happens when events are read from storage, written to storage, or both. They also control whether upcasted events should be rewritten to the store for gradual migration.</p>"},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.UpcastingStrategy.should_upcast_on_read","title":"should_upcast_on_read  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_read() -&gt; bool\n</code></pre> <p>Should events be upcasted when loaded from the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_read(self) -&gt; bool:\n    \"\"\"Should events be upcasted when loaded from the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.UpcastingStrategy.should_upcast_on_write","title":"should_upcast_on_write  <code>abstractmethod</code>","text":"<pre><code>should_upcast_on_write() -&gt; bool\n</code></pre> <p>Should events be upcasted when saved to the event store?</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_upcast_on_write(self) -&gt; bool:\n    \"\"\"Should events be upcasted when saved to the event store?\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.UpcastingStrategy.should_rewrite_on_load","title":"should_rewrite_on_load  <code>abstractmethod</code>","text":"<pre><code>should_rewrite_on_load() -&gt; bool\n</code></pre> <p>Should upcasted events be persisted back to the event store?</p> <p>When True, events that are upcasted during load will be rewritten to the store with their new schema. This enables gradual migration of historical events as aggregates are accessed.</p> RETURNS DESCRIPTION <code>bool</code> <p>True to rewrite upcasted events, False to leave them unchanged.</p> Source code in <code>interlock/application/events/upcasting/strategies.py</code> <pre><code>@abstractmethod\ndef should_rewrite_on_load(self) -&gt; bool:\n    \"\"\"Should upcasted events be persisted back to the event store?\n\n    When True, events that are upcasted during load will be rewritten\n    to the store with their new schema. This enables gradual migration\n    of historical events as aggregates are accessed.\n\n    Returns:\n        True to rewrite upcasted events, False to leave them unchanged.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.LazyUpcastingStrategy","title":"LazyUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Lazy upcasting: transform events only when reading from storage.</p> <p>This is the recommended default strategy. Old events remain in storage with their original schema, and are transformed on-the-fly when loaded.</p> <p>Advantages: - No need to rewrite event store - Supports multiple concurrent versions - Can evolve upcasting logic over time - Preserves event immutability</p> <p>Disadvantages: - Slight performance cost on reads - Old schemas must remain in codebase forever</p>"},{"location":"reference/application/events/upcasting/strategies/#interlock.application.events.upcasting.strategies.EagerUpcastingStrategy","title":"EagerUpcastingStrategy","text":"<p>               Bases: <code>UpcastingStrategy</code></p> <p>Eager upcasting: transform and rewrite events for gradual migration.</p> <p>This strategy applies transformations when events are loaded AND when new events are saved. Crucially, it also rewrites upcasted events back to the store, enabling gradual migration as aggregates are accessed.</p> <p>Advantages: - Event store migrates to new schema over time - Eventually can remove old event types from codebase - No separate migration job needed</p> <p>Disadvantages: - Modifies historical events (breaks strict immutability) - Rarely-accessed aggregates may retain old events indefinitely - Slightly more I/O on reads (for rewriting)</p> <p>Use this when you have a clear migration timeline and want to eventually remove old event types from your codebase.</p>"},{"location":"reference/application/middleware/","title":"middleware","text":""},{"location":"reference/application/middleware/#interlock.application.middleware","title":"middleware","text":"<p>Middleware infrastructure for commands and queries.</p> <p>Middleware components wrap handlers to provide cross-cutting concerns like logging, validation, authentication, or transaction management. They follow the chain of responsibility pattern and can intercept both commands (write side) and queries (read side).</p>"},{"location":"reference/application/middleware/#interlock.application.middleware.Middleware","title":"Middleware","text":"<p>Base class for middleware with annotation-based routing.</p> <p>Middleware components wrap handlers to provide cross-cutting concerns like logging, validation, authentication, or transaction management. They follow the chain of responsibility pattern.</p> <p>Middleware can intercept both commands and queries using the @intercepts decorator. The framework automatically routes messages to the appropriate methods based on their type annotations.</p> <p>By default, if no interceptor matches the message type, the middleware forwards to the next handler (pass-through behavior).</p> <p>Examples:</p> <p>Intercept all commands:</p> <pre><code>&gt;&gt;&gt; class LoggingMiddleware(Middleware):\n...     @intercepts\n...     async def log_command(self, cmd: Command, next: Handler) -&gt; Any:\n...         print(f\"Command: {type(cmd).__name__}\")\n...         return await next(cmd)\n</code></pre> <p>Intercept specific command type:</p> <pre><code>&gt;&gt;&gt; class AdminOnlyMiddleware(Middleware):\n...     @intercepts\n...     async def check_admin(self, cmd: DeleteUser, next: Handler) -&gt; Any:\n...         if not self.is_admin(cmd.requester_id):\n...             raise PermissionError(\"Admin required\")\n...         return await next(cmd)\n</code></pre> <p>Intercept queries:</p> <pre><code>&gt;&gt;&gt; class CachingMiddleware(Middleware):\n...     @intercepts\n...     async def cache_query(self, query: Query, next: Handler) -&gt; Any:\n...         if cached := self.cache.get(query):\n...             return cached\n...         result = await next(query)\n...         self.cache.set(query, result)\n...         return result\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.Middleware.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up routing when a subclass is defined.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    from ...routing import setup_middleware_routing\n\n    cls._command_router = setup_middleware_routing(cls)\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.Middleware.intercept","title":"intercept  <code>async</code>","text":"<pre><code>intercept(message: BaseModel, next: Handler) -&gt; Any\n</code></pre> <p>Route message to interceptor method or forward to next.</p> <p>This method is called by the bus for each message. It uses the routing table to find an appropriate interceptor method based on the message type. If no interceptor is registered for the message type, it forwards to the next handler.</p> PARAMETER DESCRIPTION <code>message</code> <p>The command or query to intercept.</p> <p> TYPE: <code>BaseModel</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the interceptor or next handler.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>async def intercept(self, message: BaseModel, next: Handler) -&gt; Any:\n    \"\"\"Route message to interceptor method or forward to next.\n\n    This method is called by the bus for each message. It uses the\n    routing table to find an appropriate interceptor method based\n    on the message type. If no interceptor is registered for the\n    message type, it forwards to the next handler.\n\n    Args:\n        message: The command or query to intercept.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the interceptor or next handler.\n    \"\"\"\n    # Route to interceptor, passing next as an extra argument\n    result = self._command_router.route(self, message, next)\n\n    # If router returned None (IgnoreHandler), forward to next\n    if result is None:\n        return await next(message)\n    elif inspect.isawaitable(result):\n        # Router returned coroutine (async interceptor), await it\n        return await result\n    else:\n        return result\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.ConcurrencyRetryMiddleware","title":"ConcurrencyRetryMiddleware","text":"<pre><code>ConcurrencyRetryMiddleware(\n    max_attempts: int, retry_delay: float\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that retries commands that fail due to concurrency issues.</p> <p>This middleware retries commands that fail due to concurrency conflicts. It will attempt the command up to <code>max_attempts</code> times with a delay between attempts. If the command still fails after all attempts, it will raise a ConcurrencyError.</p> ATTRIBUTE DESCRIPTION <code>max_attempts</code> <p>The maximum number of attempts (initial + retries). Must be positive. For example, max_attempts=3 means 1 initial attempt + up to 2 retries.</p> <p> </p> <code>retry_delay</code> <p>The delay in seconds between retry attempts. Must be non-negative.</p> <p> </p> <p>Examples:</p> <p>Retry up to 3 times with 0.1s delay:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=3, retry_delay=0.1)\n</code></pre> <p>No delay between retries:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=5, retry_delay=0.0)\n</code></pre> PARAMETER DESCRIPTION <code>max_attempts</code> <p>Maximum number of attempts (must be positive).</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Delay in seconds between retries (must be non-negative).</p> <p> TYPE: <code>float</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If max_attempts &lt;= 0 or retry_delay &lt; 0.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>def __init__(self, max_attempts: int, retry_delay: float):\n    \"\"\"Initialize the concurrency retry middleware.\n\n    Args:\n        max_attempts: Maximum number of attempts (must be positive).\n        retry_delay: Delay in seconds between retries (must be non-negative).\n\n    Raises:\n        ValueError: If max_attempts &lt;= 0 or retry_delay &lt; 0.\n    \"\"\"\n    if max_attempts &lt;= 0:\n        raise ValueError(\"max_attempts must be positive\")\n    if retry_delay &lt; 0:\n        raise ValueError(\"retry_delay must be non-negative\")\n    self.max_attempts = max_attempts\n    self.retry_delay = retry_delay\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.ConcurrencyRetryMiddleware.retry_on_concurrency","title":"retry_on_concurrency  <code>async</code>","text":"<pre><code>retry_on_concurrency(\n    command: Command, next: Handler\n) -&gt; Any\n</code></pre> <p>Intercept all commands and retry on concurrency errors.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If all attempts fail due to concurrency conflicts.</p> <code>Exception</code> <p>Any non-ConcurrencyError exceptions are re-raised immediately.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>@intercepts\nasync def retry_on_concurrency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Intercept all commands and retry on concurrency errors.\n\n    Args:\n        command: The command to process.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n\n    Raises:\n        ConcurrencyError: If all attempts fail due to concurrency conflicts.\n        Exception: Any non-ConcurrencyError exceptions are re-raised immediately.\n    \"\"\"\n    last_error: ConcurrencyError | None = None\n    for attempt in range(self.max_attempts):\n        try:\n            return await next(command)\n        except ConcurrencyError as e:\n            last_error = e\n            LOGGER.warning(\n                f\"Concurrency error on attempt {attempt + 1}/{self.max_attempts}: {e}\"\n            )\n            # Don't sleep after the last attempt\n            if attempt &lt; self.max_attempts - 1:\n                await asyncio.sleep(self.retry_delay)\n    raise ConcurrencyError(f\"Max attempts ({self.max_attempts}) reached\") from last_error\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.ContextPropagationMiddleware","title":"ContextPropagationMiddleware","text":"<p>               Bases: <code>Middleware</code></p> <p>Middleware that propagates execution context from commands.</p> <p>This middleware extracts correlation_id, causation_id, and command_id from incoming commands and sets up the execution context before the command is handled. This enables:</p> <ol> <li>Distributed Tracing: Track entire operations across    services</li> <li>Causation Tracking: Understand what caused each    command/event</li> <li>Automatic Context Flow: Events emitted by aggregates    automatically inherit the context set by this middleware</li> </ol> <p>Context Setup: - If command has correlation_id: use it - If command has no correlation_id: generate a new one   (entry point) - If command has causation_id: use it - If command has no causation_id: use correlation_id   (self-referencing entry point) - Always use command.command_id for tracking</p> <p>Context Cleanup: The middleware ensures the context is cleared after command execution (even if the command fails) to prevent context leakage between operations.</p> <p>Middleware Order: This middleware should typically run early in the middleware chain, before logging or other cross-cutting concerns that might need access to context.</p> <p>Examples:</p> <p>Add to all commands:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .build())\n</code></pre> <p>Add with other middleware:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>This middleware is automatically registered when using ApplicationBuilder.use_correlation_tracking().</p>"},{"location":"reference/application/middleware/#interlock.application.middleware.ContextPropagationMiddleware.propagate_context","title":"propagate_context  <code>async</code>","text":"<pre><code>propagate_context(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Set up execution context and pass command to next handler.</p> <p>The context is cleared after command execution (even on failure) to prevent context leakage.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process. Context is extracted from its correlation_id, causation_id, and command_id fields.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/context.py</code> <pre><code>@intercepts\nasync def propagate_context(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Set up execution context and pass command to next handler.\n\n    The context is cleared after command execution (even on\n    failure) to prevent context leakage.\n\n    Args:\n        command: The command to process. Context is extracted from\n            its correlation_id, causation_id, and command_id\n            fields.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Extract context from command, generate defaults for missing values\n    correlation_id = command.correlation_id\n    if correlation_id is None:\n        # Entry point: generate new correlation_id\n        correlation_id = uuid4()\n\n    causation_id = command.causation_id\n    if causation_id is None:\n        # Entry point: self-referencing causation\n        causation_id = correlation_id\n\n    # Create and set execution context\n    ctx = ExecutionContext(\n        correlation_id=correlation_id,\n        causation_id=causation_id,\n        command_id=command.command_id,\n    )\n    set_context(ctx)\n\n    try:\n        # Pass to next handler with context set\n        return await next(command)\n    finally:\n        # Always clear context after command execution to prevent leakage\n        clear_context()\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.HasIdempotencyKey","title":"HasIdempotencyKey","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for commands that have an idempotency key.</p> <p>Commands can provide idempotency tracking by having an <code>idempotency_key</code> attribute (field or property). The idempotency middleware will detect this and use it to prevent duplicate processing.</p> <p>Examples:</p> <p>Field-based idempotency key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n</code></pre> <p>Property-based idempotency key (computed):</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account_id: UUID\n...     to_account_id: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account_id}-{self.to_account_id}-{self.amount}\"\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.HasIdempotencyKey.idempotency_key","title":"idempotency_key  <code>property</code>","text":"<pre><code>idempotency_key: str\n</code></pre> <p>The idempotency key for this command.</p>"},{"location":"reference/application/middleware/#interlock.application.middleware.IdempotencyMiddleware","title":"IdempotencyMiddleware","text":"<pre><code>IdempotencyMiddleware(\n    idempotency_storage_backend: IdempotencyStorageBackend,\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that ensures commands are idempotent.</p> <p>This middleware intercepts commands that have an <code>idempotency_key</code> attribute (field or property) and ensures they are only processed once.</p> <p>Commands without an idempotency_key are passed through unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; app = (\n...     ApplicationBuilder()\n...     .register_dependency(IdempotencyStorageBackend, InMemoryIdempotencyStorageBackend)\n...     .register_middleware(IdempotencyMiddleware)\n...     .build()\n... )\n</code></pre> <p>Field-based key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n...\n&gt;&gt;&gt; await app.dispatch(DepositMoney(aggregate_id=id, amount=100, idempotency_key=\"dep-123\"))\n</code></pre> <p>Property-based key:</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account: UUID\n...     to_account: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account}-{self.to_account}-{self.amount}\"\n</code></pre> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self, idempotency_storage_backend: IdempotencyStorageBackend):\n    self.idempotency_storage_backend = idempotency_storage_backend\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.IdempotencyMiddleware.ensure_idempotency","title":"ensure_idempotency  <code>async</code>","text":"<pre><code>ensure_idempotency(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Check idempotency and process command if not processed.</p> <p>Commands with an <code>idempotency_key</code> attribute are checked against the storage backend. Commands without this attribute are passed through unchanged.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to check.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler, or None if skipped.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@intercepts\nasync def ensure_idempotency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Check idempotency and process command if not processed.\n\n    Commands with an `idempotency_key` attribute are checked against\n    the storage backend. Commands without this attribute are passed\n    through unchanged.\n\n    Args:\n        command: The command to check.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler, or None if skipped.\n    \"\"\"\n    # Check if command has idempotency tracking\n    if not isinstance(command, HasIdempotencyKey):\n        return await next(command)\n\n    idempotency_key = command.idempotency_key\n\n    if await self.idempotency_storage_backend.has_idempotency_key(idempotency_key):\n        LOGGER.warning(\n            \"Skipping previously processed command\",\n            extra={\"idempotency_key\": idempotency_key},\n        )\n        return None\n\n    result = await next(command)\n    await self.idempotency_storage_backend.store_idempotency_key(idempotency_key)\n    return result\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.IdempotencyStorageBackend","title":"IdempotencyStorageBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for idempotency storage backends.</p> <p>This backend is used to store idempotency keys for commands. It will store the idempotency key for a command and return it when the command is dispatched.</p>"},{"location":"reference/application/middleware/#interlock.application.middleware.IdempotencyStorageBackend.store_idempotency_key","title":"store_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>store_idempotency_key(key: str) -&gt; None\n</code></pre> <p>Store an idempotency key as processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def store_idempotency_key(self, key: str) -&gt; None:\n    \"\"\"Store an idempotency key as processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.IdempotencyStorageBackend.has_idempotency_key","title":"has_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>has_idempotency_key(key: str) -&gt; bool\n</code></pre> <p>Check if an idempotency key has been processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def has_idempotency_key(self, key: str) -&gt; bool:\n    \"\"\"Check if an idempotency key has been processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.InMemoryIdempotencyStorageBackend","title":"InMemoryIdempotencyStorageBackend","text":"<pre><code>InMemoryIdempotencyStorageBackend()\n</code></pre> <p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>In-memory implementation of the idempotency storage backend.</p> <p>This backend stores idempotency keys in memory. Suitable for single-process applications and testing.</p> Note <p>Keys are lost on application restart. For production use, implement a persistent backend (Redis, database, etc.).</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self):\n    self.idempotency_keys: set[str] = set()\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.NullIdempotencyStorageBackend","title":"NullIdempotencyStorageBackend","text":"<p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>A null implementation that never detects duplicates.</p> <p>Use this to effectively disable idempotency checking.</p>"},{"location":"reference/application/middleware/#interlock.application.middleware.LoggingMiddleware","title":"LoggingMiddleware","text":"<pre><code>LoggingMiddleware(level: str)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that logs command execution with correlation.</p> <p>Logs each command received at the specified logging level with the command type and correlation/causation IDs for distributed tracing. Command data is NOT logged to avoid exposing PII or sensitive information.</p> ATTRIBUTE DESCRIPTION <code>level</code> <p>The numeric logging level (e.g., logging.INFO, logging.DEBUG).</p> <p> </p> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> <p>With correlation tracking:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .use_correlation_tracking()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>For correlation tracking to work, ContextPropagationMiddleware should be registered before LoggingMiddleware in the middleware chain.</p> PARAMETER DESCRIPTION <code>level</code> <p>String representation of the log level (e.g., \"INFO\", \"DEBUG\"). Case-insensitive.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>def __init__(self, level: str):\n    \"\"\"Initialize the logging middleware.\n\n    Args:\n        level: String representation of the log level (e.g.,\n            \"INFO\", \"DEBUG\"). Case-insensitive.\n    \"\"\"\n    self.level = getattr(logging, level.upper())\n</code></pre>"},{"location":"reference/application/middleware/#interlock.application.middleware.LoggingMiddleware.log_command","title":"log_command  <code>async</code>","text":"<pre><code>log_command(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Log the command type with correlation context.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to log and process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>@intercepts\nasync def log_command(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Log the command type with correlation context.\n\n    Args:\n        command: The command to log and process.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Build log extra with command type and aggregate_id only\n    extra = {\n        \"command_type\": type(command).__name__,\n        \"aggregate_id\": str(command.aggregate_id),\n    }\n\n    # Add correlation context if available\n    ctx = get_context()\n    if ctx.correlation_id is not None:\n        extra[\"correlation_id\"] = str(ctx.correlation_id)\n    if ctx.causation_id is not None:\n        extra[\"causation_id\"] = str(ctx.causation_id)\n    if ctx.command_id is not None:\n        extra[\"command_id\"] = str(ctx.command_id)\n\n    LOGGER.log(self.level, \"Received Command\", extra=extra)\n    return await next(command)\n</code></pre>"},{"location":"reference/application/middleware/base/","title":"base","text":""},{"location":"reference/application/middleware/base/#interlock.application.middleware.base","title":"base","text":"<p>Base middleware class for commands and queries.</p> <p>Middleware components wrap handlers to provide cross-cutting concerns like logging, validation, authentication, or transaction management.</p>"},{"location":"reference/application/middleware/base/#interlock.application.middleware.base.Middleware","title":"Middleware","text":"<p>Base class for middleware with annotation-based routing.</p> <p>Middleware components wrap handlers to provide cross-cutting concerns like logging, validation, authentication, or transaction management. They follow the chain of responsibility pattern.</p> <p>Middleware can intercept both commands and queries using the @intercepts decorator. The framework automatically routes messages to the appropriate methods based on their type annotations.</p> <p>By default, if no interceptor matches the message type, the middleware forwards to the next handler (pass-through behavior).</p> <p>Examples:</p> <p>Intercept all commands:</p> <pre><code>&gt;&gt;&gt; class LoggingMiddleware(Middleware):\n...     @intercepts\n...     async def log_command(self, cmd: Command, next: Handler) -&gt; Any:\n...         print(f\"Command: {type(cmd).__name__}\")\n...         return await next(cmd)\n</code></pre> <p>Intercept specific command type:</p> <pre><code>&gt;&gt;&gt; class AdminOnlyMiddleware(Middleware):\n...     @intercepts\n...     async def check_admin(self, cmd: DeleteUser, next: Handler) -&gt; Any:\n...         if not self.is_admin(cmd.requester_id):\n...             raise PermissionError(\"Admin required\")\n...         return await next(cmd)\n</code></pre> <p>Intercept queries:</p> <pre><code>&gt;&gt;&gt; class CachingMiddleware(Middleware):\n...     @intercepts\n...     async def cache_query(self, query: Query, next: Handler) -&gt; Any:\n...         if cached := self.cache.get(query):\n...             return cached\n...         result = await next(query)\n...         self.cache.set(query, result)\n...         return result\n</code></pre>"},{"location":"reference/application/middleware/base/#interlock.application.middleware.base.Middleware.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up routing when a subclass is defined.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    from ...routing import setup_middleware_routing\n\n    cls._command_router = setup_middleware_routing(cls)\n</code></pre>"},{"location":"reference/application/middleware/base/#interlock.application.middleware.base.Middleware.intercept","title":"intercept  <code>async</code>","text":"<pre><code>intercept(message: BaseModel, next: Handler) -&gt; Any\n</code></pre> <p>Route message to interceptor method or forward to next.</p> <p>This method is called by the bus for each message. It uses the routing table to find an appropriate interceptor method based on the message type. If no interceptor is registered for the message type, it forwards to the next handler.</p> PARAMETER DESCRIPTION <code>message</code> <p>The command or query to intercept.</p> <p> TYPE: <code>BaseModel</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the interceptor or next handler.</p> Source code in <code>interlock/application/middleware/base.py</code> <pre><code>async def intercept(self, message: BaseModel, next: Handler) -&gt; Any:\n    \"\"\"Route message to interceptor method or forward to next.\n\n    This method is called by the bus for each message. It uses the\n    routing table to find an appropriate interceptor method based\n    on the message type. If no interceptor is registered for the\n    message type, it forwards to the next handler.\n\n    Args:\n        message: The command or query to intercept.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the interceptor or next handler.\n    \"\"\"\n    # Route to interceptor, passing next as an extra argument\n    result = self._command_router.route(self, message, next)\n\n    # If router returned None (IgnoreHandler), forward to next\n    if result is None:\n        return await next(message)\n    elif inspect.isawaitable(result):\n        # Router returned coroutine (async interceptor), await it\n        return await result\n    else:\n        return result\n</code></pre>"},{"location":"reference/application/middleware/concurrency/","title":"concurrency","text":""},{"location":"reference/application/middleware/concurrency/#interlock.application.middleware.concurrency","title":"concurrency","text":"<p>Concurrency retry middleware for handling optimistic locking conflicts.</p>"},{"location":"reference/application/middleware/concurrency/#interlock.application.middleware.concurrency.ConcurrencyRetryMiddleware","title":"ConcurrencyRetryMiddleware","text":"<pre><code>ConcurrencyRetryMiddleware(\n    max_attempts: int, retry_delay: float\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that retries commands that fail due to concurrency issues.</p> <p>This middleware retries commands that fail due to concurrency conflicts. It will attempt the command up to <code>max_attempts</code> times with a delay between attempts. If the command still fails after all attempts, it will raise a ConcurrencyError.</p> ATTRIBUTE DESCRIPTION <code>max_attempts</code> <p>The maximum number of attempts (initial + retries). Must be positive. For example, max_attempts=3 means 1 initial attempt + up to 2 retries.</p> <p> </p> <code>retry_delay</code> <p>The delay in seconds between retry attempts. Must be non-negative.</p> <p> </p> <p>Examples:</p> <p>Retry up to 3 times with 0.1s delay:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=3, retry_delay=0.1)\n</code></pre> <p>No delay between retries:</p> <pre><code>&gt;&gt;&gt; middleware = ConcurrencyRetryMiddleware(max_attempts=5, retry_delay=0.0)\n</code></pre> PARAMETER DESCRIPTION <code>max_attempts</code> <p>Maximum number of attempts (must be positive).</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Delay in seconds between retries (must be non-negative).</p> <p> TYPE: <code>float</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If max_attempts &lt;= 0 or retry_delay &lt; 0.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>def __init__(self, max_attempts: int, retry_delay: float):\n    \"\"\"Initialize the concurrency retry middleware.\n\n    Args:\n        max_attempts: Maximum number of attempts (must be positive).\n        retry_delay: Delay in seconds between retries (must be non-negative).\n\n    Raises:\n        ValueError: If max_attempts &lt;= 0 or retry_delay &lt; 0.\n    \"\"\"\n    if max_attempts &lt;= 0:\n        raise ValueError(\"max_attempts must be positive\")\n    if retry_delay &lt; 0:\n        raise ValueError(\"retry_delay must be non-negative\")\n    self.max_attempts = max_attempts\n    self.retry_delay = retry_delay\n</code></pre>"},{"location":"reference/application/middleware/concurrency/#interlock.application.middleware.concurrency.ConcurrencyRetryMiddleware.retry_on_concurrency","title":"retry_on_concurrency  <code>async</code>","text":"<pre><code>retry_on_concurrency(\n    command: Command, next: Handler\n) -&gt; Any\n</code></pre> <p>Intercept all commands and retry on concurrency errors.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If all attempts fail due to concurrency conflicts.</p> <code>Exception</code> <p>Any non-ConcurrencyError exceptions are re-raised immediately.</p> Source code in <code>interlock/application/middleware/concurrency.py</code> <pre><code>@intercepts\nasync def retry_on_concurrency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Intercept all commands and retry on concurrency errors.\n\n    Args:\n        command: The command to process.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n\n    Raises:\n        ConcurrencyError: If all attempts fail due to concurrency conflicts.\n        Exception: Any non-ConcurrencyError exceptions are re-raised immediately.\n    \"\"\"\n    last_error: ConcurrencyError | None = None\n    for attempt in range(self.max_attempts):\n        try:\n            return await next(command)\n        except ConcurrencyError as e:\n            last_error = e\n            LOGGER.warning(\n                f\"Concurrency error on attempt {attempt + 1}/{self.max_attempts}: {e}\"\n            )\n            # Don't sleep after the last attempt\n            if attempt &lt; self.max_attempts - 1:\n                await asyncio.sleep(self.retry_delay)\n    raise ConcurrencyError(f\"Max attempts ({self.max_attempts}) reached\") from last_error\n</code></pre>"},{"location":"reference/application/middleware/context/","title":"context","text":""},{"location":"reference/application/middleware/context/#interlock.application.middleware.context","title":"context","text":"<p>Context propagation middleware for correlation and causation tracking.</p> <p>This middleware automatically manages execution context for commands, enabling distributed tracing across the entire system. It extracts context from commands and sets up the execution context before command execution.</p>"},{"location":"reference/application/middleware/context/#interlock.application.middleware.context.ContextPropagationMiddleware","title":"ContextPropagationMiddleware","text":"<p>               Bases: <code>Middleware</code></p> <p>Middleware that propagates execution context from commands.</p> <p>This middleware extracts correlation_id, causation_id, and command_id from incoming commands and sets up the execution context before the command is handled. This enables:</p> <ol> <li>Distributed Tracing: Track entire operations across    services</li> <li>Causation Tracking: Understand what caused each    command/event</li> <li>Automatic Context Flow: Events emitted by aggregates    automatically inherit the context set by this middleware</li> </ol> <p>Context Setup: - If command has correlation_id: use it - If command has no correlation_id: generate a new one   (entry point) - If command has causation_id: use it - If command has no causation_id: use correlation_id   (self-referencing entry point) - Always use command.command_id for tracking</p> <p>Context Cleanup: The middleware ensures the context is cleared after command execution (even if the command fails) to prevent context leakage between operations.</p> <p>Middleware Order: This middleware should typically run early in the middleware chain, before logging or other cross-cutting concerns that might need access to context.</p> <p>Examples:</p> <p>Add to all commands:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .build())\n</code></pre> <p>Add with other middleware:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(ContextPropagationMiddleware)\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>This middleware is automatically registered when using ApplicationBuilder.use_correlation_tracking().</p>"},{"location":"reference/application/middleware/context/#interlock.application.middleware.context.ContextPropagationMiddleware.propagate_context","title":"propagate_context  <code>async</code>","text":"<pre><code>propagate_context(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Set up execution context and pass command to next handler.</p> <p>The context is cleared after command execution (even on failure) to prevent context leakage.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to process. Context is extracted from its correlation_id, causation_id, and command_id fields.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the middleware chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/context.py</code> <pre><code>@intercepts\nasync def propagate_context(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Set up execution context and pass command to next handler.\n\n    The context is cleared after command execution (even on\n    failure) to prevent context leakage.\n\n    Args:\n        command: The command to process. Context is extracted from\n            its correlation_id, causation_id, and command_id\n            fields.\n        next: The next handler in the middleware chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Extract context from command, generate defaults for missing values\n    correlation_id = command.correlation_id\n    if correlation_id is None:\n        # Entry point: generate new correlation_id\n        correlation_id = uuid4()\n\n    causation_id = command.causation_id\n    if causation_id is None:\n        # Entry point: self-referencing causation\n        causation_id = correlation_id\n\n    # Create and set execution context\n    ctx = ExecutionContext(\n        correlation_id=correlation_id,\n        causation_id=causation_id,\n        command_id=command.command_id,\n    )\n    set_context(ctx)\n\n    try:\n        # Pass to next handler with context set\n        return await next(command)\n    finally:\n        # Always clear context after command execution to prevent leakage\n        clear_context()\n</code></pre>"},{"location":"reference/application/middleware/idempotency/","title":"idempotency","text":""},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency","title":"idempotency","text":"<p>Idempotency middleware for preventing duplicate command processing.</p>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.HasIdempotencyKey","title":"HasIdempotencyKey","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for commands that have an idempotency key.</p> <p>Commands can provide idempotency tracking by having an <code>idempotency_key</code> attribute (field or property). The idempotency middleware will detect this and use it to prevent duplicate processing.</p> <p>Examples:</p> <p>Field-based idempotency key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n</code></pre> <p>Property-based idempotency key (computed):</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account_id: UUID\n...     to_account_id: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account_id}-{self.to_account_id}-{self.amount}\"\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.HasIdempotencyKey.idempotency_key","title":"idempotency_key  <code>property</code>","text":"<pre><code>idempotency_key: str\n</code></pre> <p>The idempotency key for this command.</p>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.IdempotencyStorageBackend","title":"IdempotencyStorageBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for idempotency storage backends.</p> <p>This backend is used to store idempotency keys for commands. It will store the idempotency key for a command and return it when the command is dispatched.</p>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.IdempotencyStorageBackend.store_idempotency_key","title":"store_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>store_idempotency_key(key: str) -&gt; None\n</code></pre> <p>Store an idempotency key as processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def store_idempotency_key(self, key: str) -&gt; None:\n    \"\"\"Store an idempotency key as processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.IdempotencyStorageBackend.has_idempotency_key","title":"has_idempotency_key  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>has_idempotency_key(key: str) -&gt; bool\n</code></pre> <p>Check if an idempotency key has been processed.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@abstractmethod\nasync def has_idempotency_key(self, key: str) -&gt; bool:\n    \"\"\"Check if an idempotency key has been processed.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.IdempotencyMiddleware","title":"IdempotencyMiddleware","text":"<pre><code>IdempotencyMiddleware(\n    idempotency_storage_backend: IdempotencyStorageBackend,\n)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that ensures commands are idempotent.</p> <p>This middleware intercepts commands that have an <code>idempotency_key</code> attribute (field or property) and ensures they are only processed once.</p> <p>Commands without an idempotency_key are passed through unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; app = (\n...     ApplicationBuilder()\n...     .register_dependency(IdempotencyStorageBackend, InMemoryIdempotencyStorageBackend)\n...     .register_middleware(IdempotencyMiddleware)\n...     .build()\n... )\n</code></pre> <p>Field-based key:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: int\n...     idempotency_key: str\n...\n&gt;&gt;&gt; await app.dispatch(DepositMoney(aggregate_id=id, amount=100, idempotency_key=\"dep-123\"))\n</code></pre> <p>Property-based key:</p> <pre><code>&gt;&gt;&gt; class TransferMoney(Command[None]):\n...     from_account: UUID\n...     to_account: UUID\n...     amount: int\n...\n...     @property\n...     def idempotency_key(self) -&gt; str:\n...         return f\"{self.from_account}-{self.to_account}-{self.amount}\"\n</code></pre> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self, idempotency_storage_backend: IdempotencyStorageBackend):\n    self.idempotency_storage_backend = idempotency_storage_backend\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.IdempotencyMiddleware.ensure_idempotency","title":"ensure_idempotency  <code>async</code>","text":"<pre><code>ensure_idempotency(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Check idempotency and process command if not processed.</p> <p>Commands with an <code>idempotency_key</code> attribute are checked against the storage backend. Commands without this attribute are passed through unchanged.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to check.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler, or None if skipped.</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>@intercepts\nasync def ensure_idempotency(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Check idempotency and process command if not processed.\n\n    Commands with an `idempotency_key` attribute are checked against\n    the storage backend. Commands without this attribute are passed\n    through unchanged.\n\n    Args:\n        command: The command to check.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler, or None if skipped.\n    \"\"\"\n    # Check if command has idempotency tracking\n    if not isinstance(command, HasIdempotencyKey):\n        return await next(command)\n\n    idempotency_key = command.idempotency_key\n\n    if await self.idempotency_storage_backend.has_idempotency_key(idempotency_key):\n        LOGGER.warning(\n            \"Skipping previously processed command\",\n            extra={\"idempotency_key\": idempotency_key},\n        )\n        return None\n\n    result = await next(command)\n    await self.idempotency_storage_backend.store_idempotency_key(idempotency_key)\n    return result\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.InMemoryIdempotencyStorageBackend","title":"InMemoryIdempotencyStorageBackend","text":"<pre><code>InMemoryIdempotencyStorageBackend()\n</code></pre> <p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>In-memory implementation of the idempotency storage backend.</p> <p>This backend stores idempotency keys in memory. Suitable for single-process applications and testing.</p> Note <p>Keys are lost on application restart. For production use, implement a persistent backend (Redis, database, etc.).</p> Source code in <code>interlock/application/middleware/idempotency.py</code> <pre><code>def __init__(self):\n    self.idempotency_keys: set[str] = set()\n</code></pre>"},{"location":"reference/application/middleware/idempotency/#interlock.application.middleware.idempotency.NullIdempotencyStorageBackend","title":"NullIdempotencyStorageBackend","text":"<p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>A null implementation that never detects duplicates.</p> <p>Use this to effectively disable idempotency checking.</p>"},{"location":"reference/application/middleware/logging/","title":"logging","text":""},{"location":"reference/application/middleware/logging/#interlock.application.middleware.logging","title":"logging","text":"<p>Logging middleware for command and query tracing.</p>"},{"location":"reference/application/middleware/logging/#interlock.application.middleware.logging.LoggingMiddleware","title":"LoggingMiddleware","text":"<pre><code>LoggingMiddleware(level: str)\n</code></pre> <p>               Bases: <code>Middleware</code></p> <p>Middleware that logs command execution with correlation.</p> <p>Logs each command received at the specified logging level with the command type and correlation/causation IDs for distributed tracing. Command data is NOT logged to avoid exposing PII or sensitive information.</p> ATTRIBUTE DESCRIPTION <code>level</code> <p>The numeric logging level (e.g., logging.INFO, logging.DEBUG).</p> <p> </p> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> <p>With correlation tracking:</p> <pre><code>&gt;&gt;&gt; app = (ApplicationBuilder()\n...     .use_correlation_tracking()\n...     .register_middleware(LoggingMiddleware)\n...     .build())\n</code></pre> Note <p>For correlation tracking to work, ContextPropagationMiddleware should be registered before LoggingMiddleware in the middleware chain.</p> PARAMETER DESCRIPTION <code>level</code> <p>String representation of the log level (e.g., \"INFO\", \"DEBUG\"). Case-insensitive.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>def __init__(self, level: str):\n    \"\"\"Initialize the logging middleware.\n\n    Args:\n        level: String representation of the log level (e.g.,\n            \"INFO\", \"DEBUG\"). Case-insensitive.\n    \"\"\"\n    self.level = getattr(logging, level.upper())\n</code></pre>"},{"location":"reference/application/middleware/logging/#interlock.application.middleware.logging.LoggingMiddleware.log_command","title":"log_command  <code>async</code>","text":"<pre><code>log_command(command: Command, next: Handler) -&gt; Any\n</code></pre> <p>Log the command type with correlation context.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to log and process.</p> <p> TYPE: <code>Command</code> </p> <code>next</code> <p>The next handler in the chain.</p> <p> TYPE: <code>Handler</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result from the command handler.</p> Source code in <code>interlock/application/middleware/logging.py</code> <pre><code>@intercepts\nasync def log_command(self, command: Command, next: Handler) -&gt; Any:\n    \"\"\"Log the command type with correlation context.\n\n    Args:\n        command: The command to log and process.\n        next: The next handler in the chain.\n\n    Returns:\n        The result from the command handler.\n    \"\"\"\n    # Build log extra with command type and aggregate_id only\n    extra = {\n        \"command_type\": type(command).__name__,\n        \"aggregate_id\": str(command.aggregate_id),\n    }\n\n    # Add correlation context if available\n    ctx = get_context()\n    if ctx.correlation_id is not None:\n        extra[\"correlation_id\"] = str(ctx.correlation_id)\n    if ctx.causation_id is not None:\n        extra[\"causation_id\"] = str(ctx.causation_id)\n    if ctx.command_id is not None:\n        extra[\"command_id\"] = str(ctx.command_id)\n\n    LOGGER.log(self.level, \"Received Command\", extra=extra)\n    return await next(command)\n</code></pre>"},{"location":"reference/application/projections/","title":"projections","text":""},{"location":"reference/application/projections/#interlock.application.projections","title":"projections","text":"<p>Projection infrastructure for building read models.</p> <p>This package provides: - Projection: Base class combining event handling with query serving - QueryBus: Routes queries through middleware to projections - QueryToProjectionMap: Maps query types to projection types - ProjectionRegistry: Registry of projection instances - DelegateToProjection: Root handler for query dispatch</p>"},{"location":"reference/application/projections/#interlock.application.projections.DelegateToProjection","title":"DelegateToProjection","text":"<pre><code>DelegateToProjection(\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n)\n</code></pre> <p>Root handler that delegates queries to the appropriate projection.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n):\n    self.query_to_projection_map = query_to_projection_map\n    self.projection_registry = projection_registry\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.DelegateToProjection.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch a query to its projection handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def handle(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch a query to its projection handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The query result.\n    \"\"\"\n    projection_type = self.query_to_projection_map.get(type(query))\n    projection = self.projection_registry.get(projection_type)\n    return await projection.query(query)\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.ProjectionRegistry","title":"ProjectionRegistry","text":"<pre><code>ProjectionRegistry()\n</code></pre> <p>Registry of projection instances for query dispatch.</p> <p>This is the query-side equivalent of AggregateToRepositoryMap. Unlike aggregates which are loaded per-request, projections are typically long-lived singletons that maintain read model state.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.projections: dict[type[Projection], Projection] = {}\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.ProjectionRegistry.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[Projection],\n) -&gt; ProjectionRegistry\n</code></pre> <p>Build a registry from a list of projection instances.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection instances to register.</p> <p> TYPE: <code>list[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionRegistry</code> <p>A configured ProjectionRegistry.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[Projection],\n) -&gt; \"ProjectionRegistry\":\n    \"\"\"Build a registry from a list of projection instances.\n\n    Args:\n        projections: List of projection instances to register.\n\n    Returns:\n        A configured ProjectionRegistry.\n    \"\"\"\n    registry = ProjectionRegistry()\n    for projection in projections:\n        registry.add(projection)\n    return registry\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.ProjectionRegistry.add","title":"add","text":"<pre><code>add(projection: Projection) -&gt; None\n</code></pre> <p>Register a projection instance.</p> PARAMETER DESCRIPTION <code>projection</code> <p>The projection instance to register.</p> <p> TYPE: <code>Projection</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection: Projection) -&gt; None:\n    \"\"\"Register a projection instance.\n\n    Args:\n        projection: The projection instance to register.\n    \"\"\"\n    self.projections[type(projection)] = projection\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.ProjectionRegistry.get","title":"get","text":"<pre><code>get(projection_type: type[Projection]) -&gt; Projection\n</code></pre> <p>Get a projection instance by type.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to look up.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>Projection</code> <p>The registered projection instance.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection of this type is registered.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, projection_type: type[Projection]) -&gt; Projection:\n    \"\"\"Get a projection instance by type.\n\n    Args:\n        projection_type: The projection class to look up.\n\n    Returns:\n        The registered projection instance.\n\n    Raises:\n        KeyError: If no projection of this type is registered.\n    \"\"\"\n    return self.projections[projection_type]\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryBus","title":"QueryBus","text":"<pre><code>QueryBus(\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n)\n</code></pre> <p>Routes queries through middleware to projections.</p> <p>The QueryBus manages the middleware chain and delegates queries to the appropriate projection for handling. Middleware is applied in registration order, with each middleware deciding via annotation- based routing whether to intercept a query.</p> PARAMETER DESCRIPTION <code>root_handler</code> <p>The final handler that delegates to projections.</p> <p> TYPE: <code>DelegateToProjection</code> </p> <code>middleware</code> <p>List of middleware to apply (in order).</p> <p> TYPE: <code>list[Middleware]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n):\n    self.root_handler = root_handler\n    self.middleware = middleware\n    # Build the middleware chain by reducing from right to left\n    self.chain: Callable[[Query[Any]], Coroutine[Any, Any, Any]] = reduce(\n        lambda next, mw: lambda q, n=next, m=mw: m.intercept(q, n),\n        reversed(middleware),\n        self.root_handler.handle,\n    )\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryBus.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch query through the middleware chain to handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the query handler.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def dispatch(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch query through the middleware chain to handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The result from the query handler.\n    \"\"\"\n    return await self.chain(query)\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryToProjectionMap","title":"QueryToProjectionMap","text":"<pre><code>QueryToProjectionMap()\n</code></pre> <p>Maps query types to projection types.</p> <p>This is the query-side equivalent of CommandToAggregateMap. It scans projection classes for @handles_query decorated methods and builds a routing table.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.query_to_projection_map: dict[type[Query[Any]], type[Projection]] = {}\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryToProjectionMap.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[type[Projection]],\n) -&gt; QueryToProjectionMap\n</code></pre> <p>Build a map from a list of projection types.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection classes to scan.</p> <p> TYPE: <code>list[type[Projection]]</code> </p> RETURNS DESCRIPTION <code>QueryToProjectionMap</code> <p>A configured QueryToProjectionMap.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[type[Projection]],\n) -&gt; \"QueryToProjectionMap\":\n    \"\"\"Build a map from a list of projection types.\n\n    Args:\n        projections: List of projection classes to scan.\n\n    Returns:\n        A configured QueryToProjectionMap.\n    \"\"\"\n    map = QueryToProjectionMap()\n    for projection in projections:\n        map.add(projection)\n    return map\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryToProjectionMap.add","title":"add","text":"<pre><code>add(projection_type: type[Projection]) -&gt; None\n</code></pre> <p>Register a projection's query handlers.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to scan for handlers.</p> <p> TYPE: <code>type[Projection]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection_type: type[Projection]) -&gt; None:\n    \"\"\"Register a projection's query handlers.\n\n    Args:\n        projection_type: The projection class to scan for handlers.\n    \"\"\"\n    for value in projection_type.__dict__.values():\n        if hasattr(value, \"_handles_query_type\"):\n            query_type = value._handles_query_type\n            self.query_to_projection_map[query_type] = projection_type\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.QueryToProjectionMap.get","title":"get","text":"<pre><code>get(query_type: type[Query[Any]]) -&gt; type[Projection]\n</code></pre> <p>Get the projection type that handles a query type.</p> PARAMETER DESCRIPTION <code>query_type</code> <p>The query class to look up.</p> <p> TYPE: <code>type[Query[Any]]</code> </p> RETURNS DESCRIPTION <code>type[Projection]</code> <p>The projection type that handles this query.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection handles this query type.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, query_type: type[Query[Any]]) -&gt; type[Projection]:\n    \"\"\"Get the projection type that handles a query type.\n\n    Args:\n        query_type: The query class to look up.\n\n    Returns:\n        The projection type that handles this query.\n\n    Raises:\n        KeyError: If no projection handles this query type.\n    \"\"\"\n    return self.query_to_projection_map[query_type]\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.Projection","title":"Projection","text":"<p>               Bases: <code>EventProcessor</code></p> <p>Base class for read models that handle events and serve queries.</p> <p>Projections are the read side of CQRS. They: 1. Subscribe to events and update their internal state (read model) 2. Serve queries by returning data from their read model</p> <p>Unlike aggregates which enforce invariants and emit events, projections are optimized for reads. They maintain denormalized views that can be queried efficiently.</p> <p>Event Handling: Use @handles_event to mark methods that process events:</p> <pre><code>@handles_event\nasync def on_user_created(self, event: UserCreated) -&gt; None:\n    self.users[event.user_id] = UserProfile(\n        id=event.user_id,\n        name=event.name,\n        email=event.email\n    )\n</code></pre> <p>Query Handling: Use @handles_query to mark methods that serve queries:</p> <pre><code>@handles_query\nasync def get_user(self, query: GetUserById) -&gt; UserProfile:\n    return self.users[query.user_id]\n</code></pre> <p>State Management: Projections are responsible for their own state persistence. Inject repositories or database clients via dependency injection:</p> <pre><code>class UserProjection(Projection):\n    def __init__(self, repository: UserRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_user_created(self, event: UserCreated) -&gt; None:\n        await self.repository.save(UserProfile(...))\n\n    @handles_query\n    async def get_user(self, query: GetUserById) -&gt; UserProfile:\n        return await self.repository.get(query.user_id)\n</code></pre> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Routing table for event handlers (inherited)</p> <p> TYPE: <code>MessageRouter</code> </p> <code>_query_router</code> <p>Routing table for query handlers</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock import Projection, handles_event, handles_query from interlock.domain import Query</p> <p>class GetUserById(Query[UserProfile]): ...     user_id: UUID</p> <p>class GetUserByEmail(Query[UUID | None]): ...     email: str</p> <p>class UserProjection(Projection): ...     def init(self): ...         super().init() ...         self.users: dict[UUID, UserProfile] = {} ...         self.email_index: dict[str, UUID] = {} ... ...     @handles_event ...     async def on_user_created(self, event: UserCreated) -&gt; None: ...         profile = UserProfile( ...             id=event.user_id, ...             name=event.name, ...             email=event.email ...         ) ...         self.users[event.user_id] = profile ...         self.email_index[event.email] = event.user_id ... ...     @handles_query ...     async def get_user(self, query: GetUserById) -&gt; UserProfile: ...         return self.users[query.user_id] ... ...     @handles_query ...     async def find_by_email(self, q: GetUserByEmail) -&gt; UUID | None: ...         return self.email_index.get(q.email)</p>"},{"location":"reference/application/projections/#interlock.application.projections.Projection.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event and query routing when a subclass is defined.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event and query routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    # Event routing is set up by EventProcessor.__init_subclass__\n    # We need to set up query routing here\n    cls._query_router = setup_query_routing(cls)\n</code></pre>"},{"location":"reference/application/projections/#interlock.application.projections.Projection.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Route a query to its registered handler method.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to handle.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for the query.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Route a query to its registered handler method.\n\n    Args:\n        query: The query to handle.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n\n    Raises:\n        NotImplementedError: If no handler is registered for the query.\n    \"\"\"\n    result = self._query_router.route(self, query)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/application/projections/bus/","title":"bus","text":""},{"location":"reference/application/projections/bus/#interlock.application.projections.bus","title":"bus","text":"<p>Query bus and routing infrastructure for projections.</p>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryToProjectionMap","title":"QueryToProjectionMap","text":"<pre><code>QueryToProjectionMap()\n</code></pre> <p>Maps query types to projection types.</p> <p>This is the query-side equivalent of CommandToAggregateMap. It scans projection classes for @handles_query decorated methods and builds a routing table.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.query_to_projection_map: dict[type[Query[Any]], type[Projection]] = {}\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryToProjectionMap.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[type[Projection]],\n) -&gt; QueryToProjectionMap\n</code></pre> <p>Build a map from a list of projection types.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection classes to scan.</p> <p> TYPE: <code>list[type[Projection]]</code> </p> RETURNS DESCRIPTION <code>QueryToProjectionMap</code> <p>A configured QueryToProjectionMap.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[type[Projection]],\n) -&gt; \"QueryToProjectionMap\":\n    \"\"\"Build a map from a list of projection types.\n\n    Args:\n        projections: List of projection classes to scan.\n\n    Returns:\n        A configured QueryToProjectionMap.\n    \"\"\"\n    map = QueryToProjectionMap()\n    for projection in projections:\n        map.add(projection)\n    return map\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryToProjectionMap.add","title":"add","text":"<pre><code>add(projection_type: type[Projection]) -&gt; None\n</code></pre> <p>Register a projection's query handlers.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to scan for handlers.</p> <p> TYPE: <code>type[Projection]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection_type: type[Projection]) -&gt; None:\n    \"\"\"Register a projection's query handlers.\n\n    Args:\n        projection_type: The projection class to scan for handlers.\n    \"\"\"\n    for value in projection_type.__dict__.values():\n        if hasattr(value, \"_handles_query_type\"):\n            query_type = value._handles_query_type\n            self.query_to_projection_map[query_type] = projection_type\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryToProjectionMap.get","title":"get","text":"<pre><code>get(query_type: type[Query[Any]]) -&gt; type[Projection]\n</code></pre> <p>Get the projection type that handles a query type.</p> PARAMETER DESCRIPTION <code>query_type</code> <p>The query class to look up.</p> <p> TYPE: <code>type[Query[Any]]</code> </p> RETURNS DESCRIPTION <code>type[Projection]</code> <p>The projection type that handles this query.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection handles this query type.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, query_type: type[Query[Any]]) -&gt; type[Projection]:\n    \"\"\"Get the projection type that handles a query type.\n\n    Args:\n        query_type: The query class to look up.\n\n    Returns:\n        The projection type that handles this query.\n\n    Raises:\n        KeyError: If no projection handles this query type.\n    \"\"\"\n    return self.query_to_projection_map[query_type]\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.ProjectionRegistry","title":"ProjectionRegistry","text":"<pre><code>ProjectionRegistry()\n</code></pre> <p>Registry of projection instances for query dispatch.</p> <p>This is the query-side equivalent of AggregateToRepositoryMap. Unlike aggregates which are loaded per-request, projections are typically long-lived singletons that maintain read model state.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.projections: dict[type[Projection], Projection] = {}\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.ProjectionRegistry.from_projections","title":"from_projections  <code>staticmethod</code>","text":"<pre><code>from_projections(\n    projections: list[Projection],\n) -&gt; ProjectionRegistry\n</code></pre> <p>Build a registry from a list of projection instances.</p> PARAMETER DESCRIPTION <code>projections</code> <p>List of projection instances to register.</p> <p> TYPE: <code>list[Projection]</code> </p> RETURNS DESCRIPTION <code>ProjectionRegistry</code> <p>A configured ProjectionRegistry.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>@staticmethod\ndef from_projections(\n    projections: list[Projection],\n) -&gt; \"ProjectionRegistry\":\n    \"\"\"Build a registry from a list of projection instances.\n\n    Args:\n        projections: List of projection instances to register.\n\n    Returns:\n        A configured ProjectionRegistry.\n    \"\"\"\n    registry = ProjectionRegistry()\n    for projection in projections:\n        registry.add(projection)\n    return registry\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.ProjectionRegistry.add","title":"add","text":"<pre><code>add(projection: Projection) -&gt; None\n</code></pre> <p>Register a projection instance.</p> PARAMETER DESCRIPTION <code>projection</code> <p>The projection instance to register.</p> <p> TYPE: <code>Projection</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def add(self, projection: Projection) -&gt; None:\n    \"\"\"Register a projection instance.\n\n    Args:\n        projection: The projection instance to register.\n    \"\"\"\n    self.projections[type(projection)] = projection\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.ProjectionRegistry.get","title":"get","text":"<pre><code>get(projection_type: type[Projection]) -&gt; Projection\n</code></pre> <p>Get a projection instance by type.</p> PARAMETER DESCRIPTION <code>projection_type</code> <p>The projection class to look up.</p> <p> TYPE: <code>type[Projection]</code> </p> RETURNS DESCRIPTION <code>Projection</code> <p>The registered projection instance.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If no projection of this type is registered.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def get(self, projection_type: type[Projection]) -&gt; Projection:\n    \"\"\"Get a projection instance by type.\n\n    Args:\n        projection_type: The projection class to look up.\n\n    Returns:\n        The registered projection instance.\n\n    Raises:\n        KeyError: If no projection of this type is registered.\n    \"\"\"\n    return self.projections[projection_type]\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.DelegateToProjection","title":"DelegateToProjection","text":"<pre><code>DelegateToProjection(\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n)\n</code></pre> <p>Root handler that delegates queries to the appropriate projection.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    query_to_projection_map: QueryToProjectionMap,\n    projection_registry: ProjectionRegistry,\n):\n    self.query_to_projection_map = query_to_projection_map\n    self.projection_registry = projection_registry\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.DelegateToProjection.handle","title":"handle  <code>async</code>","text":"<pre><code>handle(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch a query to its projection handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def handle(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch a query to its projection handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The query result.\n    \"\"\"\n    projection_type = self.query_to_projection_map.get(type(query))\n    projection = self.projection_registry.get(projection_type)\n    return await projection.query(query)\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryBus","title":"QueryBus","text":"<pre><code>QueryBus(\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n)\n</code></pre> <p>Routes queries through middleware to projections.</p> <p>The QueryBus manages the middleware chain and delegates queries to the appropriate projection for handling. Middleware is applied in registration order, with each middleware deciding via annotation- based routing whether to intercept a query.</p> PARAMETER DESCRIPTION <code>root_handler</code> <p>The final handler that delegates to projections.</p> <p> TYPE: <code>DelegateToProjection</code> </p> <code>middleware</code> <p>List of middleware to apply (in order).</p> <p> TYPE: <code>list[Middleware]</code> </p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>def __init__(\n    self,\n    root_handler: DelegateToProjection,\n    middleware: list[Middleware],\n):\n    self.root_handler = root_handler\n    self.middleware = middleware\n    # Build the middleware chain by reducing from right to left\n    self.chain: Callable[[Query[Any]], Coroutine[Any, Any, Any]] = reduce(\n        lambda next, mw: lambda q, n=next, m=mw: m.intercept(q, n),\n        reversed(middleware),\n        self.root_handler.handle,\n    )\n</code></pre>"},{"location":"reference/application/projections/bus/#interlock.application.projections.bus.QueryBus.dispatch","title":"dispatch  <code>async</code>","text":"<pre><code>dispatch(query: Query[T]) -&gt; T\n</code></pre> <p>Dispatch query through the middleware chain to handler.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to dispatch.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The result from the query handler.</p> Source code in <code>interlock/application/projections/bus.py</code> <pre><code>async def dispatch(self, query: Query[T]) -&gt; T:\n    \"\"\"Dispatch query through the middleware chain to handler.\n\n    Args:\n        query: The query to dispatch.\n\n    Returns:\n        The result from the query handler.\n    \"\"\"\n    return await self.chain(query)\n</code></pre>"},{"location":"reference/application/projections/projection/","title":"projection","text":""},{"location":"reference/application/projections/projection/#interlock.application.projections.projection","title":"projection","text":"<p>Projection base class for building read models with query support.</p> <p>Projections combine event handling (from EventProcessor) with query handling, providing a unified abstraction for the read side of CQRS.</p>"},{"location":"reference/application/projections/projection/#interlock.application.projections.projection.Projection","title":"Projection","text":"<p>               Bases: <code>EventProcessor</code></p> <p>Base class for read models that handle events and serve queries.</p> <p>Projections are the read side of CQRS. They: 1. Subscribe to events and update their internal state (read model) 2. Serve queries by returning data from their read model</p> <p>Unlike aggregates which enforce invariants and emit events, projections are optimized for reads. They maintain denormalized views that can be queried efficiently.</p> <p>Event Handling: Use @handles_event to mark methods that process events:</p> <pre><code>@handles_event\nasync def on_user_created(self, event: UserCreated) -&gt; None:\n    self.users[event.user_id] = UserProfile(\n        id=event.user_id,\n        name=event.name,\n        email=event.email\n    )\n</code></pre> <p>Query Handling: Use @handles_query to mark methods that serve queries:</p> <pre><code>@handles_query\nasync def get_user(self, query: GetUserById) -&gt; UserProfile:\n    return self.users[query.user_id]\n</code></pre> <p>State Management: Projections are responsible for their own state persistence. Inject repositories or database clients via dependency injection:</p> <pre><code>class UserProjection(Projection):\n    def __init__(self, repository: UserRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_user_created(self, event: UserCreated) -&gt; None:\n        await self.repository.save(UserProfile(...))\n\n    @handles_query\n    async def get_user(self, query: GetUserById) -&gt; UserProfile:\n        return await self.repository.get(query.user_id)\n</code></pre> ATTRIBUTE DESCRIPTION <code>_event_router</code> <p>Routing table for event handlers (inherited)</p> <p> TYPE: <code>MessageRouter</code> </p> <code>_query_router</code> <p>Routing table for query handlers</p> <p> TYPE: <code>MessageRouter</code> </p> Example <p>from interlock import Projection, handles_event, handles_query from interlock.domain import Query</p> <p>class GetUserById(Query[UserProfile]): ...     user_id: UUID</p> <p>class GetUserByEmail(Query[UUID | None]): ...     email: str</p> <p>class UserProjection(Projection): ...     def init(self): ...         super().init() ...         self.users: dict[UUID, UserProfile] = {} ...         self.email_index: dict[str, UUID] = {} ... ...     @handles_event ...     async def on_user_created(self, event: UserCreated) -&gt; None: ...         profile = UserProfile( ...             id=event.user_id, ...             name=event.name, ...             email=event.email ...         ) ...         self.users[event.user_id] = profile ...         self.email_index[event.email] = event.user_id ... ...     @handles_query ...     async def get_user(self, query: GetUserById) -&gt; UserProfile: ...         return self.users[query.user_id] ... ...     @handles_query ...     async def find_by_email(self, q: GetUserByEmail) -&gt; UUID | None: ...         return self.email_index.get(q.email)</p>"},{"location":"reference/application/projections/projection/#interlock.application.projections.projection.Projection.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up event and query routing when a subclass is defined.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up event and query routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)\n    # Event routing is set up by EventProcessor.__init_subclass__\n    # We need to set up query routing here\n    cls._query_router = setup_query_routing(cls)\n</code></pre>"},{"location":"reference/application/projections/projection/#interlock.application.projections.projection.Projection.query","title":"query  <code>async</code>","text":"<pre><code>query(query: Query[T]) -&gt; T\n</code></pre> <p>Route a query to its registered handler method.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to handle.</p> <p> TYPE: <code>Query[T]</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The query result as declared by the Query's type parameter.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for the query.</p> Source code in <code>interlock/application/projections/projection.py</code> <pre><code>async def query(self, query: Query[T]) -&gt; T:\n    \"\"\"Route a query to its registered handler method.\n\n    Args:\n        query: The query to handle.\n\n    Returns:\n        The query result as declared by the Query's type parameter.\n\n    Raises:\n        NotImplementedError: If no handler is registered for the query.\n    \"\"\"\n    result = self._query_router.route(self, query)\n\n    # If the handler is async, await the coroutine\n    if inspect.iscoroutine(result):\n        return await result\n    return result  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/domain/","title":"domain","text":""},{"location":"reference/domain/#interlock.domain","title":"domain","text":"<p>Domain primitives for event sourcing and CQRS.</p> <p>This module contains the core building blocks that users extend to create their domain models:</p> <ul> <li>Aggregate: Base class for domain aggregates that emit events</li> <li>Command: Base class for command messages (write side)</li> <li>Query: Base class for query messages (read side)</li> <li>Event: Base class for event messages</li> <li>ConcurrencyError: Exception for optimistic concurrency conflicts</li> </ul>"},{"location":"reference/domain/#interlock.domain.Aggregate","title":"Aggregate","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all aggregates in the event sourcing system.</p> <p>Aggregates are the core domain objects that maintain consistency boundaries and emit domain events when their state changes. Each aggregate has a unique identifier and maintains its version through event sequencing.</p> <p>The aggregate pattern ensures that all business rules and invariants are enforced within a single consistency boundary. State changes are expressed as events that are applied to update the aggregate's state.</p> <p>Command and event handling is automatically routed based on method decorators. Use @handles_command to mark command handler methods and @applies_event to mark event applier methods. The framework will automatically route commands and events to the appropriate methods based on their type annotations.</p> <p>Examples:</p> <p>Create a simple bank account aggregate:</p> <pre><code>&gt;&gt;&gt; from decimal import Decimal\n&gt;&gt;&gt; from interlock.routing import handles_command, applies_event\n&gt;&gt;&gt;\n&gt;&gt;&gt; class DepositMoney(Command):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MoneyDeposited(BaseModel):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     balance: Decimal = Decimal(\"0.00\")\n...\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         if cmd.amount &lt;= 0:\n...             raise ValueError(\"Amount must be positive\")\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n...\n...     @applies_event\n...     def apply_deposited(self, evt: MoneyDeposited) -&gt; None:\n...         self.balance += evt.amount\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.handle(DepositMoney(aggregate_id=account.id, amount=Decimal(\"100.00\")))\n&gt;&gt;&gt; print(account.balance)\n100.00\n</code></pre> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this aggregate instance. Auto-generated if not provided.</p> <p> TYPE: <code>UUID</code> </p> <code>version</code> <p>Current version number, incremented with each event. Used for optimistic concurrency control.</p> <p> TYPE: <code>int</code> </p> <code>last_snapshot_time</code> <p>Timestamp of the last snapshot creation. Used for snapshot management.</p> <p> TYPE: <code>datetime</code> </p> <code>last_event_time</code> <p>Timestamp of the most recent event. Used for tracking aggregate activity.</p> <p> TYPE: <code>datetime</code> </p> <code>uncommitted_events</code> <p>List of events that have been emitted but not yet persisted to the event store. This field is excluded from serialization.</p> <p> TYPE: <code>list[Event[Any]]</code> </p>"},{"location":"reference/domain/#interlock.domain.Aggregate.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up command and event routing when a subclass is defined.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up command and event routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)  # type: ignore[arg-type]\n    cls._command_router = setup_command_routing(cls)\n    cls._event_router = setup_event_applying(cls)\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.handle","title":"handle","text":"<pre><code>handle(command: BaseModel) -&gt; object\n</code></pre> <p>Route a command to its registered handler method.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to handle.</p> <p> TYPE: <code>BaseModel</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for this command type.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def handle(self, command: BaseModel) -&gt; object:\n    \"\"\"Route a command to its registered handler method.\n\n    Args:\n        command: The command to handle.\n\n    Raises:\n        NotImplementedError: If no handler is registered for this command type.\n    \"\"\"\n    return self._command_router.route(self, command)\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.apply","title":"apply","text":"<pre><code>apply(event: BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered applier method.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to apply to the aggregate state.</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def apply(self, event: BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered applier method.\n\n    Args:\n        event: The event to apply to the aggregate state.\n    \"\"\"\n    return self._event_router.route(self, event)\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.emit","title":"emit","text":"<pre><code>emit(data: T) -&gt; None\n</code></pre> <p>Emit a domain event and apply it to the aggregate state.</p> <p>This method should be called by business logic methods when the aggregate's state needs to change. It increments the version, creates an event with proper metadata, adds it to uncommitted events, and applies the event.</p> <p>The emit method automatically populates correlation_id and causation_id from the current execution context: - correlation_id is inherited from the context (traces the entire operation) - causation_id is set to the command_id from context (the command that caused this event)</p> PARAMETER DESCRIPTION <code>data</code> <p>The event data as a Pydantic model representing what happened.</p> <p> TYPE: <code>T</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class AccountOpened(BaseModel):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def emit(self, data: T) -&gt; None:\n    \"\"\"Emit a domain event and apply it to the aggregate state.\n\n    This method should be called by business logic methods when the aggregate's\n    state needs to change. It increments the version, creates an event with\n    proper metadata, adds it to uncommitted events, and applies the event.\n\n    The emit method automatically populates correlation_id and causation_id from\n    the current execution context:\n    - correlation_id is inherited from the context (traces the entire operation)\n    - causation_id is set to the command_id from context (the command that caused this event)\n\n    Args:\n        data: The event data as a Pydantic model representing what happened.\n\n    Examples:\n        &gt;&gt;&gt; class AccountOpened(BaseModel):\n        ...     owner: str\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n        &gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n    \"\"\"\n    self.version += 1\n    current_time = utc_now()\n\n    # Get context for correlation/causation tracking\n    ctx = get_context()\n\n    event: Event[T] = Event(\n        aggregate_id=self.id,\n        sequence_number=self.version,\n        data=data,\n        timestamp=current_time,\n        correlation_id=ctx.correlation_id,\n        causation_id=ctx.command_id,  # The command caused this event\n    )\n    self.last_event_time = current_time\n    self.uncommitted_events.append(event)\n    self.apply(data)\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.changed_since","title":"changed_since","text":"<pre><code>changed_since(version: int) -&gt; bool\n</code></pre> <p>Check if the aggregate has changed since a specific version.</p> PARAMETER DESCRIPTION <code>version</code> <p>The version number to compare against.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the current version is greater than the provided version,</p> <code>bool</code> <p>False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n&gt;&gt;&gt; account.changed_since(0)\nTrue\n&gt;&gt;&gt; account.changed_since(1)\nFalse\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def changed_since(self, version: int) -&gt; bool:\n    \"\"\"Check if the aggregate has changed since a specific version.\n\n    Args:\n        version: The version number to compare against.\n\n    Returns:\n        True if the current version is greater than the provided version,\n        False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n        &gt;&gt;&gt; account.changed_since(0)\n        True\n        &gt;&gt;&gt; account.changed_since(1)\n        False\n    \"\"\"\n    return self.version &gt; version\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.mark_snapshot","title":"mark_snapshot","text":"<pre><code>mark_snapshot() -&gt; None\n</code></pre> <p>Mark the current time as when a snapshot was taken.</p> <p>This method is typically called by the repository after creating a snapshot of the aggregate's current state.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def mark_snapshot(self) -&gt; None:\n    \"\"\"Mark the current time as when a snapshot was taken.\n\n    This method is typically called by the repository after creating\n    a snapshot of the aggregate's current state.\n    \"\"\"\n    self.last_snapshot_time = utc_now()\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.get_uncommitted_events","title":"get_uncommitted_events","text":"<pre><code>get_uncommitted_events() -&gt; list[Event[Any]]\n</code></pre> <p>Get the list of events that haven't been persisted yet.</p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of uncommitted event objects.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def get_uncommitted_events(self) -&gt; list[Event[Any]]:\n    \"\"\"Get the list of events that haven't been persisted yet.\n\n    Returns:\n        List of uncommitted event objects.\n    \"\"\"\n    return self.uncommitted_events\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.clear_uncommitted_events","title":"clear_uncommitted_events","text":"<pre><code>clear_uncommitted_events() -&gt; None\n</code></pre> <p>Clear the list of uncommitted events.</p> <p>This is typically called after events have been successfully persisted to the event store.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def clear_uncommitted_events(self) -&gt; None:\n    \"\"\"Clear the list of uncommitted events.\n\n    This is typically called after events have been successfully\n    persisted to the event store.\n    \"\"\"\n    self.uncommitted_events.clear()\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Aggregate.replay_events","title":"replay_events","text":"<pre><code>replay_events(events: list[BaseModel]) -&gt; None\n</code></pre> <p>Replay a sequence of events to rebuild the aggregate's state.</p> <p>This method is called when loading an aggregate from the event store. It applies each event in order to reconstruct the current state.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of event data objects to replay.</p> <p> TYPE: <code>list[BaseModel]</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def replay_events(self, events: list[BaseModel]) -&gt; None:\n    \"\"\"Replay a sequence of events to rebuild the aggregate's state.\n\n    This method is called when loading an aggregate from the event store.\n    It applies each event in order to reconstruct the current state.\n\n    Args:\n        events: List of event data objects to replay.\n    \"\"\"\n    for event in events:\n        self.apply(event)\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Command","title":"Command","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all commands in the system.</p> <p>Commands represent intentions to change state and are dispatched to command handlers. All commands must include an aggregate_id to identify which aggregate instance to operate on.</p> <p>Commands are generic over their response type <code>TResponse</code>, allowing handlers to return typed results. Use <code>Command[None]</code> for commands that don't return a value.</p> ATTRIBUTE DESCRIPTION <code>aggregate_id</code> <p>UUID of the aggregate that should handle this command.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this command.</p> <p> TYPE: <code>UUID | None</code> </p> <code>command_id</code> <p>Unique identifier for this command instance.</p> <p> TYPE: <code>UUID</code> </p> <p>Examples:</p> <p>Command that returns the new aggregate ID:</p> <pre><code>&gt;&gt;&gt; class CreateAccount(Command[UUID]):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_create(self, cmd: CreateAccount) -&gt; UUID:\n...         self.emit(AccountCreated(owner=cmd.owner))\n...         return self.id\n</code></pre> <p>Command that returns nothing:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n</code></pre>"},{"location":"reference/domain/#interlock.domain.Event","title":"Event","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Immutable record of a state change in an aggregate.</p> <p>Event is the core data structure in event sourcing. Each event represents a fact that occurred in the past - a state transition in an aggregate's lifecycle. Events are:</p> <ul> <li>Immutable: Once created, events cannot be modified</li> <li>Ordered: Events have sequence numbers for ordering within an aggregate</li> <li>Typed: Generic type parameter T specifies the event data schema</li> <li>Timestamped: All events record when they occurred (UTC)</li> <li>Identifiable: Each event has a unique ID and belongs to an aggregate</li> <li>Traceable: Events can include correlation/causation IDs for distributed tracing</li> </ul> <p>The Event class is a generic wrapper that combines event metadata (id, aggregate_id, sequence_number, timestamp) with strongly-typed event data. The type parameter <code>T</code> is a Pydantic BaseModel subclass defining the event data schema.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this specific event instance</p> <p> TYPE: <code>UUID</code> </p> <code>aggregate_id</code> <p>ID of the aggregate that produced this event</p> <p> TYPE: <code>UUID</code> </p> <code>data</code> <p>Typed event data (e.g., AccountCreated, MoneyDeposited)</p> <p> TYPE: <code>T</code> </p> <code>sequence_number</code> <p>Position in the aggregate's event stream (1-indexed)</p> <p> TYPE: <code>int</code> </p> <code>timestamp</code> <p>When the event occurred (UTC timezone)</p> <p> TYPE: <code>datetime</code> </p> <code>correlation_id</code> <p>Optional correlation ID for tracing the entire logical operation</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this event (typically the command_id)</p> <p> TYPE: <code>UUID | None</code> </p> Note <p>Events are typically created by aggregates via the <code>emit()</code> method, not constructed directly. The EventBus handles persistence and delivery. The Aggregate.emit() method automatically populates correlation_id and causation_id from the current execution context.</p> <p>Examples:</p> <p>Event created by aggregate (context auto-populated):</p> <pre><code>&gt;&gt;&gt; # Inside aggregate command handler\n&gt;&gt;&gt; self.emit(AccountCreated(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically set from context\n</code></pre> <p>Event created manually with full context:</p> <pre><code>&gt;&gt;&gt; event = Event(\n...     aggregate_id=account_id,\n...     data=MoneyDeposited(amount=100),\n...     sequence_number=5,\n...     correlation_id=correlation_id,\n...     causation_id=command_id\n... )\n</code></pre>"},{"location":"reference/domain/#interlock.domain.ConcurrencyError","title":"ConcurrencyError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimistic concurrency check fails.</p> <p>This exception indicates that another process has modified the aggregate between when it was loaded and when changes were attempted to be saved.</p>"},{"location":"reference/domain/#interlock.domain.Query","title":"Query","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all queries in the system.</p> <p>Queries represent requests for data and are dispatched to projections. Each query is generic over its response type, providing type safety for query handlers.</p> <p>Unlike commands, queries: - Do not mutate state - Return typed responses - Are routed to projections (not aggregates)</p> <p>The type parameter <code>TResponse</code> specifies the type returned by query handlers for this query.</p> ATTRIBUTE DESCRIPTION <code>query_id</code> <p>Unique identifier for this query instance.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this query.</p> <p> TYPE: <code>UUID | None</code> </p> <p>Examples:</p> <p>Define a query with a typed response:</p> <pre><code>&gt;&gt;&gt; class GetUserById(Query[UserProfile]):\n...     user_id: UUID\n&gt;&gt;&gt;\n&gt;&gt;&gt; class GetUserByEmail(Query[UUID | None]):\n...     email: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Query handlers must return the declared response type\n&gt;&gt;&gt; class UserProjection(Projection):\n...     @handles_query\n...     async def get_user_by_id(self, query: GetUserById) -&gt; UserProfile:\n...         return self.users[query.user_id]\n</code></pre>"},{"location":"reference/domain/#interlock.domain.utc_now","title":"utc_now","text":"<pre><code>utc_now() -&gt; datetime\n</code></pre> <p>Get the current UTC timestamp.</p> RETURNS DESCRIPTION <code>datetime</code> <p>Current datetime with UTC timezone information</p> Note <p>Used as default_factory for Event.timestamp to ensure all events are timestamped in UTC regardless of system timezone.</p> Source code in <code>interlock/domain/event.py</code> <pre><code>def utc_now() -&gt; datetime:\n    \"\"\"Get the current UTC timestamp.\n\n    Returns:\n        Current datetime with UTC timezone information\n\n    Note:\n        Used as default_factory for Event.timestamp to ensure all\n        events are timestamped in UTC regardless of system timezone.\n    \"\"\"\n    return datetime.now(tz=timezone.utc)\n</code></pre>"},{"location":"reference/domain/aggregate/","title":"aggregate","text":""},{"location":"reference/domain/aggregate/#interlock.domain.aggregate","title":"aggregate","text":""},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate","title":"Aggregate","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all aggregates in the event sourcing system.</p> <p>Aggregates are the core domain objects that maintain consistency boundaries and emit domain events when their state changes. Each aggregate has a unique identifier and maintains its version through event sequencing.</p> <p>The aggregate pattern ensures that all business rules and invariants are enforced within a single consistency boundary. State changes are expressed as events that are applied to update the aggregate's state.</p> <p>Command and event handling is automatically routed based on method decorators. Use @handles_command to mark command handler methods and @applies_event to mark event applier methods. The framework will automatically route commands and events to the appropriate methods based on their type annotations.</p> <p>Examples:</p> <p>Create a simple bank account aggregate:</p> <pre><code>&gt;&gt;&gt; from decimal import Decimal\n&gt;&gt;&gt; from interlock.routing import handles_command, applies_event\n&gt;&gt;&gt;\n&gt;&gt;&gt; class DepositMoney(Command):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MoneyDeposited(BaseModel):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     balance: Decimal = Decimal(\"0.00\")\n...\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         if cmd.amount &lt;= 0:\n...             raise ValueError(\"Amount must be positive\")\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n...\n...     @applies_event\n...     def apply_deposited(self, evt: MoneyDeposited) -&gt; None:\n...         self.balance += evt.amount\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.handle(DepositMoney(aggregate_id=account.id, amount=Decimal(\"100.00\")))\n&gt;&gt;&gt; print(account.balance)\n100.00\n</code></pre> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this aggregate instance. Auto-generated if not provided.</p> <p> TYPE: <code>UUID</code> </p> <code>version</code> <p>Current version number, incremented with each event. Used for optimistic concurrency control.</p> <p> TYPE: <code>int</code> </p> <code>last_snapshot_time</code> <p>Timestamp of the last snapshot creation. Used for snapshot management.</p> <p> TYPE: <code>datetime</code> </p> <code>last_event_time</code> <p>Timestamp of the most recent event. Used for tracking aggregate activity.</p> <p> TYPE: <code>datetime</code> </p> <code>uncommitted_events</code> <p>List of events that have been emitted but not yet persisted to the event store. This field is excluded from serialization.</p> <p> TYPE: <code>list[Event[Any]]</code> </p>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs: object) -&gt; None\n</code></pre> <p>Set up command and event routing when a subclass is defined.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def __init_subclass__(cls, **kwargs: object) -&gt; None:\n    \"\"\"Set up command and event routing when a subclass is defined.\"\"\"\n    super().__init_subclass__(**kwargs)  # type: ignore[arg-type]\n    cls._command_router = setup_command_routing(cls)\n    cls._event_router = setup_event_applying(cls)\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.handle","title":"handle","text":"<pre><code>handle(command: BaseModel) -&gt; object\n</code></pre> <p>Route a command to its registered handler method.</p> PARAMETER DESCRIPTION <code>command</code> <p>The command to handle.</p> <p> TYPE: <code>BaseModel</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If no handler is registered for this command type.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def handle(self, command: BaseModel) -&gt; object:\n    \"\"\"Route a command to its registered handler method.\n\n    Args:\n        command: The command to handle.\n\n    Raises:\n        NotImplementedError: If no handler is registered for this command type.\n    \"\"\"\n    return self._command_router.route(self, command)\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.apply","title":"apply","text":"<pre><code>apply(event: BaseModel) -&gt; object\n</code></pre> <p>Route an event to its registered applier method.</p> PARAMETER DESCRIPTION <code>event</code> <p>The event to apply to the aggregate state.</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def apply(self, event: BaseModel) -&gt; object:\n    \"\"\"Route an event to its registered applier method.\n\n    Args:\n        event: The event to apply to the aggregate state.\n    \"\"\"\n    return self._event_router.route(self, event)\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.emit","title":"emit","text":"<pre><code>emit(data: T) -&gt; None\n</code></pre> <p>Emit a domain event and apply it to the aggregate state.</p> <p>This method should be called by business logic methods when the aggregate's state needs to change. It increments the version, creates an event with proper metadata, adds it to uncommitted events, and applies the event.</p> <p>The emit method automatically populates correlation_id and causation_id from the current execution context: - correlation_id is inherited from the context (traces the entire operation) - causation_id is set to the command_id from context (the command that caused this event)</p> PARAMETER DESCRIPTION <code>data</code> <p>The event data as a Pydantic model representing what happened.</p> <p> TYPE: <code>T</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class AccountOpened(BaseModel):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def emit(self, data: T) -&gt; None:\n    \"\"\"Emit a domain event and apply it to the aggregate state.\n\n    This method should be called by business logic methods when the aggregate's\n    state needs to change. It increments the version, creates an event with\n    proper metadata, adds it to uncommitted events, and applies the event.\n\n    The emit method automatically populates correlation_id and causation_id from\n    the current execution context:\n    - correlation_id is inherited from the context (traces the entire operation)\n    - causation_id is set to the command_id from context (the command that caused this event)\n\n    Args:\n        data: The event data as a Pydantic model representing what happened.\n\n    Examples:\n        &gt;&gt;&gt; class AccountOpened(BaseModel):\n        ...     owner: str\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.emit(AccountOpened(owner=\"Alice\"))\n        &gt;&gt;&gt; # correlation_id and causation_id are automatically populated from context\n    \"\"\"\n    self.version += 1\n    current_time = utc_now()\n\n    # Get context for correlation/causation tracking\n    ctx = get_context()\n\n    event: Event[T] = Event(\n        aggregate_id=self.id,\n        sequence_number=self.version,\n        data=data,\n        timestamp=current_time,\n        correlation_id=ctx.correlation_id,\n        causation_id=ctx.command_id,  # The command caused this event\n    )\n    self.last_event_time = current_time\n    self.uncommitted_events.append(event)\n    self.apply(data)\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.changed_since","title":"changed_since","text":"<pre><code>changed_since(version: int) -&gt; bool\n</code></pre> <p>Check if the aggregate has changed since a specific version.</p> PARAMETER DESCRIPTION <code>version</code> <p>The version number to compare against.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the current version is greater than the provided version,</p> <code>bool</code> <p>False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; account = BankAccount()\n&gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n&gt;&gt;&gt; account.changed_since(0)\nTrue\n&gt;&gt;&gt; account.changed_since(1)\nFalse\n</code></pre> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def changed_since(self, version: int) -&gt; bool:\n    \"\"\"Check if the aggregate has changed since a specific version.\n\n    Args:\n        version: The version number to compare against.\n\n    Returns:\n        True if the current version is greater than the provided version,\n        False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; account = BankAccount()\n        &gt;&gt;&gt; account.deposit(Decimal(\"100\"))\n        &gt;&gt;&gt; account.changed_since(0)\n        True\n        &gt;&gt;&gt; account.changed_since(1)\n        False\n    \"\"\"\n    return self.version &gt; version\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.mark_snapshot","title":"mark_snapshot","text":"<pre><code>mark_snapshot() -&gt; None\n</code></pre> <p>Mark the current time as when a snapshot was taken.</p> <p>This method is typically called by the repository after creating a snapshot of the aggregate's current state.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def mark_snapshot(self) -&gt; None:\n    \"\"\"Mark the current time as when a snapshot was taken.\n\n    This method is typically called by the repository after creating\n    a snapshot of the aggregate's current state.\n    \"\"\"\n    self.last_snapshot_time = utc_now()\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.get_uncommitted_events","title":"get_uncommitted_events","text":"<pre><code>get_uncommitted_events() -&gt; list[Event[Any]]\n</code></pre> <p>Get the list of events that haven't been persisted yet.</p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of uncommitted event objects.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def get_uncommitted_events(self) -&gt; list[Event[Any]]:\n    \"\"\"Get the list of events that haven't been persisted yet.\n\n    Returns:\n        List of uncommitted event objects.\n    \"\"\"\n    return self.uncommitted_events\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.clear_uncommitted_events","title":"clear_uncommitted_events","text":"<pre><code>clear_uncommitted_events() -&gt; None\n</code></pre> <p>Clear the list of uncommitted events.</p> <p>This is typically called after events have been successfully persisted to the event store.</p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def clear_uncommitted_events(self) -&gt; None:\n    \"\"\"Clear the list of uncommitted events.\n\n    This is typically called after events have been successfully\n    persisted to the event store.\n    \"\"\"\n    self.uncommitted_events.clear()\n</code></pre>"},{"location":"reference/domain/aggregate/#interlock.domain.aggregate.Aggregate.replay_events","title":"replay_events","text":"<pre><code>replay_events(events: list[BaseModel]) -&gt; None\n</code></pre> <p>Replay a sequence of events to rebuild the aggregate's state.</p> <p>This method is called when loading an aggregate from the event store. It applies each event in order to reconstruct the current state.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of event data objects to replay.</p> <p> TYPE: <code>list[BaseModel]</code> </p> Source code in <code>interlock/domain/aggregate.py</code> <pre><code>def replay_events(self, events: list[BaseModel]) -&gt; None:\n    \"\"\"Replay a sequence of events to rebuild the aggregate's state.\n\n    This method is called when loading an aggregate from the event store.\n    It applies each event in order to reconstruct the current state.\n\n    Args:\n        events: List of event data objects to replay.\n    \"\"\"\n    for event in events:\n        self.apply(event)\n</code></pre>"},{"location":"reference/domain/command/","title":"command","text":""},{"location":"reference/domain/command/#interlock.domain.command","title":"command","text":"<p>Command base class for the write side of CQRS.</p> <p>Commands represent intentions to change state and are dispatched to aggregates.</p>"},{"location":"reference/domain/command/#interlock.domain.command.Command","title":"Command","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all commands in the system.</p> <p>Commands represent intentions to change state and are dispatched to command handlers. All commands must include an aggregate_id to identify which aggregate instance to operate on.</p> <p>Commands are generic over their response type <code>TResponse</code>, allowing handlers to return typed results. Use <code>Command[None]</code> for commands that don't return a value.</p> ATTRIBUTE DESCRIPTION <code>aggregate_id</code> <p>UUID of the aggregate that should handle this command.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this command.</p> <p> TYPE: <code>UUID | None</code> </p> <code>command_id</code> <p>Unique identifier for this command instance.</p> <p> TYPE: <code>UUID</code> </p> <p>Examples:</p> <p>Command that returns the new aggregate ID:</p> <pre><code>&gt;&gt;&gt; class CreateAccount(Command[UUID]):\n...     owner: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_create(self, cmd: CreateAccount) -&gt; UUID:\n...         self.emit(AccountCreated(owner=cmd.owner))\n...         return self.id\n</code></pre> <p>Command that returns nothing:</p> <pre><code>&gt;&gt;&gt; class DepositMoney(Command[None]):\n...     amount: Decimal\n&gt;&gt;&gt;\n&gt;&gt;&gt; class BankAccount(Aggregate):\n...     @handles_command\n...     def handle_deposit(self, cmd: DepositMoney) -&gt; None:\n...         self.emit(MoneyDeposited(amount=cmd.amount))\n</code></pre>"},{"location":"reference/domain/event/","title":"event","text":""},{"location":"reference/domain/event/#interlock.domain.event","title":"event","text":""},{"location":"reference/domain/event/#interlock.domain.event.Event","title":"Event","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Immutable record of a state change in an aggregate.</p> <p>Event is the core data structure in event sourcing. Each event represents a fact that occurred in the past - a state transition in an aggregate's lifecycle. Events are:</p> <ul> <li>Immutable: Once created, events cannot be modified</li> <li>Ordered: Events have sequence numbers for ordering within an aggregate</li> <li>Typed: Generic type parameter T specifies the event data schema</li> <li>Timestamped: All events record when they occurred (UTC)</li> <li>Identifiable: Each event has a unique ID and belongs to an aggregate</li> <li>Traceable: Events can include correlation/causation IDs for distributed tracing</li> </ul> <p>The Event class is a generic wrapper that combines event metadata (id, aggregate_id, sequence_number, timestamp) with strongly-typed event data. The type parameter <code>T</code> is a Pydantic BaseModel subclass defining the event data schema.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier for this specific event instance</p> <p> TYPE: <code>UUID</code> </p> <code>aggregate_id</code> <p>ID of the aggregate that produced this event</p> <p> TYPE: <code>UUID</code> </p> <code>data</code> <p>Typed event data (e.g., AccountCreated, MoneyDeposited)</p> <p> TYPE: <code>T</code> </p> <code>sequence_number</code> <p>Position in the aggregate's event stream (1-indexed)</p> <p> TYPE: <code>int</code> </p> <code>timestamp</code> <p>When the event occurred (UTC timezone)</p> <p> TYPE: <code>datetime</code> </p> <code>correlation_id</code> <p>Optional correlation ID for tracing the entire logical operation</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this event (typically the command_id)</p> <p> TYPE: <code>UUID | None</code> </p> Note <p>Events are typically created by aggregates via the <code>emit()</code> method, not constructed directly. The EventBus handles persistence and delivery. The Aggregate.emit() method automatically populates correlation_id and causation_id from the current execution context.</p> <p>Examples:</p> <p>Event created by aggregate (context auto-populated):</p> <pre><code>&gt;&gt;&gt; # Inside aggregate command handler\n&gt;&gt;&gt; self.emit(AccountCreated(owner=\"Alice\"))\n&gt;&gt;&gt; # correlation_id and causation_id are automatically set from context\n</code></pre> <p>Event created manually with full context:</p> <pre><code>&gt;&gt;&gt; event = Event(\n...     aggregate_id=account_id,\n...     data=MoneyDeposited(amount=100),\n...     sequence_number=5,\n...     correlation_id=correlation_id,\n...     causation_id=command_id\n... )\n</code></pre>"},{"location":"reference/domain/event/#interlock.domain.event.utc_now","title":"utc_now","text":"<pre><code>utc_now() -&gt; datetime\n</code></pre> <p>Get the current UTC timestamp.</p> RETURNS DESCRIPTION <code>datetime</code> <p>Current datetime with UTC timezone information</p> Note <p>Used as default_factory for Event.timestamp to ensure all events are timestamped in UTC regardless of system timezone.</p> Source code in <code>interlock/domain/event.py</code> <pre><code>def utc_now() -&gt; datetime:\n    \"\"\"Get the current UTC timestamp.\n\n    Returns:\n        Current datetime with UTC timezone information\n\n    Note:\n        Used as default_factory for Event.timestamp to ensure all\n        events are timestamped in UTC regardless of system timezone.\n    \"\"\"\n    return datetime.now(tz=timezone.utc)\n</code></pre>"},{"location":"reference/domain/exceptions/","title":"exceptions","text":""},{"location":"reference/domain/exceptions/#interlock.domain.exceptions","title":"exceptions","text":"<p>Exceptions for the aggregates module.</p>"},{"location":"reference/domain/exceptions/#interlock.domain.exceptions.ConcurrencyError","title":"ConcurrencyError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an optimistic concurrency check fails.</p> <p>This exception indicates that another process has modified the aggregate between when it was loaded and when changes were attempted to be saved.</p>"},{"location":"reference/domain/query/","title":"query","text":""},{"location":"reference/domain/query/#interlock.domain.query","title":"query","text":"<p>Query base class for the read side of CQRS.</p> <p>Queries represent requests for data and are dispatched to projections. Unlike commands, queries do not mutate state - they return data.</p>"},{"location":"reference/domain/query/#interlock.domain.query.Query","title":"Query","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[TResponse]</code></p> <p>Base class for all queries in the system.</p> <p>Queries represent requests for data and are dispatched to projections. Each query is generic over its response type, providing type safety for query handlers.</p> <p>Unlike commands, queries: - Do not mutate state - Return typed responses - Are routed to projections (not aggregates)</p> <p>The type parameter <code>TResponse</code> specifies the type returned by query handlers for this query.</p> ATTRIBUTE DESCRIPTION <code>query_id</code> <p>Unique identifier for this query instance.</p> <p> TYPE: <code>UUID</code> </p> <code>correlation_id</code> <p>Optional correlation ID for distributed tracing.</p> <p> TYPE: <code>UUID | None</code> </p> <code>causation_id</code> <p>Optional ID of what caused this query.</p> <p> TYPE: <code>UUID | None</code> </p> <p>Examples:</p> <p>Define a query with a typed response:</p> <pre><code>&gt;&gt;&gt; class GetUserById(Query[UserProfile]):\n...     user_id: UUID\n&gt;&gt;&gt;\n&gt;&gt;&gt; class GetUserByEmail(Query[UUID | None]):\n...     email: str\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Query handlers must return the declared response type\n&gt;&gt;&gt; class UserProjection(Projection):\n...     @handles_query\n...     async def get_user_by_id(self, query: GetUserById) -&gt; UserProfile:\n...         return self.users[query.user_id]\n</code></pre>"},{"location":"reference/integrations/","title":"integrations","text":""},{"location":"reference/integrations/#interlock.integrations","title":"integrations","text":"<p>Database integrations for Interlock.</p>"},{"location":"reference/integrations/mongodb/","title":"mongodb","text":""},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb","title":"mongodb","text":"<p>MongoDB integration for Interlock.</p> <p>Provides MongoDB-backed implementations for: - EventStore: Durable event persistence with optimistic concurrency control - SagaStateStore: Persistent saga state management with step idempotency - AggregateSnapshotStorageBackend: Aggregate snapshot storage (single or multiple versions) - IdempotencyStorageBackend: Command idempotency tracking with TTL-based cleanup</p> <p>The MongoConfiguration class acts as both a settings container and a factory for MongoDB resources (client, database, collections).</p> <p>Type resolution is automatic - event, state, and aggregate types are dynamically loaded from their stored qualified names using Python's import machinery. No manual type registration is required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, ...     MongoEventStore, ...     MongoSagaStateStore, ...     MongoSnapshotStorage, ...     MongoIdempotencyStorage, ... )</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb--configuration-provides-client-db-and-collection-access","title":"Configuration provides client, db, and collection access","text":"<p>config = MongoConfiguration()</p> <p>app = ( ...     ApplicationBuilder() ...     .register_dependency(MongoConfiguration, lambda: config) ...     .register_dependency(EventStore, MongoEventStore) ...     .register_dependency(SagaStateStore, MongoSagaStateStore) ...     .register_dependency(AggregateSnapshotStorageBackend, MongoSnapshotStorage) ...     .register_dependency(IdempotencyStorageBackend, MongoIdempotencyStorage) ...     .build() ... )</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexDirection","title":"IndexDirection","text":"<p>               Bases: <code>IntEnum</code></p> <p>Sort direction for MongoDB index fields.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexDirection.ASC","title":"ASC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ASC = ASCENDING\n</code></pre> <p>Ascending order (1).</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexDirection.DESC","title":"DESC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DESC = DESCENDING\n</code></pre> <p>Descending order (-1).</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec","title":"IndexSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification for a MongoDB index.</p> Example"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec--simple-index","title":"Simple index","text":"<p>IndexSpec(keys=[(\"aggregate_id\", IndexDirection.ASC)])</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec--compound-unique-index","title":"Compound unique index","text":"<p>IndexSpec( ...     keys=[ ...         (\"aggregate_id\", IndexDirection.ASC), ...         (\"version\", IndexDirection.DESC), ...     ], ...     unique=True, ... )</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec--ttl-index","title":"TTL index","text":"<p>IndexSpec( ...     keys=[(\"created_at\", IndexDirection.ASC)], ...     expire_after_seconds=86400, ... )</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys: list[tuple[str, IndexDirection]]\n</code></pre> <p>(field_name, direction) tuples.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec.unique","title":"unique  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>unique: bool = False\n</code></pre> <p>If True, enforce uniqueness.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec.expire_after_seconds","title":"expire_after_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expire_after_seconds: int | None = None\n</code></pre> <p>If set, create a TTL index.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.IndexSpec.apply","title":"apply  <code>async</code>","text":"<pre><code>apply(collection: AsyncCollection[dict[str, Any]]) -&gt; None\n</code></pre> <p>Apply this index specification to a collection.</p> PARAMETER DESCRIPTION <code>collection</code> <p>The MongoDB collection to create the index on.</p> <p> TYPE: <code>AsyncCollection[dict[str, Any]]</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def apply(self, collection: AsyncCollection[dict[str, Any]]) -&gt; None:\n    \"\"\"Apply this index specification to a collection.\n\n    Args:\n        collection: The MongoDB collection to create the index on.\n    \"\"\"\n    kwargs: dict[str, Any] = {}\n    if self.unique:\n        kwargs[\"unique\"] = True\n    if self.expire_after_seconds is not None:\n        kwargs[\"expireAfterSeconds\"] = self.expire_after_seconds\n\n    await collection.create_index(self.keys, **kwargs)\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration","title":"MongoConfiguration","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration and factory for MongoDB resources.</p> <p>Implements the HasLifecycle protocol for integration with Interlock's application lifecycle management. The client is closed on shutdown.</p> <p>All settings can be configured via environment variables with the INTERLOCK_ prefix. For example: - INTERLOCK_MONGO_URI=mongodb://localhost:27017 - INTERLOCK_MONGO_DATABASE=myapp - INTERLOCK_MONGO_EVENTS_COLLECTION=domain_events</p> <p>The configuration also acts as a factory, providing lazy-initialized properties for the MongoDB client, database, and collections.</p> ATTRIBUTE DESCRIPTION <code>uri</code> <p>MongoDB connection URI.</p> <p> TYPE: <code>str</code> </p> <code>database</code> <p>Database name to use.</p> <p> TYPE: <code>str</code> </p> <code>events_collection</code> <p>Collection name for event storage.</p> <p> TYPE: <code>str</code> </p> <code>saga_states_collection</code> <p>Collection name for saga state storage.</p> <p> TYPE: <code>str</code> </p> <code>snapshots_collection</code> <p>Collection name for aggregate snapshots.</p> <p> TYPE: <code>str</code> </p> <code>idempotency_keys_collection</code> <p>Collection name for idempotency keys.</p> <p> TYPE: <code>str</code> </p> <code>snapshot_mode</code> <p>Storage mode for snapshots - \"single\" overwrites, \"multiple\" keeps version history.</p> <p> TYPE: <code>Literal['single', 'multiple']</code> </p> <code>idempotency_ttl_seconds</code> <p>TTL for idempotency keys in seconds.</p> <p> TYPE: <code>int</code> </p> Example <p>config = MongoConfiguration()</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration--access-the-database","title":"Access the database","text":"<p>db = config.db</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration--access-collections","title":"Access collections","text":"<p>events = config.events sagas = config.saga_states</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration--with-applicationbuilder-lifecycle-managed-automatically","title":"With ApplicationBuilder (lifecycle managed automatically)","text":"<p>app = ( ...     ApplicationBuilder() ...     .register_dependency(MongoConfiguration) ...     .build() ... ) async with app:  # calls on_startup/on_shutdown ...     ...</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.client","title":"client  <code>cached</code> <code>property</code>","text":"<pre><code>client: AsyncMongoClient[dict[str, Any]]\n</code></pre> <p>Get the MongoDB async client.</p> <p>The client is lazily created and cached for reuse.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.db","title":"db  <code>cached</code> <code>property</code>","text":"<pre><code>db: AsyncDatabase[dict[str, Any]]\n</code></pre> <p>Get the MongoDB async database.</p> <p>Uses the database name from configuration.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.events","title":"events  <code>cached</code> <code>property</code>","text":"<pre><code>events: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the events collection.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.saga_states","title":"saga_states  <code>cached</code> <code>property</code>","text":"<pre><code>saga_states: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the saga states collection.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.snapshots","title":"snapshots  <code>cached</code> <code>property</code>","text":"<pre><code>snapshots: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the snapshots collection.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.idempotency_keys","title":"idempotency_keys  <code>cached</code> <code>property</code>","text":"<pre><code>idempotency_keys: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the idempotency keys collection.</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.on_startup","title":"on_startup  <code>async</code>","text":"<pre><code>on_startup() -&gt; None\n</code></pre> <p>Called when the application starts.</p> <p>No-op for MongoDB - connections are established lazily.</p> Source code in <code>interlock/integrations/mongodb/config.py</code> <pre><code>async def on_startup(self) -&gt; None:\n    \"\"\"Called when the application starts.\n\n    No-op for MongoDB - connections are established lazily.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoConfiguration.on_shutdown","title":"on_shutdown  <code>async</code>","text":"<pre><code>on_shutdown() -&gt; None\n</code></pre> <p>Called when the application shuts down.</p> <p>Closes the MongoDB client connection if it was created.</p> Source code in <code>interlock/integrations/mongodb/config.py</code> <pre><code>async def on_shutdown(self) -&gt; None:\n    \"\"\"Called when the application shuts down.\n\n    Closes the MongoDB client connection if it was created.\n    \"\"\"\n    if \"client\" in self.__dict__:\n        self.client.close()\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore","title":"MongoEventStore","text":"<pre><code>MongoEventStore(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>EventStore</code></p> <p>MongoDB-backed event store with optimistic concurrency control.</p> <p>Stores events in a MongoDB collection with a unique compound index on (aggregate_id, sequence_number) to enforce ordering and enable optimistic concurrency control.</p> <p>The store supports: - Atomic event persistence with version checking - Loading events by aggregate ID with optional version filtering - Rewriting events for schema migration (upcasting)</p> <p>Event data types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoEventStore ... )</p> <p>config = MongoConfiguration() store = MongoEventStore(config)</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and collections.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB event store.\n\n    Args:\n        config: MongoDB configuration providing connection and collections.\n    \"\"\"\n    self._collection = IndexedCollection(config.events, indexes=EVENTS_INDEXES)\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore--save-events-with-optimistic-concurrency","title":"Save events with optimistic concurrency","text":"<p>await store.save_events(events, expected_version=0)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore--load-all-events-for-an-aggregate","title":"Load all events for an aggregate","text":"<p>events = await store.load_events(aggregate_id, min_version=0)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore.save_events","title":"save_events  <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Persist events to MongoDB with optimistic concurrency control.</p> <p>Events are inserted atomically. If any event's sequence number conflicts with an existing event, the entire operation fails with a ConcurrencyError.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to persist.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>Expected aggregate version before these events.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version (duplicate sequence number detected).</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Persist events to MongoDB with optimistic concurrency control.\n\n    Events are inserted atomically. If any event's sequence number\n    conflicts with an existing event, the entire operation fails with\n    a ConcurrencyError.\n\n    Args:\n        events: List of events to persist.\n        expected_version: Expected aggregate version before these events.\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current\n            version (duplicate sequence number detected).\n    \"\"\"\n    if not events:\n        return\n\n    aggregate_id = events[0].aggregate_id\n\n    # Verify expected version by checking current max sequence number\n    latest = await self._collection.find_latest(\n        {\"aggregate_id\": str(aggregate_id)},\n        sort_field=\"sequence_number\",\n    )\n    current_version = latest[\"sequence_number\"] if latest else 0\n\n    if current_version != expected_version:\n        raise ConcurrencyError(f\"Expected version {expected_version}, got {current_version}\")\n\n    # Convert events to documents\n    documents = [EventDocument.from_value(event).model_dump(mode=\"json\") for event in events]\n\n    try:\n        await self._collection.insert_many(documents, ordered=True)\n    except DuplicateKeyError as e:\n        raise ConcurrencyError(\n            f\"Concurrent modification detected for aggregate {aggregate_id}\"\n        ) from e\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate from MongoDB.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The aggregate whose events to load.</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum sequence number (inclusive).</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events in sequence order.</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate from MongoDB.\n\n    Args:\n        aggregate_id: The aggregate whose events to load.\n        min_version: Minimum sequence number (inclusive).\n\n    Returns:\n        List of events in sequence order.\n    \"\"\"\n    cursor = self._collection.find(\n        {\n            \"aggregate_id\": str(aggregate_id),\n            \"sequence_number\": {\"$gte\": min_version},\n        },\n        sort=[(\"sequence_number\", IndexDirection.ASC)],\n    )\n\n    return [EventDocument.model_validate(doc).to_value() async for doc in cursor]\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoEventStore.rewrite_events","title":"rewrite_events  <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place for schema migration.</p> <p>Updates events by matching (aggregate_id, sequence_number).</p> PARAMETER DESCRIPTION <code>events</code> <p>Events with updated data to write back.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place for schema migration.\n\n    Updates events by matching (aggregate_id, sequence_number).\n\n    Args:\n        events: Events with updated data to write back.\n    \"\"\"\n    for event in events:\n        doc = EventDocument.from_value(event).model_dump(mode=\"json\")\n        await self._collection.update_one(\n            {\n                \"aggregate_id\": str(event.aggregate_id),\n                \"sequence_number\": event.sequence_number,\n            },\n            {\"$set\": doc},\n        )\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoIdempotencyStorage","title":"MongoIdempotencyStorage","text":"<pre><code>MongoIdempotencyStorage(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>MongoDB-backed idempotency storage with TTL-based cleanup.</p> <p>Stores idempotency keys in MongoDB with a TTL index for automatic expiration. This prevents the collection from growing indefinitely while ensuring commands are not processed twice within the TTL window.</p> Document schema <p>{     \"_id\": \"idempotency_key\",     \"created_at\": datetime }</p> <p>The TTL index on <code>created_at</code> automatically removes documents after the configured <code>idempotency_ttl_seconds</code> (default: 24 hours).</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoIdempotencyStorage ... )</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and TTL setting.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB idempotency storage.\n\n    Args:\n        config: MongoDB configuration providing connection and TTL setting.\n    \"\"\"\n    self._collection = IndexedCollection(\n        config.idempotency_keys,\n        indexes=[idempotency_ttl_index(config.idempotency_ttl_seconds)],\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoIdempotencyStorage--configure-with-1-hour-ttl","title":"Configure with 1 hour TTL","text":"<p>config = MongoConfiguration(idempotency_ttl_seconds=3600) storage = MongoIdempotencyStorage(config)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoIdempotencyStorage--check-if-command-was-already-processed","title":"Check if command was already processed","text":"<p>if await storage.has_idempotency_key(\"cmd-123\"): ...     print(\"Already processed\") ... else: ...     # Process command... ...     await storage.store_idempotency_key(\"cmd-123\")</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoIdempotencyStorage.store_idempotency_key","title":"store_idempotency_key  <code>async</code>","text":"<pre><code>store_idempotency_key(key: str) -&gt; None\n</code></pre> <p>Store an idempotency key as processed.</p> <p>If the key already exists, this is a no-op (idempotent).</p> PARAMETER DESCRIPTION <code>key</code> <p>The idempotency key to store.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>async def store_idempotency_key(self, key: str) -&gt; None:\n    \"\"\"Store an idempotency key as processed.\n\n    If the key already exists, this is a no-op (idempotent).\n\n    Args:\n        key: The idempotency key to store.\n    \"\"\"\n    with contextlib.suppress(DuplicateKeyError):\n        await self._collection.insert_one(\n            {\n                \"_id\": key,\n                \"created_at\": datetime.now(tz=timezone.utc),\n            }\n        )\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoIdempotencyStorage.has_idempotency_key","title":"has_idempotency_key  <code>async</code>","text":"<pre><code>has_idempotency_key(key: str) -&gt; bool\n</code></pre> <p>Check if an idempotency key has been processed.</p> PARAMETER DESCRIPTION <code>key</code> <p>The idempotency key to check.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the key exists (command was processed), False otherwise.</p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>async def has_idempotency_key(self, key: str) -&gt; bool:\n    \"\"\"Check if an idempotency key has been processed.\n\n    Args:\n        key: The idempotency key to check.\n\n    Returns:\n        True if the key exists (command was processed), False otherwise.\n    \"\"\"\n    doc = await self._collection.find_one({\"_id\": key}, projection={\"_id\": 1})\n    return doc is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore","title":"MongoSagaStateStore","text":"<pre><code>MongoSagaStateStore(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>SagaStateStore</code></p> <p>MongoDB-backed saga state store.</p> <p>Stores saga state and completed step tracking in a MongoDB collection. Each saga instance is stored as a single document with its state and a list of completed steps for idempotency.</p> Document schema <p>{     \"_id\": \"saga_id\",     \"state_type\": \"module.ClassName\",     \"state\": { ... serialized state ... },     \"completed_steps\": [\"step1\", \"step2\", ...] }</p> <p>State types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoSagaStateStore ... )</p> <p>config = MongoConfiguration() store = MongoSagaStateStore(config)</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and collections.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB saga state store.\n\n    Args:\n        config: MongoDB configuration providing connection and collections.\n    \"\"\"\n    # No indexes needed - _id is indexed by default\n    self._collection = IndexedCollection(config.saga_states)\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore--save-saga-state","title":"Save saga state","text":"<p>await store.save(\"order-123\", CheckoutState(status=\"started\"))</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore--mark-steps-complete-for-idempotency","title":"Mark steps complete for idempotency","text":"<p>was_new = await store.mark_step_complete(\"order-123\", \"reserve_inventory\")</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore.load","title":"load  <code>async</code>","text":"<pre><code>load(saga_id: str) -&gt; BaseModel | None\n</code></pre> <p>Load saga state by ID.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseModel | None</code> <p>The saga state if found, None otherwise.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def load(self, saga_id: str) -&gt; BaseModel | None:\n    \"\"\"Load saga state by ID.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n\n    Returns:\n        The saga state if found, None otherwise.\n    \"\"\"\n    doc = await self._collection.find_one({\"_id\": saga_id})\n\n    if doc is None:\n        return None\n\n    state_doc = SagaStateDocument.model_validate(doc)\n    return state_doc.to_value()\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore.save","title":"save  <code>async</code>","text":"<pre><code>save(saga_id: str, state: BaseModel) -&gt; None\n</code></pre> <p>Save saga state.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>state</code> <p>The state to save.</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def save(self, saga_id: str, state: BaseModel) -&gt; None:\n    \"\"\"Save saga state.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        state: The state to save.\n    \"\"\"\n    state_doc = SagaStateDocument.from_value(state)\n\n    await self._collection.update_one(\n        {\"_id\": saga_id},\n        {\n            \"$set\": {\n                \"state_type\": state_doc.state_type,\n                \"state\": state_doc.state,\n            },\n            \"$setOnInsert\": {\n                \"completed_steps\": [],\n            },\n        },\n        upsert=True,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(saga_id: str) -&gt; None\n</code></pre> <p>Delete saga state (cleanup after completion).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def delete(self, saga_id: str) -&gt; None:\n    \"\"\"Delete saga state (cleanup after completion).\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n    \"\"\"\n    await self._collection.delete_one({\"_id\": saga_id})\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore.mark_step_complete","title":"mark_step_complete  <code>async</code>","text":"<pre><code>mark_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Mark a saga step as completed (for idempotency).</p> <p>Uses MongoDB's $addToSet to atomically add the step name to the completed_steps array if it doesn't already exist.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to mark complete.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if newly marked, False if already complete.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def mark_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Mark a saga step as completed (for idempotency).\n\n    Uses MongoDB's $addToSet to atomically add the step name to the\n    completed_steps array if it doesn't already exist.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        step_name: Name of the step to mark complete.\n\n    Returns:\n        True if newly marked, False if already complete.\n    \"\"\"\n    # First check if already complete\n    if await self.is_step_complete(saga_id, step_name):\n        return False\n\n    # Add to completed steps (upsert in case saga doesn't exist yet)\n    result = await self._collection.update_one(\n        {\"_id\": saga_id},\n        {\"$addToSet\": {\"completed_steps\": step_name}},\n        upsert=True,\n    )\n\n    # If modified_count &gt; 0, the step was newly added\n    # If upserted_id is set, it was a new document\n    return result.modified_count &gt; 0 or result.upserted_id is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSagaStateStore.is_step_complete","title":"is_step_complete  <code>async</code>","text":"<pre><code>is_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Check if a saga step has been completed.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to check.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if step is complete, False otherwise.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def is_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Check if a saga step has been completed.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        step_name: Name of the step to check.\n\n    Returns:\n        True if step is complete, False otherwise.\n    \"\"\"\n    doc = await self._collection.find_one(\n        {\"_id\": saga_id, \"completed_steps\": step_name},\n        projection={\"_id\": 1},\n    )\n    return doc is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage","title":"MongoSnapshotStorage","text":"<pre><code>MongoSnapshotStorage(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>AggregateSnapshotStorageBackend</code></p> <p>MongoDB-backed aggregate snapshot storage.</p> <p>Supports two storage modes controlled by the <code>snapshot_mode</code> config:</p> <ul> <li>single: One snapshot per aggregate (overwrites on save).   Lower storage requirements, simpler queries.</li> <li>multiple: Multiple versions per aggregate (appends).   Supports historical lookups via <code>intended_version</code>.</li> </ul> Document schema <p>{     \"_id\": ObjectId (or aggregate_id in single mode),     \"aggregate_id\": \"UUID string\",     \"aggregate_type\": \"module.ClassName\",     \"version\": int,     \"snapshot\": { ... serialized aggregate ... } }</p> <p>Aggregate types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoSnapshotStorage ... )</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and snapshot_mode.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB snapshot storage.\n\n    Args:\n        config: MongoDB configuration providing connection and snapshot_mode.\n    \"\"\"\n    self._strategy: SnapshotStrategy = (\n        SingleSnapshotStrategy()\n        if config.snapshot_mode == \"single\"\n        else MultipleSnapshotStrategy()\n    )\n    self._collection = IndexedCollection(\n        config.snapshots,\n        indexes=self._strategy.indexes,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage--single-mode-default-one-snapshot-per-aggregate","title":"Single mode (default) - one snapshot per aggregate","text":"<p>config = MongoConfiguration(snapshot_mode=\"single\") storage = MongoSnapshotStorage(config)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage--multiple-mode-keeps-version-history","title":"Multiple mode - keeps version history","text":"<p>config = MongoConfiguration(snapshot_mode=\"multiple\") storage = MongoSnapshotStorage(config)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage--save-a-snapshot","title":"Save a snapshot","text":"<p>await storage.save_snapshot(my_aggregate)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage--load-latest-snapshot","title":"Load latest snapshot","text":"<p>aggregate = await storage.load_snapshot(aggregate_id)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage--load-snapshot-at-specific-version-multiple-mode","title":"Load snapshot at specific version (multiple mode)","text":"<p>aggregate = await storage.load_snapshot(aggregate_id, intended_version=5)</p>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage.save_snapshot","title":"save_snapshot  <code>async</code>","text":"<pre><code>save_snapshot(aggregate: Aggregate) -&gt; None\n</code></pre> <p>Save a snapshot of the aggregate.</p> <p>In single mode, overwrites any existing snapshot. In multiple mode, appends a new version.</p> PARAMETER DESCRIPTION <code>aggregate</code> <p>The aggregate to save.</p> <p> TYPE: <code>Aggregate</code> </p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def save_snapshot(self, aggregate: Aggregate) -&gt; None:\n    \"\"\"Save a snapshot of the aggregate.\n\n    In single mode, overwrites any existing snapshot.\n    In multiple mode, appends a new version.\n\n    Args:\n        aggregate: The aggregate to save.\n    \"\"\"\n    await self._strategy.save(self._collection, aggregate)\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage.load_snapshot","title":"load_snapshot  <code>async</code>","text":"<pre><code>load_snapshot(\n    aggregate_id: UUID, intended_version: int | None = None\n) -&gt; Aggregate | None\n</code></pre> <p>Load a snapshot of the aggregate.</p> In single mode <ul> <li>Returns the snapshot if intended_version is None or &gt;= stored version</li> <li>Returns None if intended_version &lt; stored version</li> </ul> In multiple mode <ul> <li>Returns the latest snapshot with version &lt;= intended_version</li> <li>Returns the latest snapshot if intended_version is None</li> </ul> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The ID of the aggregate to load.</p> <p> TYPE: <code>UUID</code> </p> <code>intended_version</code> <p>Optional maximum version to load.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Aggregate | None</code> <p>The aggregate snapshot if found and valid, None otherwise.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def load_snapshot(\n    self,\n    aggregate_id: UUID,\n    intended_version: int | None = None,\n) -&gt; Aggregate | None:\n    \"\"\"Load a snapshot of the aggregate.\n\n    In single mode:\n        - Returns the snapshot if intended_version is None or &gt;= stored version\n        - Returns None if intended_version &lt; stored version\n\n    In multiple mode:\n        - Returns the latest snapshot with version &lt;= intended_version\n        - Returns the latest snapshot if intended_version is None\n\n    Args:\n        aggregate_id: The ID of the aggregate to load.\n        intended_version: Optional maximum version to load.\n\n    Returns:\n        The aggregate snapshot if found and valid, None otherwise.\n    \"\"\"\n    doc = await self._strategy.load(self._collection, aggregate_id, intended_version)\n    if doc is None:\n        return None\n\n    snapshot_doc = SnapshotDocument.model_validate(doc)\n    return snapshot_doc.to_value()\n</code></pre>"},{"location":"reference/integrations/mongodb/#interlock.integrations.mongodb.MongoSnapshotStorage.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of a given type that have snapshots.</p> <p>Uses an aggregation pipeline to avoid the 16MB limit of distinct().</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class type to filter by.</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs with snapshots of this type.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def list_aggregate_ids_by_type(self, aggregate_type: type[Aggregate]) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of a given type that have snapshots.\n\n    Uses an aggregation pipeline to avoid the 16MB limit of distinct().\n\n    Args:\n        aggregate_type: The aggregate class type to filter by.\n\n    Returns:\n        List of aggregate IDs with snapshots of this type.\n    \"\"\"\n    aggregate_type_name = get_qualified_name(aggregate_type)\n\n    aggregate_ids: list[UUID] = []\n    async for value in self._collection.distinct_values(\n        \"aggregate_id\",\n        filter={\"aggregate_type\": aggregate_type_name},\n    ):\n        aggregate_ids.append(UUID(value))\n\n    return aggregate_ids\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/","title":"collection","text":""},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection","title":"collection","text":"<p>MongoDB collection wrapper with index management and query helpers.</p> <p>This module provides an IndexedCollection class that wraps a MongoDB AsyncCollection with automatic index management and helper methods for common query patterns.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexDirection","title":"IndexDirection","text":"<p>               Bases: <code>IntEnum</code></p> <p>Sort direction for MongoDB index fields.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexDirection.ASC","title":"ASC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ASC = ASCENDING\n</code></pre> <p>Ascending order (1).</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexDirection.DESC","title":"DESC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DESC = DESCENDING\n</code></pre> <p>Descending order (-1).</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec","title":"IndexSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification for a MongoDB index.</p> Example"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec--simple-index","title":"Simple index","text":"<p>IndexSpec(keys=[(\"aggregate_id\", IndexDirection.ASC)])</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec--compound-unique-index","title":"Compound unique index","text":"<p>IndexSpec( ...     keys=[ ...         (\"aggregate_id\", IndexDirection.ASC), ...         (\"version\", IndexDirection.DESC), ...     ], ...     unique=True, ... )</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec--ttl-index","title":"TTL index","text":"<p>IndexSpec( ...     keys=[(\"created_at\", IndexDirection.ASC)], ...     expire_after_seconds=86400, ... )</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys: list[tuple[str, IndexDirection]]\n</code></pre> <p>(field_name, direction) tuples.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec.unique","title":"unique  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>unique: bool = False\n</code></pre> <p>If True, enforce uniqueness.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec.expire_after_seconds","title":"expire_after_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expire_after_seconds: int | None = None\n</code></pre> <p>If set, create a TTL index.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexSpec.apply","title":"apply  <code>async</code>","text":"<pre><code>apply(collection: AsyncCollection[dict[str, Any]]) -&gt; None\n</code></pre> <p>Apply this index specification to a collection.</p> PARAMETER DESCRIPTION <code>collection</code> <p>The MongoDB collection to create the index on.</p> <p> TYPE: <code>AsyncCollection[dict[str, Any]]</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def apply(self, collection: AsyncCollection[dict[str, Any]]) -&gt; None:\n    \"\"\"Apply this index specification to a collection.\n\n    Args:\n        collection: The MongoDB collection to create the index on.\n    \"\"\"\n    kwargs: dict[str, Any] = {}\n    if self.unique:\n        kwargs[\"unique\"] = True\n    if self.expire_after_seconds is not None:\n        kwargs[\"expireAfterSeconds\"] = self.expire_after_seconds\n\n    await collection.create_index(self.keys, **kwargs)\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.UpdateResult","title":"UpdateResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of an update operation.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.UpdateResult.modified_count","title":"modified_count  <code>instance-attribute</code>","text":"<pre><code>modified_count: int\n</code></pre> <p>Number of documents modified.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.UpdateResult.upserted_id","title":"upserted_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>upserted_id: Any | None = None\n</code></pre> <p>ID of upserted document, if any.</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection","title":"IndexedCollection","text":"<pre><code>IndexedCollection(\n    collection: AsyncCollection[dict[str, Any]],\n    indexes: list[IndexSpec] | None = None,\n)\n</code></pre> <p>A MongoDB collection wrapper with automatic index management.</p> <p>IndexedCollection wraps an AsyncCollection and handles: - Lazy index creation (indexes created on first use) - Common query patterns (find one, find many, aggregation) - Insert/update/delete operations</p> <p>This class is used by storage backends to separate concerns: - The backend handles type conversion (via representations) - IndexedCollection handles MongoDB operations and indexing</p> Example <p>collection = IndexedCollection( ...     config.events, ...     indexes=[ ...         IndexSpec( ...             keys=[(\"aggregate_id\", 1), (\"sequence_number\", 1)], ...             unique=True, ...         ), ...         IndexSpec(keys=[(\"aggregate_id\", 1)]), ...     ] ... )</p> PARAMETER DESCRIPTION <code>collection</code> <p>The underlying MongoDB AsyncCollection.</p> <p> TYPE: <code>AsyncCollection[dict[str, Any]]</code> </p> <code>indexes</code> <p>List of index specifications to create.</p> <p> TYPE: <code>list[IndexSpec] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>def __init__(\n    self,\n    collection: AsyncCollection[dict[str, Any]],\n    indexes: list[\"IndexSpec\"] | None = None,\n) -&gt; None:\n    \"\"\"Initialize the indexed collection.\n\n    Args:\n        collection: The underlying MongoDB AsyncCollection.\n        indexes: List of index specifications to create.\n    \"\"\"\n    self._collection = collection\n    self._indexes = indexes or []\n    self._indexes_created = False\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection--indexes-are-created-on-first-operation","title":"Indexes are created on first operation","text":"<p>await collection.insert_one(doc) async for doc in collection.find({\"aggregate_id\": \"...\"}): ...     print(doc)</p>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.ensure_indexes","title":"ensure_indexes  <code>async</code>","text":"<pre><code>ensure_indexes() -&gt; None\n</code></pre> <p>Create indexes if not already created.</p> <p>Called automatically by other methods, but can be called explicitly for eager initialization.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def ensure_indexes(self) -&gt; None:\n    \"\"\"Create indexes if not already created.\n\n    Called automatically by other methods, but can be called\n    explicitly for eager initialization.\n    \"\"\"\n    if self._indexes_created:\n        return\n\n    for spec in self._indexes:\n        await spec.apply(self._collection)\n\n    self._indexes_created = True\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.find_one","title":"find_one  <code>async</code>","text":"<pre><code>find_one(\n    filter: dict[str, Any],\n    projection: dict[str, Any] | None = None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Find a single document matching the filter.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>projection</code> <p>Optional projection to limit returned fields.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The matching document or None.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def find_one(\n    self,\n    filter: dict[str, Any],\n    projection: dict[str, Any] | None = None,\n) -&gt; dict[str, Any] | None:\n    \"\"\"Find a single document matching the filter.\n\n    Args:\n        filter: MongoDB query filter.\n        projection: Optional projection to limit returned fields.\n\n    Returns:\n        The matching document or None.\n    \"\"\"\n    await self.ensure_indexes()\n    result: dict[str, Any] | None = await self._collection.find_one(\n        filter, projection=projection\n    )\n    return result\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.find","title":"find  <code>async</code>","text":"<pre><code>find(\n    filter: dict[str, Any],\n    sort: list[tuple[str, int]] | None = None,\n    limit: int | None = None,\n) -&gt; AsyncIterator[dict[str, Any]]\n</code></pre> <p>Find documents matching the filter.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>sort</code> <p>Optional list of (field, direction) tuples.</p> <p> TYPE: <code>list[tuple[str, int]] | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>Optional maximum number of documents to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> YIELDS DESCRIPTION <code>AsyncIterator[dict[str, Any]]</code> <p>Matching documents.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def find(\n    self,\n    filter: dict[str, Any],\n    sort: list[tuple[str, int]] | None = None,\n    limit: int | None = None,\n) -&gt; AsyncIterator[dict[str, Any]]:\n    \"\"\"Find documents matching the filter.\n\n    Args:\n        filter: MongoDB query filter.\n        sort: Optional list of (field, direction) tuples.\n        limit: Optional maximum number of documents to return.\n\n    Yields:\n        Matching documents.\n    \"\"\"\n    await self.ensure_indexes()\n\n    cursor = self._collection.find(filter)\n\n    if sort:\n        cursor = cursor.sort(sort)\n    if limit:\n        cursor = cursor.limit(limit)\n\n    async for doc in cursor:\n        yield doc\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.find_latest","title":"find_latest  <code>async</code>","text":"<pre><code>find_latest(\n    filter: dict[str, Any], sort_field: str\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Find the latest document by a sort field.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>sort_field</code> <p>Field to sort by descending.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The latest matching document or None.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def find_latest(\n    self,\n    filter: dict[str, Any],\n    sort_field: str,\n) -&gt; dict[str, Any] | None:\n    \"\"\"Find the latest document by a sort field.\n\n    Args:\n        filter: MongoDB query filter.\n        sort_field: Field to sort by descending.\n\n    Returns:\n        The latest matching document or None.\n    \"\"\"\n    await self.ensure_indexes()\n\n    cursor = self._collection.find(filter).sort(sort_field, DESCENDING).limit(1)\n\n    async for doc in cursor:\n        result: dict[str, Any] = doc\n        return result\n    return None\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.insert_one","title":"insert_one  <code>async</code>","text":"<pre><code>insert_one(document: dict[str, Any]) -&gt; None\n</code></pre> <p>Insert a single document.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to insert.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def insert_one(self, document: dict[str, Any]) -&gt; None:\n    \"\"\"Insert a single document.\n\n    Args:\n        document: The document to insert.\n    \"\"\"\n    await self.ensure_indexes()\n    await self._collection.insert_one(document)\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.insert_many","title":"insert_many  <code>async</code>","text":"<pre><code>insert_many(\n    documents: list[dict[str, Any]], ordered: bool = True\n) -&gt; None\n</code></pre> <p>Insert multiple documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of documents to insert.</p> <p> TYPE: <code>list[dict[str, Any]]</code> </p> <code>ordered</code> <p>If True, stop on first error. If False, continue.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def insert_many(\n    self,\n    documents: list[dict[str, Any]],\n    ordered: bool = True,\n) -&gt; None:\n    \"\"\"Insert multiple documents.\n\n    Args:\n        documents: List of documents to insert.\n        ordered: If True, stop on first error. If False, continue.\n    \"\"\"\n    await self.ensure_indexes()\n    await self._collection.insert_many(documents, ordered=ordered)\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.update_one","title":"update_one  <code>async</code>","text":"<pre><code>update_one(\n    filter: dict[str, Any],\n    update: dict[str, Any],\n    upsert: bool = False,\n) -&gt; UpdateResult\n</code></pre> <p>Update a single document.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>update</code> <p>Update operations (e.g., {\"$set\": {...}}).</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>upsert</code> <p>If True, insert if no matching document exists.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>UpdateResult</code> <p>UpdateResult with modified_count and upserted_id.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def update_one(\n    self,\n    filter: dict[str, Any],\n    update: dict[str, Any],\n    upsert: bool = False,\n) -&gt; \"UpdateResult\":\n    \"\"\"Update a single document.\n\n    Args:\n        filter: MongoDB query filter.\n        update: Update operations (e.g., {\"$set\": {...}}).\n        upsert: If True, insert if no matching document exists.\n\n    Returns:\n        UpdateResult with modified_count and upserted_id.\n    \"\"\"\n    await self.ensure_indexes()\n    result = await self._collection.update_one(filter, update, upsert=upsert)\n    return UpdateResult(\n        modified_count=result.modified_count,\n        upserted_id=result.upserted_id,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.replace_one","title":"replace_one  <code>async</code>","text":"<pre><code>replace_one(\n    filter: dict[str, Any],\n    replacement: dict[str, Any],\n    upsert: bool = False,\n) -&gt; None\n</code></pre> <p>Replace a single document.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>replacement</code> <p>The new document.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>upsert</code> <p>If True, insert if no matching document exists.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def replace_one(\n    self,\n    filter: dict[str, Any],\n    replacement: dict[str, Any],\n    upsert: bool = False,\n) -&gt; None:\n    \"\"\"Replace a single document.\n\n    Args:\n        filter: MongoDB query filter.\n        replacement: The new document.\n        upsert: If True, insert if no matching document exists.\n    \"\"\"\n    await self.ensure_indexes()\n    await self._collection.replace_one(filter, replacement, upsert=upsert)\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.delete_one","title":"delete_one  <code>async</code>","text":"<pre><code>delete_one(filter: dict[str, Any]) -&gt; None\n</code></pre> <p>Delete a single document.</p> PARAMETER DESCRIPTION <code>filter</code> <p>MongoDB query filter.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def delete_one(self, filter: dict[str, Any]) -&gt; None:\n    \"\"\"Delete a single document.\n\n    Args:\n        filter: MongoDB query filter.\n    \"\"\"\n    await self.ensure_indexes()\n    await self._collection.delete_one(filter)\n</code></pre>"},{"location":"reference/integrations/mongodb/collection/#interlock.integrations.mongodb.collection.IndexedCollection.distinct_values","title":"distinct_values  <code>async</code>","text":"<pre><code>distinct_values(\n    field: str, filter: dict[str, Any] | None = None\n) -&gt; AsyncIterator[Any]\n</code></pre> <p>Get distinct values for a field using aggregation pipeline.</p> <p>Uses aggregation instead of distinct() to avoid the 16MB size limit.</p> PARAMETER DESCRIPTION <code>field</code> <p>The field to get distinct values for.</p> <p> TYPE: <code>str</code> </p> <code>filter</code> <p>Optional query filter.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> YIELDS DESCRIPTION <code>AsyncIterator[Any]</code> <p>Distinct values.</p> Source code in <code>interlock/integrations/mongodb/collection.py</code> <pre><code>async def distinct_values(\n    self,\n    field: str,\n    filter: dict[str, Any] | None = None,\n) -&gt; AsyncIterator[Any]:\n    \"\"\"Get distinct values for a field using aggregation pipeline.\n\n    Uses aggregation instead of distinct() to avoid the 16MB size limit.\n\n    Args:\n        field: The field to get distinct values for.\n        filter: Optional query filter.\n\n    Yields:\n        Distinct values.\n    \"\"\"\n    await self.ensure_indexes()\n\n    pipeline: list[dict[str, Any]] = []\n    if filter:\n        pipeline.append({\"$match\": filter})\n    pipeline.append({\"$group\": {\"_id\": f\"${field}\"}})\n\n    cursor = await self._collection.aggregate(pipeline)\n    async for doc in cursor:\n        yield doc[\"_id\"]\n</code></pre>"},{"location":"reference/integrations/mongodb/config/","title":"config","text":""},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config","title":"config","text":"<p>MongoDB configuration using pydantic-settings.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration","title":"MongoConfiguration","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration and factory for MongoDB resources.</p> <p>Implements the HasLifecycle protocol for integration with Interlock's application lifecycle management. The client is closed on shutdown.</p> <p>All settings can be configured via environment variables with the INTERLOCK_ prefix. For example: - INTERLOCK_MONGO_URI=mongodb://localhost:27017 - INTERLOCK_MONGO_DATABASE=myapp - INTERLOCK_MONGO_EVENTS_COLLECTION=domain_events</p> <p>The configuration also acts as a factory, providing lazy-initialized properties for the MongoDB client, database, and collections.</p> ATTRIBUTE DESCRIPTION <code>uri</code> <p>MongoDB connection URI.</p> <p> TYPE: <code>str</code> </p> <code>database</code> <p>Database name to use.</p> <p> TYPE: <code>str</code> </p> <code>events_collection</code> <p>Collection name for event storage.</p> <p> TYPE: <code>str</code> </p> <code>saga_states_collection</code> <p>Collection name for saga state storage.</p> <p> TYPE: <code>str</code> </p> <code>snapshots_collection</code> <p>Collection name for aggregate snapshots.</p> <p> TYPE: <code>str</code> </p> <code>idempotency_keys_collection</code> <p>Collection name for idempotency keys.</p> <p> TYPE: <code>str</code> </p> <code>snapshot_mode</code> <p>Storage mode for snapshots - \"single\" overwrites, \"multiple\" keeps version history.</p> <p> TYPE: <code>Literal['single', 'multiple']</code> </p> <code>idempotency_ttl_seconds</code> <p>TTL for idempotency keys in seconds.</p> <p> TYPE: <code>int</code> </p> Example <p>config = MongoConfiguration()</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration--access-the-database","title":"Access the database","text":"<p>db = config.db</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration--access-collections","title":"Access collections","text":"<p>events = config.events sagas = config.saga_states</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration--with-applicationbuilder-lifecycle-managed-automatically","title":"With ApplicationBuilder (lifecycle managed automatically)","text":"<p>app = ( ...     ApplicationBuilder() ...     .register_dependency(MongoConfiguration) ...     .build() ... ) async with app:  # calls on_startup/on_shutdown ...     ...</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.client","title":"client  <code>cached</code> <code>property</code>","text":"<pre><code>client: AsyncMongoClient[dict[str, Any]]\n</code></pre> <p>Get the MongoDB async client.</p> <p>The client is lazily created and cached for reuse.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.db","title":"db  <code>cached</code> <code>property</code>","text":"<pre><code>db: AsyncDatabase[dict[str, Any]]\n</code></pre> <p>Get the MongoDB async database.</p> <p>Uses the database name from configuration.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.events","title":"events  <code>cached</code> <code>property</code>","text":"<pre><code>events: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the events collection.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.saga_states","title":"saga_states  <code>cached</code> <code>property</code>","text":"<pre><code>saga_states: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the saga states collection.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.snapshots","title":"snapshots  <code>cached</code> <code>property</code>","text":"<pre><code>snapshots: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the snapshots collection.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.idempotency_keys","title":"idempotency_keys  <code>cached</code> <code>property</code>","text":"<pre><code>idempotency_keys: AsyncCollection[dict[str, Any]]\n</code></pre> <p>Get the idempotency keys collection.</p>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.on_startup","title":"on_startup  <code>async</code>","text":"<pre><code>on_startup() -&gt; None\n</code></pre> <p>Called when the application starts.</p> <p>No-op for MongoDB - connections are established lazily.</p> Source code in <code>interlock/integrations/mongodb/config.py</code> <pre><code>async def on_startup(self) -&gt; None:\n    \"\"\"Called when the application starts.\n\n    No-op for MongoDB - connections are established lazily.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/mongodb/config/#interlock.integrations.mongodb.config.MongoConfiguration.on_shutdown","title":"on_shutdown  <code>async</code>","text":"<pre><code>on_shutdown() -&gt; None\n</code></pre> <p>Called when the application shuts down.</p> <p>Closes the MongoDB client connection if it was created.</p> Source code in <code>interlock/integrations/mongodb/config.py</code> <pre><code>async def on_shutdown(self) -&gt; None:\n    \"\"\"Called when the application shuts down.\n\n    Closes the MongoDB client connection if it was created.\n    \"\"\"\n    if \"client\" in self.__dict__:\n        self.client.close()\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/","title":"event_store","text":""},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store","title":"event_store","text":"<p>MongoDB implementation of EventStore.</p>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.EventDocument","title":"EventDocument","text":"<p>               Bases: <code>BaseModel</code></p> <p>Event document representation for MongoDB storage.</p>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.EventDocument.from_value","title":"from_value  <code>classmethod</code>","text":"<pre><code>from_value(event: Event[Any]) -&gt; EventDocument\n</code></pre> <p>Create a document from an Event.</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>@classmethod\ndef from_value(cls, event: Event[Any]) -&gt; \"EventDocument\":\n    \"\"\"Create a document from an Event.\"\"\"\n    return cls(\n        event_id=str(event.id),\n        aggregate_id=str(event.aggregate_id),\n        sequence_number=event.sequence_number,\n        timestamp=event.timestamp,\n        correlation_id=str(event.correlation_id) if event.correlation_id else None,\n        causation_id=str(event.causation_id) if event.causation_id else None,\n        event_type=get_qualified_name(type(event.data)),\n        data=event.data.model_dump(mode=\"json\"),\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.EventDocument.to_value","title":"to_value","text":"<pre><code>to_value() -&gt; Event[Any]\n</code></pre> <p>Convert the document back to an Event.</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>def to_value(self) -&gt; Event[Any]:\n    \"\"\"Convert the document back to an Event.\"\"\"\n    event_type = load_type(self.event_type)\n\n    return Event(\n        id=UUID(self.event_id),\n        aggregate_id=UUID(self.aggregate_id),\n        sequence_number=self.sequence_number,\n        timestamp=self.timestamp,\n        correlation_id=UUID(self.correlation_id) if self.correlation_id else None,\n        causation_id=UUID(self.causation_id) if self.causation_id else None,\n        data=event_type(**self.data),\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore","title":"MongoEventStore","text":"<pre><code>MongoEventStore(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>EventStore</code></p> <p>MongoDB-backed event store with optimistic concurrency control.</p> <p>Stores events in a MongoDB collection with a unique compound index on (aggregate_id, sequence_number) to enforce ordering and enable optimistic concurrency control.</p> <p>The store supports: - Atomic event persistence with version checking - Loading events by aggregate ID with optional version filtering - Rewriting events for schema migration (upcasting)</p> <p>Event data types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoEventStore ... )</p> <p>config = MongoConfiguration() store = MongoEventStore(config)</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and collections.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB event store.\n\n    Args:\n        config: MongoDB configuration providing connection and collections.\n    \"\"\"\n    self._collection = IndexedCollection(config.events, indexes=EVENTS_INDEXES)\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore--save-events-with-optimistic-concurrency","title":"Save events with optimistic concurrency","text":"<p>await store.save_events(events, expected_version=0)</p>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore--load-all-events-for-an-aggregate","title":"Load all events for an aggregate","text":"<p>events = await store.load_events(aggregate_id, min_version=0)</p>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore.save_events","title":"save_events  <code>async</code>","text":"<pre><code>save_events(\n    events: list[Event[Any]], expected_version: int\n) -&gt; None\n</code></pre> <p>Persist events to MongoDB with optimistic concurrency control.</p> <p>Events are inserted atomically. If any event's sequence number conflicts with an existing event, the entire operation fails with a ConcurrencyError.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of events to persist.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> <code>expected_version</code> <p>Expected aggregate version before these events.</p> <p> TYPE: <code>int</code> </p> RAISES DESCRIPTION <code>ConcurrencyError</code> <p>If expected_version doesn't match the current version (duplicate sequence number detected).</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def save_events(\n    self,\n    events: list[Event[Any]],\n    expected_version: int,\n) -&gt; None:\n    \"\"\"Persist events to MongoDB with optimistic concurrency control.\n\n    Events are inserted atomically. If any event's sequence number\n    conflicts with an existing event, the entire operation fails with\n    a ConcurrencyError.\n\n    Args:\n        events: List of events to persist.\n        expected_version: Expected aggregate version before these events.\n\n    Raises:\n        ConcurrencyError: If expected_version doesn't match the current\n            version (duplicate sequence number detected).\n    \"\"\"\n    if not events:\n        return\n\n    aggregate_id = events[0].aggregate_id\n\n    # Verify expected version by checking current max sequence number\n    latest = await self._collection.find_latest(\n        {\"aggregate_id\": str(aggregate_id)},\n        sort_field=\"sequence_number\",\n    )\n    current_version = latest[\"sequence_number\"] if latest else 0\n\n    if current_version != expected_version:\n        raise ConcurrencyError(f\"Expected version {expected_version}, got {current_version}\")\n\n    # Convert events to documents\n    documents = [EventDocument.from_value(event).model_dump(mode=\"json\") for event in events]\n\n    try:\n        await self._collection.insert_many(documents, ordered=True)\n    except DuplicateKeyError as e:\n        raise ConcurrencyError(\n            f\"Concurrent modification detected for aggregate {aggregate_id}\"\n        ) from e\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore.load_events","title":"load_events  <code>async</code>","text":"<pre><code>load_events(\n    aggregate_id: UUID, min_version: int\n) -&gt; list[Event[Any]]\n</code></pre> <p>Load events for an aggregate from MongoDB.</p> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The aggregate whose events to load.</p> <p> TYPE: <code>UUID</code> </p> <code>min_version</code> <p>Minimum sequence number (inclusive).</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Event[Any]]</code> <p>List of events in sequence order.</p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def load_events(\n    self,\n    aggregate_id: UUID,\n    min_version: int,\n) -&gt; list[Event[Any]]:\n    \"\"\"Load events for an aggregate from MongoDB.\n\n    Args:\n        aggregate_id: The aggregate whose events to load.\n        min_version: Minimum sequence number (inclusive).\n\n    Returns:\n        List of events in sequence order.\n    \"\"\"\n    cursor = self._collection.find(\n        {\n            \"aggregate_id\": str(aggregate_id),\n            \"sequence_number\": {\"$gte\": min_version},\n        },\n        sort=[(\"sequence_number\", IndexDirection.ASC)],\n    )\n\n    return [EventDocument.model_validate(doc).to_value() async for doc in cursor]\n</code></pre>"},{"location":"reference/integrations/mongodb/event_store/#interlock.integrations.mongodb.event_store.MongoEventStore.rewrite_events","title":"rewrite_events  <code>async</code>","text":"<pre><code>rewrite_events(events: list[Event[Any]]) -&gt; None\n</code></pre> <p>Rewrite existing events in place for schema migration.</p> <p>Updates events by matching (aggregate_id, sequence_number).</p> PARAMETER DESCRIPTION <code>events</code> <p>Events with updated data to write back.</p> <p> TYPE: <code>list[Event[Any]]</code> </p> Source code in <code>interlock/integrations/mongodb/event_store.py</code> <pre><code>async def rewrite_events(self, events: list[Event[Any]]) -&gt; None:\n    \"\"\"Rewrite existing events in place for schema migration.\n\n    Updates events by matching (aggregate_id, sequence_number).\n\n    Args:\n        events: Events with updated data to write back.\n    \"\"\"\n    for event in events:\n        doc = EventDocument.from_value(event).model_dump(mode=\"json\")\n        await self._collection.update_one(\n            {\n                \"aggregate_id\": str(event.aggregate_id),\n                \"sequence_number\": event.sequence_number,\n            },\n            {\"$set\": doc},\n        )\n</code></pre>"},{"location":"reference/integrations/mongodb/idempotency/","title":"idempotency","text":""},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency","title":"idempotency","text":"<p>MongoDB implementation of IdempotencyStorageBackend.</p>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.MongoIdempotencyStorage","title":"MongoIdempotencyStorage","text":"<pre><code>MongoIdempotencyStorage(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>IdempotencyStorageBackend</code></p> <p>MongoDB-backed idempotency storage with TTL-based cleanup.</p> <p>Stores idempotency keys in MongoDB with a TTL index for automatic expiration. This prevents the collection from growing indefinitely while ensuring commands are not processed twice within the TTL window.</p> Document schema <p>{     \"_id\": \"idempotency_key\",     \"created_at\": datetime }</p> <p>The TTL index on <code>created_at</code> automatically removes documents after the configured <code>idempotency_ttl_seconds</code> (default: 24 hours).</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoIdempotencyStorage ... )</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and TTL setting.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB idempotency storage.\n\n    Args:\n        config: MongoDB configuration providing connection and TTL setting.\n    \"\"\"\n    self._collection = IndexedCollection(\n        config.idempotency_keys,\n        indexes=[idempotency_ttl_index(config.idempotency_ttl_seconds)],\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.MongoIdempotencyStorage--configure-with-1-hour-ttl","title":"Configure with 1 hour TTL","text":"<p>config = MongoConfiguration(idempotency_ttl_seconds=3600) storage = MongoIdempotencyStorage(config)</p>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.MongoIdempotencyStorage--check-if-command-was-already-processed","title":"Check if command was already processed","text":"<p>if await storage.has_idempotency_key(\"cmd-123\"): ...     print(\"Already processed\") ... else: ...     # Process command... ...     await storage.store_idempotency_key(\"cmd-123\")</p>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.MongoIdempotencyStorage.store_idempotency_key","title":"store_idempotency_key  <code>async</code>","text":"<pre><code>store_idempotency_key(key: str) -&gt; None\n</code></pre> <p>Store an idempotency key as processed.</p> <p>If the key already exists, this is a no-op (idempotent).</p> PARAMETER DESCRIPTION <code>key</code> <p>The idempotency key to store.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>async def store_idempotency_key(self, key: str) -&gt; None:\n    \"\"\"Store an idempotency key as processed.\n\n    If the key already exists, this is a no-op (idempotent).\n\n    Args:\n        key: The idempotency key to store.\n    \"\"\"\n    with contextlib.suppress(DuplicateKeyError):\n        await self._collection.insert_one(\n            {\n                \"_id\": key,\n                \"created_at\": datetime.now(tz=timezone.utc),\n            }\n        )\n</code></pre>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.MongoIdempotencyStorage.has_idempotency_key","title":"has_idempotency_key  <code>async</code>","text":"<pre><code>has_idempotency_key(key: str) -&gt; bool\n</code></pre> <p>Check if an idempotency key has been processed.</p> PARAMETER DESCRIPTION <code>key</code> <p>The idempotency key to check.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the key exists (command was processed), False otherwise.</p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>async def has_idempotency_key(self, key: str) -&gt; bool:\n    \"\"\"Check if an idempotency key has been processed.\n\n    Args:\n        key: The idempotency key to check.\n\n    Returns:\n        True if the key exists (command was processed), False otherwise.\n    \"\"\"\n    doc = await self._collection.find_one({\"_id\": key}, projection={\"_id\": 1})\n    return doc is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/idempotency/#interlock.integrations.mongodb.idempotency.idempotency_ttl_index","title":"idempotency_ttl_index","text":"<pre><code>idempotency_ttl_index(ttl_seconds: int) -&gt; IndexSpec\n</code></pre> <p>Create a TTL index specification for idempotency keys.</p> PARAMETER DESCRIPTION <code>ttl_seconds</code> <p>Time-to-live in seconds for idempotency keys.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>IndexSpec</code> <p>IndexSpec configured with the TTL.</p> Source code in <code>interlock/integrations/mongodb/idempotency.py</code> <pre><code>def idempotency_ttl_index(ttl_seconds: int) -&gt; IndexSpec:\n    \"\"\"Create a TTL index specification for idempotency keys.\n\n    Args:\n        ttl_seconds: Time-to-live in seconds for idempotency keys.\n\n    Returns:\n        IndexSpec configured with the TTL.\n    \"\"\"\n    return IndexSpec(\n        keys=[(\"created_at\", IndexDirection.ASC)],\n        expire_after_seconds=ttl_seconds,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/","title":"saga_store","text":""},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store","title":"saga_store","text":"<p>MongoDB implementation of SagaStateStore.</p>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.SagaStateDocument","title":"SagaStateDocument","text":"<p>               Bases: <code>BaseModel</code></p> <p>Saga state document representation for MongoDB storage.</p>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.SagaStateDocument.from_value","title":"from_value  <code>classmethod</code>","text":"<pre><code>from_value(state: BaseModel) -&gt; SagaStateDocument\n</code></pre> <p>Create a document from saga state.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>@classmethod\ndef from_value(cls, state: BaseModel) -&gt; \"SagaStateDocument\":\n    \"\"\"Create a document from saga state.\"\"\"\n    return cls(\n        state_type=get_qualified_name(type(state)),\n        state=state.model_dump(mode=\"json\"),\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.SagaStateDocument.to_value","title":"to_value","text":"<pre><code>to_value() -&gt; BaseModel\n</code></pre> <p>Convert the document back to saga state.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>def to_value(self) -&gt; BaseModel:\n    \"\"\"Convert the document back to saga state.\"\"\"\n    state_type = load_type(self.state_type)\n    result: BaseModel = state_type(**self.state)\n    return result\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore","title":"MongoSagaStateStore","text":"<pre><code>MongoSagaStateStore(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>SagaStateStore</code></p> <p>MongoDB-backed saga state store.</p> <p>Stores saga state and completed step tracking in a MongoDB collection. Each saga instance is stored as a single document with its state and a list of completed steps for idempotency.</p> Document schema <p>{     \"_id\": \"saga_id\",     \"state_type\": \"module.ClassName\",     \"state\": { ... serialized state ... },     \"completed_steps\": [\"step1\", \"step2\", ...] }</p> <p>State types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoSagaStateStore ... )</p> <p>config = MongoConfiguration() store = MongoSagaStateStore(config)</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and collections.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB saga state store.\n\n    Args:\n        config: MongoDB configuration providing connection and collections.\n    \"\"\"\n    # No indexes needed - _id is indexed by default\n    self._collection = IndexedCollection(config.saga_states)\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore--save-saga-state","title":"Save saga state","text":"<p>await store.save(\"order-123\", CheckoutState(status=\"started\"))</p>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore--mark-steps-complete-for-idempotency","title":"Mark steps complete for idempotency","text":"<p>was_new = await store.mark_step_complete(\"order-123\", \"reserve_inventory\")</p>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore.load","title":"load  <code>async</code>","text":"<pre><code>load(saga_id: str) -&gt; BaseModel | None\n</code></pre> <p>Load saga state by ID.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseModel | None</code> <p>The saga state if found, None otherwise.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def load(self, saga_id: str) -&gt; BaseModel | None:\n    \"\"\"Load saga state by ID.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n\n    Returns:\n        The saga state if found, None otherwise.\n    \"\"\"\n    doc = await self._collection.find_one({\"_id\": saga_id})\n\n    if doc is None:\n        return None\n\n    state_doc = SagaStateDocument.model_validate(doc)\n    return state_doc.to_value()\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore.save","title":"save  <code>async</code>","text":"<pre><code>save(saga_id: str, state: BaseModel) -&gt; None\n</code></pre> <p>Save saga state.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>state</code> <p>The state to save.</p> <p> TYPE: <code>BaseModel</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def save(self, saga_id: str, state: BaseModel) -&gt; None:\n    \"\"\"Save saga state.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        state: The state to save.\n    \"\"\"\n    state_doc = SagaStateDocument.from_value(state)\n\n    await self._collection.update_one(\n        {\"_id\": saga_id},\n        {\n            \"$set\": {\n                \"state_type\": state_doc.state_type,\n                \"state\": state_doc.state,\n            },\n            \"$setOnInsert\": {\n                \"completed_steps\": [],\n            },\n        },\n        upsert=True,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(saga_id: str) -&gt; None\n</code></pre> <p>Delete saga state (cleanup after completion).</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def delete(self, saga_id: str) -&gt; None:\n    \"\"\"Delete saga state (cleanup after completion).\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n    \"\"\"\n    await self._collection.delete_one({\"_id\": saga_id})\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore.mark_step_complete","title":"mark_step_complete  <code>async</code>","text":"<pre><code>mark_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Mark a saga step as completed (for idempotency).</p> <p>Uses MongoDB's $addToSet to atomically add the step name to the completed_steps array if it doesn't already exist.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to mark complete.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if newly marked, False if already complete.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def mark_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Mark a saga step as completed (for idempotency).\n\n    Uses MongoDB's $addToSet to atomically add the step name to the\n    completed_steps array if it doesn't already exist.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        step_name: Name of the step to mark complete.\n\n    Returns:\n        True if newly marked, False if already complete.\n    \"\"\"\n    # First check if already complete\n    if await self.is_step_complete(saga_id, step_name):\n        return False\n\n    # Add to completed steps (upsert in case saga doesn't exist yet)\n    result = await self._collection.update_one(\n        {\"_id\": saga_id},\n        {\"$addToSet\": {\"completed_steps\": step_name}},\n        upsert=True,\n    )\n\n    # If modified_count &gt; 0, the step was newly added\n    # If upserted_id is set, it was a new document\n    return result.modified_count &gt; 0 or result.upserted_id is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/saga_store/#interlock.integrations.mongodb.saga_store.MongoSagaStateStore.is_step_complete","title":"is_step_complete  <code>async</code>","text":"<pre><code>is_step_complete(saga_id: str, step_name: str) -&gt; bool\n</code></pre> <p>Check if a saga step has been completed.</p> PARAMETER DESCRIPTION <code>saga_id</code> <p>Unique identifier for the saga instance.</p> <p> TYPE: <code>str</code> </p> <code>step_name</code> <p>Name of the step to check.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if step is complete, False otherwise.</p> Source code in <code>interlock/integrations/mongodb/saga_store.py</code> <pre><code>async def is_step_complete(self, saga_id: str, step_name: str) -&gt; bool:\n    \"\"\"Check if a saga step has been completed.\n\n    Args:\n        saga_id: Unique identifier for the saga instance.\n        step_name: Name of the step to check.\n\n    Returns:\n        True if step is complete, False otherwise.\n    \"\"\"\n    doc = await self._collection.find_one(\n        {\"_id\": saga_id, \"completed_steps\": step_name},\n        projection={\"_id\": 1},\n    )\n    return doc is not None\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/","title":"snapshot_storage","text":""},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage","title":"snapshot_storage","text":"<p>MongoDB implementation of AggregateSnapshotStorageBackend.</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotDocument","title":"SnapshotDocument","text":"<p>               Bases: <code>BaseModel</code></p> <p>Aggregate snapshot document representation for MongoDB storage.</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotDocument.from_value","title":"from_value  <code>classmethod</code>","text":"<pre><code>from_value(aggregate: Aggregate) -&gt; SnapshotDocument\n</code></pre> <p>Create a document from an aggregate.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>@classmethod\ndef from_value(cls, aggregate: Aggregate) -&gt; \"SnapshotDocument\":\n    \"\"\"Create a document from an aggregate.\"\"\"\n    return cls(\n        aggregate_id=str(aggregate.id),\n        aggregate_type=get_qualified_name(type(aggregate)),\n        version=aggregate.version,\n        snapshot=aggregate.model_dump(mode=\"json\"),\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotDocument.to_value","title":"to_value","text":"<pre><code>to_value() -&gt; Aggregate\n</code></pre> <p>Convert the document back to an aggregate.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>def to_value(self) -&gt; Aggregate:\n    \"\"\"Convert the document back to an aggregate.\"\"\"\n    aggregate_type = load_type(self.aggregate_type)\n    result: Aggregate = aggregate_type(**self.snapshot)\n    return result\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotStrategy","title":"SnapshotStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Strategy for snapshot storage behavior.</p> <p>Encapsulates the differences between single and multiple snapshot modes: - Index specifications - Save behavior (overwrite vs append) - Load behavior (simple lookup vs version filtering)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotStrategy.indexes","title":"indexes  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>indexes: list[IndexSpec]\n</code></pre> <p>Index specifications for this strategy.</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotStrategy.save","title":"save  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save(\n    collection: IndexedCollection, aggregate: Aggregate\n) -&gt; None\n</code></pre> <p>Save a snapshot using this strategy.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>@abstractmethod\nasync def save(\n    self,\n    collection: IndexedCollection,\n    aggregate: Aggregate,\n) -&gt; None:\n    \"\"\"Save a snapshot using this strategy.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SnapshotStrategy.load","title":"load  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load(\n    collection: IndexedCollection,\n    aggregate_id: UUID,\n    intended_version: int | None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Load a snapshot document using this strategy.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>@abstractmethod\nasync def load(\n    self,\n    collection: IndexedCollection,\n    aggregate_id: UUID,\n    intended_version: int | None,\n) -&gt; dict[str, Any] | None:\n    \"\"\"Load a snapshot document using this strategy.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.SingleSnapshotStrategy","title":"SingleSnapshotStrategy","text":"<p>               Bases: <code>SnapshotStrategy</code></p> <p>Strategy for single snapshot mode - one snapshot per aggregate.</p> <p>Overwrites the existing snapshot on save. More storage efficient but doesn't support historical version lookups.</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MultipleSnapshotStrategy","title":"MultipleSnapshotStrategy","text":"<p>               Bases: <code>SnapshotStrategy</code></p> <p>Strategy for multiple snapshot mode - keeps version history.</p> <p>Appends new snapshots without overwriting. Supports historical version lookups via intended_version parameter.</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage","title":"MongoSnapshotStorage","text":"<pre><code>MongoSnapshotStorage(config: MongoConfiguration)\n</code></pre> <p>               Bases: <code>AggregateSnapshotStorageBackend</code></p> <p>MongoDB-backed aggregate snapshot storage.</p> <p>Supports two storage modes controlled by the <code>snapshot_mode</code> config:</p> <ul> <li>single: One snapshot per aggregate (overwrites on save).   Lower storage requirements, simpler queries.</li> <li>multiple: Multiple versions per aggregate (appends).   Supports historical lookups via <code>intended_version</code>.</li> </ul> Document schema <p>{     \"_id\": ObjectId (or aggregate_id in single mode),     \"aggregate_id\": \"UUID string\",     \"aggregate_type\": \"module.ClassName\",     \"version\": int,     \"snapshot\": { ... serialized aggregate ... } }</p> <p>Aggregate types are automatically resolved via dynamic import from the stored qualified type name - no manual registration required.</p> Example <p>from interlock.integrations.mongodb import ( ...     MongoConfiguration, MongoSnapshotStorage ... )</p> PARAMETER DESCRIPTION <code>config</code> <p>MongoDB configuration providing connection and snapshot_mode.</p> <p> TYPE: <code>MongoConfiguration</code> </p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>def __init__(self, config: MongoConfiguration) -&gt; None:\n    \"\"\"Initialize the MongoDB snapshot storage.\n\n    Args:\n        config: MongoDB configuration providing connection and snapshot_mode.\n    \"\"\"\n    self._strategy: SnapshotStrategy = (\n        SingleSnapshotStrategy()\n        if config.snapshot_mode == \"single\"\n        else MultipleSnapshotStrategy()\n    )\n    self._collection = IndexedCollection(\n        config.snapshots,\n        indexes=self._strategy.indexes,\n    )\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage--single-mode-default-one-snapshot-per-aggregate","title":"Single mode (default) - one snapshot per aggregate","text":"<p>config = MongoConfiguration(snapshot_mode=\"single\") storage = MongoSnapshotStorage(config)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage--multiple-mode-keeps-version-history","title":"Multiple mode - keeps version history","text":"<p>config = MongoConfiguration(snapshot_mode=\"multiple\") storage = MongoSnapshotStorage(config)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage--save-a-snapshot","title":"Save a snapshot","text":"<p>await storage.save_snapshot(my_aggregate)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage--load-latest-snapshot","title":"Load latest snapshot","text":"<p>aggregate = await storage.load_snapshot(aggregate_id)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage--load-snapshot-at-specific-version-multiple-mode","title":"Load snapshot at specific version (multiple mode)","text":"<p>aggregate = await storage.load_snapshot(aggregate_id, intended_version=5)</p>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage.save_snapshot","title":"save_snapshot  <code>async</code>","text":"<pre><code>save_snapshot(aggregate: Aggregate) -&gt; None\n</code></pre> <p>Save a snapshot of the aggregate.</p> <p>In single mode, overwrites any existing snapshot. In multiple mode, appends a new version.</p> PARAMETER DESCRIPTION <code>aggregate</code> <p>The aggregate to save.</p> <p> TYPE: <code>Aggregate</code> </p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def save_snapshot(self, aggregate: Aggregate) -&gt; None:\n    \"\"\"Save a snapshot of the aggregate.\n\n    In single mode, overwrites any existing snapshot.\n    In multiple mode, appends a new version.\n\n    Args:\n        aggregate: The aggregate to save.\n    \"\"\"\n    await self._strategy.save(self._collection, aggregate)\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage.load_snapshot","title":"load_snapshot  <code>async</code>","text":"<pre><code>load_snapshot(\n    aggregate_id: UUID, intended_version: int | None = None\n) -&gt; Aggregate | None\n</code></pre> <p>Load a snapshot of the aggregate.</p> In single mode <ul> <li>Returns the snapshot if intended_version is None or &gt;= stored version</li> <li>Returns None if intended_version &lt; stored version</li> </ul> In multiple mode <ul> <li>Returns the latest snapshot with version &lt;= intended_version</li> <li>Returns the latest snapshot if intended_version is None</li> </ul> PARAMETER DESCRIPTION <code>aggregate_id</code> <p>The ID of the aggregate to load.</p> <p> TYPE: <code>UUID</code> </p> <code>intended_version</code> <p>Optional maximum version to load.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Aggregate | None</code> <p>The aggregate snapshot if found and valid, None otherwise.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def load_snapshot(\n    self,\n    aggregate_id: UUID,\n    intended_version: int | None = None,\n) -&gt; Aggregate | None:\n    \"\"\"Load a snapshot of the aggregate.\n\n    In single mode:\n        - Returns the snapshot if intended_version is None or &gt;= stored version\n        - Returns None if intended_version &lt; stored version\n\n    In multiple mode:\n        - Returns the latest snapshot with version &lt;= intended_version\n        - Returns the latest snapshot if intended_version is None\n\n    Args:\n        aggregate_id: The ID of the aggregate to load.\n        intended_version: Optional maximum version to load.\n\n    Returns:\n        The aggregate snapshot if found and valid, None otherwise.\n    \"\"\"\n    doc = await self._strategy.load(self._collection, aggregate_id, intended_version)\n    if doc is None:\n        return None\n\n    snapshot_doc = SnapshotDocument.model_validate(doc)\n    return snapshot_doc.to_value()\n</code></pre>"},{"location":"reference/integrations/mongodb/snapshot_storage/#interlock.integrations.mongodb.snapshot_storage.MongoSnapshotStorage.list_aggregate_ids_by_type","title":"list_aggregate_ids_by_type  <code>async</code>","text":"<pre><code>list_aggregate_ids_by_type(\n    aggregate_type: type[Aggregate],\n) -&gt; list[UUID]\n</code></pre> <p>Get all aggregate IDs of a given type that have snapshots.</p> <p>Uses an aggregation pipeline to avoid the 16MB limit of distinct().</p> PARAMETER DESCRIPTION <code>aggregate_type</code> <p>The aggregate class type to filter by.</p> <p> TYPE: <code>type[Aggregate]</code> </p> RETURNS DESCRIPTION <code>list[UUID]</code> <p>List of aggregate IDs with snapshots of this type.</p> Source code in <code>interlock/integrations/mongodb/snapshot_storage.py</code> <pre><code>async def list_aggregate_ids_by_type(self, aggregate_type: type[Aggregate]) -&gt; list[UUID]:\n    \"\"\"Get all aggregate IDs of a given type that have snapshots.\n\n    Uses an aggregation pipeline to avoid the 16MB limit of distinct().\n\n    Args:\n        aggregate_type: The aggregate class type to filter by.\n\n    Returns:\n        List of aggregate IDs with snapshots of this type.\n    \"\"\"\n    aggregate_type_name = get_qualified_name(aggregate_type)\n\n    aggregate_ids: list[UUID] = []\n    async for value in self._collection.distinct_values(\n        \"aggregate_id\",\n        filter={\"aggregate_type\": aggregate_type_name},\n    ):\n        aggregate_ids.append(UUID(value))\n\n    return aggregate_ids\n</code></pre>"},{"location":"reference/integrations/mongodb/type_loader/","title":"type_loader","text":""},{"location":"reference/integrations/mongodb/type_loader/#interlock.integrations.mongodb.type_loader","title":"type_loader","text":"<p>Type loading utilities for MongoDB documents.</p> <p>Provides utilities for dynamically loading Python types from their fully qualified names, used when deserializing documents back to domain objects.</p>"},{"location":"reference/integrations/mongodb/type_loader/#interlock.integrations.mongodb.type_loader.get_qualified_name","title":"get_qualified_name","text":"<pre><code>get_qualified_name(cls: type) -&gt; str\n</code></pre> <p>Get the fully qualified name of a class.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to get the qualified name for.</p> <p> TYPE: <code>type</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The fully qualified name (module.ClassName).</p> Example <p>from interlock.domain import Event get_qualified_name(Event) 'interlock.domain.event.Event'</p> Source code in <code>interlock/integrations/mongodb/type_loader.py</code> <pre><code>def get_qualified_name(cls: type) -&gt; str:\n    \"\"\"Get the fully qualified name of a class.\n\n    Args:\n        cls: The class to get the qualified name for.\n\n    Returns:\n        The fully qualified name (module.ClassName).\n\n    Example:\n        &gt;&gt;&gt; from interlock.domain import Event\n        &gt;&gt;&gt; get_qualified_name(Event)\n        'interlock.domain.event.Event'\n    \"\"\"\n    return f\"{cls.__module__}.{cls.__qualname__}\"\n</code></pre>"},{"location":"reference/integrations/mongodb/type_loader/#interlock.integrations.mongodb.type_loader.load_type","title":"load_type  <code>cached</code>","text":"<pre><code>load_type(qualified_name: str) -&gt; type[Any]\n</code></pre> <p>Load a type from its fully qualified name.</p> <p>Uses Python's import machinery to dynamically load the type. Results are cached for performance.</p> PARAMETER DESCRIPTION <code>qualified_name</code> <p>The fully qualified name (module.ClassName).</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>type[Any]</code> <p>The loaded type.</p> RAISES DESCRIPTION <code>ImportError</code> <p>If the module cannot be imported or class doesn't exist.</p> Example <p>cls = load_type(\"interlock.domain.event.Event\") cls.name 'Event'</p> Source code in <code>interlock/integrations/mongodb/type_loader.py</code> <pre><code>@lru_cache(maxsize=256)\ndef load_type(qualified_name: str) -&gt; type[Any]:\n    \"\"\"Load a type from its fully qualified name.\n\n    Uses Python's import machinery to dynamically load the type.\n    Results are cached for performance.\n\n    Args:\n        qualified_name: The fully qualified name (module.ClassName).\n\n    Returns:\n        The loaded type.\n\n    Raises:\n        ImportError: If the module cannot be imported or class doesn't exist.\n\n    Example:\n        &gt;&gt;&gt; cls = load_type(\"interlock.domain.event.Event\")\n        &gt;&gt;&gt; cls.__name__\n        'Event'\n    \"\"\"\n    module_path, _, class_name = qualified_name.rpartition(\".\")\n    if not module_path:\n        raise ImportError(f\"Invalid qualified name: {qualified_name}\")\n\n    module = importlib.import_module(module_path)\n    try:\n        return getattr(module, class_name)  # type: ignore[no-any-return]\n    except AttributeError:\n        raise ImportError(f\"Module '{module_path}' has no attribute '{class_name}'\") from None\n</code></pre>"},{"location":"reference/testing/","title":"testing","text":""},{"location":"reference/testing/#interlock.testing","title":"testing","text":""},{"location":"reference/testing/#interlock.testing.AggregateScenario","title":"AggregateScenario","text":"<pre><code>AggregateScenario(\n    aggregate: type[A], aggregate_id: UUID | None = None\n)\n</code></pre> <p>               Bases: <code>Scenario[A]</code>, <code>Generic[A]</code></p> <p>A scenario for testing an aggregate.</p> <p>This scenario allows you to test an aggregate by: - Given a list of events that have already been emitted - When a list of commands are executed - Then a list of expectations are met</p> <p>The scenario will execute the commands and assert the expectations. If the expectations are not met, an AssertionError will be raised.</p> Source code in <code>interlock/testing/aggregate_scenario.py</code> <pre><code>def __init__(self, aggregate: type[A], aggregate_id: UUID | None = None):\n    super().__init__()\n    self.aggregate_id = aggregate_id or uuid4()\n    self.aggregate = aggregate(id=self.aggregate_id)\n    self.commands: list[Command] = []\n</code></pre>"},{"location":"reference/testing/#interlock.testing.ProcessorScenario","title":"ProcessorScenario","text":"<pre><code>ProcessorScenario(processor: TProcessor)\n</code></pre> <p>               Bases: <code>Scenario[Any]</code>, <code>Generic[TProcessor]</code></p> <p>A scenario for testing an event processor.</p> <p>This scenario allows you to test an event processor by: - Given a list of events to process - Then a list of expectations are met (state assertions)</p> <p>Use via Application.processor_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.processor_scenario(AccountBalanceProjection) as scenario:\n...     scenario.given(MoneyDeposited(...))\n...     scenario.should_have_state(lambda p: p.repo.get_balance(id) == 100)\n</code></pre> <p>Or instantiate directly for simple processors:</p> <pre><code>&gt;&gt;&gt; async with ProcessorScenario(SimpleProcessor()) as scenario:\n...     scenario.given(SomeEvent()).should_have_state(lambda p: p.count == 1)\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, processor: TProcessor):\n    super().__init__()\n    self.processor = processor\n</code></pre>"},{"location":"reference/testing/#interlock.testing.ProjectionScenario","title":"ProjectionScenario","text":"<pre><code>ProjectionScenario(projection: TProjection)\n</code></pre> <p>               Bases: <code>Scenario[Any]</code>, <code>Generic[TProjection]</code></p> <p>A scenario for testing a projection.</p> <p>Projections combine event handling with query handling. This scenario allows you to test both capabilities: - Given: Process events to build read model state - When: Execute queries against the projection - Then: Assert on query results or projection state</p> <p>Use via Application.projection_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.projection_scenario(UserProjection) as scenario:\n...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n...     result = await scenario.when(GetUserById(user_id=id))\n...     assert result.name == \"Alice\"\n</code></pre> <p>Or instantiate directly:</p> <pre><code>&gt;&gt;&gt; async with ProjectionScenario(UserProjection()) as scenario:\n...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n...     scenario.should_have_state(lambda p: len(p.users) == 1)\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, projection: TProjection):\n    super().__init__()\n    self.projection = projection\n    self.query_results: list[Any] = []\n</code></pre>"},{"location":"reference/testing/#interlock.testing.ProjectionScenario.when","title":"when  <code>async</code>","text":"<pre><code>when(query: Query[TResponse]) -&gt; TResponse\n</code></pre> <p>Execute a query against the projection.</p> <p>This method processes any pending events first, then executes the query and returns the result.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to execute.</p> <p> TYPE: <code>Query[TResponse]</code> </p> RETURNS DESCRIPTION <code>TResponse</code> <p>The query result.</p> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>async def when(self, query: Query[TResponse]) -&gt; TResponse:\n    \"\"\"Execute a query against the projection.\n\n    This method processes any pending events first, then executes\n    the query and returns the result.\n\n    Args:\n        query: The query to execute.\n\n    Returns:\n        The query result.\n    \"\"\"\n    # Process any pending events first\n    await self.perform_actions()\n    self.event_payloads = []  # Clear processed events\n\n    # Execute the query\n    result = await self.projection.query(query)\n    self.query_results.append(result)\n    return result\n</code></pre>"},{"location":"reference/testing/#interlock.testing.ProjectionScenario.should_have_state","title":"should_have_state","text":"<pre><code>should_have_state(\n    predicate: Callable[[TProjection], bool],\n) -&gt; ProjectionScenario[TProjection]\n</code></pre> <p>Assert that the projection state matches a predicate.</p> PARAMETER DESCRIPTION <code>predicate</code> <p>A function that receives the projection and returns True if the state is valid.</p> <p> TYPE: <code>Callable[[TProjection], bool]</code> </p> RETURNS DESCRIPTION <code>ProjectionScenario[TProjection]</code> <p>Self for chaining.</p> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def should_have_state(\n    self, predicate: Callable[[TProjection], bool]\n) -&gt; \"ProjectionScenario[TProjection]\":\n    \"\"\"Assert that the projection state matches a predicate.\n\n    Args:\n        predicate: A function that receives the projection and returns\n            True if the state is valid.\n\n    Returns:\n        Self for chaining.\n    \"\"\"\n    self.expectations.append(\n        StateMatches(PROJECTION_STATE_KEY, cast(\"NullablePredicate\", predicate))\n    )\n    return self\n</code></pre>"},{"location":"reference/testing/#interlock.testing.SagaScenario","title":"SagaScenario","text":"<pre><code>SagaScenario(saga: TSaga)\n</code></pre> <p>               Bases: <code>Scenario[TSagaState]</code>, <code>Generic[TSaga, TSagaState]</code></p> <p>A scenario for testing a saga.</p> <p>This scenario allows you to test a saga by: - Given a list of events to process - Then a list of expectations are met (state assertions)</p> <p>Use via Application.saga_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.saga_scenario(OrderSaga) as scenario:\n...     scenario.given(OrderPlaced(order_id=\"123\"))\n...     scenario.should_have_state(\"123\", lambda s: s.status == \"placed\")\n</code></pre> <p>Or instantiate directly:</p> <pre><code>&gt;&gt;&gt; saga = OrderSaga(SagaStateStore.in_memory())\n&gt;&gt;&gt; async with SagaScenario(saga) as scenario:\n...     scenario.given(OrderPlaced(order_id=\"123\"))\n...     scenario.should_have_state(\"123\", lambda s: s.status == \"placed\")\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, saga: TSaga):\n    super().__init__()\n    self.saga = saga\n    self.state_store = saga.state_store\n</code></pre>"},{"location":"reference/testing/aggregate_scenario/","title":"aggregate_scenario","text":""},{"location":"reference/testing/aggregate_scenario/#interlock.testing.aggregate_scenario","title":"aggregate_scenario","text":""},{"location":"reference/testing/aggregate_scenario/#interlock.testing.aggregate_scenario.AggregateScenario","title":"AggregateScenario","text":"<pre><code>AggregateScenario(\n    aggregate: type[A], aggregate_id: UUID | None = None\n)\n</code></pre> <p>               Bases: <code>Scenario[A]</code>, <code>Generic[A]</code></p> <p>A scenario for testing an aggregate.</p> <p>This scenario allows you to test an aggregate by: - Given a list of events that have already been emitted - When a list of commands are executed - Then a list of expectations are met</p> <p>The scenario will execute the commands and assert the expectations. If the expectations are not met, an AssertionError will be raised.</p> Source code in <code>interlock/testing/aggregate_scenario.py</code> <pre><code>def __init__(self, aggregate: type[A], aggregate_id: UUID | None = None):\n    super().__init__()\n    self.aggregate_id = aggregate_id or uuid4()\n    self.aggregate = aggregate(id=self.aggregate_id)\n    self.commands: list[Command] = []\n</code></pre>"},{"location":"reference/testing/core/","title":"core","text":""},{"location":"reference/testing/core/#interlock.testing.core","title":"core","text":""},{"location":"reference/testing/core/#interlock.testing.core.Result","title":"Result","text":"<pre><code>Result(\n    events: list[BaseModel],\n    errors: list[Exception],\n    states: Mapping[Any, TState | None] | None = None,\n)\n</code></pre> <p>               Bases: <code>Generic[TState]</code></p> Source code in <code>interlock/testing/core.py</code> <pre><code>def __init__(\n    self,\n    events: list[BaseModel],\n    errors: list[Exception],\n    states: Mapping[Any, TState | None] | None = None,\n):\n    self.events = events\n    self.errors = errors\n    self.states = states if states is not None else {}\n</code></pre>"},{"location":"reference/testing/processor_scenario/","title":"processor_scenario","text":""},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario","title":"processor_scenario","text":""},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario.ProcessorScenario","title":"ProcessorScenario","text":"<pre><code>ProcessorScenario(processor: TProcessor)\n</code></pre> <p>               Bases: <code>Scenario[Any]</code>, <code>Generic[TProcessor]</code></p> <p>A scenario for testing an event processor.</p> <p>This scenario allows you to test an event processor by: - Given a list of events to process - Then a list of expectations are met (state assertions)</p> <p>Use via Application.processor_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.processor_scenario(AccountBalanceProjection) as scenario:\n...     scenario.given(MoneyDeposited(...))\n...     scenario.should_have_state(lambda p: p.repo.get_balance(id) == 100)\n</code></pre> <p>Or instantiate directly for simple processors:</p> <pre><code>&gt;&gt;&gt; async with ProcessorScenario(SimpleProcessor()) as scenario:\n...     scenario.given(SomeEvent()).should_have_state(lambda p: p.count == 1)\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, processor: TProcessor):\n    super().__init__()\n    self.processor = processor\n</code></pre>"},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario.SagaScenario","title":"SagaScenario","text":"<pre><code>SagaScenario(saga: TSaga)\n</code></pre> <p>               Bases: <code>Scenario[TSagaState]</code>, <code>Generic[TSaga, TSagaState]</code></p> <p>A scenario for testing a saga.</p> <p>This scenario allows you to test a saga by: - Given a list of events to process - Then a list of expectations are met (state assertions)</p> <p>Use via Application.saga_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.saga_scenario(OrderSaga) as scenario:\n...     scenario.given(OrderPlaced(order_id=\"123\"))\n...     scenario.should_have_state(\"123\", lambda s: s.status == \"placed\")\n</code></pre> <p>Or instantiate directly:</p> <pre><code>&gt;&gt;&gt; saga = OrderSaga(SagaStateStore.in_memory())\n&gt;&gt;&gt; async with SagaScenario(saga) as scenario:\n...     scenario.given(OrderPlaced(order_id=\"123\"))\n...     scenario.should_have_state(\"123\", lambda s: s.status == \"placed\")\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, saga: TSaga):\n    super().__init__()\n    self.saga = saga\n    self.state_store = saga.state_store\n</code></pre>"},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario.ProjectionScenario","title":"ProjectionScenario","text":"<pre><code>ProjectionScenario(projection: TProjection)\n</code></pre> <p>               Bases: <code>Scenario[Any]</code>, <code>Generic[TProjection]</code></p> <p>A scenario for testing a projection.</p> <p>Projections combine event handling with query handling. This scenario allows you to test both capabilities: - Given: Process events to build read model state - When: Execute queries against the projection - Then: Assert on query results or projection state</p> <p>Use via Application.projection_scenario() for automatic DI:</p> <pre><code>&gt;&gt;&gt; async with app.projection_scenario(UserProjection) as scenario:\n...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n...     result = await scenario.when(GetUserById(user_id=id))\n...     assert result.name == \"Alice\"\n</code></pre> <p>Or instantiate directly:</p> <pre><code>&gt;&gt;&gt; async with ProjectionScenario(UserProjection()) as scenario:\n...     scenario.given(UserCreated(user_id=id, name=\"Alice\"))\n...     scenario.should_have_state(lambda p: len(p.users) == 1)\n</code></pre> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def __init__(self, projection: TProjection):\n    super().__init__()\n    self.projection = projection\n    self.query_results: list[Any] = []\n</code></pre>"},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario.ProjectionScenario.when","title":"when  <code>async</code>","text":"<pre><code>when(query: Query[TResponse]) -&gt; TResponse\n</code></pre> <p>Execute a query against the projection.</p> <p>This method processes any pending events first, then executes the query and returns the result.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to execute.</p> <p> TYPE: <code>Query[TResponse]</code> </p> RETURNS DESCRIPTION <code>TResponse</code> <p>The query result.</p> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>async def when(self, query: Query[TResponse]) -&gt; TResponse:\n    \"\"\"Execute a query against the projection.\n\n    This method processes any pending events first, then executes\n    the query and returns the result.\n\n    Args:\n        query: The query to execute.\n\n    Returns:\n        The query result.\n    \"\"\"\n    # Process any pending events first\n    await self.perform_actions()\n    self.event_payloads = []  # Clear processed events\n\n    # Execute the query\n    result = await self.projection.query(query)\n    self.query_results.append(result)\n    return result\n</code></pre>"},{"location":"reference/testing/processor_scenario/#interlock.testing.processor_scenario.ProjectionScenario.should_have_state","title":"should_have_state","text":"<pre><code>should_have_state(\n    predicate: Callable[[TProjection], bool],\n) -&gt; ProjectionScenario[TProjection]\n</code></pre> <p>Assert that the projection state matches a predicate.</p> PARAMETER DESCRIPTION <code>predicate</code> <p>A function that receives the projection and returns True if the state is valid.</p> <p> TYPE: <code>Callable[[TProjection], bool]</code> </p> RETURNS DESCRIPTION <code>ProjectionScenario[TProjection]</code> <p>Self for chaining.</p> Source code in <code>interlock/testing/processor_scenario.py</code> <pre><code>def should_have_state(\n    self, predicate: Callable[[TProjection], bool]\n) -&gt; \"ProjectionScenario[TProjection]\":\n    \"\"\"Assert that the projection state matches a predicate.\n\n    Args:\n        predicate: A function that receives the projection and returns\n            True if the state is valid.\n\n    Returns:\n        Self for chaining.\n    \"\"\"\n    self.expectations.append(\n        StateMatches(PROJECTION_STATE_KEY, cast(\"NullablePredicate\", predicate))\n    )\n    return self\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":"<p>Welcome to the Interlock tutorial! This step-by-step guide will teach you how to build event-sourced applications using CQRS patterns.</p>"},{"location":"tutorial/#what-youll-build","title":"What You'll Build","text":"<p>Throughout this tutorial, you'll build a Bank Account application that demonstrates:</p> <ul> <li>Creating and managing aggregates</li> <li>Handling commands and emitting events</li> <li>Processing events to build read models</li> <li>Querying read models with typed queries</li> <li>Using middleware for cross-cutting concerns</li> <li>Structuring your application with conventions</li> </ul>"},{"location":"tutorial/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Basic understanding of async/await</li> <li>Familiarity with Pydantic is helpful but not required</li> </ul>"},{"location":"tutorial/#tutorial-sections","title":"Tutorial Sections","text":"Section Description Your First Aggregate Create a domain aggregate that manages state Commands &amp; Handlers Define commands and handle them in aggregates Events &amp; Sourcing Emit events and rebuild state from event history Event Processors React to events and build read models Queries &amp; Projections Serve typed queries from read models Middleware Add logging, caching, and more Structuring Your Application Organize your code with conventions Putting It Together Build a complete application"},{"location":"tutorial/#getting-help","title":"Getting Help","text":"<p>If you get stuck:</p> <ul> <li>Check the Concepts section for deeper explanations</li> <li>Browse the API Reference for detailed documentation</li> <li>Open an issue on GitHub</li> </ul> <p>Ready? Let's start with Your First Aggregate!</p>"},{"location":"tutorial/01-your-first-aggregate/","title":"Your First Aggregate","text":"<p>In this section, you'll create your first aggregate\u2014the core building block of event-sourced applications.</p>"},{"location":"tutorial/01-your-first-aggregate/#what-is-an-aggregate","title":"What is an Aggregate?","text":"<p>An aggregate is a cluster of domain objects that are treated as a single unit for data changes.  Aggregates are the core building blocks in Domain-Driven Design and Event Sourcing. They:</p> <ul> <li>Define consistency boundaries</li> <li>Encapsulate business rules</li> <li>Emit events when state changes</li> <li>Are loaded and saved as a unit</li> </ul>"},{"location":"tutorial/01-your-first-aggregate/#creating-an-aggregate","title":"Creating an Aggregate","text":"<p>The <code>Aggregate</code> base class is a actually a Pydantic model. This means it has all the features of a Pydantic model, including:</p> <ul> <li>Validation</li> <li>Serialization</li> <li>Deserialization</li> <li>Documentation</li> <li>Type hints</li> </ul> <p>For now, we can focus on modeling the state of the aggregate. Lets start by defining some expected behavior of the aggregate.</p> <pre><code># tests/aggregates/test_bank_account.py\ndef test_has_sufficient_balance_is_sufficient():\n    balance = BankAccount(balance=100)\n    assert balance.has_sufficient_balance(50)\n\ndef test_has_sufficient_balance_is_not_sufficient():\n    balance = BankAccount(balance=100)\n    assert not balance.has_sufficient_balance(150)\n</code></pre> <p>And now lets create a simple aggregate for a bank account:</p> <pre><code># my_app/aggregates/bank_account.py\nfrom interlock.domain import Aggregate\n\nclass BankAccount(Aggregate):\n    balance: int = 0\n    is_active: bool = False\n\n    def has_sufficient_balance(self, amount: int) -&gt; bool:\n        return self.balance &gt;= amount\n</code></pre> <p>Aggregates need starting state</p> <p>Aggregates need a starting state to be created. When creating new aggregates, you need to provide a starting state.  In effect, this means that the aggregate needs to be constructable without passing an argument to the constructor.</p> <p>In this case, we define a couple of fields that represent the state of the aggregate.  Often, however, you will want to define a collection of more complicated objects that represent the state of the aggregate. That can be done by combining multiple Pydantic models into a single aggregate. For example, lets factor out the balance into a seperate model with a bit more complexity:</p> <pre><code>from pydantic import BaseModel, Field\nfrom interlock.domain import Aggregate\n\nclass Balance(BaseModel):\n    amount: int = 0\n    currency: str = \"USD\"\n\n    def is_atleast(self, amount: int) -&gt; bool:\n        return self.amount &gt;= amount\n\nclass BankAccount(Aggregate):\n    balance: Balance = Field(default_factory=Balance)\n    is_active: bool = True\n\n    def has_sufficient_balance(self, amount: int) -&gt; bool:\n        return self.balance.is_atleast(amount)\n</code></pre> <p>Keep Aggregates Small</p> <p>An aggregate should be the smallest possible unit that maintains consistency.  Large aggregates lead to contention and performance issues.</p>"},{"location":"tutorial/01-your-first-aggregate/#next-steps","title":"Next Steps","text":"<p>Obviously, this aggregate isn't very useful yet. Let's add commands to trigger state changes to make it more useful.</p>"},{"location":"tutorial/02-commands-and-handlers/","title":"Commands &amp; Handlers","text":"<p>Commands represent intent to change the system.  In this section, you'll learn how to define commands and handle them in your aggregates.</p>"},{"location":"tutorial/02-commands-and-handlers/#what-is-a-command","title":"What is a Command?","text":"<p>A command is a message that expresses an intent to perform an action. Commands are:</p> <ul> <li>Conventionally named in imperative form (e.g., <code>CreateAccount</code>, <code>DepositMoney</code>)</li> <li>Handled by exactly one aggregate</li> <li>Generally contain no logic themselves (Data Class style)</li> </ul>"},{"location":"tutorial/02-commands-and-handlers/#defining-commands","title":"Defining Commands","text":"<p>Commands, like aggregates, are pydantic models. </p> <pre><code>from interlock.domain import Command\n\nclass CreateAccount(Command):\n    owner_name: str\n\nclass DepositMoney(Command):\n    amount: int\n</code></pre> <p>When inheriting from the <code>Command</code> base class, you will automatically inherit an <code>aggregate_id</code> field. to identify the aggregate that should handle the command.  This is used by the framework to route the command to the appropriate aggregate.  There are other fields that are automatically inherited from the <code>Command</code> base class that you can use to add more metadata to the command. We'll cover these in a later section.</p>"},{"location":"tutorial/02-commands-and-handlers/#writing-tests-for-our-command-handling","title":"Writing Tests for Our Command Handling","text":"<pre><code># tests/aggregates/test_bank_account.py\ndef test_deposit_money_increases_balance():\n    account = BankAccount()\n    account.handle(DepositMoney(aggregate_id=account.id, amount=50))\n    assert account.balance.amount == 50\n</code></pre> <p>In this test, we're using the <code>handle</code> method to test the execution of a command. The <code>handle</code> method routes the command to the appropriate handler method via type annotations.  This means that if the command is not handled by the aggregate, the test will fail.</p> <p>Commands require an aggregate_id</p> <p>Every command needs an <code>aggregate_id</code> to identify which aggregate instance handles it. In tests, we use <code>account.id</code> to get the aggregate's auto-generated ID.</p>"},{"location":"tutorial/02-commands-and-handlers/#handling-commands-in-aggregates","title":"Handling Commands in Aggregates","text":"<p>Now that we have our test, lets crack open the aggregate and add the command handler.</p> <pre><code>from pydantic import BaseModel, Field \nfrom interlock.domain import Aggregate\nfrom interlock.routing import handles_command  # (1)!\n\nclass Balance(BaseModel):\n    amount: int = 0\n    currency: str = \"USD\"\n\n    def increase(self, amount: int) -&gt; None:  # (2)!\n        self.amount += amount\n\n    def is_atleast(self, amount: int) -&gt; bool:\n        return self.amount &gt;= amount\n\nclass BankAccount(Aggregate):\n    balance: Balance = Field(default_factory=Balance)\n    is_active: bool = True\n\n    @handles_command  # (3)!\n    def handle_deposit_money(self, command: DepositMoney) -&gt; None:\n        self.balance.increase(command.amount)  # THIS IS WRONG! We'll fix this in the next section.\n\n    def has_sufficient_balance(self, amount: int) -&gt; bool:\n        return self.balance.is_atleast(amount)\n</code></pre> <ol> <li>Import the <code>handles_command</code> decorator</li> <li>Add a method to mutate the balance</li> <li>Decorate command handler methods with <code>@handles_command</code></li> </ol> <p>Wait, This Handler is Wrong!</p> <p>Look closely at line 20\u2014we're directly mutating <code>self.balance</code>.  This works for our test, but it breaks event sourcing.</p> <p>If we directly mutate state, we lose the history of what happened.  We can't replay events to rebuild state, we can't audit changes, and we can't  project events to other systems.</p> <p>In the next section, we'll fix this by introducing events.</p>"},{"location":"tutorial/02-commands-and-handlers/#command-handler-discovery","title":"Command Handler Discovery","text":"<p>Interlock discovers command handlers via the <code>@handles_command</code> decorator and type annotations. Common naming conventions (not required, but recommended):</p> Command Handler Method <code>CreateAccount</code> <code>handle_create_account</code> <code>DepositMoney</code> <code>handle_deposit_money</code>"},{"location":"tutorial/02-commands-and-handlers/#next-steps","title":"Next Steps","text":"<p>Our command handler works, but it's not event-sourced.  Let's fix this with events.</p>"},{"location":"tutorial/03-events-and-sourcing/","title":"Events &amp; Sourcing","text":"<p>In the previous section, we wrote a command handler that directly mutated state.  However, event sourcing is a key principle of Interlock and direct mutation is a violation of that principle. Instead, we rely on the capturing and application of events to record and update the state of the aggregate. That is the essence of event sourcing.</p>"},{"location":"tutorial/03-events-and-sourcing/#the-problem-with-direct-mutation","title":"The Problem with Direct Mutation","text":"<p>Here's what we wrote in the last section:</p> <pre><code>@handles_command\ndef handle_deposit_money(self, command: DepositMoney) -&gt; None:\n    self.balance.increase(command.amount)  # Direct mutation!\n</code></pre> <p>This has several weaknesses that we hope to address with an event sourced system:</p> <ol> <li>No history: We only know the current balance, not how we got there</li> <li>No auditability: We can't answer \"what happened to this account?\"</li> <li>No replay: We can't rebuild state from scratch</li> <li>No projections: We can't notify other systems about what happened</li> </ol>"},{"location":"tutorial/03-events-and-sourcing/#what-is-an-event","title":"What is an Event?","text":"<p>An event is an immutable record of something that happened. Events are:</p> <ul> <li>Conventionally named in past tense (e.g., <code>AccountCreated</code>, <code>MoneyDeposited</code>)</li> <li>Immutable\u2014once created, they never change (except for upcasting)</li> <li>Contain all the data needed to understand what happened over an aggregate's lifetime</li> <li>Are the source of truth for aggregate state and are the basis for projections and other derived data.</li> </ul>"},{"location":"tutorial/03-events-and-sourcing/#defining-events","title":"Defining Events","text":"<p>Events, like commands and aggregates, are pydantic models. In fact, they are literally pydantic models. There is no special event class that you need to inherit from.</p> <pre><code>from pydantic import BaseModel\n\nclass MoneyDeposited(BaseModel):\n    amount: int\n</code></pre> <p>Events don't need an aggregate_id</p> <p>Unlike commands, event payloads don't need to specify which aggregate they belong to. The framework wraps your event data in an <code>Event</code> object that includes the <code>aggregate_id</code>  and other metadata automatically. Event processors can access this via <code>Event[MoneyDeposited]</code>  type annotations if needed.</p>"},{"location":"tutorial/03-events-and-sourcing/#fixing-our-command-handler","title":"Fixing Our Command Handler","text":"<p>Instead of directly mutating state, command handlers should emit events:</p> <pre><code>@handles_command\ndef handle_deposit_money(self, command: DepositMoney) -&gt; None:\n    # Don't mutate directly\u2014emit an event instead!\n    self.emit(MoneyDeposited(amount=command.amount))\n</code></pre> <p>The <code>emit()</code> method does two things:</p> <ol> <li>Records the event (for persistence and projections)</li> <li>Applies the event to the aggregate. </li> </ol>"},{"location":"tutorial/03-events-and-sourcing/#event-handlers","title":"Event Handlers","text":"<p>Event handlers are where state actually changes. They're marked with the <code>@applies_event</code> decorator:</p> <pre><code>@applies_event\ndef apply_money_deposited(self, event: MoneyDeposited) -&gt; None:\n    self.balance.increase(event.amount)\n</code></pre>"},{"location":"tutorial/03-events-and-sourcing/#the-complete-fixed-aggregate","title":"The Complete Fixed Aggregate","text":"<p>Let's put it all together:</p> <pre><code>from pydantic import BaseModel, Field\nfrom interlock.domain import Aggregate\nfrom interlock.routing import handles_command, applies_event\n\nclass Balance(BaseModel):\n    amount: int = 0\n    currency: str = \"USD\"\n\n    def increase(self, amount: int) -&gt; None:\n        self.amount += amount\n\nclass MoneyDeposited(BaseModel):\n    amount: int\n\nclass BankAccount(Aggregate):\n    balance: Balance = Field(default_factory=Balance)\n    is_active: bool = True\n\n    def has_sufficient_balance(self, amount: int) -&gt; bool:\n        return self.balance.amount &gt;= amount\n\n    @handles_command\n    def handle_deposit_money(self, command: DepositMoney) -&gt; None:\n        event = MoneyDeposited(amount=command.amount)\n        self.emit(event)  # (2)!\n\n    @applies_event\n    def apply_money_deposited(self, event: MoneyDeposited) -&gt; None:  # (3)!\n        self.balance.increase(event.amount)\n</code></pre> <p>Ultimately handling commands and events forms the core of the aggregate pattern: 1. Define a command that represents the action that happened 2. Define the event that records what happened 3. Emit the event instead of mutating directly 4. Apply the event to the aggregate to update state</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Store as Event Store\n    participant Agg as BankAccount\n\n    App-&gt;&gt;Store: Load aggregate \"acc-123\"\n    Store-&gt;&gt;Agg: Create fresh BankAccount()\n    Note over Agg: balance = 0\n    Store-&gt;&gt;Agg: Replay MoneyDeposited(100)\n    Agg-&gt;&gt;Agg: apply_money_deposited()\n    Note over Agg: balance = 100\n    Store-&gt;&gt;Agg: Replay MoneyDeposited(50)\n    Agg-&gt;&gt;Agg: apply_money_deposited()\n    Note over Agg: balance = 150\n    Store-&gt;&gt;App: Return hydrated aggregate</code></pre> <p>We've now officially event sourced something!! </p>"},{"location":"tutorial/03-events-and-sourcing/#updating-our-test","title":"Updating Our Test","text":"<p>Interlock provides testing utilities that make it easy to write expressive,  behavior-driven tests. Let's use <code>AggregateScenario</code>:</p> <pre><code>from interlock.testing import AggregateScenario\n\nasync def test_deposit_money_emits_event():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given_no_events() \\\n            .when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=50)) \\\n            .should_emit(MoneyDeposited)  # (1)!\n</code></pre> <ol> <li>You can assert on the event type or an exact event instance</li> </ol> <p>The scenario automatically generates an <code>aggregate_id</code> accessible via <code>scenario.aggregate_id</code>.</p> <p>The scenario follows the Given-When-Then pattern:</p> <ul> <li>Given: The starting state (events that already happened)</li> <li>When: The command being tested</li> <li>Should: The expected outcome (events emitted, state changes, or errors)</li> </ul> <p>You can also assert on the resulting state:</p> <pre><code>async def test_deposit_money_updates_balance():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given_no_events() \\\n            .when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=50)) \\\n            .should_have_state(lambda acc: acc.balance.amount == 50)\n</code></pre> <p>Or test behavior that depends on prior events:</p> <pre><code>async def test_multiple_deposits():\n    async with AggregateScenario(BankAccount) as scenario:\n        scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .when(DepositMoney(aggregate_id=scenario.aggregate_id, amount=50)) \\\n            .should_emit(MoneyDeposited) \\\n            .should_have_state(lambda acc: acc.balance.amount == 150)\n</code></pre> <p>Given-When-Then</p> <p>This pattern maps naturally to event sourcing: \"given these events happened,  when this command is executed, then these events should be emitted.\"</p>"},{"location":"tutorial/03-events-and-sourcing/#next-steps","title":"Next Steps","text":"<p>Now that we understand events and sourcing, let's learn how to  react to events outside of the aggregate with Event Processors.</p>"},{"location":"tutorial/04-event-processors/","title":"Event Processors","text":"<p>Event processors react to events and perform side effects. Use them to build read models (projections), send notifications, or trigger workflows.</p>"},{"location":"tutorial/04-event-processors/#what-is-an-event-processor","title":"What is an Event Processor?","text":"<p>In CQRS, the read side is separate from the write side. Event processors subscribe to events and use them to:</p> <ul> <li>Build read-optimized projections of the data</li> <li>Send notifications to users</li> <li>Trigger external API calls to update other systems</li> <li>Start sagas/workflows for complex business processes</li> </ul>"},{"location":"tutorial/04-event-processors/#building-a-projection","title":"Building a Projection","text":"<p>Let's build a projection that tracks account balances for quick lookups. First, we'll define a repository interface and an in-memory implementation:</p> <pre><code>from abc import ABC, abstractmethod\nfrom uuid import UUID, uuid4\n\nclass AccountBalanceRepository(ABC):\n    \"\"\"Repository for account balance projections.\"\"\"\n\n    @abstractmethod\n    def get_balance(self, account_id: UUID) -&gt; int:\n        \"\"\"Get the current balance for an account.\"\"\"\n        ...\n\n    @abstractmethod\n    def set_balance(self, account_id: UUID, balance: int) -&gt; None:\n        \"\"\"Set the balance for an account.\"\"\"\n        ...\n\nclass InMemoryAccountBalanceRepository(AccountBalanceRepository):\n    \"\"\"In-memory implementation for testing and development.\"\"\"\n\n    def __init__(self):\n        self._balances: dict[UUID, int] = {}\n\n    def get_balance(self, account_id: UUID) -&gt; int:\n        return self._balances.get(account_id, 0)\n\n    def set_balance(self, account_id: UUID, balance: int) -&gt; None:\n        self._balances[account_id] = balance\n</code></pre> <p>This pattern lets you swap implementations\u2014use <code>InMemoryAccountBalanceRepository</code> for  tests and development, then switch to <code>PostgresAccountBalanceRepository</code> in production.</p>"},{"location":"tutorial/04-event-processors/#writing-tests-first","title":"Writing Tests First","text":"<p>Following TDD, let's write tests for our projection using <code>app.processor_scenario()</code>. First, we'll create a pytest fixture that builds the application with our test dependencies:</p> <pre><code>import pytest\nfrom interlock.application import ApplicationBuilder\n\n@pytest.fixture\ndef app():\n    return (\n        ApplicationBuilder()\n        .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n        .register_event_processor(AccountBalanceProjection)\n        .build()\n    )\n</code></pre> <p>Now our tests are clean and focused on behavior:</p> <pre><code>async def test_tracks_balance_after_deposit(app):\n    async with app.processor_scenario(AccountBalanceProjection) as scenario:  # (1)!\n        scenario \\\n            .given(MoneyDeposited(amount=100)) \\\n            .should_have_state(\n                lambda p: p.repository.get_balance(scenario.aggregate_id) == 100\n            )\n\nasync def test_accumulates_multiple_deposits(app):\n    async with app.processor_scenario(AccountBalanceProjection) as scenario:\n        scenario \\\n            .given(\n                MoneyDeposited(amount=100),\n                MoneyDeposited(amount=50),\n            ) \\\n            .should_have_state(\n                lambda p: p.repository.get_balance(scenario.aggregate_id) == 150\n            )\n</code></pre> <ol> <li>The processor is resolved from the DI container with all dependencies injected</li> </ol>"},{"location":"tutorial/04-event-processors/#implementing-the-projection","title":"Implementing the Projection","text":"<p>Now let's implement the processor to make our tests pass:</p> <pre><code>from interlock.application.events import EventProcessor\nfrom interlock.domain import Event\nfrom interlock.routing import handles_event\n\nclass AccountBalanceProjection(EventProcessor):\n    \"\"\"Projection that maintains account balances for quick lookups.\"\"\"\n\n    def __init__(self, repository: AccountBalanceRepository):\n        self.repository = repository\n\n    @handles_event\n    async def on_money_deposited(self, event: Event[MoneyDeposited]) -&gt; None:  # (1)!\n        current = self.repository.get_balance(event.aggregate_id)  # (2)!\n        self.repository.set_balance(\n            event.aggregate_id, \n            current + event.data.amount  # (3)!\n        )\n</code></pre> <ol> <li>Use <code>Event[MoneyDeposited]</code> to receive the full event wrapper with metadata</li> <li>Access <code>aggregate_id</code> from the event wrapper\u2014no need to duplicate it in the payload</li> <li>The actual event data is in <code>event.data</code></li> </ol>"},{"location":"tutorial/04-event-processors/#registering-event-processors","title":"Registering Event Processors","text":"<p>Register processors imperatively with the <code>ApplicationBuilder</code>:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(\n        AccountBalanceRepository,  # (1)!\n        InMemoryAccountBalanceRepository\n    )\n    .register_event_processor(AccountBalanceProjection)\n    .build()\n)\n</code></pre> <ol> <li>Register the interface with its concrete implementation\u2014swap to <code>PostgresAccountBalanceRepository</code> in production</li> </ol>"},{"location":"tutorial/04-event-processors/#projections-vs-side-effects","title":"Projections vs Side Effects","text":"<p>There are two main patterns for event processors:</p> Pattern Purpose Example Projection Build read models <code>AccountBalanceProjection</code> Side Effect External actions <code>EmailNotificationProcessor</code> <p>For side effects, you typically inject services:</p> <pre><code>class EmailNotificationProcessor(EventProcessor):\n    def __init__(self, email_service: EmailService):\n        self.email_service = email_service\n\n    @handles_event\n    async def on_money_deposited(self, event: MoneyDeposited) -&gt; None:\n        await self.email_service.send(\n            subject=\"Deposit Received\",\n            body=f\"You deposited ${event.amount}\"\n        )\n</code></pre>"},{"location":"tutorial/04-event-processors/#next-steps","title":"Next Steps","text":"<p>Learn how to serve typed queries from your projections in Queries &amp; Projections.</p>"},{"location":"tutorial/05-queries-and-projections/","title":"Queries &amp; Projections","text":"<p>In the previous section, we built an event processor that maintains a read model. Now let's add the ability to query that read model with typed queries.</p>"},{"location":"tutorial/05-queries-and-projections/#from-event-processor-to-projection","title":"From Event Processor to Projection","text":"<p>A Projection is an event processor that can also serve queries. It combines:</p> <ul> <li>Event handling: Updating state when events occur</li> <li>Query handling: Returning data in response to queries</li> </ul> <p>Let's upgrade our <code>AccountBalanceProjection</code> to serve queries.</p>"},{"location":"tutorial/05-queries-and-projections/#defining-queries","title":"Defining Queries","text":"<p>First, define query types. Queries are like commands but for reading data:</p> <pre><code>from interlock.domain import Query\nfrom uuid import UUID, uuid4\n\nclass GetAccountBalance(Query[int]):  # (1)!\n    account_id: UUID\n\nclass GetAccountByEmail(Query[UUID | None]):  # (2)!\n    email: str\n\nclass CountAccounts(Query[int]):\n    pass\n</code></pre> <ol> <li>Returns an <code>int</code> (the balance)</li> <li>Returns <code>UUID | None</code> (the account ID if found)</li> </ol> <p>The type parameter (<code>Query[int]</code>) specifies what the query returns, giving you  type safety and IDE autocomplete.</p>"},{"location":"tutorial/05-queries-and-projections/#writing-tests-first","title":"Writing Tests First","text":"<p>Let's test our projection's query capabilities using <code>ProjectionScenario</code>:</p> <pre><code>import pytest\nfrom interlock.testing import ProjectionScenario\n\n@pytest.fixture\ndef projection():\n    repository = InMemoryAccountBalanceRepository()\n    return AccountBalanceProjection(repository)\n\nasync def test_query_returns_balance(projection):\n    account_id = uuid4()\n\n    async with ProjectionScenario(projection) as scenario:\n        # Given: money was deposited\n        scenario.given(\n            MoneyDeposited(account_id=account_id, amount=100)\n        )\n\n        # When: we query the balance\n        balance = await scenario.when(\n            GetAccountBalance(account_id=account_id)\n        )\n\n        # Then: we get the correct balance\n        assert balance == 100\n\nasync def test_query_returns_zero_for_unknown_account(projection):\n    async with ProjectionScenario(projection) as scenario:\n        balance = await scenario.when(\n            GetAccountBalance(account_id=uuid4())\n        )\n        assert balance == 0\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#implementing-the-projection","title":"Implementing the Projection","text":"<p>Upgrade from <code>EventProcessor</code> to <code>Projection</code> and add query handlers:</p> <pre><code>from interlock.application import Projection\nfrom interlock.routing import handles_event, handles_query\n\nclass AccountBalanceProjection(Projection):  # (1)!\n    \"\"\"Projection that maintains account balances and serves queries.\"\"\"\n\n    def __init__(self, repository: AccountBalanceRepository):\n        super().__init__()\n        self.repository = repository\n\n    # Event handlers update state\n    @handles_event\n    async def on_money_deposited(self, event: MoneyDeposited) -&gt; None:\n        current = await self.repository.get_balance(event.account_id)\n        await self.repository.set_balance(\n            event.account_id, \n            current + event.amount\n        )\n\n    @handles_event\n    async def on_money_withdrawn(self, event: MoneyWithdrawn) -&gt; None:\n        current = await self.repository.get_balance(event.account_id)\n        await self.repository.set_balance(\n            event.account_id, \n            current - event.amount\n        )\n\n    # Query handlers return data\n    @handles_query  # (2)!\n    async def get_balance(self, query: GetAccountBalance) -&gt; int:\n        return await self.repository.get_balance(query.account_id)\n</code></pre> <ol> <li>Changed from <code>EventProcessor</code> to <code>Projection</code></li> <li><code>@handles_query</code> marks methods that handle specific query types</li> </ol>"},{"location":"tutorial/05-queries-and-projections/#registering-projections","title":"Registering Projections","text":"<p>Register projections with the <code>ApplicationBuilder</code>:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n    .register_projection(AccountBalanceProjection)  # (1)!\n    .build()\n)\n</code></pre> <ol> <li>Use <code>register_projection()</code> instead of <code>register_event_processor()</code></li> </ol>"},{"location":"tutorial/05-queries-and-projections/#dispatching-queries","title":"Dispatching Queries","text":"<p>Send queries through the application's <code>query()</code> method:</p> <pre><code>async def main():\n    async with app:\n        account_id = uuid4()\n\n        # Create account and deposit money\n        await app.dispatch(OpenAccount(\n            aggregate_id=account_id,\n            owner_name=\"Alice\"\n        ))\n        await app.dispatch(DepositMoney(\n            aggregate_id=account_id,\n            amount=1000\n        ))\n\n        # Query the balance\n        balance = await app.query(GetAccountBalance(account_id=account_id))\n        print(f\"Balance: ${balance}\")  # Balance: $1000\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#id-lookup-pattern","title":"ID Lookup Pattern","text":"<p>A common use case is looking up an aggregate ID by a natural key (like email). This lets external systems reference entities by human-readable identifiers.</p>"},{"location":"tutorial/05-queries-and-projections/#define-the-query","title":"Define the Query","text":"<pre><code>class GetAccountIdByEmail(Query[UUID | None]):\n    \"\"\"Find account aggregate ID by email address.\"\"\"\n    email: str\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#update-the-repository","title":"Update the Repository","text":"<pre><code>from abc import ABC, abstractmethod\n\nclass AccountLookupRepository(ABC):\n    @abstractmethod\n    async def save_mapping(self, email: str, account_id: UUID) -&gt; None:\n        ...\n\n    @abstractmethod\n    async def get_account_id(self, email: str) -&gt; UUID | None:\n        ...\n\nclass InMemoryAccountLookupRepository(AccountLookupRepository):\n    def __init__(self):\n        self.email_to_id: dict[str, UUID] = {}\n\n    async def save_mapping(self, email: str, account_id: UUID) -&gt; None:\n        self.email_to_id[email] = account_id\n\n    async def get_account_id(self, email: str) -&gt; UUID | None:\n        return self.email_to_id.get(email)\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#implement-the-projection","title":"Implement the Projection","text":"<pre><code>class AccountLookupProjection(Projection):\n    def __init__(self, repository: AccountLookupRepository):\n        super().__init__()\n        self.repository = repository\n\n    @handles_event\n    async def on_account_opened(self, event: AccountOpened) -&gt; None:\n        await self.repository.save_mapping(event.email, event.account_id)\n\n    @handles_query\n    async def lookup(self, query: GetAccountIdByEmail) -&gt; UUID | None:\n        return await self.repository.get_account_id(query.email)\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#use-the-lookup","title":"Use the Lookup","text":"<pre><code># Find account by email, then dispatch a command\naccount_id = await app.query(GetAccountIdByEmail(email=\"alice@example.com\"))\n\nif account_id:\n    await app.dispatch(DepositMoney(aggregate_id=account_id, amount=500))\nelse:\n    print(\"Account not found\")\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#queries-vs-commands","title":"Queries vs Commands","text":"Aspect Commands Queries Purpose Change state Read state Side effects Yes (events emitted) No Handler Aggregate Projection Return value Optional Required (typed) Idempotency May need handling Naturally idempotent"},{"location":"tutorial/05-queries-and-projections/#query-middleware","title":"Query Middleware","text":"<p>Middleware can intercept queries just like commands. This is useful for:</p> <ul> <li>Caching: Cache expensive query results</li> <li>Authorization: Check read permissions</li> <li>Logging: Track query patterns</li> </ul> <pre><code>from interlock.application.middleware import Middleware, Handler\nfrom interlock.routing import intercepts\n\nclass QueryLoggingMiddleware(Middleware):\n    @intercepts\n    async def log_query(self, query: Query, next: Handler):\n        print(f\"Query: {type(query).__name__}\")\n        result = await next(query)\n        print(f\"Result: {result}\")\n        return result\n</code></pre>"},{"location":"tutorial/05-queries-and-projections/#summary","title":"Summary","text":"Concept Description <code>Query[T]</code> Base class for queries with typed responses <code>Projection</code> Event processor that also serves queries <code>@handles_query</code> Decorator for query handler methods <code>app.query()</code> Dispatch a query and get the result <code>ProjectionScenario</code> Test utility for projections"},{"location":"tutorial/05-queries-and-projections/#next-steps","title":"Next Steps","text":"<p>Learn how to add cross-cutting concerns with Middleware.</p>"},{"location":"tutorial/06-middleware/","title":"Middleware","text":"<p>Middleware wraps command and query execution to add cross-cutting concerns like  logging, metrics, and error handling.</p> <p>Middleware intercepts messages before and/or after they're handled. Use middleware for:</p> <ul> <li>Logging and tracing</li> <li>Authentication and authorization</li> <li>Fraud detection</li> <li>Caching query results</li> <li>Rate limiting</li> <li>Performance monitoring</li> </ul>"},{"location":"tutorial/06-middleware/#creating-custom-middleware","title":"Creating Custom Middleware","text":"<p>Let's build a fraud detection middleware that checks transactions against a fraud service. First, we'll define a service interface and implementation:</p> <pre><code>from abc import ABC, abstractmethod\nimport random\n\nclass FraudService(ABC):\n    \"\"\"Service for detecting fraudulent transactions.\"\"\"\n\n    @abstractmethod\n    def is_fraudulent(self, amount: int) -&gt; bool:\n        \"\"\"Check if a transaction amount is suspicious.\"\"\"\n        ...\n\nclass RandomFraudService(FraudService):\n    \"\"\"A silly fraud service that randomly flags transactions.\"\"\"\n\n    def __init__(self, fraud_probability: float = 0.1):\n        self.fraud_probability = fraud_probability\n\n    def is_fraudulent(self, amount: int) -&gt; bool:\n        return random.random() &lt; self.fraud_probability\n</code></pre>"},{"location":"tutorial/06-middleware/#writing-tests-first","title":"Writing Tests First","text":"<p>Before implementing the middleware, let's write tests to define the expected behavior. We'll create a testable fraud service that we can control:</p> <pre><code>class StubFraudService(FraudService):\n    \"\"\"A controllable fraud service for testing.\"\"\"\n\n    def __init__(self, is_fraud: bool = False):\n        self._is_fraud = is_fraud\n\n    def is_fraudulent(self, amount: int) -&gt; bool:\n        return self._is_fraud\n</code></pre> <p>Now let's create a fixture that builds an app with the stub service:</p> <pre><code>import pytest\nfrom interlock.application import ApplicationBuilder\n\n@pytest.fixture\ndef app_with_fraud_detection():\n    \"\"\"Build an app that always flags transactions as fraudulent.\"\"\"\n    return (\n        ApplicationBuilder()\n        .register_aggregate(BankAccount)\n        .register_dependency(FraudService, lambda: StubFraudService(is_fraud=True))\n        .register_middleware(FraudDetectionMiddleware)\n        .build()\n    )\n\n@pytest.fixture\ndef app_without_fraud():\n    \"\"\"Build an app that never flags transactions.\"\"\"\n    return (\n        ApplicationBuilder()\n        .register_aggregate(BankAccount)\n        .register_dependency(FraudService, lambda: StubFraudService(is_fraud=False))\n        .register_middleware(FraudDetectionMiddleware)\n        .build()\n    )\n</code></pre> <p>Now we can test the middleware through the application:</p> <pre><code>async def test_middleware_blocks_fraudulent_deposits(app_with_fraud_detection):\n    async with app_with_fraud_detection:\n        with pytest.raises(FraudDetectedError):\n            await app_with_fraud_detection.dispatch(\n                DepositMoney(aggregate_id=uuid4(), amount=100)\n            )\n\nasync def test_middleware_allows_clean_deposits(app_without_fraud):\n    async with app_without_fraud:\n        # Should not raise - deposit goes through\n        await app_without_fraud.dispatch(\n            DepositMoney(aggregate_id=uuid4(), amount=100)\n        )\n</code></pre> <p>Testing with DI</p> <p>By swapping the <code>FraudService</code> implementation in the fixture, we can test different scenarios without changing our middleware code.</p>"},{"location":"tutorial/06-middleware/#implementing-the-middleware","title":"Implementing the Middleware","text":"<p>Now let's implement the middleware:</p> <pre><code>from interlock.application.middleware import Middleware, Handler\nfrom interlock.routing import intercepts\n\nclass FraudDetectionMiddleware(Middleware):\n    \"\"\"Check transactions against a fraud detection service.\"\"\"\n\n    def __init__(self, fraud_service: FraudService):  # (1)!\n        self.fraud_service = fraud_service\n\n    @intercepts  # (2)!\n    async def check_deposit(\n        self, \n        command: DepositMoney,  # (3)!\n        next: Handler\n    ):\n        if self.fraud_service.is_fraudulent(command.amount):\n            raise FraudDetectedError(\n                f\"Suspicious deposit of {command.amount} detected!\"\n            )\n        return await next(command)  # (4)!\n</code></pre> <ol> <li>The <code>FraudService</code> dependency is automatically injected by the DI container</li> <li>The <code>@intercepts</code> decorator marks this method as an interceptor</li> <li>Type annotation determines which messages this method intercepts</li> <li>Call <code>await next(command)</code> to pass control to the next handler; return the result</li> </ol> <p>Selective Interception</p> <p>Middleware methods only intercept messages matching their type annotation. To intercept all commands, annotate with the base <code>Command</code> type. To intercept all queries, annotate with <code>Query</code>.</p>"},{"location":"tutorial/06-middleware/#intercepting-both-commands-and-queries","title":"Intercepting Both Commands and Queries","text":"<p>The same middleware can intercept both commands and queries:</p> <pre><code>from interlock.domain import Command, Query\n\nclass LoggingMiddleware(Middleware):\n    @intercepts\n    async def log_command(self, command: Command, next: Handler):\n        print(f\"Command: {type(command).__name__}\")\n        return await next(command)\n\n    @intercepts\n    async def log_query(self, query: Query, next: Handler):\n        print(f\"Query: {type(query).__name__}\")\n        return await next(query)\n</code></pre> <p>Or intercept everything with a single method:</p> <pre><code>from pydantic import BaseModel\n\nclass UnifiedLoggingMiddleware(Middleware):\n    @intercepts\n    async def log_all(self, message: BaseModel, next: Handler):\n        print(f\"Message: {type(message).__name__}\")\n        return await next(message)\n</code></pre>"},{"location":"tutorial/06-middleware/#using-built-in-middleware","title":"Using Built-in Middleware","text":"<p>Interlock provides several built-in middleware. Let's use <code>LoggingMiddleware</code>:</p> <pre><code>from interlock.application.middleware import LoggingMiddleware\n</code></pre> <p><code>LoggingMiddleware</code> logs each command and query with correlation context for  distributed tracing. It takes a log level as a parameter:</p> <pre><code>LoggingMiddleware(\"INFO\")   # Log at INFO level\nLoggingMiddleware(\"DEBUG\")  # Log at DEBUG level\n</code></pre>"},{"location":"tutorial/06-middleware/#registering-middleware","title":"Registering Middleware","text":"<p>Register middleware and its dependencies with the <code>ApplicationBuilder</code>:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom interlock.application.middleware import LoggingMiddleware\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_projection(BalanceProjection)\n    .register_dependency(FraudService, RandomFraudService)  # (1)!\n    .register_middleware(LoggingMiddleware)\n    .register_middleware(FraudDetectionMiddleware)  # (2)!\n    .build()\n)\n</code></pre> <ol> <li>Register <code>RandomFraudService</code> as the implementation of <code>FraudService</code></li> <li>When <code>FraudDetectionMiddleware</code> is created, the container injects <code>FraudService</code> automatically</li> </ol> <p>This is the power of dependency injection\u2014your middleware doesn't need to know which  fraud service implementation it's using. You can easily swap <code>RandomFraudService</code> for  a real <code>MLFraudService</code> in production without changing the middleware code.</p> <p>Middleware Order</p> <p>Middleware executes in registration order. <code>LoggingMiddleware</code> runs first,  then <code>FraudDetectionMiddleware</code>, then the handler (aggregate or projection).</p>"},{"location":"tutorial/06-middleware/#the-middleware-chain","title":"The Middleware Chain","text":"<p>When a command or query is dispatched, it flows through the middleware chain:</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Log as LoggingMiddleware\n    participant Fraud as FraudDetectionMiddleware\n    participant Svc as FraudService\n    participant Agg as BankAccount\n\n    App-&gt;&gt;Log: dispatch(DepositMoney)\n    Log-&gt;&gt;Log: Log command\n    Log-&gt;&gt;Fraud: next(command)\n    Fraud-&gt;&gt;Svc: is_fraudulent(amount)\n    Svc--&gt;&gt;Fraud: true/false\n    alt Fraud detected\n        Fraud--&gt;&gt;App: raise FraudDetectedError\n    else Clean\n        Fraud-&gt;&gt;Agg: next(command)\n        Agg-&gt;&gt;Agg: Handle command\n        Agg--&gt;&gt;Fraud: return\n        Fraud--&gt;&gt;Log: return\n        Log--&gt;&gt;App: return\n    end</code></pre> <p>Queries follow the same pattern, but route to projections instead of aggregates.</p>"},{"location":"tutorial/06-middleware/#other-built-in-middleware","title":"Other Built-in Middleware","text":"Middleware Purpose <code>LoggingMiddleware</code> Log commands/queries with correlation context <code>IdempotencyMiddleware</code> Prevent duplicate command processing <code>ConcurrencyRetryMiddleware</code> Retry on optimistic concurrency conflicts <code>ContextPropagationMiddleware</code> Propagate correlation/causation IDs"},{"location":"tutorial/06-middleware/#next-steps","title":"Next Steps","text":"<p>Now let's learn about Structuring Your Application with conventions.</p>"},{"location":"tutorial/07-structuring-the-application/","title":"Structuring Your Application","text":"<p>So far, we've been building our application imperatively\u2014registering each aggregate,  projection, and middleware by hand. This works great for learning, but as your  application grows, it becomes tedious.</p> <p>Interlock provides a convention-based approach that automatically discovers  and registers components based on your project structure.</p>"},{"location":"tutorial/07-structuring-the-application/#the-imperative-approach-what-weve-done","title":"The Imperative Approach (What We've Done)","text":"<p>Up to this point, we've been explicit about every registration:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .register_aggregate(BankAccount)\n    .register_dependency(AccountBalanceRepository, InMemoryAccountBalanceRepository)\n    .register_dependency(FraudService, RandomFraudService)\n    .register_projection(AccountBalanceProjection)\n    .register_middleware(LoggingMiddleware)\n    .register_middleware(FraudDetectionMiddleware)\n    .build()\n)\n</code></pre> <p>This is explicit and testable, but it doesn't scale well.</p>"},{"location":"tutorial/07-structuring-the-application/#recommended-project-structure","title":"Recommended Project Structure","text":"<p>Interlock's conventions expect a specific project layout:</p> <pre><code>my_bank_app/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 aggregates/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 bank_account.py      # Contains BankAccount aggregate\n\u251c\u2500\u2500 events/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_events.py    # Contains MoneyDeposited, etc.\n\u251c\u2500\u2500 commands/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_commands.py  # Contains DepositMoney, etc.\n\u251c\u2500\u2500 queries/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_queries.py   # Contains GetAccountBalance, etc.\n\u251c\u2500\u2500 projections/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 balance_projection.py # Contains AccountBalanceProjection\n\u251c\u2500\u2500 middleware/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 fraud.py             # Contains FraudDetectionMiddleware\n\u2514\u2500\u2500 services/\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 fraud_service.py     # Contains FraudService implementations\n</code></pre>"},{"location":"tutorial/07-structuring-the-application/#the-convention-based-approach","title":"The Convention-Based Approach","text":"<p>With the right structure, you can use <code>convention_based()</code> to auto-discover components:</p> <pre><code>from interlock.application import ApplicationBuilder\n\napp = (\n    ApplicationBuilder()\n    .convention_based(\"my_bank_app\")  # (1)!\n    .build()\n)\n</code></pre> <ol> <li>Scans <code>my_bank_app</code> and all submodules for aggregates, projections, middleware, etc.</li> </ol> <p>The <code>convention_based()</code> method:</p> <ul> <li>Scans the package recursively</li> <li>Discovers classes that inherit from <code>Aggregate</code>, <code>Projection</code>, <code>Middleware</code>, etc.</li> <li>Registers them automatically with the builder</li> </ul>"},{"location":"tutorial/07-structuring-the-application/#how-discovery-works","title":"How Discovery Works","text":"<p>Interlock uses type introspection to find components:</p> Base Class Discovered From <code>Aggregate</code> Any module in the package <code>Projection</code> Any module in the package <code>EventProcessor</code> Any module in the package <code>Middleware</code> Any module in the package <code>EventUpcaster</code> Any module in the package"},{"location":"tutorial/07-structuring-the-application/#mixing-approaches","title":"Mixing Approaches","text":"<p>You can combine convention-based discovery with explicit registration:</p> <pre><code>app = (\n    ApplicationBuilder()\n    .convention_based(\"my_bank_app\")  # Auto-discover most things\n    .register_dependency(FraudService, MLFraudService)  # Override for production\n    .build()\n)\n</code></pre> <p>This is useful when you want conventions for most things but need explicit  control over certain dependencies (like swapping implementations for different environments).</p>"},{"location":"tutorial/07-structuring-the-application/#testing-with-conventions","title":"Testing with Conventions","text":"<p>For tests, you might want to use the imperative approach for isolation:</p> <pre><code># In tests, be explicit for control\ndef create_test_app():\n    return (\n        ApplicationBuilder()\n        .register_aggregate(BankAccount)\n        .register_projection(AccountBalanceProjection)\n        .register_dependency(FraudService, StubFraudService)\n        .build()\n    )\n</code></pre> <p>Or use conventions with test-specific overrides:</p> <pre><code>def create_test_app():\n    return (\n        ApplicationBuilder()\n        .convention_based(\"my_bank_app\")\n        .register_dependency(FraudService, StubFraudService)  # Test double\n        .build()\n    )\n</code></pre>"},{"location":"tutorial/07-structuring-the-application/#best-practices","title":"Best Practices","text":"<ol> <li>Start imperative: When learning or prototyping, explicit registration is clearer</li> <li>Migrate to conventions: As your app grows, switch to convention-based discovery</li> <li>Keep services explicit: Dependencies like database connections should be explicit</li> <li>Use overrides: Combine conventions with explicit registration for flexibility</li> </ol>"},{"location":"tutorial/07-structuring-the-application/#next-steps","title":"Next Steps","text":"<p>Finally, let's put everything together into a complete application.</p>"},{"location":"tutorial/08-putting-it-together/","title":"Putting It Together","text":"<p>Congratulations! You've learned the core concepts of Interlock.  Now let's see how everything fits together in a complete application.</p>"},{"location":"tutorial/08-putting-it-together/#complete-bank-account-example","title":"Complete Bank Account Example","text":"<p>Here's the full project structure following Interlock conventions:</p>"},{"location":"tutorial/08-putting-it-together/#project-structure","title":"Project Structure","text":"<pre><code>bank_app/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 aggregates/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 bank_account.py\n\u251c\u2500\u2500 events/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_events.py\n\u251c\u2500\u2500 commands/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_commands.py\n\u251c\u2500\u2500 queries/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 account_queries.py\n\u251c\u2500\u2500 projections/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 balance_projection.py\n\u251c\u2500\u2500 middleware/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 fraud_detection.py\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 fraud_service.py\n\u2514\u2500\u2500 main.py\n</code></pre>"},{"location":"tutorial/08-putting-it-together/#the-application","title":"The Application","text":"<p>Using the convention-based approach from the previous section:</p> <pre><code># main.py\nimport asyncio\nfrom uuid import UUID, uuid4\nfrom interlock.application import ApplicationBuilder\n\nfrom bank_app.commands.account_commands import OpenAccount, DepositMoney\nfrom bank_app.queries.account_queries import GetAccountBalance, GetAccountByEmail\nfrom bank_app.services.fraud_service import FraudService, MLFraudService\n\nasync def main():\n    app = (\n        ApplicationBuilder()\n        .convention_based(\"bank_app\")  # (1)!\n        .register_dependency(FraudService, MLFraudService)  # (2)!\n        .build()\n    )\n\n    async with app:\n        # Create an account\n        account_id = uuid4()\n        await app.dispatch(OpenAccount(\n            aggregate_id=account_id,\n            owner_name=\"Alice\",\n            email=\"alice@example.com\"\n        ))\n\n        # Make deposits\n        await app.dispatch(DepositMoney(\n            aggregate_id=account_id,\n            amount=1000\n        ))\n\n        # Query the balance\n        balance = await app.query(GetAccountBalance(account_id=account_id))\n        print(f\"Balance: ${balance}\")\n\n        # Look up by email\n        found_id = await app.query(GetAccountByEmail(email=\"alice@example.com\"))\n        print(f\"Found account: {found_id}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Auto-discovers all aggregates, projections, and middleware in <code>bank_app</code></li> <li>Explicitly registers the production fraud service implementation</li> </ol>"},{"location":"tutorial/08-putting-it-together/#running-event-processors","title":"Running Event Processors","text":"<p>For long-running projections, run processors separately:</p> <pre><code>from interlock.application import ApplicationBuilder\nfrom bank_app.projections.balance_projection import AccountBalanceProjection\n\nasync def run_processors():\n    app = (\n        ApplicationBuilder()\n        .convention_based(\"bank_app\")\n        .build()\n    )\n\n    async with app:\n        # Run processors until interrupted\n        await app.run_event_processors(\n            AccountBalanceProjection,\n        )\n</code></pre>"},{"location":"tutorial/08-putting-it-together/#the-complete-flow","title":"The Complete Flow","text":"<p>Here's how commands and queries flow through the system:</p> <pre><code>flowchart TD\n    subgraph \"Write Side\"\n        CMD[DepositMoney Command]\n        MW1[Middleware Chain]\n        AGG[BankAccount Aggregate]\n        EVT[MoneyDeposited Event]\n    end\n\n    subgraph \"Storage\"\n        STORE[(Event Store)]\n    end\n\n    subgraph \"Read Side\"\n        PROJ[BalanceProjection]\n        QRY[GetAccountBalance Query]\n        RES[Balance: $1000]\n    end\n\n    CMD --&gt; MW1\n    MW1 --&gt; AGG\n    AGG --&gt; EVT\n    EVT --&gt; STORE\n    STORE --&gt; PROJ\n    QRY --&gt; MW1\n    MW1 --&gt; PROJ\n    PROJ --&gt; RES</code></pre>"},{"location":"tutorial/08-putting-it-together/#recap-what-weve-learned","title":"Recap: What We've Learned","text":"Section Concept Aggregates Domain objects that encapsulate state Commands Messages that express intent to change Events Immutable records of what happened Event Processors Build read models from events Queries &amp; Projections Serve typed queries from read models Middleware Cross-cutting concerns via interception Structure Convention-based organization"},{"location":"tutorial/08-putting-it-together/#whats-next","title":"What's Next?","text":"<p>You now have a solid foundation in Interlock! Continue your learning:</p> <ul> <li> <p> Concepts</p> <p>Deep dive into CQRS and Event Sourcing theory</p> <p> Concepts</p> </li> <li> <p> Guides</p> <p>Task-focused how-to guides for specific features</p> <p> Guides</p> </li> <li> <p> API Reference</p> <p>Complete API documentation</p> <p> Reference</p> </li> </ul>"}]}